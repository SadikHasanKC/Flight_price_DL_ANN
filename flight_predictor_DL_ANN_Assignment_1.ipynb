{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SadikHasanKC/Flight_price_DL_ANN/blob/main/flight_predictor_DL_ANN_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgVYfH3YFILJ"
      },
      "source": [
        "Group members: Frederik Kaminski Klitte, Patrick Riber Sørensen, Emmanouil Tzevelekos, Sadik Hasan Khan Chowdhury\n",
        "\n",
        "Flight Price DL ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkVWihP-FILM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730c34ec-1faf-48c3-d74e-4642ac33fc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.16.0-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.8.1 (from gradio)\n",
            "  Downloading gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.7-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.1.7 (from gradio)\n",
            "  Downloading ruff-0.2.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.16.2 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->gradio)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=adc2b11a018b999f8dd20b3e7c187354656b7837351c2731941da6fe32a067ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.14\n",
            "    Uninstalling pydantic-1.10.14:\n",
            "      Successfully uninstalled pydantic-1.10.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.109.2 ffmpy-0.3.1 gradio-4.16.0 gradio-client-0.8.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 orjson-3.9.13 pydantic-2.6.1 pydantic-core-2.16.2 pydub-0.25.1 python-multipart-0.0.7 ruff-0.2.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 typing-extensions-4.9.0 uvicorn-0.27.0.post1 websockets-11.0.3\n",
            "Collecting shap\n",
            "  Downloading shap-0.44.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (535 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.7/535.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.1 slicer-0.0.7\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install gradio\n",
        "!pip install shap\n",
        "!pip install imblearn\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8PW6Bl0FILO"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from tqdm import tqdm_notebook\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import torch\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "TY6MNLIIFILO"
      },
      "outputs": [],
      "source": [
        "# Reading in the dataset from the csv file\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/SadikHasanKC/Flight_price_DL_ANN/main/Clean_Dataset.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0KdPz_d8ix-",
        "outputId": "8acf5fda-bfd0-4ef4-b7c3-6fc53a6da3e3"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300153, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.iloc[:20000]"
      ],
      "metadata": {
        "id": "AfvrjazR8qBN"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX2oRzVI8xPR",
        "outputId": "8dac2471-4e11-465f-ab6d-fec71fd92858"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "QBTzuIh_FILP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b1f75677-d035-4976-e004-8aa22c8192e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    airline   flight source_city departure_time stops   arrival_time  \\\n",
              "0  SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
              "1  SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
              "2   AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
              "3   Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
              "4   Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
              "\n",
              "  destination_city    class  duration  days_left  price  \n",
              "0           Mumbai  Economy      2.17          1   5953  \n",
              "1           Mumbai  Economy      2.33          1   5953  \n",
              "2           Mumbai  Economy      2.17          1   5956  \n",
              "3           Mumbai  Economy      2.25          1   5955  \n",
              "4           Mumbai  Economy      2.33          1   5955  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fd3cba0-917e-4892-b501-30e16ef4e6a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>flight</th>\n",
              "      <th>source_city</th>\n",
              "      <th>departure_time</th>\n",
              "      <th>stops</th>\n",
              "      <th>arrival_time</th>\n",
              "      <th>destination_city</th>\n",
              "      <th>class</th>\n",
              "      <th>duration</th>\n",
              "      <th>days_left</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SpiceJet</td>\n",
              "      <td>SG-8709</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>Evening</td>\n",
              "      <td>zero</td>\n",
              "      <td>Night</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.17</td>\n",
              "      <td>1</td>\n",
              "      <td>5953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SpiceJet</td>\n",
              "      <td>SG-8157</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>Early_Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Morning</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.33</td>\n",
              "      <td>1</td>\n",
              "      <td>5953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AirAsia</td>\n",
              "      <td>I5-764</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>Early_Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Early_Morning</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.17</td>\n",
              "      <td>1</td>\n",
              "      <td>5956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>UK-995</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1</td>\n",
              "      <td>5955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>UK-963</td>\n",
              "      <td>Delhi</td>\n",
              "      <td>Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Morning</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.33</td>\n",
              "      <td>1</td>\n",
              "      <td>5955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fd3cba0-917e-4892-b501-30e16ef4e6a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fd3cba0-917e-4892-b501-30e16ef4e6a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fd3cba0-917e-4892-b501-30e16ef4e6a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14673dc1-b4d5-45d8-ac95-16581fd7ce3f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14673dc1-b4d5-45d8-ac95-16581fd7ce3f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14673dc1-b4d5-45d8-ac95-16581fd7ce3f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "nLWsC3YeFILQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcd5b32-9b21-458e-bf32-0d23dd01b42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 20000 entries, 0 to 19999\n",
            "Data columns (total 11 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   airline           20000 non-null  object \n",
            " 1   flight            20000 non-null  object \n",
            " 2   source_city       20000 non-null  object \n",
            " 3   departure_time    20000 non-null  object \n",
            " 4   stops             20000 non-null  object \n",
            " 5   arrival_time      20000 non-null  object \n",
            " 6   destination_city  20000 non-null  object \n",
            " 7   class             20000 non-null  object \n",
            " 8   duration          20000 non-null  float64\n",
            " 9   days_left         20000 non-null  int64  \n",
            " 10  price             20000 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(8)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "6N-CgqosFILQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "e77c7e12-14fd-4261-f0f9-2565135371d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           duration     days_left         price\n",
              "count  20000.000000  20000.000000  20000.000000\n",
              "mean       9.744345     25.849950   6125.027950\n",
              "std        6.711598     13.553019   3647.292391\n",
              "min        2.000000      1.000000   2281.000000\n",
              "25%        4.920000     14.000000   3855.000000\n",
              "50%        8.170000     26.000000   4896.000000\n",
              "75%       12.580000     38.000000   7424.000000\n",
              "max       36.920000     49.000000  31917.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46f33f89-48da-4f03-b70d-7b8841cb852d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>days_left</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "      <td>20000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.744345</td>\n",
              "      <td>25.849950</td>\n",
              "      <td>6125.027950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.711598</td>\n",
              "      <td>13.553019</td>\n",
              "      <td>3647.292391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2281.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.920000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3855.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.170000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>4896.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.580000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>7424.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>36.920000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>31917.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46f33f89-48da-4f03-b70d-7b8841cb852d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46f33f89-48da-4f03-b70d-7b8841cb852d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46f33f89-48da-4f03-b70d-7b8841cb852d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb7798bb-8298-43a0-8bf1-2e3d580c469f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb7798bb-8298-43a0-8bf1-2e3d580c469f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb7798bb-8298-43a0-8bf1-2e3d580c469f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "vt5zKqzdFILR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff8734e-d85c-4aee-d019-f0ed85c44573"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "airline             0\n",
              "flight              0\n",
              "source_city         0\n",
              "departure_time      0\n",
              "stops               0\n",
              "arrival_time        0\n",
              "destination_city    0\n",
              "class               0\n",
              "duration            0\n",
              "days_left           0\n",
              "price               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "T9tPzg29FILV"
      },
      "outputs": [],
      "source": [
        "y= data['price']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named 'data'\n",
        "columns_to_select = ['airline', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class', 'duration', 'days_left']\n",
        "x = data[columns_to_select]\n"
      ],
      "metadata": {
        "id": "2-tbKJZhQ4uw"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "5EKtyE6rQAGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "788edd07-b9aa-407e-f210-b9ecbd028482"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        airline departure_time stops   arrival_time destination_city    class  \\\n",
              "0      SpiceJet        Evening  zero          Night           Mumbai  Economy   \n",
              "1      SpiceJet  Early_Morning  zero        Morning           Mumbai  Economy   \n",
              "2       AirAsia  Early_Morning  zero  Early_Morning           Mumbai  Economy   \n",
              "3       Vistara        Morning  zero      Afternoon           Mumbai  Economy   \n",
              "4       Vistara        Morning  zero        Morning           Mumbai  Economy   \n",
              "...         ...            ...   ...            ...              ...      ...   \n",
              "19995   Vistara        Morning   one        Evening        Bangalore  Economy   \n",
              "19996   Vistara      Afternoon   one        Evening        Bangalore  Economy   \n",
              "19997   Vistara      Afternoon   one          Night        Bangalore  Economy   \n",
              "19998   Vistara      Afternoon   one          Night        Bangalore  Economy   \n",
              "19999   Vistara        Morning   one        Evening        Bangalore  Economy   \n",
              "\n",
              "       duration  days_left  \n",
              "0          2.17          1  \n",
              "1          2.33          1  \n",
              "2          2.17          1  \n",
              "3          2.25          1  \n",
              "4          2.33          1  \n",
              "...         ...        ...  \n",
              "19995      6.08         49  \n",
              "19996      6.42         49  \n",
              "19997      6.58         49  \n",
              "19998      7.33         49  \n",
              "19999      7.42         49  \n",
              "\n",
              "[20000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73c4d8a7-d308-4981-b806-27efcb33e32d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>departure_time</th>\n",
              "      <th>stops</th>\n",
              "      <th>arrival_time</th>\n",
              "      <th>destination_city</th>\n",
              "      <th>class</th>\n",
              "      <th>duration</th>\n",
              "      <th>days_left</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SpiceJet</td>\n",
              "      <td>Evening</td>\n",
              "      <td>zero</td>\n",
              "      <td>Night</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SpiceJet</td>\n",
              "      <td>Early_Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Morning</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AirAsia</td>\n",
              "      <td>Early_Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Early_Morning</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>Morning</td>\n",
              "      <td>zero</td>\n",
              "      <td>Morning</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Economy</td>\n",
              "      <td>2.33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>Morning</td>\n",
              "      <td>one</td>\n",
              "      <td>Evening</td>\n",
              "      <td>Bangalore</td>\n",
              "      <td>Economy</td>\n",
              "      <td>6.08</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>one</td>\n",
              "      <td>Evening</td>\n",
              "      <td>Bangalore</td>\n",
              "      <td>Economy</td>\n",
              "      <td>6.42</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>one</td>\n",
              "      <td>Night</td>\n",
              "      <td>Bangalore</td>\n",
              "      <td>Economy</td>\n",
              "      <td>6.58</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>one</td>\n",
              "      <td>Night</td>\n",
              "      <td>Bangalore</td>\n",
              "      <td>Economy</td>\n",
              "      <td>7.33</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>Vistara</td>\n",
              "      <td>Morning</td>\n",
              "      <td>one</td>\n",
              "      <td>Evening</td>\n",
              "      <td>Bangalore</td>\n",
              "      <td>Economy</td>\n",
              "      <td>7.42</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73c4d8a7-d308-4981-b806-27efcb33e32d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73c4d8a7-d308-4981-b806-27efcb33e32d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73c4d8a7-d308-4981-b806-27efcb33e32d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e01f77db-8759-4a3d-95b1-99e5461e20fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e01f77db-8759-4a3d-95b1-99e5461e20fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e01f77db-8759-4a3d-95b1-99e5461e20fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "93rAadgdQuxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47984225-529e-4fd9-e6c6-fbecc5ea4f92"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        5953\n",
              "1        5953\n",
              "2        5956\n",
              "3        5955\n",
              "4        5955\n",
              "         ... \n",
              "19995    4496\n",
              "19996    4496\n",
              "19997    4496\n",
              "19998    4496\n",
              "19999    4496\n",
              "Name: price, Length: 20000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'x' is your DataFrame\n",
        "columns_to_encode = ['airline', 'departure_time', 'stops', 'arrival_time', 'destination_city', 'class']\n",
        "\n",
        "# Extract the columns to be one-hot encoded\n",
        "data_to_encode = x[columns_to_encode]\n",
        "\n",
        "# Create an instance of OneHotEncoder\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "\n",
        "# Fit and transform the data\n",
        "encoded_data = encoder.fit_transform(data_to_encode)\n",
        "\n",
        "# Create a DataFrame with the encoded data\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(columns_to_encode))\n",
        "\n",
        "# Concatenate the original DataFrame with the encoded DataFrame\n",
        "x_encoded = pd.concat([x, encoded_df], axis=1)\n",
        "\n",
        "# Drop the original columns that have been encoded\n",
        "x_encoded = x_encoded.drop(columns=columns_to_encode)\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(x_encoded)\n"
      ],
      "metadata": {
        "id": "xjpx3W8aSMpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3813bae-d3f8-42f8-8ed7-7b143db3887f"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       duration  days_left  airline_Air_India  airline_GO_FIRST  \\\n",
            "0          2.17          1                0.0               0.0   \n",
            "1          2.33          1                0.0               0.0   \n",
            "2          2.17          1                0.0               0.0   \n",
            "3          2.25          1                0.0               0.0   \n",
            "4          2.33          1                0.0               0.0   \n",
            "...         ...        ...                ...               ...   \n",
            "19995      6.08         49                0.0               0.0   \n",
            "19996      6.42         49                0.0               0.0   \n",
            "19997      6.58         49                0.0               0.0   \n",
            "19998      7.33         49                0.0               0.0   \n",
            "19999      7.42         49                0.0               0.0   \n",
            "\n",
            "       airline_Indigo  airline_SpiceJet  airline_Vistara  \\\n",
            "0                 0.0               1.0              0.0   \n",
            "1                 0.0               1.0              0.0   \n",
            "2                 0.0               0.0              0.0   \n",
            "3                 0.0               0.0              1.0   \n",
            "4                 0.0               0.0              1.0   \n",
            "...               ...               ...              ...   \n",
            "19995             0.0               0.0              1.0   \n",
            "19996             0.0               0.0              1.0   \n",
            "19997             0.0               0.0              1.0   \n",
            "19998             0.0               0.0              1.0   \n",
            "19999             0.0               0.0              1.0   \n",
            "\n",
            "       departure_time_Early_Morning  departure_time_Evening  \\\n",
            "0                               0.0                     1.0   \n",
            "1                               1.0                     0.0   \n",
            "2                               1.0                     0.0   \n",
            "3                               0.0                     0.0   \n",
            "4                               0.0                     0.0   \n",
            "...                             ...                     ...   \n",
            "19995                           0.0                     0.0   \n",
            "19996                           0.0                     0.0   \n",
            "19997                           0.0                     0.0   \n",
            "19998                           0.0                     0.0   \n",
            "19999                           0.0                     0.0   \n",
            "\n",
            "       departure_time_Late_Night  departure_time_Morning  \\\n",
            "0                            0.0                     0.0   \n",
            "1                            0.0                     0.0   \n",
            "2                            0.0                     0.0   \n",
            "3                            0.0                     1.0   \n",
            "4                            0.0                     1.0   \n",
            "...                          ...                     ...   \n",
            "19995                        0.0                     1.0   \n",
            "19996                        0.0                     0.0   \n",
            "19997                        0.0                     0.0   \n",
            "19998                        0.0                     0.0   \n",
            "19999                        0.0                     1.0   \n",
            "\n",
            "       departure_time_Night  stops_two_or_more  stops_zero  \\\n",
            "0                       0.0                0.0         1.0   \n",
            "1                       0.0                0.0         1.0   \n",
            "2                       0.0                0.0         1.0   \n",
            "3                       0.0                0.0         1.0   \n",
            "4                       0.0                0.0         1.0   \n",
            "...                     ...                ...         ...   \n",
            "19995                   0.0                0.0         0.0   \n",
            "19996                   0.0                0.0         0.0   \n",
            "19997                   0.0                0.0         0.0   \n",
            "19998                   0.0                0.0         0.0   \n",
            "19999                   0.0                0.0         0.0   \n",
            "\n",
            "       arrival_time_Early_Morning  arrival_time_Evening  \\\n",
            "0                             0.0                   0.0   \n",
            "1                             0.0                   0.0   \n",
            "2                             1.0                   0.0   \n",
            "3                             0.0                   0.0   \n",
            "4                             0.0                   0.0   \n",
            "...                           ...                   ...   \n",
            "19995                         0.0                   1.0   \n",
            "19996                         0.0                   1.0   \n",
            "19997                         0.0                   0.0   \n",
            "19998                         0.0                   0.0   \n",
            "19999                         0.0                   1.0   \n",
            "\n",
            "       arrival_time_Late_Night  arrival_time_Morning  arrival_time_Night  \\\n",
            "0                          0.0                   0.0                 1.0   \n",
            "1                          0.0                   1.0                 0.0   \n",
            "2                          0.0                   0.0                 0.0   \n",
            "3                          0.0                   0.0                 0.0   \n",
            "4                          0.0                   1.0                 0.0   \n",
            "...                        ...                   ...                 ...   \n",
            "19995                      0.0                   0.0                 0.0   \n",
            "19996                      0.0                   0.0                 0.0   \n",
            "19997                      0.0                   0.0                 1.0   \n",
            "19998                      0.0                   0.0                 1.0   \n",
            "19999                      0.0                   0.0                 0.0   \n",
            "\n",
            "       destination_city_Mumbai  \n",
            "0                          1.0  \n",
            "1                          1.0  \n",
            "2                          1.0  \n",
            "3                          1.0  \n",
            "4                          1.0  \n",
            "...                        ...  \n",
            "19995                      0.0  \n",
            "19996                      0.0  \n",
            "19997                      0.0  \n",
            "19998                      0.0  \n",
            "19999                      0.0  \n",
            "\n",
            "[20000 rows x 20 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'y' is your target variable\n",
        "\n",
        "# Drop the target variable from the features\n",
        "X = x_encoded  # Replace 'price' with the actual column name for your target variable\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the resulting sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "v2AozzYpShHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13551807-76da-4d76-9273-cd74bdfa7a87"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (16000, 20)\n",
            "X_test shape: (4000, 20)\n",
            "y_train shape: (16000,)\n",
            "y_test shape: (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "YoQI1LRRSuAW"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert y_train and y_test to NumPy arrays\n",
        "y_train_array = y_train.to_numpy()\n",
        "y_test_array = y_test.to_numpy()\n",
        "\n",
        "# Initialize StandardScaler for y\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "# Fit and transform y_train\n",
        "y_train = scaler_y.fit_transform(y_train_array.reshape(-1, 1))\n",
        "\n",
        "# Transform y_test\n",
        "y_test = scaler_y.transform(y_test_array.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "4tiOEExBr9tt"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "sqLLO1W4cc0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e46591-3bfb-4485-ca57-37d694719894"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.39676776,  0.30690846, -0.53504863, ..., -0.47949739,\n",
              "         1.48604902,  1.00388254],\n",
              "       [ 0.08612414, -0.42919338,  1.86898901, ...,  2.08551708,\n",
              "        -0.67292531,  1.00388254],\n",
              "       [-0.13674904,  1.33745103, -0.53504863, ..., -0.47949739,\n",
              "        -0.67292531,  1.00388254],\n",
              "       ...,\n",
              "       [-0.06245798,  0.15968809, -0.53504863, ..., -0.47949739,\n",
              "        -0.67292531,  1.00388254],\n",
              "       [ 0.39666078, -1.45973595, -0.53504863, ...,  2.08551708,\n",
              "        -0.67292531,  1.00388254],\n",
              "       [ 0.18567417,  0.30690846, -0.53504863, ...,  2.08551708,\n",
              "        -0.67292531, -0.99613248]])"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "hlar-EWtcf5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0eaa2f4-47f3-440a-8a6b-12bb2d883f7b"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.22462512],\n",
              "       [-0.16906323],\n",
              "       [ 0.87946126],\n",
              "       ...,\n",
              "       [-0.77281749],\n",
              "       [ 1.65320192],\n",
              "       [-0.82865445]])"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X_train to PyTorch tensor\n",
        "tensor_data_X = torch.tensor(X_train, dtype=torch.float32)\n",
        "\n",
        "# Convert y_train to PyTorch tensor\n",
        "tensor_data_Y = torch.tensor(y_train, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "jcKNHqLF4396"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data_X[0]"
      ],
      "metadata": {
        "id": "xECJ8Yv1_PQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3de3693-2183-4b93-b4f0-ca822dc53920"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3968,  0.3069, -0.5350,  2.3260, -0.4655, -0.2428, -0.6252, -0.5056,\n",
              "        -0.5807, -0.0986, -0.5418, -0.3390, -0.1670, -0.5133, -0.2261, -0.5506,\n",
              "        -0.2646, -0.4795,  1.4860,  1.0039])"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data_Y[0]"
      ],
      "metadata": {
        "id": "-Cu-WB9T_Qaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2901e9fa-25ee-476d-87b5-1a9f1722e358"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2246])"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data_X.reshape(-1, 1).shape"
      ],
      "metadata": {
        "id": "cXBoc96e_adD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb1b5b6-d1e2-4967-9843-d317a98126da"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([320000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting our initial training model with these hyperparameters\n",
        "epochs = 3\n",
        "learning_rate = 2\n",
        "input_size = 20\n",
        "Neurons = 50\n",
        "activation_input = 50\n",
        "activation function = relu\n",
        "output = 1"
      ],
      "metadata": {
        "id": "0CpD22RaHLLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm_notebook\n",
        "# Initializing Hyperparameters\n",
        "epochs = 3\n",
        "learning_rate = 2\n",
        "\n",
        "\n",
        "# Initializing Parameters\n",
        "w = 50\n",
        "\n",
        "loss_set = {}\n",
        "\n",
        "# 1. Creating a FeedForwardNetwork\n",
        "# 1.1 Structure (Architecture) of NN\n",
        "model_net1 = torch.nn.Sequential(torch.nn.Linear(20,50),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(0.33),\n",
        "\n",
        "                                 torch.nn.Linear(50,1),\n",
        "                                 torch.nn.ReLU(),\n",
        "\n",
        "                                 );\n",
        "\n",
        "# 1.2 Loss Function\n",
        "loss_mse = torch.nn.MSELoss()\n",
        "\n",
        "# 1.3 Optmization Approch\n",
        "optimizer = torch.optim.SGD(model_net1.parameters(), lr=learning_rate)\n",
        "\n",
        "w_his = []\n",
        "w_his.append(w)\n",
        "# Loop over the number of epochs\n",
        "for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over each sample in the dataset\n",
        "    for i in range(tensor_data_X.size(0)):\n",
        "\n",
        "      # 2. Forward Pass\n",
        "      output = model_net1.forward(tensor_data_X[i].reshape(-1))\n",
        "\n",
        "      # 3. FeedForward Evaluation\n",
        "      loss = loss_mse(output, tensor_data_Y[i].reshape(-1))\n",
        "      optimizer.zero_grad();\n",
        "\n",
        "      # 4. Backward Pass / Gradient Calculation\n",
        "      loss.backward()\n",
        "\n",
        "      # Store the loss for each epoch\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # 5. Back Propagation / Update Weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store the weight value for each sample of data\n",
        "      w_his.append(float(model_net1[0].weight.data[0][0]))\n",
        "\n",
        "      # Display the loss for the current sample\n",
        "      print(f\"Epoch {epoch+1}, Sample {i+1}: Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # Calculate and display average loss for the epoch\n",
        "    epoch_loss /= tensor_data_X.size(0)\n",
        "\n",
        "    # Store the loss for each sample of data\n",
        "    loss_set[epoch] = epoch_loss\n",
        "    print(f\"\\nEpoch {epoch+1} Average Loss: {epoch_loss:.4f}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "id": "QCRfKjqA94Z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0a8a6e372d6946e8a16b5960b6b5bbf5",
            "871bd571f88d43d2a7b6b5e45e0a6c46",
            "137bfb6bf42140bdb7c594c4520ad3dd",
            "29523d1116e34f378f954933b068771d",
            "4f23741247c946bbb23b6ce0a3da6a1a",
            "e320ff06c3de4833a92246d4eed758a7",
            "f4e5e3df39b64046837bb22e0e7dbc2b",
            "18b4dc6b0f3b40d0a74ff23253991fa4",
            "4f5080e77ffd4806a655a9ceaa4b718a",
            "569fa31e08954f00811d2d47a8e62230",
            "734a43fea25b43a1a9b1589932d5857a"
          ]
        },
        "outputId": "d0e87ed7-4607-4d39-ffc4-498dd73b16ab"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-278-89c1555ae612>:34: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a8a6e372d6946e8a16b5960b6b5bbf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 11005: Loss: 0.2832\n",
            "Epoch 3, Sample 11006: Loss: 1.5597\n",
            "Epoch 3, Sample 11007: Loss: 2.6384\n",
            "Epoch 3, Sample 11008: Loss: 0.7036\n",
            "Epoch 3, Sample 11009: Loss: 0.0864\n",
            "Epoch 3, Sample 11010: Loss: 0.0008\n",
            "Epoch 3, Sample 11011: Loss: 0.0026\n",
            "Epoch 3, Sample 11012: Loss: 0.7453\n",
            "Epoch 3, Sample 11013: Loss: 0.1246\n",
            "Epoch 3, Sample 11014: Loss: 0.2032\n",
            "Epoch 3, Sample 11015: Loss: 1.4884\n",
            "Epoch 3, Sample 11016: Loss: 0.3399\n",
            "Epoch 3, Sample 11017: Loss: 0.2339\n",
            "Epoch 3, Sample 11018: Loss: 2.7925\n",
            "Epoch 3, Sample 11019: Loss: 0.0505\n",
            "Epoch 3, Sample 11020: Loss: 0.1170\n",
            "Epoch 3, Sample 11021: Loss: 0.4663\n",
            "Epoch 3, Sample 11022: Loss: 1.6418\n",
            "Epoch 3, Sample 11023: Loss: 0.2750\n",
            "Epoch 3, Sample 11024: Loss: 0.9367\n",
            "Epoch 3, Sample 11025: Loss: 0.0025\n",
            "Epoch 3, Sample 11026: Loss: 1.1265\n",
            "Epoch 3, Sample 11027: Loss: 1.0155\n",
            "Epoch 3, Sample 11028: Loss: 0.7036\n",
            "Epoch 3, Sample 11029: Loss: 0.5871\n",
            "Epoch 3, Sample 11030: Loss: 0.0212\n",
            "Epoch 3, Sample 11031: Loss: 0.0505\n",
            "Epoch 3, Sample 11032: Loss: 1.0524\n",
            "Epoch 3, Sample 11033: Loss: 1.5597\n",
            "Epoch 3, Sample 11034: Loss: 0.1838\n",
            "Epoch 3, Sample 11035: Loss: 0.0189\n",
            "Epoch 3, Sample 11036: Loss: 0.0117\n",
            "Epoch 3, Sample 11037: Loss: 0.2098\n",
            "Epoch 3, Sample 11038: Loss: 0.3399\n",
            "Epoch 3, Sample 11039: Loss: 1.0155\n",
            "Epoch 3, Sample 11040: Loss: 1.0524\n",
            "Epoch 3, Sample 11041: Loss: 0.0391\n",
            "Epoch 3, Sample 11042: Loss: 0.6304\n",
            "Epoch 3, Sample 11043: Loss: 0.0287\n",
            "Epoch 3, Sample 11044: Loss: 0.2639\n",
            "Epoch 3, Sample 11045: Loss: 0.0630\n",
            "Epoch 3, Sample 11046: Loss: 0.3441\n",
            "Epoch 3, Sample 11047: Loss: 2.7331\n",
            "Epoch 3, Sample 11048: Loss: 0.9367\n",
            "Epoch 3, Sample 11049: Loss: 0.2759\n",
            "Epoch 3, Sample 11050: Loss: 0.0084\n",
            "Epoch 3, Sample 11051: Loss: 0.0001\n",
            "Epoch 3, Sample 11052: Loss: 0.0026\n",
            "Epoch 3, Sample 11053: Loss: 0.2032\n",
            "Epoch 3, Sample 11054: Loss: 0.0554\n",
            "Epoch 3, Sample 11055: Loss: 0.1248\n",
            "Epoch 3, Sample 11056: Loss: 0.0018\n",
            "Epoch 3, Sample 11057: Loss: 0.1248\n",
            "Epoch 3, Sample 11058: Loss: 13.5048\n",
            "Epoch 3, Sample 11059: Loss: 0.5972\n",
            "Epoch 3, Sample 11060: Loss: 0.0625\n",
            "Epoch 3, Sample 11061: Loss: 0.0207\n",
            "Epoch 3, Sample 11062: Loss: 0.0234\n",
            "Epoch 3, Sample 11063: Loss: 0.2044\n",
            "Epoch 3, Sample 11064: Loss: 0.9017\n",
            "Epoch 3, Sample 11065: Loss: 0.7036\n",
            "Epoch 3, Sample 11066: Loss: 1.5597\n",
            "Epoch 3, Sample 11067: Loss: 3.5504\n",
            "Epoch 3, Sample 11068: Loss: 1.0530\n",
            "Epoch 3, Sample 11069: Loss: 0.7036\n",
            "Epoch 3, Sample 11070: Loss: 0.2639\n",
            "Epoch 3, Sample 11071: Loss: 0.7036\n",
            "Epoch 3, Sample 11072: Loss: 0.5858\n",
            "Epoch 3, Sample 11073: Loss: 1.5597\n",
            "Epoch 3, Sample 11074: Loss: 2.7331\n",
            "Epoch 3, Sample 11075: Loss: 0.0026\n",
            "Epoch 3, Sample 11076: Loss: 3.9991\n",
            "Epoch 3, Sample 11077: Loss: 0.4367\n",
            "Epoch 3, Sample 11078: Loss: 0.2412\n",
            "Epoch 3, Sample 11079: Loss: 0.3399\n",
            "Epoch 3, Sample 11080: Loss: 1.5597\n",
            "Epoch 3, Sample 11081: Loss: 0.0145\n",
            "Epoch 3, Sample 11082: Loss: 0.0026\n",
            "Epoch 3, Sample 11083: Loss: 0.2639\n",
            "Epoch 3, Sample 11084: Loss: 0.0205\n",
            "Epoch 3, Sample 11085: Loss: 1.0524\n",
            "Epoch 3, Sample 11086: Loss: 0.3399\n",
            "Epoch 3, Sample 11087: Loss: 0.1559\n",
            "Epoch 3, Sample 11088: Loss: 1.0155\n",
            "Epoch 3, Sample 11089: Loss: 0.0022\n",
            "Epoch 3, Sample 11090: Loss: 0.0630\n",
            "Epoch 3, Sample 11091: Loss: 0.2044\n",
            "Epoch 3, Sample 11092: Loss: 0.0018\n",
            "Epoch 3, Sample 11093: Loss: 6.2039\n",
            "Epoch 3, Sample 11094: Loss: 0.0026\n",
            "Epoch 3, Sample 11095: Loss: 1.0524\n",
            "Epoch 3, Sample 11096: Loss: 0.2340\n",
            "Epoch 3, Sample 11097: Loss: 0.5078\n",
            "Epoch 3, Sample 11098: Loss: 0.0108\n",
            "Epoch 3, Sample 11099: Loss: 0.2295\n",
            "Epoch 3, Sample 11100: Loss: 0.2044\n",
            "Epoch 3, Sample 11101: Loss: 0.1170\n",
            "Epoch 3, Sample 11102: Loss: 0.2036\n",
            "Epoch 3, Sample 11103: Loss: 0.5858\n",
            "Epoch 3, Sample 11104: Loss: 0.2034\n",
            "Epoch 3, Sample 11105: Loss: 1.1263\n",
            "Epoch 3, Sample 11106: Loss: 0.2032\n",
            "Epoch 3, Sample 11107: Loss: 2.0225\n",
            "Epoch 3, Sample 11108: Loss: 0.0630\n",
            "Epoch 3, Sample 11109: Loss: 0.2340\n",
            "Epoch 3, Sample 11110: Loss: 1.0524\n",
            "Epoch 3, Sample 11111: Loss: 0.2032\n",
            "Epoch 3, Sample 11112: Loss: 2.6384\n",
            "Epoch 3, Sample 11113: Loss: 1.0524\n",
            "Epoch 3, Sample 11114: Loss: 1.0155\n",
            "Epoch 3, Sample 11115: Loss: 0.1250\n",
            "Epoch 3, Sample 11116: Loss: 0.4607\n",
            "Epoch 3, Sample 11117: Loss: 1.0524\n",
            "Epoch 3, Sample 11118: Loss: 0.0034\n",
            "Epoch 3, Sample 11119: Loss: 1.0524\n",
            "Epoch 3, Sample 11120: Loss: 0.7036\n",
            "Epoch 3, Sample 11121: Loss: 0.2044\n",
            "Epoch 3, Sample 11122: Loss: 0.1170\n",
            "Epoch 3, Sample 11123: Loss: 0.5278\n",
            "Epoch 3, Sample 11124: Loss: 0.2759\n",
            "Epoch 3, Sample 11125: Loss: 0.0630\n",
            "Epoch 3, Sample 11126: Loss: 0.7036\n",
            "Epoch 3, Sample 11127: Loss: 8.0504\n",
            "Epoch 3, Sample 11128: Loss: 0.4930\n",
            "Epoch 3, Sample 11129: Loss: 0.9367\n",
            "Epoch 3, Sample 11130: Loss: 5.3707\n",
            "Epoch 3, Sample 11131: Loss: 0.1250\n",
            "Epoch 3, Sample 11132: Loss: 1.0524\n",
            "Epoch 3, Sample 11133: Loss: 1.8616\n",
            "Epoch 3, Sample 11134: Loss: 0.0460\n",
            "Epoch 3, Sample 11135: Loss: 0.2036\n",
            "Epoch 3, Sample 11136: Loss: 0.0018\n",
            "Epoch 3, Sample 11137: Loss: 2.5104\n",
            "Epoch 3, Sample 11138: Loss: 1.8616\n",
            "Epoch 3, Sample 11139: Loss: 0.0001\n",
            "Epoch 3, Sample 11140: Loss: 0.0006\n",
            "Epoch 3, Sample 11141: Loss: 0.2759\n",
            "Epoch 3, Sample 11142: Loss: 0.4611\n",
            "Epoch 3, Sample 11143: Loss: 0.2032\n",
            "Epoch 3, Sample 11144: Loss: 0.2219\n",
            "Epoch 3, Sample 11145: Loss: 0.7036\n",
            "Epoch 3, Sample 11146: Loss: 0.0062\n",
            "Epoch 3, Sample 11147: Loss: 6.2547\n",
            "Epoch 3, Sample 11148: Loss: 0.0501\n",
            "Epoch 3, Sample 11149: Loss: 0.7036\n",
            "Epoch 3, Sample 11150: Loss: 0.4535\n",
            "Epoch 3, Sample 11151: Loss: 0.2036\n",
            "Epoch 3, Sample 11152: Loss: 2.7331\n",
            "Epoch 3, Sample 11153: Loss: 0.6990\n",
            "Epoch 3, Sample 11154: Loss: 0.0802\n",
            "Epoch 3, Sample 11155: Loss: 0.1250\n",
            "Epoch 3, Sample 11156: Loss: 0.6304\n",
            "Epoch 3, Sample 11157: Loss: 0.9785\n",
            "Epoch 3, Sample 11158: Loss: 0.8951\n",
            "Epoch 3, Sample 11159: Loss: 0.2044\n",
            "Epoch 3, Sample 11160: Loss: 0.0915\n",
            "Epoch 3, Sample 11161: Loss: 0.0026\n",
            "Epoch 3, Sample 11162: Loss: 0.0026\n",
            "Epoch 3, Sample 11163: Loss: 0.2112\n",
            "Epoch 3, Sample 11164: Loss: 2.9274\n",
            "Epoch 3, Sample 11165: Loss: 0.0144\n",
            "Epoch 3, Sample 11166: Loss: 0.2032\n",
            "Epoch 3, Sample 11167: Loss: 0.7036\n",
            "Epoch 3, Sample 11168: Loss: 0.3873\n",
            "Epoch 3, Sample 11169: Loss: 6.2547\n",
            "Epoch 3, Sample 11170: Loss: 1.5542\n",
            "Epoch 3, Sample 11171: Loss: 1.0530\n",
            "Epoch 3, Sample 11172: Loss: 0.0026\n",
            "Epoch 3, Sample 11173: Loss: 0.2036\n",
            "Epoch 3, Sample 11174: Loss: 0.1523\n",
            "Epoch 3, Sample 11175: Loss: 0.2759\n",
            "Epoch 3, Sample 11176: Loss: 0.0637\n",
            "Epoch 3, Sample 11177: Loss: 0.0026\n",
            "Epoch 3, Sample 11178: Loss: 0.8951\n",
            "Epoch 3, Sample 11179: Loss: 0.1616\n",
            "Epoch 3, Sample 11180: Loss: 0.5000\n",
            "Epoch 3, Sample 11181: Loss: 0.6190\n",
            "Epoch 3, Sample 11182: Loss: 1.0155\n",
            "Epoch 3, Sample 11183: Loss: 2.7331\n",
            "Epoch 3, Sample 11184: Loss: 1.0524\n",
            "Epoch 3, Sample 11185: Loss: 2.1055\n",
            "Epoch 3, Sample 11186: Loss: 0.4611\n",
            "Epoch 3, Sample 11187: Loss: 6.7927\n",
            "Epoch 3, Sample 11188: Loss: 0.2032\n",
            "Epoch 3, Sample 11189: Loss: 1.0155\n",
            "Epoch 3, Sample 11190: Loss: 0.0475\n",
            "Epoch 3, Sample 11191: Loss: 0.3399\n",
            "Epoch 3, Sample 11192: Loss: 0.7036\n",
            "Epoch 3, Sample 11193: Loss: 0.2639\n",
            "Epoch 3, Sample 11194: Loss: 0.2034\n",
            "Epoch 3, Sample 11195: Loss: 0.7036\n",
            "Epoch 3, Sample 11196: Loss: 0.2036\n",
            "Epoch 3, Sample 11197: Loss: 1.0524\n",
            "Epoch 3, Sample 11198: Loss: 0.0626\n",
            "Epoch 3, Sample 11199: Loss: 1.0530\n",
            "Epoch 3, Sample 11200: Loss: 2.6384\n",
            "Epoch 3, Sample 11201: Loss: 0.2639\n",
            "Epoch 3, Sample 11202: Loss: 0.0027\n",
            "Epoch 3, Sample 11203: Loss: 0.2034\n",
            "Epoch 3, Sample 11204: Loss: 0.0083\n",
            "Epoch 3, Sample 11205: Loss: 0.4611\n",
            "Epoch 3, Sample 11206: Loss: 1.0524\n",
            "Epoch 3, Sample 11207: Loss: 1.0524\n",
            "Epoch 3, Sample 11208: Loss: 1.0956\n",
            "Epoch 3, Sample 11209: Loss: 0.0630\n",
            "Epoch 3, Sample 11210: Loss: 0.0026\n",
            "Epoch 3, Sample 11211: Loss: 0.2044\n",
            "Epoch 3, Sample 11212: Loss: 0.2832\n",
            "Epoch 3, Sample 11213: Loss: 0.3441\n",
            "Epoch 3, Sample 11214: Loss: 0.4996\n",
            "Epoch 3, Sample 11215: Loss: 0.5375\n",
            "Epoch 3, Sample 11216: Loss: 0.0460\n",
            "Epoch 3, Sample 11217: Loss: 3.5504\n",
            "Epoch 3, Sample 11218: Loss: 0.1250\n",
            "Epoch 3, Sample 11219: Loss: 1.0524\n",
            "Epoch 3, Sample 11220: Loss: 0.0027\n",
            "Epoch 3, Sample 11221: Loss: 0.0108\n",
            "Epoch 3, Sample 11222: Loss: 1.0155\n",
            "Epoch 3, Sample 11223: Loss: 0.0026\n",
            "Epoch 3, Sample 11224: Loss: 0.1170\n",
            "Epoch 3, Sample 11225: Loss: 0.0018\n",
            "Epoch 3, Sample 11226: Loss: 0.2034\n",
            "Epoch 3, Sample 11227: Loss: 0.2340\n",
            "Epoch 3, Sample 11228: Loss: 2.0108\n",
            "Epoch 3, Sample 11229: Loss: 0.1225\n",
            "Epoch 3, Sample 11230: Loss: 0.1674\n",
            "Epoch 3, Sample 11231: Loss: 1.0155\n",
            "Epoch 3, Sample 11232: Loss: 0.3402\n",
            "Epoch 3, Sample 11233: Loss: 0.2340\n",
            "Epoch 3, Sample 11234: Loss: 0.0026\n",
            "Epoch 3, Sample 11235: Loss: 0.1463\n",
            "Epoch 3, Sample 11236: Loss: 0.8951\n",
            "Epoch 3, Sample 11237: Loss: 0.2044\n",
            "Epoch 3, Sample 11238: Loss: 0.4032\n",
            "Epoch 3, Sample 11239: Loss: 0.8584\n",
            "Epoch 3, Sample 11240: Loss: 0.4032\n",
            "Epoch 3, Sample 11241: Loss: 0.0234\n",
            "Epoch 3, Sample 11242: Loss: 0.6990\n",
            "Epoch 3, Sample 11243: Loss: 0.0363\n",
            "Epoch 3, Sample 11244: Loss: 2.4095\n",
            "Epoch 3, Sample 11245: Loss: 0.0625\n",
            "Epoch 3, Sample 11246: Loss: 1.0359\n",
            "Epoch 3, Sample 11247: Loss: 0.1546\n",
            "Epoch 3, Sample 11248: Loss: 0.3907\n",
            "Epoch 3, Sample 11249: Loss: 0.2098\n",
            "Epoch 3, Sample 11250: Loss: 1.0155\n",
            "Epoch 3, Sample 11251: Loss: 0.0915\n",
            "Epoch 3, Sample 11252: Loss: 0.9367\n",
            "Epoch 3, Sample 11253: Loss: 0.0026\n",
            "Epoch 3, Sample 11254: Loss: 0.1559\n",
            "Epoch 3, Sample 11255: Loss: 0.3399\n",
            "Epoch 3, Sample 11256: Loss: 0.3402\n",
            "Epoch 3, Sample 11257: Loss: 0.1250\n",
            "Epoch 3, Sample 11258: Loss: 1.4884\n",
            "Epoch 3, Sample 11259: Loss: 0.6990\n",
            "Epoch 3, Sample 11260: Loss: 1.0524\n",
            "Epoch 3, Sample 11261: Loss: 1.2192\n",
            "Epoch 3, Sample 11262: Loss: 0.0026\n",
            "Epoch 3, Sample 11263: Loss: 0.0391\n",
            "Epoch 3, Sample 11264: Loss: 0.3441\n",
            "Epoch 3, Sample 11265: Loss: 0.8951\n",
            "Epoch 3, Sample 11266: Loss: 5.1063\n",
            "Epoch 3, Sample 11267: Loss: 0.0001\n",
            "Epoch 3, Sample 11268: Loss: 0.2759\n",
            "Epoch 3, Sample 11269: Loss: 0.6304\n",
            "Epoch 3, Sample 11270: Loss: 0.2759\n",
            "Epoch 3, Sample 11271: Loss: 0.2034\n",
            "Epoch 3, Sample 11272: Loss: 0.5858\n",
            "Epoch 3, Sample 11273: Loss: 0.0018\n",
            "Epoch 3, Sample 11274: Loss: 0.3399\n",
            "Epoch 3, Sample 11275: Loss: 1.0266\n",
            "Epoch 3, Sample 11276: Loss: 0.0475\n",
            "Epoch 3, Sample 11277: Loss: 0.0915\n",
            "Epoch 3, Sample 11278: Loss: 0.2044\n",
            "Epoch 3, Sample 11279: Loss: 0.7036\n",
            "Epoch 3, Sample 11280: Loss: 0.3399\n",
            "Epoch 3, Sample 11281: Loss: 2.2434\n",
            "Epoch 3, Sample 11282: Loss: 0.0070\n",
            "Epoch 3, Sample 11283: Loss: 1.0359\n",
            "Epoch 3, Sample 11284: Loss: 0.0018\n",
            "Epoch 3, Sample 11285: Loss: 0.4930\n",
            "Epoch 3, Sample 11286: Loss: 1.4884\n",
            "Epoch 3, Sample 11287: Loss: 2.7331\n",
            "Epoch 3, Sample 11288: Loss: 0.4032\n",
            "Epoch 3, Sample 11289: Loss: 0.2759\n",
            "Epoch 3, Sample 11290: Loss: 0.1335\n",
            "Epoch 3, Sample 11291: Loss: 0.4032\n",
            "Epoch 3, Sample 11292: Loss: 4.4745\n",
            "Epoch 3, Sample 11293: Loss: 0.5871\n",
            "Epoch 3, Sample 11294: Loss: 0.3399\n",
            "Epoch 3, Sample 11295: Loss: 1.5597\n",
            "Epoch 3, Sample 11296: Loss: 0.0630\n",
            "Epoch 3, Sample 11297: Loss: 0.4032\n",
            "Epoch 3, Sample 11298: Loss: 0.2044\n",
            "Epoch 3, Sample 11299: Loss: 0.4867\n",
            "Epoch 3, Sample 11300: Loss: 1.8616\n",
            "Epoch 3, Sample 11301: Loss: 0.4607\n",
            "Epoch 3, Sample 11302: Loss: 0.2044\n",
            "Epoch 3, Sample 11303: Loss: 0.1559\n",
            "Epoch 3, Sample 11304: Loss: 0.2659\n",
            "Epoch 3, Sample 11305: Loss: 13.7179\n",
            "Epoch 3, Sample 11306: Loss: 0.0212\n",
            "Epoch 3, Sample 11307: Loss: 1.0359\n",
            "Epoch 3, Sample 11308: Loss: 2.7331\n",
            "Epoch 3, Sample 11309: Loss: 0.6990\n",
            "Epoch 3, Sample 11310: Loss: 1.5597\n",
            "Epoch 3, Sample 11311: Loss: 1.0359\n",
            "Epoch 3, Sample 11312: Loss: 0.0212\n",
            "Epoch 3, Sample 11313: Loss: 0.2182\n",
            "Epoch 3, Sample 11314: Loss: 0.3399\n",
            "Epoch 3, Sample 11315: Loss: 0.3399\n",
            "Epoch 3, Sample 11316: Loss: 0.0915\n",
            "Epoch 3, Sample 11317: Loss: 0.7036\n",
            "Epoch 3, Sample 11318: Loss: 0.0576\n",
            "Epoch 3, Sample 11319: Loss: 0.4611\n",
            "Epoch 3, Sample 11320: Loss: 0.6092\n",
            "Epoch 3, Sample 11321: Loss: 0.1523\n",
            "Epoch 3, Sample 11322: Loss: 0.3949\n",
            "Epoch 3, Sample 11323: Loss: 0.2738\n",
            "Epoch 3, Sample 11324: Loss: 0.9367\n",
            "Epoch 3, Sample 11325: Loss: 0.1040\n",
            "Epoch 3, Sample 11326: Loss: 1.0524\n",
            "Epoch 3, Sample 11327: Loss: 0.3949\n",
            "Epoch 3, Sample 11328: Loss: 0.1264\n",
            "Epoch 3, Sample 11329: Loss: 0.0013\n",
            "Epoch 3, Sample 11330: Loss: 0.2044\n",
            "Epoch 3, Sample 11331: Loss: 0.0455\n",
            "Epoch 3, Sample 11332: Loss: 0.3399\n",
            "Epoch 3, Sample 11333: Loss: 1.5597\n",
            "Epoch 3, Sample 11334: Loss: 0.0501\n",
            "Epoch 3, Sample 11335: Loss: 3.8747\n",
            "Epoch 3, Sample 11336: Loss: 0.5799\n",
            "Epoch 3, Sample 11337: Loss: 0.2729\n",
            "Epoch 3, Sample 11338: Loss: 0.4761\n",
            "Epoch 3, Sample 11339: Loss: 0.0466\n",
            "Epoch 3, Sample 11340: Loss: 0.3332\n",
            "Epoch 3, Sample 11341: Loss: 0.2044\n",
            "Epoch 3, Sample 11342: Loss: 0.7036\n",
            "Epoch 3, Sample 11343: Loss: 0.2079\n",
            "Epoch 3, Sample 11344: Loss: 0.1250\n",
            "Epoch 3, Sample 11345: Loss: 0.2014\n",
            "Epoch 3, Sample 11346: Loss: 17.3544\n",
            "Epoch 3, Sample 11347: Loss: 0.2832\n",
            "Epoch 3, Sample 11348: Loss: 0.5019\n",
            "Epoch 3, Sample 11349: Loss: 2.0225\n",
            "Epoch 3, Sample 11350: Loss: 0.3399\n",
            "Epoch 3, Sample 11351: Loss: 0.0026\n",
            "Epoch 3, Sample 11352: Loss: 0.9651\n",
            "Epoch 3, Sample 11353: Loss: 0.8951\n",
            "Epoch 3, Sample 11354: Loss: 0.3367\n",
            "Epoch 3, Sample 11355: Loss: 0.1248\n",
            "Epoch 3, Sample 11356: Loss: 4.9766\n",
            "Epoch 3, Sample 11357: Loss: 0.5972\n",
            "Epoch 3, Sample 11358: Loss: 0.2044\n",
            "Epoch 3, Sample 11359: Loss: 0.1627\n",
            "Epoch 3, Sample 11360: Loss: 1.5597\n",
            "Epoch 3, Sample 11361: Loss: 0.1225\n",
            "Epoch 3, Sample 11362: Loss: 0.3805\n",
            "Epoch 3, Sample 11363: Loss: 0.0026\n",
            "Epoch 3, Sample 11364: Loss: 0.0068\n",
            "Epoch 3, Sample 11365: Loss: 0.5858\n",
            "Epoch 3, Sample 11366: Loss: 0.2034\n",
            "Epoch 3, Sample 11367: Loss: 0.4032\n",
            "Epoch 3, Sample 11368: Loss: 0.5858\n",
            "Epoch 3, Sample 11369: Loss: 1.5597\n",
            "Epoch 3, Sample 11370: Loss: 0.1250\n",
            "Epoch 3, Sample 11371: Loss: 0.0161\n",
            "Epoch 3, Sample 11372: Loss: 0.0144\n",
            "Epoch 3, Sample 11373: Loss: 0.0001\n",
            "Epoch 3, Sample 11374: Loss: 1.0524\n",
            "Epoch 3, Sample 11375: Loss: 0.2759\n",
            "Epoch 3, Sample 11376: Loss: 0.2084\n",
            "Epoch 3, Sample 11377: Loss: 2.4541\n",
            "Epoch 3, Sample 11378: Loss: 1.5597\n",
            "Epoch 3, Sample 11379: Loss: 0.2962\n",
            "Epoch 3, Sample 11380: Loss: 0.0460\n",
            "Epoch 3, Sample 11381: Loss: 1.0524\n",
            "Epoch 3, Sample 11382: Loss: 0.0838\n",
            "Epoch 3, Sample 11383: Loss: 0.7036\n",
            "Epoch 3, Sample 11384: Loss: 10.8862\n",
            "Epoch 3, Sample 11385: Loss: 0.2079\n",
            "Epoch 3, Sample 11386: Loss: 0.1250\n",
            "Epoch 3, Sample 11387: Loss: 0.0834\n",
            "Epoch 3, Sample 11388: Loss: 0.0972\n",
            "Epoch 3, Sample 11389: Loss: 0.9007\n",
            "Epoch 3, Sample 11390: Loss: 0.5871\n",
            "Epoch 3, Sample 11391: Loss: 1.0266\n",
            "Epoch 3, Sample 11392: Loss: 0.6099\n",
            "Epoch 3, Sample 11393: Loss: 0.0700\n",
            "Epoch 3, Sample 11394: Loss: 0.3441\n",
            "Epoch 3, Sample 11395: Loss: 4.9766\n",
            "Epoch 3, Sample 11396: Loss: 1.0524\n",
            "Epoch 3, Sample 11397: Loss: 0.0567\n",
            "Epoch 3, Sample 11398: Loss: 4.1748\n",
            "Epoch 3, Sample 11399: Loss: 0.4792\n",
            "Epoch 3, Sample 11400: Loss: 0.1219\n",
            "Epoch 3, Sample 11401: Loss: 0.2044\n",
            "Epoch 3, Sample 11402: Loss: 0.0026\n",
            "Epoch 3, Sample 11403: Loss: 0.0626\n",
            "Epoch 3, Sample 11404: Loss: 0.2759\n",
            "Epoch 3, Sample 11405: Loss: 1.0524\n",
            "Epoch 3, Sample 11406: Loss: 1.0524\n",
            "Epoch 3, Sample 11407: Loss: 1.0155\n",
            "Epoch 3, Sample 11408: Loss: 1.8616\n",
            "Epoch 3, Sample 11409: Loss: 0.0018\n",
            "Epoch 3, Sample 11410: Loss: 0.0018\n",
            "Epoch 3, Sample 11411: Loss: 0.2044\n",
            "Epoch 3, Sample 11412: Loss: 0.8951\n",
            "Epoch 3, Sample 11413: Loss: 0.0101\n",
            "Epoch 3, Sample 11414: Loss: 0.2832\n",
            "Epoch 3, Sample 11415: Loss: 0.0777\n",
            "Epoch 3, Sample 11416: Loss: 0.3402\n",
            "Epoch 3, Sample 11417: Loss: 3.9991\n",
            "Epoch 3, Sample 11418: Loss: 0.0001\n",
            "Epoch 3, Sample 11419: Loss: 0.2044\n",
            "Epoch 3, Sample 11420: Loss: 0.9024\n",
            "Epoch 3, Sample 11421: Loss: 0.7453\n",
            "Epoch 3, Sample 11422: Loss: 0.2759\n",
            "Epoch 3, Sample 11423: Loss: 0.7036\n",
            "Epoch 3, Sample 11424: Loss: 0.0286\n",
            "Epoch 3, Sample 11425: Loss: 0.2034\n",
            "Epoch 3, Sample 11426: Loss: 0.2044\n",
            "Epoch 3, Sample 11427: Loss: 0.5858\n",
            "Epoch 3, Sample 11428: Loss: 1.0524\n",
            "Epoch 3, Sample 11429: Loss: 0.0018\n",
            "Epoch 3, Sample 11430: Loss: 0.5871\n",
            "Epoch 3, Sample 11431: Loss: 0.9780\n",
            "Epoch 3, Sample 11432: Loss: 0.2044\n",
            "Epoch 3, Sample 11433: Loss: 0.0026\n",
            "Epoch 3, Sample 11434: Loss: 0.1463\n",
            "Epoch 3, Sample 11435: Loss: 0.0838\n",
            "Epoch 3, Sample 11436: Loss: 0.6304\n",
            "Epoch 3, Sample 11437: Loss: 5.3707\n",
            "Epoch 3, Sample 11438: Loss: 0.2044\n",
            "Epoch 3, Sample 11439: Loss: 0.0640\n",
            "Epoch 3, Sample 11440: Loss: 0.8625\n",
            "Epoch 3, Sample 11441: Loss: 2.5922\n",
            "Epoch 3, Sample 11442: Loss: 0.0026\n",
            "Epoch 3, Sample 11443: Loss: 1.0956\n",
            "Epoch 3, Sample 11444: Loss: 1.0524\n",
            "Epoch 3, Sample 11445: Loss: 3.5504\n",
            "Epoch 3, Sample 11446: Loss: 0.3441\n",
            "Epoch 3, Sample 11447: Loss: 0.8951\n",
            "Epoch 3, Sample 11448: Loss: 0.5078\n",
            "Epoch 3, Sample 11449: Loss: 1.0524\n",
            "Epoch 3, Sample 11450: Loss: 0.9780\n",
            "Epoch 3, Sample 11451: Loss: 1.0658\n",
            "Epoch 3, Sample 11452: Loss: 0.2340\n",
            "Epoch 3, Sample 11453: Loss: 0.2832\n",
            "Epoch 3, Sample 11454: Loss: 15.4828\n",
            "Epoch 3, Sample 11455: Loss: 0.0018\n",
            "Epoch 3, Sample 11456: Loss: 1.5597\n",
            "Epoch 3, Sample 11457: Loss: 0.1210\n",
            "Epoch 3, Sample 11458: Loss: 1.0155\n",
            "Epoch 3, Sample 11459: Loss: 0.3949\n",
            "Epoch 3, Sample 11460: Loss: 0.4644\n",
            "Epoch 3, Sample 11461: Loss: 0.8484\n",
            "Epoch 3, Sample 11462: Loss: 0.1170\n",
            "Epoch 3, Sample 11463: Loss: 0.9367\n",
            "Epoch 3, Sample 11464: Loss: 0.2032\n",
            "Epoch 3, Sample 11465: Loss: 0.0022\n",
            "Epoch 3, Sample 11466: Loss: 9.5046\n",
            "Epoch 3, Sample 11467: Loss: 1.0956\n",
            "Epoch 3, Sample 11468: Loss: 0.0001\n",
            "Epoch 3, Sample 11469: Loss: 0.2639\n",
            "Epoch 3, Sample 11470: Loss: 0.5858\n",
            "Epoch 3, Sample 11471: Loss: 1.0530\n",
            "Epoch 3, Sample 11472: Loss: 0.5972\n",
            "Epoch 3, Sample 11473: Loss: 0.0142\n",
            "Epoch 3, Sample 11474: Loss: 3.1802\n",
            "Epoch 3, Sample 11475: Loss: 0.1246\n",
            "Epoch 3, Sample 11476: Loss: 0.0630\n",
            "Epoch 3, Sample 11477: Loss: 0.8951\n",
            "Epoch 3, Sample 11478: Loss: 0.7036\n",
            "Epoch 3, Sample 11479: Loss: 0.0108\n",
            "Epoch 3, Sample 11480: Loss: 0.0625\n",
            "Epoch 3, Sample 11481: Loss: 0.3441\n",
            "Epoch 3, Sample 11482: Loss: 0.0063\n",
            "Epoch 3, Sample 11483: Loss: 16.4053\n",
            "Epoch 3, Sample 11484: Loss: 0.2759\n",
            "Epoch 3, Sample 11485: Loss: 0.5972\n",
            "Epoch 3, Sample 11486: Loss: 2.7687\n",
            "Epoch 3, Sample 11487: Loss: 0.0466\n",
            "Epoch 3, Sample 11488: Loss: 0.0026\n",
            "Epoch 3, Sample 11489: Loss: 0.2034\n",
            "Epoch 3, Sample 11490: Loss: 1.0359\n",
            "Epoch 3, Sample 11491: Loss: 0.1822\n",
            "Epoch 3, Sample 11492: Loss: 0.1559\n",
            "Epoch 3, Sample 11493: Loss: 1.7711\n",
            "Epoch 3, Sample 11494: Loss: 0.4930\n",
            "Epoch 3, Sample 11495: Loss: 0.0116\n",
            "Epoch 3, Sample 11496: Loss: 0.7036\n",
            "Epoch 3, Sample 11497: Loss: 0.7036\n",
            "Epoch 3, Sample 11498: Loss: 0.2036\n",
            "Epoch 3, Sample 11499: Loss: 1.5597\n",
            "Epoch 3, Sample 11500: Loss: 0.2699\n",
            "Epoch 3, Sample 11501: Loss: 0.0110\n",
            "Epoch 3, Sample 11502: Loss: 0.3007\n",
            "Epoch 3, Sample 11503: Loss: 1.0524\n",
            "Epoch 3, Sample 11504: Loss: 0.3598\n",
            "Epoch 3, Sample 11505: Loss: 0.7036\n",
            "Epoch 3, Sample 11506: Loss: 0.0026\n",
            "Epoch 3, Sample 11507: Loss: 0.0013\n",
            "Epoch 3, Sample 11508: Loss: 0.3399\n",
            "Epoch 3, Sample 11509: Loss: 0.3441\n",
            "Epoch 3, Sample 11510: Loss: 0.0026\n",
            "Epoch 3, Sample 11511: Loss: 0.9367\n",
            "Epoch 3, Sample 11512: Loss: 2.7331\n",
            "Epoch 3, Sample 11513: Loss: 1.5597\n",
            "Epoch 3, Sample 11514: Loss: 0.0258\n",
            "Epoch 3, Sample 11515: Loss: 0.2044\n",
            "Epoch 3, Sample 11516: Loss: 0.0180\n",
            "Epoch 3, Sample 11517: Loss: 0.1588\n",
            "Epoch 3, Sample 11518: Loss: 0.0212\n",
            "Epoch 3, Sample 11519: Loss: 0.2832\n",
            "Epoch 3, Sample 11520: Loss: 0.2329\n",
            "Epoch 3, Sample 11521: Loss: 0.3399\n",
            "Epoch 3, Sample 11522: Loss: 1.0359\n",
            "Epoch 3, Sample 11523: Loss: 0.0026\n",
            "Epoch 3, Sample 11524: Loss: 0.2112\n",
            "Epoch 3, Sample 11525: Loss: 1.5597\n",
            "Epoch 3, Sample 11526: Loss: 3.3895\n",
            "Epoch 3, Sample 11527: Loss: 4.0002\n",
            "Epoch 3, Sample 11528: Loss: 0.8951\n",
            "Epoch 3, Sample 11529: Loss: 1.0155\n",
            "Epoch 3, Sample 11530: Loss: 1.0524\n",
            "Epoch 3, Sample 11531: Loss: 0.3399\n",
            "Epoch 3, Sample 11532: Loss: 4.6602\n",
            "Epoch 3, Sample 11533: Loss: 0.0084\n",
            "Epoch 3, Sample 11534: Loss: 0.0630\n",
            "Epoch 3, Sample 11535: Loss: 12.2612\n",
            "Epoch 3, Sample 11536: Loss: 1.5597\n",
            "Epoch 3, Sample 11537: Loss: 0.2558\n",
            "Epoch 3, Sample 11538: Loss: 1.0524\n",
            "Epoch 3, Sample 11539: Loss: 0.1463\n",
            "Epoch 3, Sample 11540: Loss: 8.0504\n",
            "Epoch 3, Sample 11541: Loss: 0.0018\n",
            "Epoch 3, Sample 11542: Loss: 0.7036\n",
            "Epoch 3, Sample 11543: Loss: 0.2034\n",
            "Epoch 3, Sample 11544: Loss: 0.0258\n",
            "Epoch 3, Sample 11545: Loss: 0.9780\n",
            "Epoch 3, Sample 11546: Loss: 0.1559\n",
            "Epoch 3, Sample 11547: Loss: 1.0524\n",
            "Epoch 3, Sample 11548: Loss: 1.0524\n",
            "Epoch 3, Sample 11549: Loss: 1.0155\n",
            "Epoch 3, Sample 11550: Loss: 0.6990\n",
            "Epoch 3, Sample 11551: Loss: 2.8787\n",
            "Epoch 3, Sample 11552: Loss: 0.3441\n",
            "Epoch 3, Sample 11553: Loss: 0.0306\n",
            "Epoch 3, Sample 11554: Loss: 0.7036\n",
            "Epoch 3, Sample 11555: Loss: 0.0018\n",
            "Epoch 3, Sample 11556: Loss: 0.5003\n",
            "Epoch 3, Sample 11557: Loss: 1.0155\n",
            "Epoch 3, Sample 11558: Loss: 0.2044\n",
            "Epoch 3, Sample 11559: Loss: 0.1838\n",
            "Epoch 3, Sample 11560: Loss: 0.0626\n",
            "Epoch 3, Sample 11561: Loss: 0.2759\n",
            "Epoch 3, Sample 11562: Loss: 0.5310\n",
            "Epoch 3, Sample 11563: Loss: 1.5597\n",
            "Epoch 3, Sample 11564: Loss: 1.5597\n",
            "Epoch 3, Sample 11565: Loss: 0.2112\n",
            "Epoch 3, Sample 11566: Loss: 0.2989\n",
            "Epoch 3, Sample 11567: Loss: 0.1151\n",
            "Epoch 3, Sample 11568: Loss: 0.2699\n",
            "Epoch 3, Sample 11569: Loss: 1.0524\n",
            "Epoch 3, Sample 11570: Loss: 0.2044\n",
            "Epoch 3, Sample 11571: Loss: 0.5858\n",
            "Epoch 3, Sample 11572: Loss: 0.0466\n",
            "Epoch 3, Sample 11573: Loss: 0.1817\n",
            "Epoch 3, Sample 11574: Loss: 0.1559\n",
            "Epoch 3, Sample 11575: Loss: 0.2032\n",
            "Epoch 3, Sample 11576: Loss: 0.6893\n",
            "Epoch 3, Sample 11577: Loss: 1.0524\n",
            "Epoch 3, Sample 11578: Loss: 0.2044\n",
            "Epoch 3, Sample 11579: Loss: 0.1252\n",
            "Epoch 3, Sample 11580: Loss: 0.7036\n",
            "Epoch 3, Sample 11581: Loss: 3.5504\n",
            "Epoch 3, Sample 11582: Loss: 1.0530\n",
            "Epoch 3, Sample 11583: Loss: 0.1523\n",
            "Epoch 3, Sample 11584: Loss: 1.0155\n",
            "Epoch 3, Sample 11585: Loss: 0.1654\n",
            "Epoch 3, Sample 11586: Loss: 0.5858\n",
            "Epoch 3, Sample 11587: Loss: 0.5858\n",
            "Epoch 3, Sample 11588: Loss: 0.0212\n",
            "Epoch 3, Sample 11589: Loss: 0.0501\n",
            "Epoch 3, Sample 11590: Loss: 0.0630\n",
            "Epoch 3, Sample 11591: Loss: 0.1248\n",
            "Epoch 3, Sample 11592: Loss: 0.2032\n",
            "Epoch 3, Sample 11593: Loss: 0.0018\n",
            "Epoch 3, Sample 11594: Loss: 0.2340\n",
            "Epoch 3, Sample 11595: Loss: 0.2044\n",
            "Epoch 3, Sample 11596: Loss: 0.3399\n",
            "Epoch 3, Sample 11597: Loss: 0.2034\n",
            "Epoch 3, Sample 11598: Loss: 1.4537\n",
            "Epoch 3, Sample 11599: Loss: 2.7331\n",
            "Epoch 3, Sample 11600: Loss: 2.9566\n",
            "Epoch 3, Sample 11601: Loss: 0.2044\n",
            "Epoch 3, Sample 11602: Loss: 3.1802\n",
            "Epoch 3, Sample 11603: Loss: 1.0155\n",
            "Epoch 3, Sample 11604: Loss: 0.0466\n",
            "Epoch 3, Sample 11605: Loss: 0.1246\n",
            "Epoch 3, Sample 11606: Loss: 0.3568\n",
            "Epoch 3, Sample 11607: Loss: 0.2361\n",
            "Epoch 3, Sample 11608: Loss: 0.0026\n",
            "Epoch 3, Sample 11609: Loss: 0.6092\n",
            "Epoch 3, Sample 11610: Loss: 0.3062\n",
            "Epoch 3, Sample 11611: Loss: 0.4996\n",
            "Epoch 3, Sample 11612: Loss: 1.0530\n",
            "Epoch 3, Sample 11613: Loss: 3.3270\n",
            "Epoch 3, Sample 11614: Loss: 1.0155\n",
            "Epoch 3, Sample 11615: Loss: 0.0477\n",
            "Epoch 3, Sample 11616: Loss: 17.1169\n",
            "Epoch 3, Sample 11617: Loss: 0.2044\n",
            "Epoch 3, Sample 11618: Loss: 0.2459\n",
            "Epoch 3, Sample 11619: Loss: 0.7036\n",
            "Epoch 3, Sample 11620: Loss: 0.7702\n",
            "Epoch 3, Sample 11621: Loss: 0.4996\n",
            "Epoch 3, Sample 11622: Loss: 0.2032\n",
            "Epoch 3, Sample 11623: Loss: 0.5000\n",
            "Epoch 3, Sample 11624: Loss: 0.1170\n",
            "Epoch 3, Sample 11625: Loss: 0.0460\n",
            "Epoch 3, Sample 11626: Loss: 0.2363\n",
            "Epoch 3, Sample 11627: Loss: 7.6726\n",
            "Epoch 3, Sample 11628: Loss: 0.2044\n",
            "Epoch 3, Sample 11629: Loss: 0.1924\n",
            "Epoch 3, Sample 11630: Loss: 1.0155\n",
            "Epoch 3, Sample 11631: Loss: 1.0155\n",
            "Epoch 3, Sample 11632: Loss: 0.1250\n",
            "Epoch 3, Sample 11633: Loss: 0.6139\n",
            "Epoch 3, Sample 11634: Loss: 0.0630\n",
            "Epoch 3, Sample 11635: Loss: 0.0034\n",
            "Epoch 3, Sample 11636: Loss: 0.7036\n",
            "Epoch 3, Sample 11637: Loss: 0.2032\n",
            "Epoch 3, Sample 11638: Loss: 0.2339\n",
            "Epoch 3, Sample 11639: Loss: 0.2044\n",
            "Epoch 3, Sample 11640: Loss: 0.3399\n",
            "Epoch 3, Sample 11641: Loss: 0.3399\n",
            "Epoch 3, Sample 11642: Loss: 0.0018\n",
            "Epoch 3, Sample 11643: Loss: 1.5597\n",
            "Epoch 3, Sample 11644: Loss: 1.5597\n",
            "Epoch 3, Sample 11645: Loss: 0.7036\n",
            "Epoch 3, Sample 11646: Loss: 0.2913\n",
            "Epoch 3, Sample 11647: Loss: 0.0026\n",
            "Epoch 3, Sample 11648: Loss: 0.7036\n",
            "Epoch 3, Sample 11649: Loss: 0.0018\n",
            "Epoch 3, Sample 11650: Loss: 0.5858\n",
            "Epoch 3, Sample 11651: Loss: 0.5858\n",
            "Epoch 3, Sample 11652: Loss: 0.0026\n",
            "Epoch 3, Sample 11653: Loss: 0.7036\n",
            "Epoch 3, Sample 11654: Loss: 0.1248\n",
            "Epoch 3, Sample 11655: Loss: 0.0018\n",
            "Epoch 3, Sample 11656: Loss: 0.3399\n",
            "Epoch 3, Sample 11657: Loss: 0.4032\n",
            "Epoch 3, Sample 11658: Loss: 0.0026\n",
            "Epoch 3, Sample 11659: Loss: 0.0150\n",
            "Epoch 3, Sample 11660: Loss: 0.2639\n",
            "Epoch 3, Sample 11661: Loss: 2.7331\n",
            "Epoch 3, Sample 11662: Loss: 0.5196\n",
            "Epoch 3, Sample 11663: Loss: 0.3441\n",
            "Epoch 3, Sample 11664: Loss: 1.0155\n",
            "Epoch 3, Sample 11665: Loss: 0.1170\n",
            "Epoch 3, Sample 11666: Loss: 0.2036\n",
            "Epoch 3, Sample 11667: Loss: 0.5078\n",
            "Epoch 3, Sample 11668: Loss: 0.4032\n",
            "Epoch 3, Sample 11669: Loss: 0.2832\n",
            "Epoch 3, Sample 11670: Loss: 0.2044\n",
            "Epoch 3, Sample 11671: Loss: 0.0026\n",
            "Epoch 3, Sample 11672: Loss: 0.2709\n",
            "Epoch 3, Sample 11673: Loss: 0.0001\n",
            "Epoch 3, Sample 11674: Loss: 6.2039\n",
            "Epoch 3, Sample 11675: Loss: 0.5078\n",
            "Epoch 3, Sample 11676: Loss: 0.0460\n",
            "Epoch 3, Sample 11677: Loss: 2.6384\n",
            "Epoch 3, Sample 11678: Loss: 1.0359\n",
            "Epoch 3, Sample 11679: Loss: 0.2044\n",
            "Epoch 3, Sample 11680: Loss: 0.0212\n",
            "Epoch 3, Sample 11681: Loss: 1.0524\n",
            "Epoch 3, Sample 11682: Loss: 0.5078\n",
            "Epoch 3, Sample 11683: Loss: 0.4799\n",
            "Epoch 3, Sample 11684: Loss: 1.2926\n",
            "Epoch 3, Sample 11685: Loss: 0.1170\n",
            "Epoch 3, Sample 11686: Loss: 0.0026\n",
            "Epoch 3, Sample 11687: Loss: 0.0018\n",
            "Epoch 3, Sample 11688: Loss: 0.2219\n",
            "Epoch 3, Sample 11689: Loss: 0.9780\n",
            "Epoch 3, Sample 11690: Loss: 0.0006\n",
            "Epoch 3, Sample 11691: Loss: 0.2044\n",
            "Epoch 3, Sample 11692: Loss: 0.0026\n",
            "Epoch 3, Sample 11693: Loss: 0.0498\n",
            "Epoch 3, Sample 11694: Loss: 0.5000\n",
            "Epoch 3, Sample 11695: Loss: 0.3399\n",
            "Epoch 3, Sample 11696: Loss: 0.2759\n",
            "Epoch 3, Sample 11697: Loss: 0.1791\n",
            "Epoch 3, Sample 11698: Loss: 3.8844\n",
            "Epoch 3, Sample 11699: Loss: 0.0026\n",
            "Epoch 3, Sample 11700: Loss: 0.2036\n",
            "Epoch 3, Sample 11701: Loss: 1.0956\n",
            "Epoch 3, Sample 11702: Loss: 2.2632\n",
            "Epoch 3, Sample 11703: Loss: 0.0554\n",
            "Epoch 3, Sample 11704: Loss: 0.1250\n",
            "Epoch 3, Sample 11705: Loss: 2.7331\n",
            "Epoch 3, Sample 11706: Loss: 7.4307\n",
            "Epoch 3, Sample 11707: Loss: 0.0133\n",
            "Epoch 3, Sample 11708: Loss: 2.9652\n",
            "Epoch 3, Sample 11709: Loss: 5.5054\n",
            "Epoch 3, Sample 11710: Loss: 1.0956\n",
            "Epoch 3, Sample 11711: Loss: 3.3270\n",
            "Epoch 3, Sample 11712: Loss: 3.7714\n",
            "Epoch 3, Sample 11713: Loss: 0.2759\n",
            "Epoch 3, Sample 11714: Loss: 0.2759\n",
            "Epoch 3, Sample 11715: Loss: 0.5858\n",
            "Epoch 3, Sample 11716: Loss: 1.0524\n",
            "Epoch 3, Sample 11717: Loss: 0.0630\n",
            "Epoch 3, Sample 11718: Loss: 0.5000\n",
            "Epoch 3, Sample 11719: Loss: 0.3450\n",
            "Epoch 3, Sample 11720: Loss: 1.0155\n",
            "Epoch 3, Sample 11721: Loss: 0.1250\n",
            "Epoch 3, Sample 11722: Loss: 0.2112\n",
            "Epoch 3, Sample 11723: Loss: 1.0070\n",
            "Epoch 3, Sample 11724: Loss: 2.7331\n",
            "Epoch 3, Sample 11725: Loss: 0.2112\n",
            "Epoch 3, Sample 11726: Loss: 0.2044\n",
            "Epoch 3, Sample 11727: Loss: 0.2759\n",
            "Epoch 3, Sample 11728: Loss: 0.4841\n",
            "Epoch 3, Sample 11729: Loss: 0.1559\n",
            "Epoch 3, Sample 11730: Loss: 0.3007\n",
            "Epoch 3, Sample 11731: Loss: 0.0018\n",
            "Epoch 3, Sample 11732: Loss: 0.0507\n",
            "Epoch 3, Sample 11733: Loss: 2.2765\n",
            "Epoch 3, Sample 11734: Loss: 0.3399\n",
            "Epoch 3, Sample 11735: Loss: 1.4884\n",
            "Epoch 3, Sample 11736: Loss: 10.5084\n",
            "Epoch 3, Sample 11737: Loss: 0.0026\n",
            "Epoch 3, Sample 11738: Loss: 0.0013\n",
            "Epoch 3, Sample 11739: Loss: 0.7453\n",
            "Epoch 3, Sample 11740: Loss: 3.0780\n",
            "Epoch 3, Sample 11741: Loss: 4.7222\n",
            "Epoch 3, Sample 11742: Loss: 0.1248\n",
            "Epoch 3, Sample 11743: Loss: 0.9367\n",
            "Epoch 3, Sample 11744: Loss: 0.1170\n",
            "Epoch 3, Sample 11745: Loss: 0.3441\n",
            "Epoch 3, Sample 11746: Loss: 0.5196\n",
            "Epoch 3, Sample 11747: Loss: 2.0531\n",
            "Epoch 3, Sample 11748: Loss: 0.0072\n",
            "Epoch 3, Sample 11749: Loss: 0.0630\n",
            "Epoch 3, Sample 11750: Loss: 0.1250\n",
            "Epoch 3, Sample 11751: Loss: 0.1326\n",
            "Epoch 3, Sample 11752: Loss: 0.2970\n",
            "Epoch 3, Sample 11753: Loss: 0.2832\n",
            "Epoch 3, Sample 11754: Loss: 1.2522\n",
            "Epoch 3, Sample 11755: Loss: 0.0084\n",
            "Epoch 3, Sample 11756: Loss: 0.0640\n",
            "Epoch 3, Sample 11757: Loss: 0.2036\n",
            "Epoch 3, Sample 11758: Loss: 0.4644\n",
            "Epoch 3, Sample 11759: Loss: 0.2032\n",
            "Epoch 3, Sample 11760: Loss: 0.6990\n",
            "Epoch 3, Sample 11761: Loss: 2.4360\n",
            "Epoch 3, Sample 11762: Loss: 0.0775\n",
            "Epoch 3, Sample 11763: Loss: 0.1250\n",
            "Epoch 3, Sample 11764: Loss: 0.0306\n",
            "Epoch 3, Sample 11765: Loss: 5.6013\n",
            "Epoch 3, Sample 11766: Loss: 0.0018\n",
            "Epoch 3, Sample 11767: Loss: 0.0744\n",
            "Epoch 3, Sample 11768: Loss: 0.1523\n",
            "Epoch 3, Sample 11769: Loss: 1.0155\n",
            "Epoch 3, Sample 11770: Loss: 0.5989\n",
            "Epoch 3, Sample 11771: Loss: 0.3399\n",
            "Epoch 3, Sample 11772: Loss: 1.0155\n",
            "Epoch 3, Sample 11773: Loss: 0.1248\n",
            "Epoch 3, Sample 11774: Loss: 0.1250\n",
            "Epoch 3, Sample 11775: Loss: 0.0007\n",
            "Epoch 3, Sample 11776: Loss: 1.0524\n",
            "Epoch 3, Sample 11777: Loss: 0.7638\n",
            "Epoch 3, Sample 11778: Loss: 0.2044\n",
            "Epoch 3, Sample 11779: Loss: 0.2759\n",
            "Epoch 3, Sample 11780: Loss: 0.0626\n",
            "Epoch 3, Sample 11781: Loss: 0.5000\n",
            "Epoch 3, Sample 11782: Loss: 1.0227\n",
            "Epoch 3, Sample 11783: Loss: 0.2032\n",
            "Epoch 3, Sample 11784: Loss: 0.6304\n",
            "Epoch 3, Sample 11785: Loss: 0.4841\n",
            "Epoch 3, Sample 11786: Loss: 1.0155\n",
            "Epoch 3, Sample 11787: Loss: 0.2941\n",
            "Epoch 3, Sample 11788: Loss: 0.5089\n",
            "Epoch 3, Sample 11789: Loss: 0.3949\n",
            "Epoch 3, Sample 11790: Loss: 0.0039\n",
            "Epoch 3, Sample 11791: Loss: 0.0026\n",
            "Epoch 3, Sample 11792: Loss: 0.0630\n",
            "Epoch 3, Sample 11793: Loss: 1.0155\n",
            "Epoch 3, Sample 11794: Loss: 0.0018\n",
            "Epoch 3, Sample 11795: Loss: 3.5504\n",
            "Epoch 3, Sample 11796: Loss: 0.2044\n",
            "Epoch 3, Sample 11797: Loss: 0.7453\n",
            "Epoch 3, Sample 11798: Loss: 10.4159\n",
            "Epoch 3, Sample 11799: Loss: 0.2832\n",
            "Epoch 3, Sample 11800: Loss: 0.2034\n",
            "Epoch 3, Sample 11801: Loss: 0.0630\n",
            "Epoch 3, Sample 11802: Loss: 0.0027\n",
            "Epoch 3, Sample 11803: Loss: 5.5067\n",
            "Epoch 3, Sample 11804: Loss: 0.5003\n",
            "Epoch 3, Sample 11805: Loss: 2.8294\n",
            "Epoch 3, Sample 11806: Loss: 0.0212\n",
            "Epoch 3, Sample 11807: Loss: 2.4541\n",
            "Epoch 3, Sample 11808: Loss: 0.0168\n",
            "Epoch 3, Sample 11809: Loss: 11.5233\n",
            "Epoch 3, Sample 11810: Loss: 0.0026\n",
            "Epoch 3, Sample 11811: Loss: 0.0026\n",
            "Epoch 3, Sample 11812: Loss: 0.2044\n",
            "Epoch 3, Sample 11813: Loss: 0.0640\n",
            "Epoch 3, Sample 11814: Loss: 0.2941\n",
            "Epoch 3, Sample 11815: Loss: 0.1546\n",
            "Epoch 3, Sample 11816: Loss: 0.1559\n",
            "Epoch 3, Sample 11817: Loss: 0.5858\n",
            "Epoch 3, Sample 11818: Loss: 0.3399\n",
            "Epoch 3, Sample 11819: Loss: 0.4032\n",
            "Epoch 3, Sample 11820: Loss: 0.2036\n",
            "Epoch 3, Sample 11821: Loss: 0.2639\n",
            "Epoch 3, Sample 11822: Loss: 1.0530\n",
            "Epoch 3, Sample 11823: Loss: 2.9661\n",
            "Epoch 3, Sample 11824: Loss: 0.2639\n",
            "Epoch 3, Sample 11825: Loss: 0.7036\n",
            "Epoch 3, Sample 11826: Loss: 3.1802\n",
            "Epoch 3, Sample 11827: Loss: 0.9780\n",
            "Epoch 3, Sample 11828: Loss: 2.0225\n",
            "Epoch 3, Sample 11829: Loss: 1.0530\n",
            "Epoch 3, Sample 11830: Loss: 0.2044\n",
            "Epoch 3, Sample 11831: Loss: 0.0240\n",
            "Epoch 3, Sample 11832: Loss: 0.0895\n",
            "Epoch 3, Sample 11833: Loss: 0.2044\n",
            "Epoch 3, Sample 11834: Loss: 0.2044\n",
            "Epoch 3, Sample 11835: Loss: 0.3399\n",
            "Epoch 3, Sample 11836: Loss: 0.0875\n",
            "Epoch 3, Sample 11837: Loss: 2.7331\n",
            "Epoch 3, Sample 11838: Loss: 0.2041\n",
            "Epoch 3, Sample 11839: Loss: 0.3441\n",
            "Epoch 3, Sample 11840: Loss: 0.1465\n",
            "Epoch 3, Sample 11841: Loss: 0.0026\n",
            "Epoch 3, Sample 11842: Loss: 0.7036\n",
            "Epoch 3, Sample 11843: Loss: 0.7036\n",
            "Epoch 3, Sample 11844: Loss: 1.9999\n",
            "Epoch 3, Sample 11845: Loss: 0.3584\n",
            "Epoch 3, Sample 11846: Loss: 0.3949\n",
            "Epoch 3, Sample 11847: Loss: 1.5597\n",
            "Epoch 3, Sample 11848: Loss: 0.2759\n",
            "Epoch 3, Sample 11849: Loss: 0.2759\n",
            "Epoch 3, Sample 11850: Loss: 0.2759\n",
            "Epoch 3, Sample 11851: Loss: 0.9894\n",
            "Epoch 3, Sample 11852: Loss: 0.0588\n",
            "Epoch 3, Sample 11853: Loss: 7.6726\n",
            "Epoch 3, Sample 11854: Loss: 0.8951\n",
            "Epoch 3, Sample 11855: Loss: 0.2375\n",
            "Epoch 3, Sample 11856: Loss: 0.0938\n",
            "Epoch 3, Sample 11857: Loss: 0.0018\n",
            "Epoch 3, Sample 11858: Loss: 0.0455\n",
            "Epoch 3, Sample 11859: Loss: 0.1627\n",
            "Epoch 3, Sample 11860: Loss: 0.0026\n",
            "Epoch 3, Sample 11861: Loss: 0.5375\n",
            "Epoch 3, Sample 11862: Loss: 1.0511\n",
            "Epoch 3, Sample 11863: Loss: 0.2044\n",
            "Epoch 3, Sample 11864: Loss: 0.0030\n",
            "Epoch 3, Sample 11865: Loss: 8.0426\n",
            "Epoch 3, Sample 11866: Loss: 0.7036\n",
            "Epoch 3, Sample 11867: Loss: 2.7331\n",
            "Epoch 3, Sample 11868: Loss: 0.3092\n",
            "Epoch 3, Sample 11869: Loss: 1.4537\n",
            "Epoch 3, Sample 11870: Loss: 0.0026\n",
            "Epoch 3, Sample 11871: Loss: 0.4588\n",
            "Epoch 3, Sample 11872: Loss: 0.0938\n",
            "Epoch 3, Sample 11873: Loss: 0.0466\n",
            "Epoch 3, Sample 11874: Loss: 6.3986\n",
            "Epoch 3, Sample 11875: Loss: 0.0205\n",
            "Epoch 3, Sample 11876: Loss: 1.0227\n",
            "Epoch 3, Sample 11877: Loss: 0.3399\n",
            "Epoch 3, Sample 11878: Loss: 1.0688\n",
            "Epoch 3, Sample 11879: Loss: 0.5972\n",
            "Epoch 3, Sample 11880: Loss: 0.0030\n",
            "Epoch 3, Sample 11881: Loss: 11.5326\n",
            "Epoch 3, Sample 11882: Loss: 0.5858\n",
            "Epoch 3, Sample 11883: Loss: 0.0505\n",
            "Epoch 3, Sample 11884: Loss: 0.0013\n",
            "Epoch 3, Sample 11885: Loss: 0.7036\n",
            "Epoch 3, Sample 11886: Loss: 1.0155\n",
            "Epoch 3, Sample 11887: Loss: 0.2034\n",
            "Epoch 3, Sample 11888: Loss: 0.5141\n",
            "Epoch 3, Sample 11889: Loss: 0.7036\n",
            "Epoch 3, Sample 11890: Loss: 0.2686\n",
            "Epoch 3, Sample 11891: Loss: 0.6990\n",
            "Epoch 3, Sample 11892: Loss: 0.1170\n",
            "Epoch 3, Sample 11893: Loss: 0.0026\n",
            "Epoch 3, Sample 11894: Loss: 0.2032\n",
            "Epoch 3, Sample 11895: Loss: 0.5858\n",
            "Epoch 3, Sample 11896: Loss: 1.4537\n",
            "Epoch 3, Sample 11897: Loss: 0.2639\n",
            "Epoch 3, Sample 11898: Loss: 4.9130\n",
            "Epoch 3, Sample 11899: Loss: 0.3399\n",
            "Epoch 3, Sample 11900: Loss: 8.7194\n",
            "Epoch 3, Sample 11901: Loss: 0.5003\n",
            "Epoch 3, Sample 11902: Loss: 0.3092\n",
            "Epoch 3, Sample 11903: Loss: 0.1250\n",
            "Epoch 3, Sample 11904: Loss: 0.1246\n",
            "Epoch 3, Sample 11905: Loss: 0.2832\n",
            "Epoch 3, Sample 11906: Loss: 0.3441\n",
            "Epoch 3, Sample 11907: Loss: 0.0205\n",
            "Epoch 3, Sample 11908: Loss: 0.1250\n",
            "Epoch 3, Sample 11909: Loss: 0.0026\n",
            "Epoch 3, Sample 11910: Loss: 0.3399\n",
            "Epoch 3, Sample 11911: Loss: 1.3501\n",
            "Epoch 3, Sample 11912: Loss: 0.1399\n",
            "Epoch 3, Sample 11913: Loss: 0.0625\n",
            "Epoch 3, Sample 11914: Loss: 0.2639\n",
            "Epoch 3, Sample 11915: Loss: 0.2034\n",
            "Epoch 3, Sample 11916: Loss: 1.2845\n",
            "Epoch 3, Sample 11917: Loss: 2.9661\n",
            "Epoch 3, Sample 11918: Loss: 0.0026\n",
            "Epoch 3, Sample 11919: Loss: 0.0630\n",
            "Epoch 3, Sample 11920: Loss: 2.7331\n",
            "Epoch 3, Sample 11921: Loss: 0.6990\n",
            "Epoch 3, Sample 11922: Loss: 0.3441\n",
            "Epoch 3, Sample 11923: Loss: 0.3399\n",
            "Epoch 3, Sample 11924: Loss: 0.5000\n",
            "Epoch 3, Sample 11925: Loss: 0.0630\n",
            "Epoch 3, Sample 11926: Loss: 1.0359\n",
            "Epoch 3, Sample 11927: Loss: 0.2340\n",
            "Epoch 3, Sample 11928: Loss: 0.3624\n",
            "Epoch 3, Sample 11929: Loss: 2.7331\n",
            "Epoch 3, Sample 11930: Loss: 0.4367\n",
            "Epoch 3, Sample 11931: Loss: 0.0060\n",
            "Epoch 3, Sample 11932: Loss: 3.0271\n",
            "Epoch 3, Sample 11933: Loss: 0.0554\n",
            "Epoch 3, Sample 11934: Loss: 0.9651\n",
            "Epoch 3, Sample 11935: Loss: 0.4930\n",
            "Epoch 3, Sample 11936: Loss: 0.0026\n",
            "Epoch 3, Sample 11937: Loss: 1.8819\n",
            "Epoch 3, Sample 11938: Loss: 0.1372\n",
            "Epoch 3, Sample 11939: Loss: 0.2044\n",
            "Epoch 3, Sample 11940: Loss: 1.0524\n",
            "Epoch 3, Sample 11941: Loss: 0.2044\n",
            "Epoch 3, Sample 11942: Loss: 0.1250\n",
            "Epoch 3, Sample 11943: Loss: 0.7702\n",
            "Epoch 3, Sample 11944: Loss: 0.0025\n",
            "Epoch 3, Sample 11945: Loss: 0.5858\n",
            "Epoch 3, Sample 11946: Loss: 1.0524\n",
            "Epoch 3, Sample 11947: Loss: 0.1170\n",
            "Epoch 3, Sample 11948: Loss: 0.0212\n",
            "Epoch 3, Sample 11949: Loss: 0.2036\n",
            "Epoch 3, Sample 11950: Loss: 0.3402\n",
            "Epoch 3, Sample 11951: Loss: 0.8217\n",
            "Epoch 3, Sample 11952: Loss: 0.5000\n",
            "Epoch 3, Sample 11953: Loss: 0.0838\n",
            "Epoch 3, Sample 11954: Loss: 1.5963\n",
            "Epoch 3, Sample 11955: Loss: 0.1337\n",
            "Epoch 3, Sample 11956: Loss: 0.4799\n",
            "Epoch 3, Sample 11957: Loss: 0.0625\n",
            "Epoch 3, Sample 11958: Loss: 0.4155\n",
            "Epoch 3, Sample 11959: Loss: 7.6467\n",
            "Epoch 3, Sample 11960: Loss: 0.3007\n",
            "Epoch 3, Sample 11961: Loss: 0.2759\n",
            "Epoch 3, Sample 11962: Loss: 1.5597\n",
            "Epoch 3, Sample 11963: Loss: 0.0083\n",
            "Epoch 3, Sample 11964: Loss: 0.7702\n",
            "Epoch 3, Sample 11965: Loss: 0.0018\n",
            "Epoch 3, Sample 11966: Loss: 0.2034\n",
            "Epoch 3, Sample 11967: Loss: 0.0640\n",
            "Epoch 3, Sample 11968: Loss: 7.2518\n",
            "Epoch 3, Sample 11969: Loss: 0.6990\n",
            "Epoch 3, Sample 11970: Loss: 0.2044\n",
            "Epoch 3, Sample 11971: Loss: 0.3399\n",
            "Epoch 3, Sample 11972: Loss: 0.0062\n",
            "Epoch 3, Sample 11973: Loss: 0.4799\n",
            "Epoch 3, Sample 11974: Loss: 0.4611\n",
            "Epoch 3, Sample 11975: Loss: 1.0524\n",
            "Epoch 3, Sample 11976: Loss: 0.5871\n",
            "Epoch 3, Sample 11977: Loss: 1.0524\n",
            "Epoch 3, Sample 11978: Loss: 0.2044\n",
            "Epoch 3, Sample 11979: Loss: 1.5597\n",
            "Epoch 3, Sample 11980: Loss: 0.6867\n",
            "Epoch 3, Sample 11981: Loss: 0.0000\n",
            "Epoch 3, Sample 11982: Loss: 0.5000\n",
            "Epoch 3, Sample 11983: Loss: 0.0018\n",
            "Epoch 3, Sample 11984: Loss: 0.1508\n",
            "Epoch 3, Sample 11985: Loss: 0.3506\n",
            "Epoch 3, Sample 11986: Loss: 0.5314\n",
            "Epoch 3, Sample 11987: Loss: 4.3234\n",
            "Epoch 3, Sample 11988: Loss: 1.7073\n",
            "Epoch 3, Sample 11989: Loss: 3.5504\n",
            "Epoch 3, Sample 11990: Loss: 0.2034\n",
            "Epoch 3, Sample 11991: Loss: 0.2034\n",
            "Epoch 3, Sample 11992: Loss: 0.5003\n",
            "Epoch 3, Sample 11993: Loss: 0.3598\n",
            "Epoch 3, Sample 11994: Loss: 0.0536\n",
            "Epoch 3, Sample 11995: Loss: 1.0524\n",
            "Epoch 3, Sample 11996: Loss: 0.1091\n",
            "Epoch 3, Sample 11997: Loss: 0.2036\n",
            "Epoch 3, Sample 11998: Loss: 0.1250\n",
            "Epoch 3, Sample 11999: Loss: 8.7405\n",
            "Epoch 3, Sample 12000: Loss: 0.0018\n",
            "Epoch 3, Sample 12001: Loss: 5.9195\n",
            "Epoch 3, Sample 12002: Loss: 0.0306\n",
            "Epoch 3, Sample 12003: Loss: 0.0001\n",
            "Epoch 3, Sample 12004: Loss: 0.0005\n",
            "Epoch 3, Sample 12005: Loss: 0.7344\n",
            "Epoch 3, Sample 12006: Loss: 0.1890\n",
            "Epoch 3, Sample 12007: Loss: 1.5542\n",
            "Epoch 3, Sample 12008: Loss: 0.0001\n",
            "Epoch 3, Sample 12009: Loss: 0.2044\n",
            "Epoch 3, Sample 12010: Loss: 0.0476\n",
            "Epoch 3, Sample 12011: Loss: 0.4607\n",
            "Epoch 3, Sample 12012: Loss: 0.0000\n",
            "Epoch 3, Sample 12013: Loss: 0.4930\n",
            "Epoch 3, Sample 12014: Loss: 0.1114\n",
            "Epoch 3, Sample 12015: Loss: 0.3598\n",
            "Epoch 3, Sample 12016: Loss: 0.2044\n",
            "Epoch 3, Sample 12017: Loss: 1.1263\n",
            "Epoch 3, Sample 12018: Loss: 0.0626\n",
            "Epoch 3, Sample 12019: Loss: 0.2044\n",
            "Epoch 3, Sample 12020: Loss: 3.7586\n",
            "Epoch 3, Sample 12021: Loss: 0.3949\n",
            "Epoch 3, Sample 12022: Loss: 0.3949\n",
            "Epoch 3, Sample 12023: Loss: 0.1250\n",
            "Epoch 3, Sample 12024: Loss: 1.0524\n",
            "Epoch 3, Sample 12025: Loss: 1.0524\n",
            "Epoch 3, Sample 12026: Loss: 0.2759\n",
            "Epoch 3, Sample 12027: Loss: 0.0060\n",
            "Epoch 3, Sample 12028: Loss: 0.5019\n",
            "Epoch 3, Sample 12029: Loss: 0.2219\n",
            "Epoch 3, Sample 12030: Loss: 0.4382\n",
            "Epoch 3, Sample 12031: Loss: 0.0006\n",
            "Epoch 3, Sample 12032: Loss: 0.3441\n",
            "Epoch 3, Sample 12033: Loss: 17.3544\n",
            "Epoch 3, Sample 12034: Loss: 0.3441\n",
            "Epoch 3, Sample 12035: Loss: 0.2459\n",
            "Epoch 3, Sample 12036: Loss: 0.1039\n",
            "Epoch 3, Sample 12037: Loss: 0.0018\n",
            "Epoch 3, Sample 12038: Loss: 0.0630\n",
            "Epoch 3, Sample 12039: Loss: 0.4663\n",
            "Epoch 3, Sample 12040: Loss: 0.1660\n",
            "Epoch 3, Sample 12041: Loss: 0.3367\n",
            "Epoch 3, Sample 12042: Loss: 0.0558\n",
            "Epoch 3, Sample 12043: Loss: 0.0247\n",
            "Epoch 3, Sample 12044: Loss: 0.7036\n",
            "Epoch 3, Sample 12045: Loss: 0.0026\n",
            "Epoch 3, Sample 12046: Loss: 0.2034\n",
            "Epoch 3, Sample 12047: Loss: 0.0009\n",
            "Epoch 3, Sample 12048: Loss: 0.6139\n",
            "Epoch 3, Sample 12049: Loss: 0.1559\n",
            "Epoch 3, Sample 12050: Loss: 0.5003\n",
            "Epoch 3, Sample 12051: Loss: 1.0359\n",
            "Epoch 3, Sample 12052: Loss: 0.0026\n",
            "Epoch 3, Sample 12053: Loss: 0.3584\n",
            "Epoch 3, Sample 12054: Loss: 0.1250\n",
            "Epoch 3, Sample 12055: Loss: 0.0625\n",
            "Epoch 3, Sample 12056: Loss: 0.5019\n",
            "Epoch 3, Sample 12057: Loss: 1.5597\n",
            "Epoch 3, Sample 12058: Loss: 0.1863\n",
            "Epoch 3, Sample 12059: Loss: 0.2034\n",
            "Epoch 3, Sample 12060: Loss: 0.6990\n",
            "Epoch 3, Sample 12061: Loss: 1.4537\n",
            "Epoch 3, Sample 12062: Loss: 0.0018\n",
            "Epoch 3, Sample 12063: Loss: 0.3441\n",
            "Epoch 3, Sample 12064: Loss: 0.3399\n",
            "Epoch 3, Sample 12065: Loss: 0.0201\n",
            "Epoch 3, Sample 12066: Loss: 0.0505\n",
            "Epoch 3, Sample 12067: Loss: 0.0002\n",
            "Epoch 3, Sample 12068: Loss: 0.0025\n",
            "Epoch 3, Sample 12069: Loss: 0.2032\n",
            "Epoch 3, Sample 12070: Loss: 1.8616\n",
            "Epoch 3, Sample 12071: Loss: 9.7728\n",
            "Epoch 3, Sample 12072: Loss: 20.8867\n",
            "Epoch 3, Sample 12073: Loss: 1.0155\n",
            "Epoch 3, Sample 12074: Loss: 0.7036\n",
            "Epoch 3, Sample 12075: Loss: 0.1170\n",
            "Epoch 3, Sample 12076: Loss: 0.3319\n",
            "Epoch 3, Sample 12077: Loss: 0.2044\n",
            "Epoch 3, Sample 12078: Loss: 0.0026\n",
            "Epoch 3, Sample 12079: Loss: 10.8862\n",
            "Epoch 3, Sample 12080: Loss: 0.7453\n",
            "Epoch 3, Sample 12081: Loss: 0.6867\n",
            "Epoch 3, Sample 12082: Loss: 0.7036\n",
            "Epoch 3, Sample 12083: Loss: 0.6304\n",
            "Epoch 3, Sample 12084: Loss: 0.1399\n",
            "Epoch 3, Sample 12085: Loss: 0.2759\n",
            "Epoch 3, Sample 12086: Loss: 0.8951\n",
            "Epoch 3, Sample 12087: Loss: 0.7036\n",
            "Epoch 3, Sample 12088: Loss: 1.0524\n",
            "Epoch 3, Sample 12089: Loss: 0.2044\n",
            "Epoch 3, Sample 12090: Loss: 0.2962\n",
            "Epoch 3, Sample 12091: Loss: 0.2639\n",
            "Epoch 3, Sample 12092: Loss: 0.2044\n",
            "Epoch 3, Sample 12093: Loss: 0.5314\n",
            "Epoch 3, Sample 12094: Loss: 0.0018\n",
            "Epoch 3, Sample 12095: Loss: 0.7036\n",
            "Epoch 3, Sample 12096: Loss: 0.6990\n",
            "Epoch 3, Sample 12097: Loss: 0.7036\n",
            "Epoch 3, Sample 12098: Loss: 0.0108\n",
            "Epoch 3, Sample 12099: Loss: 0.0161\n",
            "Epoch 3, Sample 12100: Loss: 1.7296\n",
            "Epoch 3, Sample 12101: Loss: 0.2036\n",
            "Epoch 3, Sample 12102: Loss: 0.2044\n",
            "Epoch 3, Sample 12103: Loss: 0.3441\n",
            "Epoch 3, Sample 12104: Loss: 0.2032\n",
            "Epoch 3, Sample 12105: Loss: 0.0630\n",
            "Epoch 3, Sample 12106: Loss: 1.0530\n",
            "Epoch 3, Sample 12107: Loss: 0.0063\n",
            "Epoch 3, Sample 12108: Loss: 0.1397\n",
            "Epoch 3, Sample 12109: Loss: 0.0116\n",
            "Epoch 3, Sample 12110: Loss: 0.0630\n",
            "Epoch 3, Sample 12111: Loss: 0.1559\n",
            "Epoch 3, Sample 12112: Loss: 0.2375\n",
            "Epoch 3, Sample 12113: Loss: 1.0524\n",
            "Epoch 3, Sample 12114: Loss: 0.7036\n",
            "Epoch 3, Sample 12115: Loss: 2.0233\n",
            "Epoch 3, Sample 12116: Loss: 1.0359\n",
            "Epoch 3, Sample 12117: Loss: 0.5972\n",
            "Epoch 3, Sample 12118: Loss: 15.5912\n",
            "Epoch 3, Sample 12119: Loss: 3.5504\n",
            "Epoch 3, Sample 12120: Loss: 0.3399\n",
            "Epoch 3, Sample 12121: Loss: 0.5196\n",
            "Epoch 3, Sample 12122: Loss: 0.2832\n",
            "Epoch 3, Sample 12123: Loss: 0.6990\n",
            "Epoch 3, Sample 12124: Loss: 0.1056\n",
            "Epoch 3, Sample 12125: Loss: 0.0145\n",
            "Epoch 3, Sample 12126: Loss: 0.0018\n",
            "Epoch 3, Sample 12127: Loss: 0.1250\n",
            "Epoch 3, Sample 12128: Loss: 0.2044\n",
            "Epoch 3, Sample 12129: Loss: 1.0530\n",
            "Epoch 3, Sample 12130: Loss: 0.0630\n",
            "Epoch 3, Sample 12131: Loss: 0.8951\n",
            "Epoch 3, Sample 12132: Loss: 4.4015\n",
            "Epoch 3, Sample 12133: Loss: 0.1248\n",
            "Epoch 3, Sample 12134: Loss: 0.2034\n",
            "Epoch 3, Sample 12135: Loss: 0.2044\n",
            "Epoch 3, Sample 12136: Loss: 2.0092\n",
            "Epoch 3, Sample 12137: Loss: 0.2759\n",
            "Epoch 3, Sample 12138: Loss: 0.1822\n",
            "Epoch 3, Sample 12139: Loss: 0.2759\n",
            "Epoch 3, Sample 12140: Loss: 0.2044\n",
            "Epoch 3, Sample 12141: Loss: 0.0144\n",
            "Epoch 3, Sample 12142: Loss: 4.4745\n",
            "Epoch 3, Sample 12143: Loss: 1.0155\n",
            "Epoch 3, Sample 12144: Loss: 0.2759\n",
            "Epoch 3, Sample 12145: Loss: 0.3402\n",
            "Epoch 3, Sample 12146: Loss: 0.5062\n",
            "Epoch 3, Sample 12147: Loss: 0.1170\n",
            "Epoch 3, Sample 12148: Loss: 0.6653\n",
            "Epoch 3, Sample 12149: Loss: 0.0626\n",
            "Epoch 3, Sample 12150: Loss: 0.1559\n",
            "Epoch 3, Sample 12151: Loss: 0.0026\n",
            "Epoch 3, Sample 12152: Loss: 1.5597\n",
            "Epoch 3, Sample 12153: Loss: 0.1250\n",
            "Epoch 3, Sample 12154: Loss: 1.4823\n",
            "Epoch 3, Sample 12155: Loss: 0.2044\n",
            "Epoch 3, Sample 12156: Loss: 0.1170\n",
            "Epoch 3, Sample 12157: Loss: 1.0530\n",
            "Epoch 3, Sample 12158: Loss: 0.0819\n",
            "Epoch 3, Sample 12159: Loss: 0.2044\n",
            "Epoch 3, Sample 12160: Loss: 0.2044\n",
            "Epoch 3, Sample 12161: Loss: 0.3399\n",
            "Epoch 3, Sample 12162: Loss: 0.0206\n",
            "Epoch 3, Sample 12163: Loss: 0.0018\n",
            "Epoch 3, Sample 12164: Loss: 0.3399\n",
            "Epoch 3, Sample 12165: Loss: 0.9780\n",
            "Epoch 3, Sample 12166: Loss: 1.5597\n",
            "Epoch 3, Sample 12167: Loss: 0.1044\n",
            "Epoch 3, Sample 12168: Loss: 0.0207\n",
            "Epoch 3, Sample 12169: Loss: 0.0212\n",
            "Epoch 3, Sample 12170: Loss: 0.7036\n",
            "Epoch 3, Sample 12171: Loss: 0.3399\n",
            "Epoch 3, Sample 12172: Loss: 0.2044\n",
            "Epoch 3, Sample 12173: Loss: 0.0013\n",
            "Epoch 3, Sample 12174: Loss: 0.1170\n",
            "Epoch 3, Sample 12175: Loss: 0.7036\n",
            "Epoch 3, Sample 12176: Loss: 0.0830\n",
            "Epoch 3, Sample 12177: Loss: 1.0524\n",
            "Epoch 3, Sample 12178: Loss: 0.0026\n",
            "Epoch 3, Sample 12179: Loss: 1.5597\n",
            "Epoch 3, Sample 12180: Loss: 0.7036\n",
            "Epoch 3, Sample 12181: Loss: 1.0524\n",
            "Epoch 3, Sample 12182: Loss: 0.0838\n",
            "Epoch 3, Sample 12183: Loss: 0.7036\n",
            "Epoch 3, Sample 12184: Loss: 0.7036\n",
            "Epoch 3, Sample 12185: Loss: 0.0034\n",
            "Epoch 3, Sample 12186: Loss: 0.4514\n",
            "Epoch 3, Sample 12187: Loss: 1.5597\n",
            "Epoch 3, Sample 12188: Loss: 0.2036\n",
            "Epoch 3, Sample 12189: Loss: 1.0524\n",
            "Epoch 3, Sample 12190: Loss: 0.0838\n",
            "Epoch 3, Sample 12191: Loss: 1.5597\n",
            "Epoch 3, Sample 12192: Loss: 0.2962\n",
            "Epoch 3, Sample 12193: Loss: 1.9213\n",
            "Epoch 3, Sample 12194: Loss: 0.0026\n",
            "Epoch 3, Sample 12195: Loss: 0.3399\n",
            "Epoch 3, Sample 12196: Loss: 0.3402\n",
            "Epoch 3, Sample 12197: Loss: 0.3441\n",
            "Epoch 3, Sample 12198: Loss: 0.4607\n",
            "Epoch 3, Sample 12199: Loss: 0.0018\n",
            "Epoch 3, Sample 12200: Loss: 0.1863\n",
            "Epoch 3, Sample 12201: Loss: 0.3399\n",
            "Epoch 3, Sample 12202: Loss: 0.1559\n",
            "Epoch 3, Sample 12203: Loss: 0.2219\n",
            "Epoch 3, Sample 12204: Loss: 0.2044\n",
            "Epoch 3, Sample 12205: Loss: 0.2759\n",
            "Epoch 3, Sample 12206: Loss: 0.5858\n",
            "Epoch 3, Sample 12207: Loss: 8.4662\n",
            "Epoch 3, Sample 12208: Loss: 0.0026\n",
            "Epoch 3, Sample 12209: Loss: 0.0415\n",
            "Epoch 3, Sample 12210: Loss: 0.1248\n",
            "Epoch 3, Sample 12211: Loss: 0.0030\n",
            "Epoch 3, Sample 12212: Loss: 2.7331\n",
            "Epoch 3, Sample 12213: Loss: 4.4745\n",
            "Epoch 3, Sample 12214: Loss: 0.5858\n",
            "Epoch 3, Sample 12215: Loss: 0.3399\n",
            "Epoch 3, Sample 12216: Loss: 0.0108\n",
            "Epoch 3, Sample 12217: Loss: 0.0026\n",
            "Epoch 3, Sample 12218: Loss: 0.3441\n",
            "Epoch 3, Sample 12219: Loss: 1.0524\n",
            "Epoch 3, Sample 12220: Loss: 0.6990\n",
            "Epoch 3, Sample 12221: Loss: 0.2044\n",
            "Epoch 3, Sample 12222: Loss: 8.0504\n",
            "Epoch 3, Sample 12223: Loss: 0.0306\n",
            "Epoch 3, Sample 12224: Loss: 0.2340\n",
            "Epoch 3, Sample 12225: Loss: 0.2034\n",
            "Epoch 3, Sample 12226: Loss: 1.0551\n",
            "Epoch 3, Sample 12227: Loss: 0.1248\n",
            "Epoch 3, Sample 12228: Loss: 0.2219\n",
            "Epoch 3, Sample 12229: Loss: 0.5636\n",
            "Epoch 3, Sample 12230: Loss: 4.4745\n",
            "Epoch 3, Sample 12231: Loss: 0.4761\n",
            "Epoch 3, Sample 12232: Loss: 0.0505\n",
            "Epoch 3, Sample 12233: Loss: 0.0000\n",
            "Epoch 3, Sample 12234: Loss: 0.2832\n",
            "Epoch 3, Sample 12235: Loss: 0.9367\n",
            "Epoch 3, Sample 12236: Loss: 0.1250\n",
            "Epoch 3, Sample 12237: Loss: 0.1687\n",
            "Epoch 3, Sample 12238: Loss: 0.0238\n",
            "Epoch 3, Sample 12239: Loss: 0.3441\n",
            "Epoch 3, Sample 12240: Loss: 2.7331\n",
            "Epoch 3, Sample 12241: Loss: 3.9629\n",
            "Epoch 3, Sample 12242: Loss: 0.6867\n",
            "Epoch 3, Sample 12243: Loss: 0.0060\n",
            "Epoch 3, Sample 12244: Loss: 0.2044\n",
            "Epoch 3, Sample 12245: Loss: 1.0155\n",
            "Epoch 3, Sample 12246: Loss: 0.1248\n",
            "Epoch 3, Sample 12247: Loss: 2.3207\n",
            "Epoch 3, Sample 12248: Loss: 0.3441\n",
            "Epoch 3, Sample 12249: Loss: 0.2112\n",
            "Epoch 3, Sample 12250: Loss: 0.7036\n",
            "Epoch 3, Sample 12251: Loss: 0.0145\n",
            "Epoch 3, Sample 12252: Loss: 0.0067\n",
            "Epoch 3, Sample 12253: Loss: 1.0524\n",
            "Epoch 3, Sample 12254: Loss: 0.0303\n",
            "Epoch 3, Sample 12255: Loss: 0.2832\n",
            "Epoch 3, Sample 12256: Loss: 2.4541\n",
            "Epoch 3, Sample 12257: Loss: 0.2032\n",
            "Epoch 3, Sample 12258: Loss: 1.0524\n",
            "Epoch 3, Sample 12259: Loss: 0.2036\n",
            "Epoch 3, Sample 12260: Loss: 1.4537\n",
            "Epoch 3, Sample 12261: Loss: 0.8951\n",
            "Epoch 3, Sample 12262: Loss: 0.5972\n",
            "Epoch 3, Sample 12263: Loss: 0.0630\n",
            "Epoch 3, Sample 12264: Loss: 0.1252\n",
            "Epoch 3, Sample 12265: Loss: 3.7299\n",
            "Epoch 3, Sample 12266: Loss: 0.4930\n",
            "Epoch 3, Sample 12267: Loss: 17.3544\n",
            "Epoch 3, Sample 12268: Loss: 0.2044\n",
            "Epoch 3, Sample 12269: Loss: 0.1170\n",
            "Epoch 3, Sample 12270: Loss: 1.0524\n",
            "Epoch 3, Sample 12271: Loss: 0.3332\n",
            "Epoch 3, Sample 12272: Loss: 1.0524\n",
            "Epoch 3, Sample 12273: Loss: 2.7331\n",
            "Epoch 3, Sample 12274: Loss: 9.5046\n",
            "Epoch 3, Sample 12275: Loss: 0.0626\n",
            "Epoch 3, Sample 12276: Loss: 9.3274\n",
            "Epoch 3, Sample 12277: Loss: 0.8484\n",
            "Epoch 3, Sample 12278: Loss: 1.0524\n",
            "Epoch 3, Sample 12279: Loss: 1.2522\n",
            "Epoch 3, Sample 12280: Loss: 0.0270\n",
            "Epoch 3, Sample 12281: Loss: 0.2032\n",
            "Epoch 3, Sample 12282: Loss: 0.1248\n",
            "Epoch 3, Sample 12283: Loss: 2.8908\n",
            "Epoch 3, Sample 12284: Loss: 0.5972\n",
            "Epoch 3, Sample 12285: Loss: 1.0155\n",
            "Epoch 3, Sample 12286: Loss: 0.1938\n",
            "Epoch 3, Sample 12287: Loss: 0.2759\n",
            "Epoch 3, Sample 12288: Loss: 1.0956\n",
            "Epoch 3, Sample 12289: Loss: 0.0026\n",
            "Epoch 3, Sample 12290: Loss: 0.0082\n",
            "Epoch 3, Sample 12291: Loss: 0.3441\n",
            "Epoch 3, Sample 12292: Loss: 0.1273\n",
            "Epoch 3, Sample 12293: Loss: 0.7036\n",
            "Epoch 3, Sample 12294: Loss: 0.0026\n",
            "Epoch 3, Sample 12295: Loss: 1.5597\n",
            "Epoch 3, Sample 12296: Loss: 0.3294\n",
            "Epoch 3, Sample 12297: Loss: 3.6506\n",
            "Epoch 3, Sample 12298: Loss: 1.0524\n",
            "Epoch 3, Sample 12299: Loss: 0.2970\n",
            "Epoch 3, Sample 12300: Loss: 0.0063\n",
            "Epoch 3, Sample 12301: Loss: 0.1113\n",
            "Epoch 3, Sample 12302: Loss: 0.4799\n",
            "Epoch 3, Sample 12303: Loss: 0.5000\n",
            "Epoch 3, Sample 12304: Loss: 0.5858\n",
            "Epoch 3, Sample 12305: Loss: 0.2938\n",
            "Epoch 3, Sample 12306: Loss: 0.0630\n",
            "Epoch 3, Sample 12307: Loss: 1.0956\n",
            "Epoch 3, Sample 12308: Loss: 1.4537\n",
            "Epoch 3, Sample 12309: Loss: 1.0530\n",
            "Epoch 3, Sample 12310: Loss: 0.7036\n",
            "Epoch 3, Sample 12311: Loss: 0.1170\n",
            "Epoch 3, Sample 12312: Loss: 2.8693\n",
            "Epoch 3, Sample 12313: Loss: 0.3399\n",
            "Epoch 3, Sample 12314: Loss: 0.6653\n",
            "Epoch 3, Sample 12315: Loss: 0.1170\n",
            "Epoch 3, Sample 12316: Loss: 0.1248\n",
            "Epoch 3, Sample 12317: Loss: 0.2044\n",
            "Epoch 3, Sample 12318: Loss: 0.1248\n",
            "Epoch 3, Sample 12319: Loss: 0.6990\n",
            "Epoch 3, Sample 12320: Loss: 0.2032\n",
            "Epoch 3, Sample 12321: Loss: 0.5062\n",
            "Epoch 3, Sample 12322: Loss: 1.0524\n",
            "Epoch 3, Sample 12323: Loss: 0.2962\n",
            "Epoch 3, Sample 12324: Loss: 1.0524\n",
            "Epoch 3, Sample 12325: Loss: 1.0524\n",
            "Epoch 3, Sample 12326: Loss: 0.0623\n",
            "Epoch 3, Sample 12327: Loss: 1.0530\n",
            "Epoch 3, Sample 12328: Loss: 0.1372\n",
            "Epoch 3, Sample 12329: Loss: 0.1559\n",
            "Epoch 3, Sample 12330: Loss: 0.0005\n",
            "Epoch 3, Sample 12331: Loss: 0.0031\n",
            "Epoch 3, Sample 12332: Loss: 5.1063\n",
            "Epoch 3, Sample 12333: Loss: 0.9024\n",
            "Epoch 3, Sample 12334: Loss: 0.9780\n",
            "Epoch 3, Sample 12335: Loss: 2.7331\n",
            "Epoch 3, Sample 12336: Loss: 0.1039\n",
            "Epoch 3, Sample 12337: Loss: 0.0063\n",
            "Epoch 3, Sample 12338: Loss: 7.4082\n",
            "Epoch 3, Sample 12339: Loss: 0.6867\n",
            "Epoch 3, Sample 12340: Loss: 0.3949\n",
            "Epoch 3, Sample 12341: Loss: 0.0026\n",
            "Epoch 3, Sample 12342: Loss: 1.0155\n",
            "Epoch 3, Sample 12343: Loss: 40.0936\n",
            "Epoch 3, Sample 12344: Loss: 0.7036\n",
            "Epoch 3, Sample 12345: Loss: 0.0001\n",
            "Epoch 3, Sample 12346: Loss: 0.4930\n",
            "Epoch 3, Sample 12347: Loss: 0.7036\n",
            "Epoch 3, Sample 12348: Loss: 0.5196\n",
            "Epoch 3, Sample 12349: Loss: 0.2036\n",
            "Epoch 3, Sample 12350: Loss: 0.9785\n",
            "Epoch 3, Sample 12351: Loss: 1.0155\n",
            "Epoch 3, Sample 12352: Loss: 0.1463\n",
            "Epoch 3, Sample 12353: Loss: 0.6092\n",
            "Epoch 3, Sample 12354: Loss: 1.5597\n",
            "Epoch 3, Sample 12355: Loss: 0.0062\n",
            "Epoch 3, Sample 12356: Loss: 0.2832\n",
            "Epoch 3, Sample 12357: Loss: 0.5858\n",
            "Epoch 3, Sample 12358: Loss: 0.3949\n",
            "Epoch 3, Sample 12359: Loss: 0.0415\n",
            "Epoch 3, Sample 12360: Loss: 4.9827\n",
            "Epoch 3, Sample 12361: Loss: 0.0026\n",
            "Epoch 3, Sample 12362: Loss: 0.7036\n",
            "Epoch 3, Sample 12363: Loss: 0.0630\n",
            "Epoch 3, Sample 12364: Loss: 1.0266\n",
            "Epoch 3, Sample 12365: Loss: 1.4128\n",
            "Epoch 3, Sample 12366: Loss: 0.3402\n",
            "Epoch 3, Sample 12367: Loss: 1.7066\n",
            "Epoch 3, Sample 12368: Loss: 0.0953\n",
            "Epoch 3, Sample 12369: Loss: 1.0524\n",
            "Epoch 3, Sample 12370: Loss: 1.0155\n",
            "Epoch 3, Sample 12371: Loss: 0.1478\n",
            "Epoch 3, Sample 12372: Loss: 0.3399\n",
            "Epoch 3, Sample 12373: Loss: 0.9780\n",
            "Epoch 3, Sample 12374: Loss: 0.1508\n",
            "Epoch 3, Sample 12375: Loss: 0.0306\n",
            "Epoch 3, Sample 12376: Loss: 0.2034\n",
            "Epoch 3, Sample 12377: Loss: 0.2044\n",
            "Epoch 3, Sample 12378: Loss: 0.8484\n",
            "Epoch 3, Sample 12379: Loss: 7.6710\n",
            "Epoch 3, Sample 12380: Loss: 0.0026\n",
            "Epoch 3, Sample 12381: Loss: 0.2034\n",
            "Epoch 3, Sample 12382: Loss: 10.1372\n",
            "Epoch 3, Sample 12383: Loss: 1.5597\n",
            "Epoch 3, Sample 12384: Loss: 0.0013\n",
            "Epoch 3, Sample 12385: Loss: 0.3852\n",
            "Epoch 3, Sample 12386: Loss: 0.7036\n",
            "Epoch 3, Sample 12387: Loss: 0.7036\n",
            "Epoch 3, Sample 12388: Loss: 0.5972\n",
            "Epoch 3, Sample 12389: Loss: 0.4799\n",
            "Epoch 3, Sample 12390: Loss: 0.0018\n",
            "Epoch 3, Sample 12391: Loss: 0.3441\n",
            "Epoch 3, Sample 12392: Loss: 0.7036\n",
            "Epoch 3, Sample 12393: Loss: 3.1294\n",
            "Epoch 3, Sample 12394: Loss: 2.7989\n",
            "Epoch 3, Sample 12395: Loss: 1.0524\n",
            "Epoch 3, Sample 12396: Loss: 0.4841\n",
            "Epoch 3, Sample 12397: Loss: 0.2204\n",
            "Epoch 3, Sample 12398: Loss: 0.2759\n",
            "Epoch 3, Sample 12399: Loss: 1.5597\n",
            "Epoch 3, Sample 12400: Loss: 1.0155\n",
            "Epoch 3, Sample 12401: Loss: 1.5597\n",
            "Epoch 3, Sample 12402: Loss: 0.7702\n",
            "Epoch 3, Sample 12403: Loss: 0.0026\n",
            "Epoch 3, Sample 12404: Loss: 0.2989\n",
            "Epoch 3, Sample 12405: Loss: 0.1170\n",
            "Epoch 3, Sample 12406: Loss: 0.0860\n",
            "Epoch 3, Sample 12407: Loss: 1.0524\n",
            "Epoch 3, Sample 12408: Loss: 0.1588\n",
            "Epoch 3, Sample 12409: Loss: 0.0026\n",
            "Epoch 3, Sample 12410: Loss: 1.7195\n",
            "Epoch 3, Sample 12411: Loss: 0.1250\n",
            "Epoch 3, Sample 12412: Loss: 4.7115\n",
            "Epoch 3, Sample 12413: Loss: 1.0524\n",
            "Epoch 3, Sample 12414: Loss: 0.0018\n",
            "Epoch 3, Sample 12415: Loss: 1.0359\n",
            "Epoch 3, Sample 12416: Loss: 0.1250\n",
            "Epoch 3, Sample 12417: Loss: 0.5858\n",
            "Epoch 3, Sample 12418: Loss: 1.0530\n",
            "Epoch 3, Sample 12419: Loss: 0.4466\n",
            "Epoch 3, Sample 12420: Loss: 0.0915\n",
            "Epoch 3, Sample 12421: Loss: 1.2198\n",
            "Epoch 3, Sample 12422: Loss: 0.2699\n",
            "Epoch 3, Sample 12423: Loss: 0.1559\n",
            "Epoch 3, Sample 12424: Loss: 0.7036\n",
            "Epoch 3, Sample 12425: Loss: 1.5597\n",
            "Epoch 3, Sample 12426: Loss: 0.0915\n",
            "Epoch 3, Sample 12427: Loss: 0.0630\n",
            "Epoch 3, Sample 12428: Loss: 0.1372\n",
            "Epoch 3, Sample 12429: Loss: 0.2034\n",
            "Epoch 3, Sample 12430: Loss: 0.5972\n",
            "Epoch 3, Sample 12431: Loss: 3.5504\n",
            "Epoch 3, Sample 12432: Loss: 0.3399\n",
            "Epoch 3, Sample 12433: Loss: 0.6190\n",
            "Epoch 3, Sample 12434: Loss: 0.7036\n",
            "Epoch 3, Sample 12435: Loss: 0.4841\n",
            "Epoch 3, Sample 12436: Loss: 0.1559\n",
            "Epoch 3, Sample 12437: Loss: 0.2032\n",
            "Epoch 3, Sample 12438: Loss: 0.0026\n",
            "Epoch 3, Sample 12439: Loss: 1.0359\n",
            "Epoch 3, Sample 12440: Loss: 1.0155\n",
            "Epoch 3, Sample 12441: Loss: 1.0524\n",
            "Epoch 3, Sample 12442: Loss: 0.2200\n",
            "Epoch 3, Sample 12443: Loss: 0.0513\n",
            "Epoch 3, Sample 12444: Loss: 13.1892\n",
            "Epoch 3, Sample 12445: Loss: 1.5597\n",
            "Epoch 3, Sample 12446: Loss: 0.5003\n",
            "Epoch 3, Sample 12447: Loss: 1.0956\n",
            "Epoch 3, Sample 12448: Loss: 0.0147\n",
            "Epoch 3, Sample 12449: Loss: 1.0524\n",
            "Epoch 3, Sample 12450: Loss: 0.4032\n",
            "Epoch 3, Sample 12451: Loss: 0.0063\n",
            "Epoch 3, Sample 12452: Loss: 0.3949\n",
            "Epoch 3, Sample 12453: Loss: 0.8951\n",
            "Epoch 3, Sample 12454: Loss: 4.0002\n",
            "Epoch 3, Sample 12455: Loss: 2.4541\n",
            "Epoch 3, Sample 12456: Loss: 0.0005\n",
            "Epoch 3, Sample 12457: Loss: 0.2182\n",
            "Epoch 3, Sample 12458: Loss: 0.7036\n",
            "Epoch 3, Sample 12459: Loss: 0.8951\n",
            "Epoch 3, Sample 12460: Loss: 0.3949\n",
            "Epoch 3, Sample 12461: Loss: 0.1248\n",
            "Epoch 3, Sample 12462: Loss: 0.5972\n",
            "Epoch 3, Sample 12463: Loss: 0.5000\n",
            "Epoch 3, Sample 12464: Loss: 1.0359\n",
            "Epoch 3, Sample 12465: Loss: 0.6304\n",
            "Epoch 3, Sample 12466: Loss: 0.0205\n",
            "Epoch 3, Sample 12467: Loss: 0.2219\n",
            "Epoch 3, Sample 12468: Loss: 0.0537\n",
            "Epoch 3, Sample 12469: Loss: 1.6326\n",
            "Epoch 3, Sample 12470: Loss: 0.2034\n",
            "Epoch 3, Sample 12471: Loss: 0.6867\n",
            "Epoch 3, Sample 12472: Loss: 0.2044\n",
            "Epoch 3, Sample 12473: Loss: 0.2036\n",
            "Epoch 3, Sample 12474: Loss: 0.0041\n",
            "Epoch 3, Sample 12475: Loss: 0.9367\n",
            "Epoch 3, Sample 12476: Loss: 0.7453\n",
            "Epoch 3, Sample 12477: Loss: 0.0364\n",
            "Epoch 3, Sample 12478: Loss: 0.1044\n",
            "Epoch 3, Sample 12479: Loss: 0.0744\n",
            "Epoch 3, Sample 12480: Loss: 0.2112\n",
            "Epoch 3, Sample 12481: Loss: 7.6726\n",
            "Epoch 3, Sample 12482: Loss: 0.4367\n",
            "Epoch 3, Sample 12483: Loss: 0.2036\n",
            "Epoch 3, Sample 12484: Loss: 0.3402\n",
            "Epoch 3, Sample 12485: Loss: 1.0359\n",
            "Epoch 3, Sample 12486: Loss: 0.4906\n",
            "Epoch 3, Sample 12487: Loss: 1.5597\n",
            "Epoch 3, Sample 12488: Loss: 0.5496\n",
            "Epoch 3, Sample 12489: Loss: 0.0027\n",
            "Epoch 3, Sample 12490: Loss: 0.7036\n",
            "Epoch 3, Sample 12491: Loss: 0.0108\n",
            "Epoch 3, Sample 12492: Loss: 0.7036\n",
            "Epoch 3, Sample 12493: Loss: 0.2044\n",
            "Epoch 3, Sample 12494: Loss: 1.0530\n",
            "Epoch 3, Sample 12495: Loss: 0.2759\n",
            "Epoch 3, Sample 12496: Loss: 8.0504\n",
            "Epoch 3, Sample 12497: Loss: 0.1170\n",
            "Epoch 3, Sample 12498: Loss: 0.2034\n",
            "Epoch 3, Sample 12499: Loss: 0.7036\n",
            "Epoch 3, Sample 12500: Loss: 0.0026\n",
            "Epoch 3, Sample 12501: Loss: 0.0018\n",
            "Epoch 3, Sample 12502: Loss: 7.6726\n",
            "Epoch 3, Sample 12503: Loss: 0.1594\n",
            "Epoch 3, Sample 12504: Loss: 1.2845\n",
            "Epoch 3, Sample 12505: Loss: 0.0108\n",
            "Epoch 3, Sample 12506: Loss: 0.1219\n",
            "Epoch 3, Sample 12507: Loss: 0.1248\n",
            "Epoch 3, Sample 12508: Loss: 0.2941\n",
            "Epoch 3, Sample 12509: Loss: 0.2044\n",
            "Epoch 3, Sample 12510: Loss: 0.4611\n",
            "Epoch 3, Sample 12511: Loss: 0.2340\n",
            "Epoch 3, Sample 12512: Loss: 0.1114\n",
            "Epoch 3, Sample 12513: Loss: 0.1056\n",
            "Epoch 3, Sample 12514: Loss: 0.7036\n",
            "Epoch 3, Sample 12515: Loss: 1.0524\n",
            "Epoch 3, Sample 12516: Loss: 0.0026\n",
            "Epoch 3, Sample 12517: Loss: 0.1248\n",
            "Epoch 3, Sample 12518: Loss: 0.3088\n",
            "Epoch 3, Sample 12519: Loss: 3.5504\n",
            "Epoch 3, Sample 12520: Loss: 0.1248\n",
            "Epoch 3, Sample 12521: Loss: 0.0013\n",
            "Epoch 3, Sample 12522: Loss: 0.0031\n",
            "Epoch 3, Sample 12523: Loss: 0.0001\n",
            "Epoch 3, Sample 12524: Loss: 0.3399\n",
            "Epoch 3, Sample 12525: Loss: 0.9367\n",
            "Epoch 3, Sample 12526: Loss: 2.7331\n",
            "Epoch 3, Sample 12527: Loss: 1.0524\n",
            "Epoch 3, Sample 12528: Loss: 0.3399\n",
            "Epoch 3, Sample 12529: Loss: 17.5959\n",
            "Epoch 3, Sample 12530: Loss: 0.2363\n",
            "Epoch 3, Sample 12531: Loss: 0.9780\n",
            "Epoch 3, Sample 12532: Loss: 0.0212\n",
            "Epoch 3, Sample 12533: Loss: 0.0027\n",
            "Epoch 3, Sample 12534: Loss: 1.0155\n",
            "Epoch 3, Sample 12535: Loss: 0.0625\n",
            "Epoch 3, Sample 12536: Loss: 0.3539\n",
            "Epoch 3, Sample 12537: Loss: 0.3402\n",
            "Epoch 3, Sample 12538: Loss: 0.8951\n",
            "Epoch 3, Sample 12539: Loss: 0.1170\n",
            "Epoch 3, Sample 12540: Loss: 0.2855\n",
            "Epoch 3, Sample 12541: Loss: 0.2044\n",
            "Epoch 3, Sample 12542: Loss: 0.1250\n",
            "Epoch 3, Sample 12543: Loss: 0.0938\n",
            "Epoch 3, Sample 12544: Loss: 0.7036\n",
            "Epoch 3, Sample 12545: Loss: 1.0524\n",
            "Epoch 3, Sample 12546: Loss: 1.2926\n",
            "Epoch 3, Sample 12547: Loss: 0.0938\n",
            "Epoch 3, Sample 12548: Loss: 0.1355\n",
            "Epoch 3, Sample 12549: Loss: 1.5597\n",
            "Epoch 3, Sample 12550: Loss: 0.0000\n",
            "Epoch 3, Sample 12551: Loss: 2.0233\n",
            "Epoch 3, Sample 12552: Loss: 0.0013\n",
            "Epoch 3, Sample 12553: Loss: 0.2044\n",
            "Epoch 3, Sample 12554: Loss: 0.0189\n",
            "Epoch 3, Sample 12555: Loss: 1.5542\n",
            "Epoch 3, Sample 12556: Loss: 0.0026\n",
            "Epoch 3, Sample 12557: Loss: 0.1233\n",
            "Epoch 3, Sample 12558: Loss: 0.1250\n",
            "Epoch 3, Sample 12559: Loss: 2.5104\n",
            "Epoch 3, Sample 12560: Loss: 1.5597\n",
            "Epoch 3, Sample 12561: Loss: 0.1250\n",
            "Epoch 3, Sample 12562: Loss: 1.0727\n",
            "Epoch 3, Sample 12563: Loss: 2.7331\n",
            "Epoch 3, Sample 12564: Loss: 1.0956\n",
            "Epoch 3, Sample 12565: Loss: 1.0956\n",
            "Epoch 3, Sample 12566: Loss: 0.1463\n",
            "Epoch 3, Sample 12567: Loss: 0.1508\n",
            "Epoch 3, Sample 12568: Loss: 0.7036\n",
            "Epoch 3, Sample 12569: Loss: 7.7260\n",
            "Epoch 3, Sample 12570: Loss: 0.0108\n",
            "Epoch 3, Sample 12571: Loss: 0.0007\n",
            "Epoch 3, Sample 12572: Loss: 0.0106\n",
            "Epoch 3, Sample 12573: Loss: 1.2845\n",
            "Epoch 3, Sample 12574: Loss: 10.8862\n",
            "Epoch 3, Sample 12575: Loss: 0.2034\n",
            "Epoch 3, Sample 12576: Loss: 2.0225\n",
            "Epoch 3, Sample 12577: Loss: 0.0466\n",
            "Epoch 3, Sample 12578: Loss: 0.1250\n",
            "Epoch 3, Sample 12579: Loss: 0.0205\n",
            "Epoch 3, Sample 12580: Loss: 0.0108\n",
            "Epoch 3, Sample 12581: Loss: 0.2989\n",
            "Epoch 3, Sample 12582: Loss: 0.0063\n",
            "Epoch 3, Sample 12583: Loss: 1.0524\n",
            "Epoch 3, Sample 12584: Loss: 0.0026\n",
            "Epoch 3, Sample 12585: Loss: 1.0956\n",
            "Epoch 3, Sample 12586: Loss: 1.5597\n",
            "Epoch 3, Sample 12587: Loss: 0.9780\n",
            "Epoch 3, Sample 12588: Loss: 1.0524\n",
            "Epoch 3, Sample 12589: Loss: 0.1250\n",
            "Epoch 3, Sample 12590: Loss: 0.7183\n",
            "Epoch 3, Sample 12591: Loss: 0.0630\n",
            "Epoch 3, Sample 12592: Loss: 2.1901\n",
            "Epoch 3, Sample 12593: Loss: 2.7331\n",
            "Epoch 3, Sample 12594: Loss: 0.9367\n",
            "Epoch 3, Sample 12595: Loss: 0.7628\n",
            "Epoch 3, Sample 12596: Loss: 0.2034\n",
            "Epoch 3, Sample 12597: Loss: 2.4326\n",
            "Epoch 3, Sample 12598: Loss: 0.2759\n",
            "Epoch 3, Sample 12599: Loss: 0.7453\n",
            "Epoch 3, Sample 12600: Loss: 2.5454\n",
            "Epoch 3, Sample 12601: Loss: 0.0022\n",
            "Epoch 3, Sample 12602: Loss: 1.0524\n",
            "Epoch 3, Sample 12603: Loss: 12.6690\n",
            "Epoch 3, Sample 12604: Loss: 0.0026\n",
            "Epoch 3, Sample 12605: Loss: 0.7036\n",
            "Epoch 3, Sample 12606: Loss: 1.0359\n",
            "Epoch 3, Sample 12607: Loss: 0.1246\n",
            "Epoch 3, Sample 12608: Loss: 0.1225\n",
            "Epoch 3, Sample 12609: Loss: 0.0026\n",
            "Epoch 3, Sample 12610: Loss: 7.7260\n",
            "Epoch 3, Sample 12611: Loss: 0.0205\n",
            "Epoch 3, Sample 12612: Loss: 0.2034\n",
            "Epoch 3, Sample 12613: Loss: 0.0025\n",
            "Epoch 3, Sample 12614: Loss: 0.0604\n",
            "Epoch 3, Sample 12615: Loss: 2.8693\n",
            "Epoch 3, Sample 12616: Loss: 7.4082\n",
            "Epoch 3, Sample 12617: Loss: 0.2044\n",
            "Epoch 3, Sample 12618: Loss: 0.2811\n",
            "Epoch 3, Sample 12619: Loss: 0.1170\n",
            "Epoch 3, Sample 12620: Loss: 0.2759\n",
            "Epoch 3, Sample 12621: Loss: 0.2044\n",
            "Epoch 3, Sample 12622: Loss: 0.5858\n",
            "Epoch 3, Sample 12623: Loss: 0.0306\n",
            "Epoch 3, Sample 12624: Loss: 0.0033\n",
            "Epoch 3, Sample 12625: Loss: 0.2962\n",
            "Epoch 3, Sample 12626: Loss: 0.3441\n",
            "Epoch 3, Sample 12627: Loss: 0.0258\n",
            "Epoch 3, Sample 12628: Loss: 0.1549\n",
            "Epoch 3, Sample 12629: Loss: 0.2032\n",
            "Epoch 3, Sample 12630: Loss: 0.1248\n",
            "Epoch 3, Sample 12631: Loss: 0.9367\n",
            "Epoch 3, Sample 12632: Loss: 0.2034\n",
            "Epoch 3, Sample 12633: Loss: 0.0099\n",
            "Epoch 3, Sample 12634: Loss: 0.0363\n",
            "Epoch 3, Sample 12635: Loss: 0.1523\n",
            "Epoch 3, Sample 12636: Loss: 0.0513\n",
            "Epoch 3, Sample 12637: Loss: 0.1417\n",
            "Epoch 3, Sample 12638: Loss: 0.2044\n",
            "Epoch 3, Sample 12639: Loss: 0.0630\n",
            "Epoch 3, Sample 12640: Loss: 0.0063\n",
            "Epoch 3, Sample 12641: Loss: 0.7910\n",
            "Epoch 3, Sample 12642: Loss: 0.1777\n",
            "Epoch 3, Sample 12643: Loss: 1.1263\n",
            "Epoch 3, Sample 12644: Loss: 1.0524\n",
            "Epoch 3, Sample 12645: Loss: 0.3568\n",
            "Epoch 3, Sample 12646: Loss: 0.7453\n",
            "Epoch 3, Sample 12647: Loss: 0.0062\n",
            "Epoch 3, Sample 12648: Loss: 0.0205\n",
            "Epoch 3, Sample 12649: Loss: 0.0630\n",
            "Epoch 3, Sample 12650: Loss: 0.4611\n",
            "Epoch 3, Sample 12651: Loss: 0.1692\n",
            "Epoch 3, Sample 12652: Loss: 0.2044\n",
            "Epoch 3, Sample 12653: Loss: 1.0956\n",
            "Epoch 3, Sample 12654: Loss: 1.0155\n",
            "Epoch 3, Sample 12655: Loss: 9.0738\n",
            "Epoch 3, Sample 12656: Loss: 3.9018\n",
            "Epoch 3, Sample 12657: Loss: 0.3441\n",
            "Epoch 3, Sample 12658: Loss: 0.4841\n",
            "Epoch 3, Sample 12659: Loss: 0.1546\n",
            "Epoch 3, Sample 12660: Loss: 0.4930\n",
            "Epoch 3, Sample 12661: Loss: 0.0018\n",
            "Epoch 3, Sample 12662: Loss: 0.7036\n",
            "Epoch 3, Sample 12663: Loss: 0.0212\n",
            "Epoch 3, Sample 12664: Loss: 0.1546\n",
            "Epoch 3, Sample 12665: Loss: 0.3399\n",
            "Epoch 3, Sample 12666: Loss: 0.2044\n",
            "Epoch 3, Sample 12667: Loss: 1.0530\n",
            "Epoch 3, Sample 12668: Loss: 0.0084\n",
            "Epoch 3, Sample 12669: Loss: 2.7989\n",
            "Epoch 3, Sample 12670: Loss: 0.0028\n",
            "Epoch 3, Sample 12671: Loss: 0.5858\n",
            "Epoch 3, Sample 12672: Loss: 3.5504\n",
            "Epoch 3, Sample 12673: Loss: 0.7453\n",
            "Epoch 3, Sample 12674: Loss: 0.0001\n",
            "Epoch 3, Sample 12675: Loss: 0.5799\n",
            "Epoch 3, Sample 12676: Loss: 0.9780\n",
            "Epoch 3, Sample 12677: Loss: 7.2518\n",
            "Epoch 3, Sample 12678: Loss: 0.3399\n",
            "Epoch 3, Sample 12679: Loss: 0.2032\n",
            "Epoch 3, Sample 12680: Loss: 16.9580\n",
            "Epoch 3, Sample 12681: Loss: 1.0524\n",
            "Epoch 3, Sample 12682: Loss: 0.3441\n",
            "Epoch 3, Sample 12683: Loss: 0.1863\n",
            "Epoch 3, Sample 12684: Loss: 0.0840\n",
            "Epoch 3, Sample 12685: Loss: 0.1555\n",
            "Epoch 3, Sample 12686: Loss: 10.6983\n",
            "Epoch 3, Sample 12687: Loss: 2.1901\n",
            "Epoch 3, Sample 12688: Loss: 0.2032\n",
            "Epoch 3, Sample 12689: Loss: 1.0524\n",
            "Epoch 3, Sample 12690: Loss: 0.2032\n",
            "Epoch 3, Sample 12691: Loss: 0.1250\n",
            "Epoch 3, Sample 12692: Loss: 0.0234\n",
            "Epoch 3, Sample 12693: Loss: 0.2219\n",
            "Epoch 3, Sample 12694: Loss: 0.2962\n",
            "Epoch 3, Sample 12695: Loss: 0.9367\n",
            "Epoch 3, Sample 12696: Loss: 0.5858\n",
            "Epoch 3, Sample 12697: Loss: 0.2044\n",
            "Epoch 3, Sample 12698: Loss: 15.4828\n",
            "Epoch 3, Sample 12699: Loss: 0.4799\n",
            "Epoch 3, Sample 12700: Loss: 0.2036\n",
            "Epoch 3, Sample 12701: Loss: 0.7910\n",
            "Epoch 3, Sample 12702: Loss: 22.7781\n",
            "Epoch 3, Sample 12703: Loss: 3.7714\n",
            "Epoch 3, Sample 12704: Loss: 1.0530\n",
            "Epoch 3, Sample 12705: Loss: 0.1248\n",
            "Epoch 3, Sample 12706: Loss: 0.2832\n",
            "Epoch 3, Sample 12707: Loss: 0.8951\n",
            "Epoch 3, Sample 12708: Loss: 0.1890\n",
            "Epoch 3, Sample 12709: Loss: 0.1394\n",
            "Epoch 3, Sample 12710: Loss: 0.2034\n",
            "Epoch 3, Sample 12711: Loss: 0.0630\n",
            "Epoch 3, Sample 12712: Loss: 0.2935\n",
            "Epoch 3, Sample 12713: Loss: 2.6384\n",
            "Epoch 3, Sample 12714: Loss: 0.0018\n",
            "Epoch 3, Sample 12715: Loss: 0.2044\n",
            "Epoch 3, Sample 12716: Loss: 0.0026\n",
            "Epoch 3, Sample 12717: Loss: 0.6990\n",
            "Epoch 3, Sample 12718: Loss: 1.0524\n",
            "Epoch 3, Sample 12719: Loss: 0.7702\n",
            "Epoch 3, Sample 12720: Loss: 0.0002\n",
            "Epoch 3, Sample 12721: Loss: 0.0026\n",
            "Epoch 3, Sample 12722: Loss: 0.4220\n",
            "Epoch 3, Sample 12723: Loss: 0.2750\n",
            "Epoch 3, Sample 12724: Loss: 0.5019\n",
            "Epoch 3, Sample 12725: Loss: 0.7036\n",
            "Epoch 3, Sample 12726: Loss: 0.7453\n",
            "Epoch 3, Sample 12727: Loss: 2.7331\n",
            "Epoch 3, Sample 12728: Loss: 2.0351\n",
            "Epoch 3, Sample 12729: Loss: 1.0155\n",
            "Epoch 3, Sample 12730: Loss: 1.0155\n",
            "Epoch 3, Sample 12731: Loss: 1.4884\n",
            "Epoch 3, Sample 12732: Loss: 0.0981\n",
            "Epoch 3, Sample 12733: Loss: 0.0460\n",
            "Epoch 3, Sample 12734: Loss: 1.3508\n",
            "Epoch 3, Sample 12735: Loss: 0.0558\n",
            "Epoch 3, Sample 12736: Loss: 2.7331\n",
            "Epoch 3, Sample 12737: Loss: 0.0640\n",
            "Epoch 3, Sample 12738: Loss: 0.4032\n",
            "Epoch 3, Sample 12739: Loss: 2.7331\n",
            "Epoch 3, Sample 12740: Loss: 1.3114\n",
            "Epoch 3, Sample 12741: Loss: 0.2832\n",
            "Epoch 3, Sample 12742: Loss: 0.2639\n",
            "Epoch 3, Sample 12743: Loss: 0.0027\n",
            "Epoch 3, Sample 12744: Loss: 1.0524\n",
            "Epoch 3, Sample 12745: Loss: 3.0780\n",
            "Epoch 3, Sample 12746: Loss: 0.0026\n",
            "Epoch 3, Sample 12747: Loss: 3.0780\n",
            "Epoch 3, Sample 12748: Loss: 0.0731\n",
            "Epoch 3, Sample 12749: Loss: 0.0018\n",
            "Epoch 3, Sample 12750: Loss: 1.0155\n",
            "Epoch 3, Sample 12751: Loss: 0.5858\n",
            "Epoch 3, Sample 12752: Loss: 0.1250\n",
            "Epoch 3, Sample 12753: Loss: 0.1250\n",
            "Epoch 3, Sample 12754: Loss: 0.0026\n",
            "Epoch 3, Sample 12755: Loss: 0.3399\n",
            "Epoch 3, Sample 12756: Loss: 0.1040\n",
            "Epoch 3, Sample 12757: Loss: 0.0590\n",
            "Epoch 3, Sample 12758: Loss: 1.0511\n",
            "Epoch 3, Sample 12759: Loss: 0.1337\n",
            "Epoch 3, Sample 12760: Loss: 0.1170\n",
            "Epoch 3, Sample 12761: Loss: 0.2112\n",
            "Epoch 3, Sample 12762: Loss: 0.3477\n",
            "Epoch 3, Sample 12763: Loss: 0.2132\n",
            "Epoch 3, Sample 12764: Loss: 0.2034\n",
            "Epoch 3, Sample 12765: Loss: 1.9658\n",
            "Epoch 3, Sample 12766: Loss: 1.6326\n",
            "Epoch 3, Sample 12767: Loss: 7.5663\n",
            "Epoch 3, Sample 12768: Loss: 0.2044\n",
            "Epoch 3, Sample 12769: Loss: 0.0205\n",
            "Epoch 3, Sample 12770: Loss: 0.0274\n",
            "Epoch 3, Sample 12771: Loss: 1.0155\n",
            "Epoch 3, Sample 12772: Loss: 1.5597\n",
            "Epoch 3, Sample 12773: Loss: 0.3399\n",
            "Epoch 3, Sample 12774: Loss: 0.3092\n",
            "Epoch 3, Sample 12775: Loss: 0.2036\n",
            "Epoch 3, Sample 12776: Loss: 0.6304\n",
            "Epoch 3, Sample 12777: Loss: 1.0530\n",
            "Epoch 3, Sample 12778: Loss: 0.5858\n",
            "Epoch 3, Sample 12779: Loss: 0.5858\n",
            "Epoch 3, Sample 12780: Loss: 2.7989\n",
            "Epoch 3, Sample 12781: Loss: 6.9441\n",
            "Epoch 3, Sample 12782: Loss: 1.0155\n",
            "Epoch 3, Sample 12783: Loss: 0.3568\n",
            "Epoch 3, Sample 12784: Loss: 2.8294\n",
            "Epoch 3, Sample 12785: Loss: 0.2175\n",
            "Epoch 3, Sample 12786: Loss: 0.2832\n",
            "Epoch 3, Sample 12787: Loss: 2.0983\n",
            "Epoch 3, Sample 12788: Loss: 0.7036\n",
            "Epoch 3, Sample 12789: Loss: 0.7036\n",
            "Epoch 3, Sample 12790: Loss: 1.0530\n",
            "Epoch 3, Sample 12791: Loss: 0.2204\n",
            "Epoch 3, Sample 12792: Loss: 0.9367\n",
            "Epoch 3, Sample 12793: Loss: 0.5196\n",
            "Epoch 3, Sample 12794: Loss: 0.2759\n",
            "Epoch 3, Sample 12795: Loss: 0.7036\n",
            "Epoch 3, Sample 12796: Loss: 0.0018\n",
            "Epoch 3, Sample 12797: Loss: 0.1252\n",
            "Epoch 3, Sample 12798: Loss: 0.2044\n",
            "Epoch 3, Sample 12799: Loss: 0.7036\n",
            "Epoch 3, Sample 12800: Loss: 0.2036\n",
            "Epoch 3, Sample 12801: Loss: 0.3402\n",
            "Epoch 3, Sample 12802: Loss: 0.3367\n",
            "Epoch 3, Sample 12803: Loss: 0.0067\n",
            "Epoch 3, Sample 12804: Loss: 0.2639\n",
            "Epoch 3, Sample 12805: Loss: 0.1246\n",
            "Epoch 3, Sample 12806: Loss: 1.6207\n",
            "Epoch 3, Sample 12807: Loss: 0.2032\n",
            "Epoch 3, Sample 12808: Loss: 0.2219\n",
            "Epoch 3, Sample 12809: Loss: 0.1246\n",
            "Epoch 3, Sample 12810: Loss: 2.7331\n",
            "Epoch 3, Sample 12811: Loss: 0.2034\n",
            "Epoch 3, Sample 12812: Loss: 0.5858\n",
            "Epoch 3, Sample 12813: Loss: 0.9780\n",
            "Epoch 3, Sample 12814: Loss: 0.2032\n",
            "Epoch 3, Sample 12815: Loss: 0.8951\n",
            "Epoch 3, Sample 12816: Loss: 0.4032\n",
            "Epoch 3, Sample 12817: Loss: 1.0155\n",
            "Epoch 3, Sample 12818: Loss: 0.0205\n",
            "Epoch 3, Sample 12819: Loss: 0.0108\n",
            "Epoch 3, Sample 12820: Loss: 0.2074\n",
            "Epoch 3, Sample 12821: Loss: 1.4537\n",
            "Epoch 3, Sample 12822: Loss: 0.2032\n",
            "Epoch 3, Sample 12823: Loss: 0.1199\n",
            "Epoch 3, Sample 12824: Loss: 0.1508\n",
            "Epoch 3, Sample 12825: Loss: 0.0714\n",
            "Epoch 3, Sample 12826: Loss: 0.2340\n",
            "Epoch 3, Sample 12827: Loss: 0.2032\n",
            "Epoch 3, Sample 12828: Loss: 0.2832\n",
            "Epoch 3, Sample 12829: Loss: 0.5858\n",
            "Epoch 3, Sample 12830: Loss: 0.0026\n",
            "Epoch 3, Sample 12831: Loss: 1.0956\n",
            "Epoch 3, Sample 12832: Loss: 1.8819\n",
            "Epoch 3, Sample 12833: Loss: 0.0031\n",
            "Epoch 3, Sample 12834: Loss: 0.0026\n",
            "Epoch 3, Sample 12835: Loss: 0.2290\n",
            "Epoch 3, Sample 12836: Loss: 1.5597\n",
            "Epoch 3, Sample 12837: Loss: 0.1246\n",
            "Epoch 3, Sample 12838: Loss: 0.0027\n",
            "Epoch 3, Sample 12839: Loss: 0.3945\n",
            "Epoch 3, Sample 12840: Loss: 0.2935\n",
            "Epoch 3, Sample 12841: Loss: 0.2704\n",
            "Epoch 3, Sample 12842: Loss: 0.0306\n",
            "Epoch 3, Sample 12843: Loss: 0.2032\n",
            "Epoch 3, Sample 12844: Loss: 0.0026\n",
            "Epoch 3, Sample 12845: Loss: 0.7036\n",
            "Epoch 3, Sample 12846: Loss: 0.5972\n",
            "Epoch 3, Sample 12847: Loss: 0.1559\n",
            "Epoch 3, Sample 12848: Loss: 0.0391\n",
            "Epoch 3, Sample 12849: Loss: 0.0915\n",
            "Epoch 3, Sample 12850: Loss: 0.4032\n",
            "Epoch 3, Sample 12851: Loss: 0.0306\n",
            "Epoch 3, Sample 12852: Loss: 0.0501\n",
            "Epoch 3, Sample 12853: Loss: 1.4676\n",
            "Epoch 3, Sample 12854: Loss: 0.2044\n",
            "Epoch 3, Sample 12855: Loss: 0.3441\n",
            "Epoch 3, Sample 12856: Loss: 0.0380\n",
            "Epoch 3, Sample 12857: Loss: 0.2032\n",
            "Epoch 3, Sample 12858: Loss: 0.4996\n",
            "Epoch 3, Sample 12859: Loss: 0.1252\n",
            "Epoch 3, Sample 12860: Loss: 1.0477\n",
            "Epoch 3, Sample 12861: Loss: 0.0002\n",
            "Epoch 3, Sample 12862: Loss: 0.8951\n",
            "Epoch 3, Sample 12863: Loss: 0.1250\n",
            "Epoch 3, Sample 12864: Loss: 0.0212\n",
            "Epoch 3, Sample 12865: Loss: 0.0680\n",
            "Epoch 3, Sample 12866: Loss: 0.0013\n",
            "Epoch 3, Sample 12867: Loss: 1.4537\n",
            "Epoch 3, Sample 12868: Loss: 0.2935\n",
            "Epoch 3, Sample 12869: Loss: 0.1250\n",
            "Epoch 3, Sample 12870: Loss: 0.8951\n",
            "Epoch 3, Sample 12871: Loss: 0.0205\n",
            "Epoch 3, Sample 12872: Loss: 0.8951\n",
            "Epoch 3, Sample 12873: Loss: 0.2032\n",
            "Epoch 3, Sample 12874: Loss: 1.2192\n",
            "Epoch 3, Sample 12875: Loss: 0.0108\n",
            "Epoch 3, Sample 12876: Loss: 0.3949\n",
            "Epoch 3, Sample 12877: Loss: 2.2765\n",
            "Epoch 3, Sample 12878: Loss: 0.2044\n",
            "Epoch 3, Sample 12879: Loss: 18.3303\n",
            "Epoch 3, Sample 12880: Loss: 0.7453\n",
            "Epoch 3, Sample 12881: Loss: 2.2690\n",
            "Epoch 3, Sample 12882: Loss: 0.4032\n",
            "Epoch 3, Sample 12883: Loss: 0.2034\n",
            "Epoch 3, Sample 12884: Loss: 0.9367\n",
            "Epoch 3, Sample 12885: Loss: 0.1622\n",
            "Epoch 3, Sample 12886: Loss: 0.2044\n",
            "Epoch 3, Sample 12887: Loss: 0.0026\n",
            "Epoch 3, Sample 12888: Loss: 0.7453\n",
            "Epoch 3, Sample 12889: Loss: 0.2832\n",
            "Epoch 3, Sample 12890: Loss: 0.0201\n",
            "Epoch 3, Sample 12891: Loss: 0.5858\n",
            "Epoch 3, Sample 12892: Loss: 0.5989\n",
            "Epoch 3, Sample 12893: Loss: 1.0524\n",
            "Epoch 3, Sample 12894: Loss: 0.0838\n",
            "Epoch 3, Sample 12895: Loss: 1.5597\n",
            "Epoch 3, Sample 12896: Loss: 0.2832\n",
            "Epoch 3, Sample 12897: Loss: 0.0011\n",
            "Epoch 3, Sample 12898: Loss: 0.0052\n",
            "Epoch 3, Sample 12899: Loss: 0.1786\n",
            "Epoch 3, Sample 12900: Loss: 1.0524\n",
            "Epoch 3, Sample 12901: Loss: 0.9780\n",
            "Epoch 3, Sample 12902: Loss: 0.0205\n",
            "Epoch 3, Sample 12903: Loss: 0.0049\n",
            "Epoch 3, Sample 12904: Loss: 0.1482\n",
            "Epoch 3, Sample 12905: Loss: 0.5972\n",
            "Epoch 3, Sample 12906: Loss: 1.0266\n",
            "Epoch 3, Sample 12907: Loss: 1.5597\n",
            "Epoch 3, Sample 12908: Loss: 0.1246\n",
            "Epoch 3, Sample 12909: Loss: 0.0001\n",
            "Epoch 3, Sample 12910: Loss: 0.0026\n",
            "Epoch 3, Sample 12911: Loss: 0.3288\n",
            "Epoch 3, Sample 12912: Loss: 0.1349\n",
            "Epoch 3, Sample 12913: Loss: 1.0956\n",
            "Epoch 3, Sample 12914: Loss: 0.1463\n",
            "Epoch 3, Sample 12915: Loss: 0.1508\n",
            "Epoch 3, Sample 12916: Loss: 0.7036\n",
            "Epoch 3, Sample 12917: Loss: 0.0018\n",
            "Epoch 3, Sample 12918: Loss: 0.0498\n",
            "Epoch 3, Sample 12919: Loss: 0.3247\n",
            "Epoch 3, Sample 12920: Loss: 0.5972\n",
            "Epoch 3, Sample 12921: Loss: 0.2219\n",
            "Epoch 3, Sample 12922: Loss: 1.5597\n",
            "Epoch 3, Sample 12923: Loss: 1.0359\n",
            "Epoch 3, Sample 12924: Loss: 0.0027\n",
            "Epoch 3, Sample 12925: Loss: 0.0079\n",
            "Epoch 3, Sample 12926: Loss: 0.2759\n",
            "Epoch 3, Sample 12927: Loss: 0.6304\n",
            "Epoch 3, Sample 12928: Loss: 0.0287\n",
            "Epoch 3, Sample 12929: Loss: 0.1170\n",
            "Epoch 3, Sample 12930: Loss: 0.1559\n",
            "Epoch 3, Sample 12931: Loss: 1.4537\n",
            "Epoch 3, Sample 12932: Loss: 0.0001\n",
            "Epoch 3, Sample 12933: Loss: 0.2034\n",
            "Epoch 3, Sample 12934: Loss: 1.0155\n",
            "Epoch 3, Sample 12935: Loss: 0.1356\n",
            "Epoch 3, Sample 12936: Loss: 5.8501\n",
            "Epoch 3, Sample 12937: Loss: 4.6602\n",
            "Epoch 3, Sample 12938: Loss: 0.0626\n",
            "Epoch 3, Sample 12939: Loss: 0.1559\n",
            "Epoch 3, Sample 12940: Loss: 0.4607\n",
            "Epoch 3, Sample 12941: Loss: 0.1588\n",
            "Epoch 3, Sample 12942: Loss: 0.1523\n",
            "Epoch 3, Sample 12943: Loss: 0.4799\n",
            "Epoch 3, Sample 12944: Loss: 0.0229\n",
            "Epoch 3, Sample 12945: Loss: 0.0972\n",
            "Epoch 3, Sample 12946: Loss: 0.1248\n",
            "Epoch 3, Sample 12947: Loss: 0.2182\n",
            "Epoch 3, Sample 12948: Loss: 0.4611\n",
            "Epoch 3, Sample 12949: Loss: 0.0108\n",
            "Epoch 3, Sample 12950: Loss: 0.0018\n",
            "Epoch 3, Sample 12951: Loss: 0.0915\n",
            "Epoch 3, Sample 12952: Loss: 0.5858\n",
            "Epoch 3, Sample 12953: Loss: 0.5633\n",
            "Epoch 3, Sample 12954: Loss: 1.0155\n",
            "Epoch 3, Sample 12955: Loss: 1.5597\n",
            "Epoch 3, Sample 12956: Loss: 0.1246\n",
            "Epoch 3, Sample 12957: Loss: 0.1240\n",
            "Epoch 3, Sample 12958: Loss: 0.3441\n",
            "Epoch 3, Sample 12959: Loss: 0.0018\n",
            "Epoch 3, Sample 12960: Loss: 0.2032\n",
            "Epoch 3, Sample 12961: Loss: 0.8951\n",
            "Epoch 3, Sample 12962: Loss: 0.0270\n",
            "Epoch 3, Sample 12963: Loss: 17.7184\n",
            "Epoch 3, Sample 12964: Loss: 1.0359\n",
            "Epoch 3, Sample 12965: Loss: 0.2044\n",
            "Epoch 3, Sample 12966: Loss: 7.6726\n",
            "Epoch 3, Sample 12967: Loss: 0.1248\n",
            "Epoch 3, Sample 12968: Loss: 0.1250\n",
            "Epoch 3, Sample 12969: Loss: 0.0363\n",
            "Epoch 3, Sample 12970: Loss: 0.2032\n",
            "Epoch 3, Sample 12971: Loss: 0.6839\n",
            "Epoch 3, Sample 12972: Loss: 0.2044\n",
            "Epoch 3, Sample 12973: Loss: 0.5858\n",
            "Epoch 3, Sample 12974: Loss: 5.7798\n",
            "Epoch 3, Sample 12975: Loss: 0.4611\n",
            "Epoch 3, Sample 12976: Loss: 0.0287\n",
            "Epoch 3, Sample 12977: Loss: 1.0524\n",
            "Epoch 3, Sample 12978: Loss: 0.2750\n",
            "Epoch 3, Sample 12979: Loss: 0.1170\n",
            "Epoch 3, Sample 12980: Loss: 0.2044\n",
            "Epoch 3, Sample 12981: Loss: 0.6990\n",
            "Epoch 3, Sample 12982: Loss: 0.2778\n",
            "Epoch 3, Sample 12983: Loss: 0.5972\n",
            "Epoch 3, Sample 12984: Loss: 1.0524\n",
            "Epoch 3, Sample 12985: Loss: 0.1250\n",
            "Epoch 3, Sample 12986: Loss: 6.3986\n",
            "Epoch 3, Sample 12987: Loss: 0.0005\n",
            "Epoch 3, Sample 12988: Loss: 0.1687\n",
            "Epoch 3, Sample 12989: Loss: 0.2759\n",
            "Epoch 3, Sample 12990: Loss: 0.6720\n",
            "Epoch 3, Sample 12991: Loss: 0.1250\n",
            "Epoch 3, Sample 12992: Loss: 0.3399\n",
            "Epoch 3, Sample 12993: Loss: 2.7331\n",
            "Epoch 3, Sample 12994: Loss: 0.1170\n",
            "Epoch 3, Sample 12995: Loss: 0.0640\n",
            "Epoch 3, Sample 12996: Loss: 0.7036\n",
            "Epoch 3, Sample 12997: Loss: 0.0026\n",
            "Epoch 3, Sample 12998: Loss: 1.0524\n",
            "Epoch 3, Sample 12999: Loss: 0.0062\n",
            "Epoch 3, Sample 13000: Loss: 0.1559\n",
            "Epoch 3, Sample 13001: Loss: 0.2044\n",
            "Epoch 3, Sample 13002: Loss: 10.0289\n",
            "Epoch 3, Sample 13003: Loss: 1.0155\n",
            "Epoch 3, Sample 13004: Loss: 3.8942\n",
            "Epoch 3, Sample 13005: Loss: 0.0026\n",
            "Epoch 3, Sample 13006: Loss: 0.0026\n",
            "Epoch 3, Sample 13007: Loss: 1.8623\n",
            "Epoch 3, Sample 13008: Loss: 0.2686\n",
            "Epoch 3, Sample 13009: Loss: 1.0524\n",
            "Epoch 3, Sample 13010: Loss: 0.1523\n",
            "Epoch 3, Sample 13011: Loss: 0.0067\n",
            "Epoch 3, Sample 13012: Loss: 1.5597\n",
            "Epoch 3, Sample 13013: Loss: 1.0524\n",
            "Epoch 3, Sample 13014: Loss: 0.2034\n",
            "Epoch 3, Sample 13015: Loss: 0.3399\n",
            "Epoch 3, Sample 13016: Loss: 0.2036\n",
            "Epoch 3, Sample 13017: Loss: 0.0947\n",
            "Epoch 3, Sample 13018: Loss: 1.0524\n",
            "Epoch 3, Sample 13019: Loss: 10.6965\n",
            "Epoch 3, Sample 13020: Loss: 1.4537\n",
            "Epoch 3, Sample 13021: Loss: 2.0233\n",
            "Epoch 3, Sample 13022: Loss: 0.2044\n",
            "Epoch 3, Sample 13023: Loss: 0.2044\n",
            "Epoch 3, Sample 13024: Loss: 0.3477\n",
            "Epoch 3, Sample 13025: Loss: 3.5504\n",
            "Epoch 3, Sample 13026: Loss: 0.5871\n",
            "Epoch 3, Sample 13027: Loss: 1.0155\n",
            "Epoch 3, Sample 13028: Loss: 0.0455\n",
            "Epoch 3, Sample 13029: Loss: 1.0155\n",
            "Epoch 3, Sample 13030: Loss: 0.0455\n",
            "Epoch 3, Sample 13031: Loss: 1.0530\n",
            "Epoch 3, Sample 13032: Loss: 0.7910\n",
            "Epoch 3, Sample 13033: Loss: 1.6701\n",
            "Epoch 3, Sample 13034: Loss: 0.3399\n",
            "Epoch 3, Sample 13035: Loss: 0.3399\n",
            "Epoch 3, Sample 13036: Loss: 0.5858\n",
            "Epoch 3, Sample 13037: Loss: 0.3805\n",
            "Epoch 3, Sample 13038: Loss: 0.3949\n",
            "Epoch 3, Sample 13039: Loss: 0.7036\n",
            "Epoch 3, Sample 13040: Loss: 0.2034\n",
            "Epoch 3, Sample 13041: Loss: 0.4845\n",
            "Epoch 3, Sample 13042: Loss: 1.0524\n",
            "Epoch 3, Sample 13043: Loss: 0.6304\n",
            "Epoch 3, Sample 13044: Loss: 2.8731\n",
            "Epoch 3, Sample 13045: Loss: 0.5871\n",
            "Epoch 3, Sample 13046: Loss: 9.5046\n",
            "Epoch 3, Sample 13047: Loss: 0.9780\n",
            "Epoch 3, Sample 13048: Loss: 0.0630\n",
            "Epoch 3, Sample 13049: Loss: 1.5597\n",
            "Epoch 3, Sample 13050: Loss: 0.2036\n",
            "Epoch 3, Sample 13051: Loss: 0.0000\n",
            "Epoch 3, Sample 13052: Loss: 0.0002\n",
            "Epoch 3, Sample 13053: Loss: 0.2034\n",
            "Epoch 3, Sample 13054: Loss: 0.2832\n",
            "Epoch 3, Sample 13055: Loss: 0.1246\n",
            "Epoch 3, Sample 13056: Loss: 0.1170\n",
            "Epoch 3, Sample 13057: Loss: 0.3441\n",
            "Epoch 3, Sample 13058: Loss: 2.1055\n",
            "Epoch 3, Sample 13059: Loss: 0.7036\n",
            "Epoch 3, Sample 13060: Loss: 0.2759\n",
            "Epoch 3, Sample 13061: Loss: 0.5858\n",
            "Epoch 3, Sample 13062: Loss: 1.0155\n",
            "Epoch 3, Sample 13063: Loss: 0.3949\n",
            "Epoch 3, Sample 13064: Loss: 1.0524\n",
            "Epoch 3, Sample 13065: Loss: 0.5310\n",
            "Epoch 3, Sample 13066: Loss: 0.6058\n",
            "Epoch 3, Sample 13067: Loss: 0.0630\n",
            "Epoch 3, Sample 13068: Loss: 0.3949\n",
            "Epoch 3, Sample 13069: Loss: 0.7036\n",
            "Epoch 3, Sample 13070: Loss: 0.2034\n",
            "Epoch 3, Sample 13071: Loss: 1.1669\n",
            "Epoch 3, Sample 13072: Loss: 0.3399\n",
            "Epoch 3, Sample 13073: Loss: 1.5597\n",
            "Epoch 3, Sample 13074: Loss: 1.0524\n",
            "Epoch 3, Sample 13075: Loss: 0.0205\n",
            "Epoch 3, Sample 13076: Loss: 0.2034\n",
            "Epoch 3, Sample 13077: Loss: 0.7036\n",
            "Epoch 3, Sample 13078: Loss: 0.3450\n",
            "Epoch 3, Sample 13079: Loss: 0.5000\n",
            "Epoch 3, Sample 13080: Loss: 0.6092\n",
            "Epoch 3, Sample 13081: Loss: 0.0947\n",
            "Epoch 3, Sample 13082: Loss: 0.0013\n",
            "Epoch 3, Sample 13083: Loss: 0.6990\n",
            "Epoch 3, Sample 13084: Loss: 0.2044\n",
            "Epoch 3, Sample 13085: Loss: 1.5597\n",
            "Epoch 3, Sample 13086: Loss: 0.5062\n",
            "Epoch 3, Sample 13087: Loss: 0.9651\n",
            "Epoch 3, Sample 13088: Loss: 0.6990\n",
            "Epoch 3, Sample 13089: Loss: 0.7453\n",
            "Epoch 3, Sample 13090: Loss: 2.7331\n",
            "Epoch 3, Sample 13091: Loss: 1.5542\n",
            "Epoch 3, Sample 13092: Loss: 0.1250\n",
            "Epoch 3, Sample 13093: Loss: 0.3399\n",
            "Epoch 3, Sample 13094: Loss: 0.0630\n",
            "Epoch 3, Sample 13095: Loss: 0.2114\n",
            "Epoch 3, Sample 13096: Loss: 0.6867\n",
            "Epoch 3, Sample 13097: Loss: 0.0108\n",
            "Epoch 3, Sample 13098: Loss: 0.5871\n",
            "Epoch 3, Sample 13099: Loss: 0.1248\n",
            "Epoch 3, Sample 13100: Loss: 0.3852\n",
            "Epoch 3, Sample 13101: Loss: 4.4745\n",
            "Epoch 3, Sample 13102: Loss: 0.5871\n",
            "Epoch 3, Sample 13103: Loss: 1.0530\n",
            "Epoch 3, Sample 13104: Loss: 0.0108\n",
            "Epoch 3, Sample 13105: Loss: 0.2044\n",
            "Epoch 3, Sample 13106: Loss: 0.1250\n",
            "Epoch 3, Sample 13107: Loss: 0.2034\n",
            "Epoch 3, Sample 13108: Loss: 0.7036\n",
            "Epoch 3, Sample 13109: Loss: 2.2756\n",
            "Epoch 3, Sample 13110: Loss: 0.0630\n",
            "Epoch 3, Sample 13111: Loss: 0.0026\n",
            "Epoch 3, Sample 13112: Loss: 0.4930\n",
            "Epoch 3, Sample 13113: Loss: 0.0707\n",
            "Epoch 3, Sample 13114: Loss: 0.6981\n",
            "Epoch 3, Sample 13115: Loss: 0.0915\n",
            "Epoch 3, Sample 13116: Loss: 0.0234\n",
            "Epoch 3, Sample 13117: Loss: 0.6990\n",
            "Epoch 3, Sample 13118: Loss: 1.0530\n",
            "Epoch 3, Sample 13119: Loss: 0.9367\n",
            "Epoch 3, Sample 13120: Loss: 6.8646\n",
            "Epoch 3, Sample 13121: Loss: 0.2044\n",
            "Epoch 3, Sample 13122: Loss: 0.2639\n",
            "Epoch 3, Sample 13123: Loss: 0.7453\n",
            "Epoch 3, Sample 13124: Loss: 0.1588\n",
            "Epoch 3, Sample 13125: Loss: 0.1170\n",
            "Epoch 3, Sample 13126: Loss: 0.1114\n",
            "Epoch 3, Sample 13127: Loss: 1.5597\n",
            "Epoch 3, Sample 13128: Loss: 0.2034\n",
            "Epoch 3, Sample 13129: Loss: 0.2034\n",
            "Epoch 3, Sample 13130: Loss: 0.4032\n",
            "Epoch 3, Sample 13131: Loss: 1.0524\n",
            "Epoch 3, Sample 13132: Loss: 0.0270\n",
            "Epoch 3, Sample 13133: Loss: 0.0026\n",
            "Epoch 3, Sample 13134: Loss: 14.3672\n",
            "Epoch 3, Sample 13135: Loss: 0.1250\n",
            "Epoch 3, Sample 13136: Loss: 3.1802\n",
            "Epoch 3, Sample 13137: Loss: 0.2639\n",
            "Epoch 3, Sample 13138: Loss: 0.3399\n",
            "Epoch 3, Sample 13139: Loss: 1.9016\n",
            "Epoch 3, Sample 13140: Loss: 0.0498\n",
            "Epoch 3, Sample 13141: Loss: 0.7453\n",
            "Epoch 3, Sample 13142: Loss: 0.0117\n",
            "Epoch 3, Sample 13143: Loss: 1.4537\n",
            "Epoch 3, Sample 13144: Loss: 0.2494\n",
            "Epoch 3, Sample 13145: Loss: 0.2044\n",
            "Epoch 3, Sample 13146: Loss: 0.1372\n",
            "Epoch 3, Sample 13147: Loss: 2.1480\n",
            "Epoch 3, Sample 13148: Loss: 0.5858\n",
            "Epoch 3, Sample 13149: Loss: 1.0155\n",
            "Epoch 3, Sample 13150: Loss: 0.0018\n",
            "Epoch 3, Sample 13151: Loss: 0.3399\n",
            "Epoch 3, Sample 13152: Loss: 0.0001\n",
            "Epoch 3, Sample 13153: Loss: 0.0001\n",
            "Epoch 3, Sample 13154: Loss: 0.0000\n",
            "Epoch 3, Sample 13155: Loss: 0.8951\n",
            "Epoch 3, Sample 13156: Loss: 6.2712\n",
            "Epoch 3, Sample 13157: Loss: 0.0052\n",
            "Epoch 3, Sample 13158: Loss: 2.7989\n",
            "Epoch 3, Sample 13159: Loss: 2.6860\n",
            "Epoch 3, Sample 13160: Loss: 0.2759\n",
            "Epoch 3, Sample 13161: Loss: 1.5542\n",
            "Epoch 3, Sample 13162: Loss: 0.1250\n",
            "Epoch 3, Sample 13163: Loss: 1.8616\n",
            "Epoch 3, Sample 13164: Loss: 0.2036\n",
            "Epoch 3, Sample 13165: Loss: 0.1250\n",
            "Epoch 3, Sample 13166: Loss: 0.0303\n",
            "Epoch 3, Sample 13167: Loss: 0.0229\n",
            "Epoch 3, Sample 13168: Loss: 0.9780\n",
            "Epoch 3, Sample 13169: Loss: 0.1625\n",
            "Epoch 3, Sample 13170: Loss: 0.3539\n",
            "Epoch 3, Sample 13171: Loss: 0.7036\n",
            "Epoch 3, Sample 13172: Loss: 0.0026\n",
            "Epoch 3, Sample 13173: Loss: 0.0000\n",
            "Epoch 3, Sample 13174: Loss: 3.9991\n",
            "Epoch 3, Sample 13175: Loss: 0.1170\n",
            "Epoch 3, Sample 13176: Loss: 1.0155\n",
            "Epoch 3, Sample 13177: Loss: 0.3402\n",
            "Epoch 3, Sample 13178: Loss: 10.4159\n",
            "Epoch 3, Sample 13179: Loss: 0.0625\n",
            "Epoch 3, Sample 13180: Loss: 0.1170\n",
            "Epoch 3, Sample 13181: Loss: 0.0026\n",
            "Epoch 3, Sample 13182: Loss: 0.1838\n",
            "Epoch 3, Sample 13183: Loss: 0.6990\n",
            "Epoch 3, Sample 13184: Loss: 0.3441\n",
            "Epoch 3, Sample 13185: Loss: 0.0026\n",
            "Epoch 3, Sample 13186: Loss: 0.2160\n",
            "Epoch 3, Sample 13187: Loss: 8.3816\n",
            "Epoch 3, Sample 13188: Loss: 0.0438\n",
            "Epoch 3, Sample 13189: Loss: 0.7036\n",
            "Epoch 3, Sample 13190: Loss: 1.0524\n",
            "Epoch 3, Sample 13191: Loss: 0.0117\n",
            "Epoch 3, Sample 13192: Loss: 0.0006\n",
            "Epoch 3, Sample 13193: Loss: 1.0530\n",
            "Epoch 3, Sample 13194: Loss: 1.0530\n",
            "Epoch 3, Sample 13195: Loss: 0.5000\n",
            "Epoch 3, Sample 13196: Loss: 0.2759\n",
            "Epoch 3, Sample 13197: Loss: 0.4607\n",
            "Epoch 3, Sample 13198: Loss: 0.0640\n",
            "Epoch 3, Sample 13199: Loss: 1.0524\n",
            "Epoch 3, Sample 13200: Loss: 0.0062\n",
            "Epoch 3, Sample 13201: Loss: 1.0530\n",
            "Epoch 3, Sample 13202: Loss: 0.2832\n",
            "Epoch 3, Sample 13203: Loss: 0.0630\n",
            "Epoch 3, Sample 13204: Loss: 0.0590\n",
            "Epoch 3, Sample 13205: Loss: 0.1838\n",
            "Epoch 3, Sample 13206: Loss: 0.3568\n",
            "Epoch 3, Sample 13207: Loss: 3.6601\n",
            "Epoch 3, Sample 13208: Loss: 0.2044\n",
            "Epoch 3, Sample 13209: Loss: 0.2032\n",
            "Epoch 3, Sample 13210: Loss: 14.5870\n",
            "Epoch 3, Sample 13211: Loss: 0.0475\n",
            "Epoch 3, Sample 13212: Loss: 0.0582\n",
            "Epoch 3, Sample 13213: Loss: 2.0225\n",
            "Epoch 3, Sample 13214: Loss: 1.0155\n",
            "Epoch 3, Sample 13215: Loss: 1.3842\n",
            "Epoch 3, Sample 13216: Loss: 1.5542\n",
            "Epoch 3, Sample 13217: Loss: 1.5597\n",
            "Epoch 3, Sample 13218: Loss: 0.7453\n",
            "Epoch 3, Sample 13219: Loss: 0.0026\n",
            "Epoch 3, Sample 13220: Loss: 0.0026\n",
            "Epoch 3, Sample 13221: Loss: 1.0524\n",
            "Epoch 3, Sample 13222: Loss: 5.9530\n",
            "Epoch 3, Sample 13223: Loss: 0.2219\n",
            "Epoch 3, Sample 13224: Loss: 0.0026\n",
            "Epoch 3, Sample 13225: Loss: 0.0212\n",
            "Epoch 3, Sample 13226: Loss: 0.0026\n",
            "Epoch 3, Sample 13227: Loss: 0.7036\n",
            "Epoch 3, Sample 13228: Loss: 1.5597\n",
            "Epoch 3, Sample 13229: Loss: 0.3598\n",
            "Epoch 3, Sample 13230: Loss: 0.1248\n",
            "Epoch 3, Sample 13231: Loss: 0.2639\n",
            "Epoch 3, Sample 13232: Loss: 1.0155\n",
            "Epoch 3, Sample 13233: Loss: 0.0026\n",
            "Epoch 3, Sample 13234: Loss: 0.0001\n",
            "Epoch 3, Sample 13235: Loss: 0.2032\n",
            "Epoch 3, Sample 13236: Loss: 0.0915\n",
            "Epoch 3, Sample 13237: Loss: 0.6092\n",
            "Epoch 3, Sample 13238: Loss: 10.3238\n",
            "Epoch 3, Sample 13239: Loss: 0.1114\n",
            "Epoch 3, Sample 13240: Loss: 6.9441\n",
            "Epoch 3, Sample 13241: Loss: 0.0026\n",
            "Epoch 3, Sample 13242: Loss: 0.0018\n",
            "Epoch 3, Sample 13243: Loss: 0.2044\n",
            "Epoch 3, Sample 13244: Loss: 1.0070\n",
            "Epoch 3, Sample 13245: Loss: 5.3707\n",
            "Epoch 3, Sample 13246: Loss: 0.1559\n",
            "Epoch 3, Sample 13247: Loss: 0.1559\n",
            "Epoch 3, Sample 13248: Loss: 0.3332\n",
            "Epoch 3, Sample 13249: Loss: 0.1250\n",
            "Epoch 3, Sample 13250: Loss: 0.0001\n",
            "Epoch 3, Sample 13251: Loss: 1.0524\n",
            "Epoch 3, Sample 13252: Loss: 17.3544\n",
            "Epoch 3, Sample 13253: Loss: 0.0026\n",
            "Epoch 3, Sample 13254: Loss: 0.0027\n",
            "Epoch 3, Sample 13255: Loss: 0.3399\n",
            "Epoch 3, Sample 13256: Loss: 0.2483\n",
            "Epoch 3, Sample 13257: Loss: 0.1248\n",
            "Epoch 3, Sample 13258: Loss: 0.0915\n",
            "Epoch 3, Sample 13259: Loss: 0.4841\n",
            "Epoch 3, Sample 13260: Loss: 1.0524\n",
            "Epoch 3, Sample 13261: Loss: 0.0026\n",
            "Epoch 3, Sample 13262: Loss: 0.4032\n",
            "Epoch 3, Sample 13263: Loss: 0.3399\n",
            "Epoch 3, Sample 13264: Loss: 0.4611\n",
            "Epoch 3, Sample 13265: Loss: 0.0000\n",
            "Epoch 3, Sample 13266: Loss: 0.0026\n",
            "Epoch 3, Sample 13267: Loss: 0.1114\n",
            "Epoch 3, Sample 13268: Loss: 0.3450\n",
            "Epoch 3, Sample 13269: Loss: 0.5858\n",
            "Epoch 3, Sample 13270: Loss: 0.0000\n",
            "Epoch 3, Sample 13271: Loss: 0.2759\n",
            "Epoch 3, Sample 13272: Loss: 1.6630\n",
            "Epoch 3, Sample 13273: Loss: 0.2759\n",
            "Epoch 3, Sample 13274: Loss: 0.1559\n",
            "Epoch 3, Sample 13275: Loss: 1.0524\n",
            "Epoch 3, Sample 13276: Loss: 0.2044\n",
            "Epoch 3, Sample 13277: Loss: 0.0364\n",
            "Epoch 3, Sample 13278: Loss: 0.3450\n",
            "Epoch 3, Sample 13279: Loss: 1.1569\n",
            "Epoch 3, Sample 13280: Loss: 0.0026\n",
            "Epoch 3, Sample 13281: Loss: 1.0524\n",
            "Epoch 3, Sample 13282: Loss: 0.2759\n",
            "Epoch 3, Sample 13283: Loss: 0.3399\n",
            "Epoch 3, Sample 13284: Loss: 0.6139\n",
            "Epoch 3, Sample 13285: Loss: 1.0155\n",
            "Epoch 3, Sample 13286: Loss: 0.0486\n",
            "Epoch 3, Sample 13287: Loss: 0.3399\n",
            "Epoch 3, Sample 13288: Loss: 0.1687\n",
            "Epoch 3, Sample 13289: Loss: 0.0026\n",
            "Epoch 3, Sample 13290: Loss: 0.2219\n",
            "Epoch 3, Sample 13291: Loss: 1.0524\n",
            "Epoch 3, Sample 13292: Loss: 0.1250\n",
            "Epoch 3, Sample 13293: Loss: 0.2558\n",
            "Epoch 3, Sample 13294: Loss: 0.4906\n",
            "Epoch 3, Sample 13295: Loss: 0.5858\n",
            "Epoch 3, Sample 13296: Loss: 0.3399\n",
            "Epoch 3, Sample 13297: Loss: 2.7331\n",
            "Epoch 3, Sample 13298: Loss: 0.5858\n",
            "Epoch 3, Sample 13299: Loss: 0.0108\n",
            "Epoch 3, Sample 13300: Loss: 0.2639\n",
            "Epoch 3, Sample 13301: Loss: 0.2941\n",
            "Epoch 3, Sample 13302: Loss: 0.2044\n",
            "Epoch 3, Sample 13303: Loss: 0.0018\n",
            "Epoch 3, Sample 13304: Loss: 0.4799\n",
            "Epoch 3, Sample 13305: Loss: 0.1791\n",
            "Epoch 3, Sample 13306: Loss: 0.9780\n",
            "Epoch 3, Sample 13307: Loss: 0.0505\n",
            "Epoch 3, Sample 13308: Loss: 0.8951\n",
            "Epoch 3, Sample 13309: Loss: 0.2044\n",
            "Epoch 3, Sample 13310: Loss: 1.5597\n",
            "Epoch 3, Sample 13311: Loss: 0.0026\n",
            "Epoch 3, Sample 13312: Loss: 1.0070\n",
            "Epoch 3, Sample 13313: Loss: 0.2044\n",
            "Epoch 3, Sample 13314: Loss: 0.2044\n",
            "Epoch 3, Sample 13315: Loss: 0.2044\n",
            "Epoch 3, Sample 13316: Loss: 0.3166\n",
            "Epoch 3, Sample 13317: Loss: 6.4222\n",
            "Epoch 3, Sample 13318: Loss: 0.0001\n",
            "Epoch 3, Sample 13319: Loss: 0.4930\n",
            "Epoch 3, Sample 13320: Loss: 3.5504\n",
            "Epoch 3, Sample 13321: Loss: 16.1876\n",
            "Epoch 3, Sample 13322: Loss: 0.0630\n",
            "Epoch 3, Sample 13323: Loss: 20.1048\n",
            "Epoch 3, Sample 13324: Loss: 1.0524\n",
            "Epoch 3, Sample 13325: Loss: 0.7036\n",
            "Epoch 3, Sample 13326: Loss: 0.0777\n",
            "Epoch 3, Sample 13327: Loss: 0.0026\n",
            "Epoch 3, Sample 13328: Loss: 0.0205\n",
            "Epoch 3, Sample 13329: Loss: 1.5963\n",
            "Epoch 3, Sample 13330: Loss: 3.5504\n",
            "Epoch 3, Sample 13331: Loss: 6.5695\n",
            "Epoch 3, Sample 13332: Loss: 0.3949\n",
            "Epoch 3, Sample 13333: Loss: 0.2759\n",
            "Epoch 3, Sample 13334: Loss: 1.0530\n",
            "Epoch 3, Sample 13335: Loss: 0.0018\n",
            "Epoch 3, Sample 13336: Loss: 0.1246\n",
            "Epoch 3, Sample 13337: Loss: 0.8951\n",
            "Epoch 3, Sample 13338: Loss: 1.0155\n",
            "Epoch 3, Sample 13339: Loss: 0.0018\n",
            "Epoch 3, Sample 13340: Loss: 0.2034\n",
            "Epoch 3, Sample 13341: Loss: 0.2832\n",
            "Epoch 3, Sample 13342: Loss: 15.4828\n",
            "Epoch 3, Sample 13343: Loss: 4.4745\n",
            "Epoch 3, Sample 13344: Loss: 0.4799\n",
            "Epoch 3, Sample 13345: Loss: 1.0524\n",
            "Epoch 3, Sample 13346: Loss: 0.6990\n",
            "Epoch 3, Sample 13347: Loss: 22.0929\n",
            "Epoch 3, Sample 13348: Loss: 10.8862\n",
            "Epoch 3, Sample 13349: Loss: 1.5597\n",
            "Epoch 3, Sample 13350: Loss: 0.3441\n",
            "Epoch 3, Sample 13351: Loss: 0.3399\n",
            "Epoch 3, Sample 13352: Loss: 1.0530\n",
            "Epoch 3, Sample 13353: Loss: 0.2713\n",
            "Epoch 3, Sample 13354: Loss: 1.5597\n",
            "Epoch 3, Sample 13355: Loss: 2.9652\n",
            "Epoch 3, Sample 13356: Loss: 0.5858\n",
            "Epoch 3, Sample 13357: Loss: 0.0060\n",
            "Epoch 3, Sample 13358: Loss: 9.5930\n",
            "Epoch 3, Sample 13359: Loss: 5.3707\n",
            "Epoch 3, Sample 13360: Loss: 0.2036\n",
            "Epoch 3, Sample 13361: Loss: 0.5972\n",
            "Epoch 3, Sample 13362: Loss: 0.0018\n",
            "Epoch 3, Sample 13363: Loss: 0.0838\n",
            "Epoch 3, Sample 13364: Loss: 0.1170\n",
            "Epoch 3, Sample 13365: Loss: 0.5858\n",
            "Epoch 3, Sample 13366: Loss: 0.3441\n",
            "Epoch 3, Sample 13367: Loss: 1.0524\n",
            "Epoch 3, Sample 13368: Loss: 0.2759\n",
            "Epoch 3, Sample 13369: Loss: 0.0026\n",
            "Epoch 3, Sample 13370: Loss: 1.2522\n",
            "Epoch 3, Sample 13371: Loss: 1.6701\n",
            "Epoch 3, Sample 13372: Loss: 0.3441\n",
            "Epoch 3, Sample 13373: Loss: 0.0018\n",
            "Epoch 3, Sample 13374: Loss: 0.0630\n",
            "Epoch 3, Sample 13375: Loss: 0.2044\n",
            "Epoch 3, Sample 13376: Loss: 0.0212\n",
            "Epoch 3, Sample 13377: Loss: 0.0026\n",
            "Epoch 3, Sample 13378: Loss: 0.0539\n",
            "Epoch 3, Sample 13379: Loss: 0.3399\n",
            "Epoch 3, Sample 13380: Loss: 0.0108\n",
            "Epoch 3, Sample 13381: Loss: 0.3367\n",
            "Epoch 3, Sample 13382: Loss: 0.7036\n",
            "Epoch 3, Sample 13383: Loss: 0.2044\n",
            "Epoch 3, Sample 13384: Loss: 0.0168\n",
            "Epoch 3, Sample 13385: Loss: 0.4799\n",
            "Epoch 3, Sample 13386: Loss: 0.0180\n",
            "Epoch 3, Sample 13387: Loss: 0.0005\n",
            "Epoch 3, Sample 13388: Loss: 0.0025\n",
            "Epoch 3, Sample 13389: Loss: 0.0640\n",
            "Epoch 3, Sample 13390: Loss: 0.0148\n",
            "Epoch 3, Sample 13391: Loss: 0.3441\n",
            "Epoch 3, Sample 13392: Loss: 0.3399\n",
            "Epoch 3, Sample 13393: Loss: 0.0418\n",
            "Epoch 3, Sample 13394: Loss: 2.9283\n",
            "Epoch 3, Sample 13395: Loss: 0.3949\n",
            "Epoch 3, Sample 13396: Loss: 5.7125\n",
            "Epoch 3, Sample 13397: Loss: 0.3506\n",
            "Epoch 3, Sample 13398: Loss: 0.7381\n",
            "Epoch 3, Sample 13399: Loss: 1.1884\n",
            "Epoch 3, Sample 13400: Loss: 0.9367\n",
            "Epoch 3, Sample 13401: Loss: 0.2796\n",
            "Epoch 3, Sample 13402: Loss: 0.2759\n",
            "Epoch 3, Sample 13403: Loss: 0.3399\n",
            "Epoch 3, Sample 13404: Loss: 2.1901\n",
            "Epoch 3, Sample 13405: Loss: 0.0018\n",
            "Epoch 3, Sample 13406: Loss: 2.7331\n",
            "Epoch 3, Sample 13407: Loss: 0.7036\n",
            "Epoch 3, Sample 13408: Loss: 1.0530\n",
            "Epoch 3, Sample 13409: Loss: 0.3399\n",
            "Epoch 3, Sample 13410: Loss: 0.0303\n",
            "Epoch 3, Sample 13411: Loss: 0.0018\n",
            "Epoch 3, Sample 13412: Loss: 0.1523\n",
            "Epoch 3, Sample 13413: Loss: 0.2044\n",
            "Epoch 3, Sample 13414: Loss: 1.0530\n",
            "Epoch 3, Sample 13415: Loss: 0.2832\n",
            "Epoch 3, Sample 13416: Loss: 1.0530\n",
            "Epoch 3, Sample 13417: Loss: 0.3399\n",
            "Epoch 3, Sample 13418: Loss: 0.2962\n",
            "Epoch 3, Sample 13419: Loss: 0.8211\n",
            "Epoch 3, Sample 13420: Loss: 1.8616\n",
            "Epoch 3, Sample 13421: Loss: 0.1559\n",
            "Epoch 3, Sample 13422: Loss: 1.0155\n",
            "Epoch 3, Sample 13423: Loss: 0.3598\n",
            "Epoch 3, Sample 13424: Loss: 1.0524\n",
            "Epoch 3, Sample 13425: Loss: 0.2483\n",
            "Epoch 3, Sample 13426: Loss: 1.0155\n",
            "Epoch 3, Sample 13427: Loss: 4.6602\n",
            "Epoch 3, Sample 13428: Loss: 0.4039\n",
            "Epoch 3, Sample 13429: Loss: 1.5542\n",
            "Epoch 3, Sample 13430: Loss: 0.1372\n",
            "Epoch 3, Sample 13431: Loss: 0.0018\n",
            "Epoch 3, Sample 13432: Loss: 0.0018\n",
            "Epoch 3, Sample 13433: Loss: 0.2340\n",
            "Epoch 3, Sample 13434: Loss: 3.4424\n",
            "Epoch 3, Sample 13435: Loss: 0.0000\n",
            "Epoch 3, Sample 13436: Loss: 0.1091\n",
            "Epoch 3, Sample 13437: Loss: 0.2034\n",
            "Epoch 3, Sample 13438: Loss: 1.0359\n",
            "Epoch 3, Sample 13439: Loss: 2.0563\n",
            "Epoch 3, Sample 13440: Loss: 3.2314\n",
            "Epoch 3, Sample 13441: Loss: 0.7036\n",
            "Epoch 3, Sample 13442: Loss: 0.3399\n",
            "Epoch 3, Sample 13443: Loss: 1.0524\n",
            "Epoch 3, Sample 13444: Loss: 0.3399\n",
            "Epoch 3, Sample 13445: Loss: 0.0026\n",
            "Epoch 3, Sample 13446: Loss: 0.1252\n",
            "Epoch 3, Sample 13447: Loss: 1.7843\n",
            "Epoch 3, Sample 13448: Loss: 0.0062\n",
            "Epoch 3, Sample 13449: Loss: 0.0117\n",
            "Epoch 3, Sample 13450: Loss: 0.1326\n",
            "Epoch 3, Sample 13451: Loss: 0.2219\n",
            "Epoch 3, Sample 13452: Loss: 0.7036\n",
            "Epoch 3, Sample 13453: Loss: 20.2332\n",
            "Epoch 3, Sample 13454: Loss: 0.2639\n",
            "Epoch 3, Sample 13455: Loss: 0.0630\n",
            "Epoch 3, Sample 13456: Loss: 3.5826\n",
            "Epoch 3, Sample 13457: Loss: 0.0429\n",
            "Epoch 3, Sample 13458: Loss: 10.6965\n",
            "Epoch 3, Sample 13459: Loss: 4.9582\n",
            "Epoch 3, Sample 13460: Loss: 0.0205\n",
            "Epoch 3, Sample 13461: Loss: 0.1248\n",
            "Epoch 3, Sample 13462: Loss: 0.7036\n",
            "Epoch 3, Sample 13463: Loss: 4.5516\n",
            "Epoch 3, Sample 13464: Loss: 0.7036\n",
            "Epoch 3, Sample 13465: Loss: 0.1252\n",
            "Epoch 3, Sample 13466: Loss: 3.5504\n",
            "Epoch 3, Sample 13467: Loss: 0.0915\n",
            "Epoch 3, Sample 13468: Loss: 0.3399\n",
            "Epoch 3, Sample 13469: Loss: 0.0018\n",
            "Epoch 3, Sample 13470: Loss: 5.8501\n",
            "Epoch 3, Sample 13471: Loss: 0.1248\n",
            "Epoch 3, Sample 13472: Loss: 0.4930\n",
            "Epoch 3, Sample 13473: Loss: 0.0103\n",
            "Epoch 3, Sample 13474: Loss: 0.0000\n",
            "Epoch 3, Sample 13475: Loss: 0.0026\n",
            "Epoch 3, Sample 13476: Loss: 0.3126\n",
            "Epoch 3, Sample 13477: Loss: 0.3260\n",
            "Epoch 3, Sample 13478: Loss: 1.0524\n",
            "Epoch 3, Sample 13479: Loss: 0.6990\n",
            "Epoch 3, Sample 13480: Loss: 0.3399\n",
            "Epoch 3, Sample 13481: Loss: 0.7036\n",
            "Epoch 3, Sample 13482: Loss: 0.0306\n",
            "Epoch 3, Sample 13483: Loss: 0.3399\n",
            "Epoch 3, Sample 13484: Loss: 0.0838\n",
            "Epoch 3, Sample 13485: Loss: 0.7036\n",
            "Epoch 3, Sample 13486: Loss: 2.7331\n",
            "Epoch 3, Sample 13487: Loss: 1.5597\n",
            "Epoch 3, Sample 13488: Loss: 0.0099\n",
            "Epoch 3, Sample 13489: Loss: 0.1989\n",
            "Epoch 3, Sample 13490: Loss: 13.5149\n",
            "Epoch 3, Sample 13491: Loss: 1.0155\n",
            "Epoch 3, Sample 13492: Loss: 0.2044\n",
            "Epoch 3, Sample 13493: Loss: 0.2759\n",
            "Epoch 3, Sample 13494: Loss: 1.5597\n",
            "Epoch 3, Sample 13495: Loss: 0.2759\n",
            "Epoch 3, Sample 13496: Loss: 23.2903\n",
            "Epoch 3, Sample 13497: Loss: 0.1170\n",
            "Epoch 3, Sample 13498: Loss: 0.9367\n",
            "Epoch 3, Sample 13499: Loss: 0.0013\n",
            "Epoch 3, Sample 13500: Loss: 0.2044\n",
            "Epoch 3, Sample 13501: Loss: 0.2032\n",
            "Epoch 3, Sample 13502: Loss: 1.5597\n",
            "Epoch 3, Sample 13503: Loss: 0.2044\n",
            "Epoch 3, Sample 13504: Loss: 0.1337\n",
            "Epoch 3, Sample 13505: Loss: 0.2219\n",
            "Epoch 3, Sample 13506: Loss: 0.1250\n",
            "Epoch 3, Sample 13507: Loss: 0.1559\n",
            "Epoch 3, Sample 13508: Loss: 0.6990\n",
            "Epoch 3, Sample 13509: Loss: 0.3441\n",
            "Epoch 3, Sample 13510: Loss: 0.4663\n",
            "Epoch 3, Sample 13511: Loss: 0.2568\n",
            "Epoch 3, Sample 13512: Loss: 0.4799\n",
            "Epoch 3, Sample 13513: Loss: 1.0524\n",
            "Epoch 3, Sample 13514: Loss: 0.2034\n",
            "Epoch 3, Sample 13515: Loss: 0.4930\n",
            "Epoch 3, Sample 13516: Loss: 0.1250\n",
            "Epoch 3, Sample 13517: Loss: 0.4930\n",
            "Epoch 3, Sample 13518: Loss: 0.1246\n",
            "Epoch 3, Sample 13519: Loss: 0.0001\n",
            "Epoch 3, Sample 13520: Loss: 0.0630\n",
            "Epoch 3, Sample 13521: Loss: 0.0212\n",
            "Epoch 3, Sample 13522: Loss: 0.2704\n",
            "Epoch 3, Sample 13523: Loss: 0.5062\n",
            "Epoch 3, Sample 13524: Loss: 0.0026\n",
            "Epoch 3, Sample 13525: Loss: 0.0026\n",
            "Epoch 3, Sample 13526: Loss: 0.0630\n",
            "Epoch 3, Sample 13527: Loss: 0.3949\n",
            "Epoch 3, Sample 13528: Loss: 0.2044\n",
            "Epoch 3, Sample 13529: Loss: 0.3626\n",
            "Epoch 3, Sample 13530: Loss: 0.0018\n",
            "Epoch 3, Sample 13531: Loss: 0.7036\n",
            "Epoch 3, Sample 13532: Loss: 0.9780\n",
            "Epoch 3, Sample 13533: Loss: 0.1248\n",
            "Epoch 3, Sample 13534: Loss: 0.5858\n",
            "Epoch 3, Sample 13535: Loss: 0.0460\n",
            "Epoch 3, Sample 13536: Loss: 0.4799\n",
            "Epoch 3, Sample 13537: Loss: 0.6990\n",
            "Epoch 3, Sample 13538: Loss: 1.8616\n",
            "Epoch 3, Sample 13539: Loss: 0.5871\n",
            "Epoch 3, Sample 13540: Loss: 0.0234\n",
            "Epoch 3, Sample 13541: Loss: 0.0875\n",
            "Epoch 3, Sample 13542: Loss: 0.0258\n",
            "Epoch 3, Sample 13543: Loss: 0.2558\n",
            "Epoch 3, Sample 13544: Loss: 0.0026\n",
            "Epoch 3, Sample 13545: Loss: 1.0524\n",
            "Epoch 3, Sample 13546: Loss: 0.3758\n",
            "Epoch 3, Sample 13547: Loss: 1.0530\n",
            "Epoch 3, Sample 13548: Loss: 0.5000\n",
            "Epoch 3, Sample 13549: Loss: 0.0108\n",
            "Epoch 3, Sample 13550: Loss: 0.3441\n",
            "Epoch 3, Sample 13551: Loss: 0.0475\n",
            "Epoch 3, Sample 13552: Loss: 0.1463\n",
            "Epoch 3, Sample 13553: Loss: 1.5597\n",
            "Epoch 3, Sample 13554: Loss: 0.2044\n",
            "Epoch 3, Sample 13555: Loss: 0.0060\n",
            "Epoch 3, Sample 13556: Loss: 6.3486\n",
            "Epoch 3, Sample 13557: Loss: 0.2044\n",
            "Epoch 3, Sample 13558: Loss: 0.0018\n",
            "Epoch 3, Sample 13559: Loss: 1.0266\n",
            "Epoch 3, Sample 13560: Loss: 0.1250\n",
            "Epoch 3, Sample 13561: Loss: 0.1170\n",
            "Epoch 3, Sample 13562: Loss: 1.0524\n",
            "Epoch 3, Sample 13563: Loss: 0.3506\n",
            "Epoch 3, Sample 13564: Loss: 0.0838\n",
            "Epoch 3, Sample 13565: Loss: 7.6726\n",
            "Epoch 3, Sample 13566: Loss: 0.6152\n",
            "Epoch 3, Sample 13567: Loss: 13.2933\n",
            "Epoch 3, Sample 13568: Loss: 0.0915\n",
            "Epoch 3, Sample 13569: Loss: 0.2044\n",
            "Epoch 3, Sample 13570: Loss: 1.0266\n",
            "Epoch 3, Sample 13571: Loss: 0.1246\n",
            "Epoch 3, Sample 13572: Loss: 0.1248\n",
            "Epoch 3, Sample 13573: Loss: 1.7195\n",
            "Epoch 3, Sample 13574: Loss: 0.5196\n",
            "Epoch 3, Sample 13575: Loss: 0.8951\n",
            "Epoch 3, Sample 13576: Loss: 0.3247\n",
            "Epoch 3, Sample 13577: Loss: 0.0026\n",
            "Epoch 3, Sample 13578: Loss: 0.0000\n",
            "Epoch 3, Sample 13579: Loss: 0.2036\n",
            "Epoch 3, Sample 13580: Loss: 0.0205\n",
            "Epoch 3, Sample 13581: Loss: 0.3399\n",
            "Epoch 3, Sample 13582: Loss: 0.1248\n",
            "Epoch 3, Sample 13583: Loss: 0.2044\n",
            "Epoch 3, Sample 13584: Loss: 0.3399\n",
            "Epoch 3, Sample 13585: Loss: 0.7910\n",
            "Epoch 3, Sample 13586: Loss: 0.9780\n",
            "Epoch 3, Sample 13587: Loss: 0.8951\n",
            "Epoch 3, Sample 13588: Loss: 0.2851\n",
            "Epoch 3, Sample 13589: Loss: 1.0359\n",
            "Epoch 3, Sample 13590: Loss: 0.2759\n",
            "Epoch 3, Sample 13591: Loss: 6.9441\n",
            "Epoch 3, Sample 13592: Loss: 0.7486\n",
            "Epoch 3, Sample 13593: Loss: 0.1246\n",
            "Epoch 3, Sample 13594: Loss: 0.3441\n",
            "Epoch 3, Sample 13595: Loss: 0.2832\n",
            "Epoch 3, Sample 13596: Loss: 0.2034\n",
            "Epoch 3, Sample 13597: Loss: 0.2855\n",
            "Epoch 3, Sample 13598: Loss: 1.0956\n",
            "Epoch 3, Sample 13599: Loss: 0.0148\n",
            "Epoch 3, Sample 13600: Loss: 0.0026\n",
            "Epoch 3, Sample 13601: Loss: 0.4930\n",
            "Epoch 3, Sample 13602: Loss: 0.0001\n",
            "Epoch 3, Sample 13603: Loss: 0.1250\n",
            "Epoch 3, Sample 13604: Loss: 0.0303\n",
            "Epoch 3, Sample 13605: Loss: 0.1248\n",
            "Epoch 3, Sample 13606: Loss: 0.2044\n",
            "Epoch 3, Sample 13607: Loss: 0.0915\n",
            "Epoch 3, Sample 13608: Loss: 0.0084\n",
            "Epoch 3, Sample 13609: Loss: 1.5597\n",
            "Epoch 3, Sample 13610: Loss: 0.2340\n",
            "Epoch 3, Sample 13611: Loss: 0.0026\n",
            "Epoch 3, Sample 13612: Loss: 0.3938\n",
            "Epoch 3, Sample 13613: Loss: 0.0042\n",
            "Epoch 3, Sample 13614: Loss: 0.0026\n",
            "Epoch 3, Sample 13615: Loss: 1.0359\n",
            "Epoch 3, Sample 13616: Loss: 1.0524\n",
            "Epoch 3, Sample 13617: Loss: 0.0630\n",
            "Epoch 3, Sample 13618: Loss: 0.0026\n",
            "Epoch 3, Sample 13619: Loss: 0.2034\n",
            "Epoch 3, Sample 13620: Loss: 0.1240\n",
            "Epoch 3, Sample 13621: Loss: 0.0026\n",
            "Epoch 3, Sample 13622: Loss: 0.1250\n",
            "Epoch 3, Sample 13623: Loss: 0.0102\n",
            "Epoch 3, Sample 13624: Loss: 0.6990\n",
            "Epoch 3, Sample 13625: Loss: 0.4367\n",
            "Epoch 3, Sample 13626: Loss: 1.7836\n",
            "Epoch 3, Sample 13627: Loss: 0.0018\n",
            "Epoch 3, Sample 13628: Loss: 2.7331\n",
            "Epoch 3, Sample 13629: Loss: 0.1508\n",
            "Epoch 3, Sample 13630: Loss: 0.1372\n",
            "Epoch 3, Sample 13631: Loss: 5.2376\n",
            "Epoch 3, Sample 13632: Loss: 0.0002\n",
            "Epoch 3, Sample 13633: Loss: 0.3758\n",
            "Epoch 3, Sample 13634: Loss: 0.3441\n",
            "Epoch 3, Sample 13635: Loss: 0.1250\n",
            "Epoch 3, Sample 13636: Loss: 1.0359\n",
            "Epoch 3, Sample 13637: Loss: 0.1508\n",
            "Epoch 3, Sample 13638: Loss: 1.0524\n",
            "Epoch 3, Sample 13639: Loss: 0.9367\n",
            "Epoch 3, Sample 13640: Loss: 1.0266\n",
            "Epoch 3, Sample 13641: Loss: 1.0524\n",
            "Epoch 3, Sample 13642: Loss: 0.1523\n",
            "Epoch 3, Sample 13643: Loss: 0.3399\n",
            "Epoch 3, Sample 13644: Loss: 1.0524\n",
            "Epoch 3, Sample 13645: Loss: 8.2989\n",
            "Epoch 3, Sample 13646: Loss: 0.7547\n",
            "Epoch 3, Sample 13647: Loss: 0.3441\n",
            "Epoch 3, Sample 13648: Loss: 0.5858\n",
            "Epoch 3, Sample 13649: Loss: 0.0108\n",
            "Epoch 3, Sample 13650: Loss: 0.8951\n",
            "Epoch 3, Sample 13651: Loss: 0.7036\n",
            "Epoch 3, Sample 13652: Loss: 0.0026\n",
            "Epoch 3, Sample 13653: Loss: 0.5000\n",
            "Epoch 3, Sample 13654: Loss: 0.9780\n",
            "Epoch 3, Sample 13655: Loss: 0.0915\n",
            "Epoch 3, Sample 13656: Loss: 1.0524\n",
            "Epoch 3, Sample 13657: Loss: 0.5000\n",
            "Epoch 3, Sample 13658: Loss: 0.1588\n",
            "Epoch 3, Sample 13659: Loss: 0.3450\n",
            "Epoch 3, Sample 13660: Loss: 0.2759\n",
            "Epoch 3, Sample 13661: Loss: 1.6326\n",
            "Epoch 3, Sample 13662: Loss: 0.0026\n",
            "Epoch 3, Sample 13663: Loss: 0.2778\n",
            "Epoch 3, Sample 13664: Loss: 0.0962\n",
            "Epoch 3, Sample 13665: Loss: 0.0000\n",
            "Epoch 3, Sample 13666: Loss: 0.2759\n",
            "Epoch 3, Sample 13667: Loss: 0.4841\n",
            "Epoch 3, Sample 13668: Loss: 0.8951\n",
            "Epoch 3, Sample 13669: Loss: 1.0155\n",
            "Epoch 3, Sample 13670: Loss: 0.0026\n",
            "Epoch 3, Sample 13671: Loss: 0.4611\n",
            "Epoch 3, Sample 13672: Loss: 0.3438\n",
            "Epoch 3, Sample 13673: Loss: 2.8535\n",
            "Epoch 3, Sample 13674: Loss: 10.0464\n",
            "Epoch 3, Sample 13675: Loss: 21.1263\n",
            "Epoch 3, Sample 13676: Loss: 0.7036\n",
            "Epoch 3, Sample 13677: Loss: 0.2112\n",
            "Epoch 3, Sample 13678: Loss: 0.7036\n",
            "Epoch 3, Sample 13679: Loss: 0.4611\n",
            "Epoch 3, Sample 13680: Loss: 0.5196\n",
            "Epoch 3, Sample 13681: Loss: 1.5597\n",
            "Epoch 3, Sample 13682: Loss: 0.2759\n",
            "Epoch 3, Sample 13683: Loss: 13.5068\n",
            "Epoch 3, Sample 13684: Loss: 1.7073\n",
            "Epoch 3, Sample 13685: Loss: 7.6726\n",
            "Epoch 3, Sample 13686: Loss: 0.4799\n",
            "Epoch 3, Sample 13687: Loss: 0.5744\n",
            "Epoch 3, Sample 13688: Loss: 0.5972\n",
            "Epoch 3, Sample 13689: Loss: 0.0026\n",
            "Epoch 3, Sample 13690: Loss: 0.3758\n",
            "Epoch 3, Sample 13691: Loss: 0.3441\n",
            "Epoch 3, Sample 13692: Loss: 0.0026\n",
            "Epoch 3, Sample 13693: Loss: 0.7036\n",
            "Epoch 3, Sample 13694: Loss: 0.3568\n",
            "Epoch 3, Sample 13695: Loss: 0.1627\n",
            "Epoch 3, Sample 13696: Loss: 0.1246\n",
            "Epoch 3, Sample 13697: Loss: 0.2034\n",
            "Epoch 3, Sample 13698: Loss: 0.2219\n",
            "Epoch 3, Sample 13699: Loss: 1.0658\n",
            "Epoch 3, Sample 13700: Loss: 0.0915\n",
            "Epoch 3, Sample 13701: Loss: 0.4032\n",
            "Epoch 3, Sample 13702: Loss: 0.3402\n",
            "Epoch 3, Sample 13703: Loss: 0.7036\n",
            "Epoch 3, Sample 13704: Loss: 0.1248\n",
            "Epoch 3, Sample 13705: Loss: 0.2034\n",
            "Epoch 3, Sample 13706: Loss: 0.0006\n",
            "Epoch 3, Sample 13707: Loss: 0.0005\n",
            "Epoch 3, Sample 13708: Loss: 0.4902\n",
            "Epoch 3, Sample 13709: Loss: 0.7036\n",
            "Epoch 3, Sample 13710: Loss: 1.0524\n",
            "Epoch 3, Sample 13711: Loss: 0.6092\n",
            "Epoch 3, Sample 13712: Loss: 0.2044\n",
            "Epoch 3, Sample 13713: Loss: 0.3399\n",
            "Epoch 3, Sample 13714: Loss: 0.3441\n",
            "Epoch 3, Sample 13715: Loss: 0.2044\n",
            "Epoch 3, Sample 13716: Loss: 0.2832\n",
            "Epoch 3, Sample 13717: Loss: 0.1326\n",
            "Epoch 3, Sample 13718: Loss: 0.0640\n",
            "Epoch 3, Sample 13719: Loss: 0.2989\n",
            "Epoch 3, Sample 13720: Loss: 0.0018\n",
            "Epoch 3, Sample 13721: Loss: 1.0530\n",
            "Epoch 3, Sample 13722: Loss: 0.4996\n",
            "Epoch 3, Sample 13723: Loss: 0.2044\n",
            "Epoch 3, Sample 13724: Loss: 4.7858\n",
            "Epoch 3, Sample 13725: Loss: 1.0155\n",
            "Epoch 3, Sample 13726: Loss: 1.0155\n",
            "Epoch 3, Sample 13727: Loss: 2.7331\n",
            "Epoch 3, Sample 13728: Loss: 0.2851\n",
            "Epoch 3, Sample 13729: Loss: 0.2034\n",
            "Epoch 3, Sample 13730: Loss: 0.1091\n",
            "Epoch 3, Sample 13731: Loss: 0.5636\n",
            "Epoch 3, Sample 13732: Loss: 1.0359\n",
            "Epoch 3, Sample 13733: Loss: 0.1817\n",
            "Epoch 3, Sample 13734: Loss: 0.7036\n",
            "Epoch 3, Sample 13735: Loss: 0.0001\n",
            "Epoch 3, Sample 13736: Loss: 1.0155\n",
            "Epoch 3, Sample 13737: Loss: 0.1770\n",
            "Epoch 3, Sample 13738: Loss: 7.0182\n",
            "Epoch 3, Sample 13739: Loss: 0.2036\n",
            "Epoch 3, Sample 13740: Loss: 0.1465\n",
            "Epoch 3, Sample 13741: Loss: 0.0205\n",
            "Epoch 3, Sample 13742: Loss: 0.2989\n",
            "Epoch 3, Sample 13743: Loss: 1.0524\n",
            "Epoch 3, Sample 13744: Loss: 1.0155\n",
            "Epoch 3, Sample 13745: Loss: 0.8484\n",
            "Epoch 3, Sample 13746: Loss: 0.4032\n",
            "Epoch 3, Sample 13747: Loss: 0.2759\n",
            "Epoch 3, Sample 13748: Loss: 0.2851\n",
            "Epoch 3, Sample 13749: Loss: 0.2036\n",
            "Epoch 3, Sample 13750: Loss: 8.7194\n",
            "Epoch 3, Sample 13751: Loss: 1.5597\n",
            "Epoch 3, Sample 13752: Loss: 1.0524\n",
            "Epoch 3, Sample 13753: Loss: 0.0794\n",
            "Epoch 3, Sample 13754: Loss: 0.2044\n",
            "Epoch 3, Sample 13755: Loss: 0.0391\n",
            "Epoch 3, Sample 13756: Loss: 0.0744\n",
            "Epoch 3, Sample 13757: Loss: 0.1246\n",
            "Epoch 3, Sample 13758: Loss: 0.2044\n",
            "Epoch 3, Sample 13759: Loss: 0.0026\n",
            "Epoch 3, Sample 13760: Loss: 9.9542\n",
            "Epoch 3, Sample 13761: Loss: 0.3949\n",
            "Epoch 3, Sample 13762: Loss: 0.5000\n",
            "Epoch 3, Sample 13763: Loss: 0.0630\n",
            "Epoch 3, Sample 13764: Loss: 1.0155\n",
            "Epoch 3, Sample 13765: Loss: 0.8951\n",
            "Epoch 3, Sample 13766: Loss: 13.5048\n",
            "Epoch 3, Sample 13767: Loss: 0.2036\n",
            "Epoch 3, Sample 13768: Loss: 0.3399\n",
            "Epoch 3, Sample 13769: Loss: 0.0026\n",
            "Epoch 3, Sample 13770: Loss: 0.8951\n",
            "Epoch 3, Sample 13771: Loss: 0.5078\n",
            "Epoch 3, Sample 13772: Loss: 0.0915\n",
            "Epoch 3, Sample 13773: Loss: 0.9785\n",
            "Epoch 3, Sample 13774: Loss: 0.4611\n",
            "Epoch 3, Sample 13775: Loss: 0.7036\n",
            "Epoch 3, Sample 13776: Loss: 0.0475\n",
            "Epoch 3, Sample 13777: Loss: 0.2044\n",
            "Epoch 3, Sample 13778: Loss: 16.1721\n",
            "Epoch 3, Sample 13779: Loss: 4.9876\n",
            "Epoch 3, Sample 13780: Loss: 1.5597\n",
            "Epoch 3, Sample 13781: Loss: 2.9283\n",
            "Epoch 3, Sample 13782: Loss: 1.3405\n",
            "Epoch 3, Sample 13783: Loss: 0.0062\n",
            "Epoch 3, Sample 13784: Loss: 0.3399\n",
            "Epoch 3, Sample 13785: Loss: 0.0625\n",
            "Epoch 3, Sample 13786: Loss: 0.7036\n",
            "Epoch 3, Sample 13787: Loss: 0.0026\n",
            "Epoch 3, Sample 13788: Loss: 0.8671\n",
            "Epoch 3, Sample 13789: Loss: 0.2931\n",
            "Epoch 3, Sample 13790: Loss: 2.3645\n",
            "Epoch 3, Sample 13791: Loss: 0.6058\n",
            "Epoch 3, Sample 13792: Loss: 0.0145\n",
            "Epoch 3, Sample 13793: Loss: 0.3441\n",
            "Epoch 3, Sample 13794: Loss: 1.0359\n",
            "Epoch 3, Sample 13795: Loss: 0.3399\n",
            "Epoch 3, Sample 13796: Loss: 0.1516\n",
            "Epoch 3, Sample 13797: Loss: 1.0359\n",
            "Epoch 3, Sample 13798: Loss: 0.0202\n",
            "Epoch 3, Sample 13799: Loss: 1.0155\n",
            "Epoch 3, Sample 13800: Loss: 5.3707\n",
            "Epoch 3, Sample 13801: Loss: 0.0084\n",
            "Epoch 3, Sample 13802: Loss: 0.0067\n",
            "Epoch 3, Sample 13803: Loss: 2.7331\n",
            "Epoch 3, Sample 13804: Loss: 0.3399\n",
            "Epoch 3, Sample 13805: Loss: 1.0524\n",
            "Epoch 3, Sample 13806: Loss: 0.1250\n",
            "Epoch 3, Sample 13807: Loss: 0.1248\n",
            "Epoch 3, Sample 13808: Loss: 0.5858\n",
            "Epoch 3, Sample 13809: Loss: 0.2879\n",
            "Epoch 3, Sample 13810: Loss: 0.3441\n",
            "Epoch 3, Sample 13811: Loss: 0.5000\n",
            "Epoch 3, Sample 13812: Loss: 0.1246\n",
            "Epoch 3, Sample 13813: Loss: 1.5597\n",
            "Epoch 3, Sample 13814: Loss: 0.0018\n",
            "Epoch 3, Sample 13815: Loss: 1.0530\n",
            "Epoch 3, Sample 13816: Loss: 0.2044\n",
            "Epoch 3, Sample 13817: Loss: 0.2044\n",
            "Epoch 3, Sample 13818: Loss: 1.0524\n",
            "Epoch 3, Sample 13819: Loss: 0.4799\n",
            "Epoch 3, Sample 13820: Loss: 0.6058\n",
            "Epoch 3, Sample 13821: Loss: 1.1205\n",
            "Epoch 3, Sample 13822: Loss: 0.2034\n",
            "Epoch 3, Sample 13823: Loss: 0.0286\n",
            "Epoch 3, Sample 13824: Loss: 5.1063\n",
            "Epoch 3, Sample 13825: Loss: 0.0626\n",
            "Epoch 3, Sample 13826: Loss: 0.2832\n",
            "Epoch 3, Sample 13827: Loss: 2.7331\n",
            "Epoch 3, Sample 13828: Loss: 0.9785\n",
            "Epoch 3, Sample 13829: Loss: 0.1170\n",
            "Epoch 3, Sample 13830: Loss: 1.0524\n",
            "Epoch 3, Sample 13831: Loss: 0.2044\n",
            "Epoch 3, Sample 13832: Loss: 0.1170\n",
            "Epoch 3, Sample 13833: Loss: 1.0477\n",
            "Epoch 3, Sample 13834: Loss: 0.0774\n",
            "Epoch 3, Sample 13835: Loss: 0.7702\n",
            "Epoch 3, Sample 13836: Loss: 0.0267\n",
            "Epoch 3, Sample 13837: Loss: 1.0524\n",
            "Epoch 3, Sample 13838: Loss: 0.0475\n",
            "Epoch 3, Sample 13839: Loss: 2.6851\n",
            "Epoch 3, Sample 13840: Loss: 0.3024\n",
            "Epoch 3, Sample 13841: Loss: 0.1252\n",
            "Epoch 3, Sample 13842: Loss: 1.0524\n",
            "Epoch 3, Sample 13843: Loss: 1.9016\n",
            "Epoch 3, Sample 13844: Loss: 0.1170\n",
            "Epoch 3, Sample 13845: Loss: 0.5000\n",
            "Epoch 3, Sample 13846: Loss: 0.0060\n",
            "Epoch 3, Sample 13847: Loss: 0.2034\n",
            "Epoch 3, Sample 13848: Loss: 0.2832\n",
            "Epoch 3, Sample 13849: Loss: 0.2219\n",
            "Epoch 3, Sample 13850: Loss: 0.4841\n",
            "Epoch 3, Sample 13851: Loss: 1.5597\n",
            "Epoch 3, Sample 13852: Loss: 0.5871\n",
            "Epoch 3, Sample 13853: Loss: 1.0530\n",
            "Epoch 3, Sample 13854: Loss: 0.0026\n",
            "Epoch 3, Sample 13855: Loss: 0.1250\n",
            "Epoch 3, Sample 13856: Loss: 0.6304\n",
            "Epoch 3, Sample 13857: Loss: 0.1326\n",
            "Epoch 3, Sample 13858: Loss: 1.0524\n",
            "Epoch 3, Sample 13859: Loss: 0.0026\n",
            "Epoch 3, Sample 13860: Loss: 6.9441\n",
            "Epoch 3, Sample 13861: Loss: 0.0010\n",
            "Epoch 3, Sample 13862: Loss: 1.0524\n",
            "Epoch 3, Sample 13863: Loss: 0.9780\n",
            "Epoch 3, Sample 13864: Loss: 7.4878\n",
            "Epoch 3, Sample 13865: Loss: 0.2759\n",
            "Epoch 3, Sample 13866: Loss: 1.0155\n",
            "Epoch 3, Sample 13867: Loss: 0.0306\n",
            "Epoch 3, Sample 13868: Loss: 0.5871\n",
            "Epoch 3, Sample 13869: Loss: 0.0303\n",
            "Epoch 3, Sample 13870: Loss: 1.0524\n",
            "Epoch 3, Sample 13871: Loss: 0.2044\n",
            "Epoch 3, Sample 13872: Loss: 0.0630\n",
            "Epoch 3, Sample 13873: Loss: 0.9367\n",
            "Epoch 3, Sample 13874: Loss: 0.0000\n",
            "Epoch 3, Sample 13875: Loss: 0.0001\n",
            "Epoch 3, Sample 13876: Loss: 0.1091\n",
            "Epoch 3, Sample 13877: Loss: 0.0018\n",
            "Epoch 3, Sample 13878: Loss: 1.6701\n",
            "Epoch 3, Sample 13879: Loss: 0.0000\n",
            "Epoch 3, Sample 13880: Loss: 0.0026\n",
            "Epoch 3, Sample 13881: Loss: 1.7073\n",
            "Epoch 3, Sample 13882: Loss: 1.2926\n",
            "Epoch 3, Sample 13883: Loss: 0.5089\n",
            "Epoch 3, Sample 13884: Loss: 0.1252\n",
            "Epoch 3, Sample 13885: Loss: 0.6092\n",
            "Epoch 3, Sample 13886: Loss: 0.7036\n",
            "Epoch 3, Sample 13887: Loss: 0.0433\n",
            "Epoch 3, Sample 13888: Loss: 0.2036\n",
            "Epoch 3, Sample 13889: Loss: 0.1246\n",
            "Epoch 3, Sample 13890: Loss: 0.0025\n",
            "Epoch 3, Sample 13891: Loss: 0.2112\n",
            "Epoch 3, Sample 13892: Loss: 0.1482\n",
            "Epoch 3, Sample 13893: Loss: 0.7036\n",
            "Epoch 3, Sample 13894: Loss: 1.2095\n",
            "Epoch 3, Sample 13895: Loss: 0.6092\n",
            "Epoch 3, Sample 13896: Loss: 0.0630\n",
            "Epoch 3, Sample 13897: Loss: 0.0744\n",
            "Epoch 3, Sample 13898: Loss: 1.0070\n",
            "Epoch 3, Sample 13899: Loss: 0.2032\n",
            "Epoch 3, Sample 13900: Loss: 1.0155\n",
            "Epoch 3, Sample 13901: Loss: 17.9111\n",
            "Epoch 3, Sample 13902: Loss: 0.0013\n",
            "Epoch 3, Sample 13903: Loss: 0.7036\n",
            "Epoch 3, Sample 13904: Loss: 2.5454\n",
            "Epoch 3, Sample 13905: Loss: 2.7331\n",
            "Epoch 3, Sample 13906: Loss: 7.7260\n",
            "Epoch 3, Sample 13907: Loss: 0.4799\n",
            "Epoch 3, Sample 13908: Loss: 0.3399\n",
            "Epoch 3, Sample 13909: Loss: 2.0225\n",
            "Epoch 3, Sample 13910: Loss: 4.0002\n",
            "Epoch 3, Sample 13911: Loss: 0.1250\n",
            "Epoch 3, Sample 13912: Loss: 0.3598\n",
            "Epoch 3, Sample 13913: Loss: 0.2034\n",
            "Epoch 3, Sample 13914: Loss: 0.1337\n",
            "Epoch 3, Sample 13915: Loss: 0.0234\n",
            "Epoch 3, Sample 13916: Loss: 1.5597\n",
            "Epoch 3, Sample 13917: Loss: 0.0093\n",
            "Epoch 3, Sample 13918: Loss: 0.4930\n",
            "Epoch 3, Sample 13919: Loss: 0.2044\n",
            "Epoch 3, Sample 13920: Loss: 0.0426\n",
            "Epoch 3, Sample 13921: Loss: 0.7036\n",
            "Epoch 3, Sample 13922: Loss: 0.1627\n",
            "Epoch 3, Sample 13923: Loss: 0.0915\n",
            "Epoch 3, Sample 13924: Loss: 0.0026\n",
            "Epoch 3, Sample 13925: Loss: 0.3399\n",
            "Epoch 3, Sample 13926: Loss: 1.0524\n",
            "Epoch 3, Sample 13927: Loss: 0.5636\n",
            "Epoch 3, Sample 13928: Loss: 0.3399\n",
            "Epoch 3, Sample 13929: Loss: 0.0102\n",
            "Epoch 3, Sample 13930: Loss: 0.2034\n",
            "Epoch 3, Sample 13931: Loss: 1.0155\n",
            "Epoch 3, Sample 13932: Loss: 0.0018\n",
            "Epoch 3, Sample 13933: Loss: 1.5597\n",
            "Epoch 3, Sample 13934: Loss: 0.0026\n",
            "Epoch 3, Sample 13935: Loss: 0.1555\n",
            "Epoch 3, Sample 13936: Loss: 0.1248\n",
            "Epoch 3, Sample 13937: Loss: 0.1336\n",
            "Epoch 3, Sample 13938: Loss: 0.2034\n",
            "Epoch 3, Sample 13939: Loss: 0.2759\n",
            "Epoch 3, Sample 13940: Loss: 0.4611\n",
            "Epoch 3, Sample 13941: Loss: 0.0630\n",
            "Epoch 3, Sample 13942: Loss: 0.1250\n",
            "Epoch 3, Sample 13943: Loss: 0.3949\n",
            "Epoch 3, Sample 13944: Loss: 1.0155\n",
            "Epoch 3, Sample 13945: Loss: 0.1559\n",
            "Epoch 3, Sample 13946: Loss: 1.0524\n",
            "Epoch 3, Sample 13947: Loss: 0.2044\n",
            "Epoch 3, Sample 13948: Loss: 0.3568\n",
            "Epoch 3, Sample 13949: Loss: 0.4588\n",
            "Epoch 3, Sample 13950: Loss: 0.5003\n",
            "Epoch 3, Sample 13951: Loss: 0.2032\n",
            "Epoch 3, Sample 13952: Loss: 1.5597\n",
            "Epoch 3, Sample 13953: Loss: 0.1250\n",
            "Epoch 3, Sample 13954: Loss: 0.2032\n",
            "Epoch 3, Sample 13955: Loss: 7.6726\n",
            "Epoch 3, Sample 13956: Loss: 0.6867\n",
            "Epoch 3, Sample 13957: Loss: 0.3949\n",
            "Epoch 3, Sample 13958: Loss: 0.2699\n",
            "Epoch 3, Sample 13959: Loss: 0.7453\n",
            "Epoch 3, Sample 13960: Loss: 1.0155\n",
            "Epoch 3, Sample 13961: Loss: 0.3399\n",
            "Epoch 3, Sample 13962: Loss: 0.7036\n",
            "Epoch 3, Sample 13963: Loss: 0.5972\n",
            "Epoch 3, Sample 13964: Loss: 0.0000\n",
            "Epoch 3, Sample 13965: Loss: 0.4607\n",
            "Epoch 3, Sample 13966: Loss: 0.3441\n",
            "Epoch 3, Sample 13967: Loss: 0.2639\n",
            "Epoch 3, Sample 13968: Loss: 0.0595\n",
            "Epoch 3, Sample 13969: Loss: 1.1569\n",
            "Epoch 3, Sample 13970: Loss: 0.7453\n",
            "Epoch 3, Sample 13971: Loss: 0.2044\n",
            "Epoch 3, Sample 13972: Loss: 0.5078\n",
            "Epoch 3, Sample 13973: Loss: 25.3240\n",
            "Epoch 3, Sample 13974: Loss: 0.9367\n",
            "Epoch 3, Sample 13975: Loss: 0.0026\n",
            "Epoch 3, Sample 13976: Loss: 0.3399\n",
            "Epoch 3, Sample 13977: Loss: 0.2044\n",
            "Epoch 3, Sample 13978: Loss: 0.0303\n",
            "Epoch 3, Sample 13979: Loss: 0.0026\n",
            "Epoch 3, Sample 13980: Loss: 0.9367\n",
            "Epoch 3, Sample 13981: Loss: 0.5972\n",
            "Epoch 3, Sample 13982: Loss: 0.1250\n",
            "Epoch 3, Sample 13983: Loss: 0.0630\n",
            "Epoch 3, Sample 13984: Loss: 0.9785\n",
            "Epoch 3, Sample 13985: Loss: 0.0630\n",
            "Epoch 3, Sample 13986: Loss: 1.5597\n",
            "Epoch 3, Sample 13987: Loss: 0.1838\n",
            "Epoch 3, Sample 13988: Loss: 1.0359\n",
            "Epoch 3, Sample 13989: Loss: 1.5597\n",
            "Epoch 3, Sample 13990: Loss: 0.3332\n",
            "Epoch 3, Sample 13991: Loss: 0.2032\n",
            "Epoch 3, Sample 13992: Loss: 0.3402\n",
            "Epoch 3, Sample 13993: Loss: 0.2034\n",
            "Epoch 3, Sample 13994: Loss: 1.0524\n",
            "Epoch 3, Sample 13995: Loss: 0.4032\n",
            "Epoch 3, Sample 13996: Loss: 3.0318\n",
            "Epoch 3, Sample 13997: Loss: 0.6990\n",
            "Epoch 3, Sample 13998: Loss: 0.0026\n",
            "Epoch 3, Sample 13999: Loss: 0.0364\n",
            "Epoch 3, Sample 14000: Loss: 1.0155\n",
            "Epoch 3, Sample 14001: Loss: 0.0838\n",
            "Epoch 3, Sample 14002: Loss: 1.5597\n",
            "Epoch 3, Sample 14003: Loss: 0.0000\n",
            "Epoch 3, Sample 14004: Loss: 0.0001\n",
            "Epoch 3, Sample 14005: Loss: 1.8220\n",
            "Epoch 3, Sample 14006: Loss: 0.2036\n",
            "Epoch 3, Sample 14007: Loss: 0.0026\n",
            "Epoch 3, Sample 14008: Loss: 0.0084\n",
            "Epoch 3, Sample 14009: Loss: 0.1399\n",
            "Epoch 3, Sample 14010: Loss: 0.7036\n",
            "Epoch 3, Sample 14011: Loss: 0.4849\n",
            "Epoch 3, Sample 14012: Loss: 0.9780\n",
            "Epoch 3, Sample 14013: Loss: 0.3441\n",
            "Epoch 3, Sample 14014: Loss: 0.4799\n",
            "Epoch 3, Sample 14015: Loss: 0.0034\n",
            "Epoch 3, Sample 14016: Loss: 1.0155\n",
            "Epoch 3, Sample 14017: Loss: 2.7331\n",
            "Epoch 3, Sample 14018: Loss: 1.9213\n",
            "Epoch 3, Sample 14019: Loss: 5.7798\n",
            "Epoch 3, Sample 14020: Loss: 20.9773\n",
            "Epoch 3, Sample 14021: Loss: 0.3399\n",
            "Epoch 3, Sample 14022: Loss: 1.0524\n",
            "Epoch 3, Sample 14023: Loss: 1.0524\n",
            "Epoch 3, Sample 14024: Loss: 0.0915\n",
            "Epoch 3, Sample 14025: Loss: 0.3399\n",
            "Epoch 3, Sample 14026: Loss: 0.0466\n",
            "Epoch 3, Sample 14027: Loss: 0.3418\n",
            "Epoch 3, Sample 14028: Loss: 0.1559\n",
            "Epoch 3, Sample 14029: Loss: 0.5278\n",
            "Epoch 3, Sample 14030: Loss: 0.9785\n",
            "Epoch 3, Sample 14031: Loss: 0.9367\n",
            "Epoch 3, Sample 14032: Loss: 0.4032\n",
            "Epoch 3, Sample 14033: Loss: 1.5597\n",
            "Epoch 3, Sample 14034: Loss: 0.5003\n",
            "Epoch 3, Sample 14035: Loss: 0.0915\n",
            "Epoch 3, Sample 14036: Loss: 1.0070\n",
            "Epoch 3, Sample 14037: Loss: 0.8951\n",
            "Epoch 3, Sample 14038: Loss: 0.4382\n",
            "Epoch 3, Sample 14039: Loss: 0.1246\n",
            "Epoch 3, Sample 14040: Loss: 0.2494\n",
            "Epoch 3, Sample 14041: Loss: 4.4745\n",
            "Epoch 3, Sample 14042: Loss: 2.0108\n",
            "Epoch 3, Sample 14043: Loss: 0.1559\n",
            "Epoch 3, Sample 14044: Loss: 0.1248\n",
            "Epoch 3, Sample 14045: Loss: 0.1250\n",
            "Epoch 3, Sample 14046: Loss: 0.9785\n",
            "Epoch 3, Sample 14047: Loss: 0.6990\n",
            "Epoch 3, Sample 14048: Loss: 0.3598\n",
            "Epoch 3, Sample 14049: Loss: 0.2044\n",
            "Epoch 3, Sample 14050: Loss: 0.0062\n",
            "Epoch 3, Sample 14051: Loss: 0.4841\n",
            "Epoch 3, Sample 14052: Loss: 0.3288\n",
            "Epoch 3, Sample 14053: Loss: 0.9367\n",
            "Epoch 3, Sample 14054: Loss: 0.1989\n",
            "Epoch 3, Sample 14055: Loss: 0.2036\n",
            "Epoch 3, Sample 14056: Loss: 1.0524\n",
            "Epoch 3, Sample 14057: Loss: 0.2036\n",
            "Epoch 3, Sample 14058: Loss: 1.0524\n",
            "Epoch 3, Sample 14059: Loss: 0.1246\n",
            "Epoch 3, Sample 14060: Loss: 0.2044\n",
            "Epoch 3, Sample 14061: Loss: 0.4611\n",
            "Epoch 3, Sample 14062: Loss: 0.3539\n",
            "Epoch 3, Sample 14063: Loss: 1.0530\n",
            "Epoch 3, Sample 14064: Loss: 0.0176\n",
            "Epoch 3, Sample 14065: Loss: 0.0018\n",
            "Epoch 3, Sample 14066: Loss: 0.1170\n",
            "Epoch 3, Sample 14067: Loss: 0.0915\n",
            "Epoch 3, Sample 14068: Loss: 0.2219\n",
            "Epoch 3, Sample 14069: Loss: 0.0063\n",
            "Epoch 3, Sample 14070: Loss: 0.0630\n",
            "Epoch 3, Sample 14071: Loss: 0.2271\n",
            "Epoch 3, Sample 14072: Loss: 0.7036\n",
            "Epoch 3, Sample 14073: Loss: 0.5574\n",
            "Epoch 3, Sample 14074: Loss: 0.0625\n",
            "Epoch 3, Sample 14075: Loss: 0.8951\n",
            "Epoch 3, Sample 14076: Loss: 0.8951\n",
            "Epoch 3, Sample 14077: Loss: 0.6092\n",
            "Epoch 3, Sample 14078: Loss: 3.4037\n",
            "Epoch 3, Sample 14079: Loss: 5.6313\n",
            "Epoch 3, Sample 14080: Loss: 3.5504\n",
            "Epoch 3, Sample 14081: Loss: 0.1246\n",
            "Epoch 3, Sample 14082: Loss: 17.1146\n",
            "Epoch 3, Sample 14083: Loss: 0.2750\n",
            "Epoch 3, Sample 14084: Loss: 0.0915\n",
            "Epoch 3, Sample 14085: Loss: 2.0108\n",
            "Epoch 3, Sample 14086: Loss: 25.6156\n",
            "Epoch 3, Sample 14087: Loss: 0.3399\n",
            "Epoch 3, Sample 14088: Loss: 0.0168\n",
            "Epoch 3, Sample 14089: Loss: 0.3441\n",
            "Epoch 3, Sample 14090: Loss: 0.2044\n",
            "Epoch 3, Sample 14091: Loss: 0.1225\n",
            "Epoch 3, Sample 14092: Loss: 0.0915\n",
            "Epoch 3, Sample 14093: Loss: 0.0000\n",
            "Epoch 3, Sample 14094: Loss: 0.0915\n",
            "Epoch 3, Sample 14095: Loss: 0.3402\n",
            "Epoch 3, Sample 14096: Loss: 1.0530\n",
            "Epoch 3, Sample 14097: Loss: 0.1170\n",
            "Epoch 3, Sample 14098: Loss: 0.1091\n",
            "Epoch 3, Sample 14099: Loss: 1.5597\n",
            "Epoch 3, Sample 14100: Loss: 0.2034\n",
            "Epoch 3, Sample 14101: Loss: 0.2044\n",
            "Epoch 3, Sample 14102: Loss: 1.0524\n",
            "Epoch 3, Sample 14103: Loss: 0.3399\n",
            "Epoch 3, Sample 14104: Loss: 0.0027\n",
            "Epoch 3, Sample 14105: Loss: 0.7036\n",
            "Epoch 3, Sample 14106: Loss: 1.0524\n",
            "Epoch 3, Sample 14107: Loss: 0.2759\n",
            "Epoch 3, Sample 14108: Loss: 0.8951\n",
            "Epoch 3, Sample 14109: Loss: 0.1092\n",
            "Epoch 3, Sample 14110: Loss: 10.8862\n",
            "Epoch 3, Sample 14111: Loss: 0.2219\n",
            "Epoch 3, Sample 14112: Loss: 0.2846\n",
            "Epoch 3, Sample 14113: Loss: 0.1248\n",
            "Epoch 3, Sample 14114: Loss: 0.3949\n",
            "Epoch 3, Sample 14115: Loss: 0.4902\n",
            "Epoch 3, Sample 14116: Loss: 0.1364\n",
            "Epoch 3, Sample 14117: Loss: 0.0229\n",
            "Epoch 3, Sample 14118: Loss: 0.1335\n",
            "Epoch 3, Sample 14119: Loss: 0.0016\n",
            "Epoch 3, Sample 14120: Loss: 0.3399\n",
            "Epoch 3, Sample 14121: Loss: 1.0511\n",
            "Epoch 3, Sample 14122: Loss: 2.4541\n",
            "Epoch 3, Sample 14123: Loss: 0.3402\n",
            "Epoch 3, Sample 14124: Loss: 9.5930\n",
            "Epoch 3, Sample 14125: Loss: 0.2832\n",
            "Epoch 3, Sample 14126: Loss: 5.1063\n",
            "Epoch 3, Sample 14127: Loss: 0.3441\n",
            "Epoch 3, Sample 14128: Loss: 0.2044\n",
            "Epoch 3, Sample 14129: Loss: 0.2938\n",
            "Epoch 3, Sample 14130: Loss: 0.0303\n",
            "Epoch 3, Sample 14131: Loss: 1.1789\n",
            "Epoch 3, Sample 14132: Loss: 0.0002\n",
            "Epoch 3, Sample 14133: Loss: 0.1248\n",
            "Epoch 3, Sample 14134: Loss: 0.0363\n",
            "Epoch 3, Sample 14135: Loss: 0.5972\n",
            "Epoch 3, Sample 14136: Loss: 0.0915\n",
            "Epoch 3, Sample 14137: Loss: 0.1240\n",
            "Epoch 3, Sample 14138: Loss: 0.3399\n",
            "Epoch 3, Sample 14139: Loss: 1.0530\n",
            "Epoch 3, Sample 14140: Loss: 0.4841\n",
            "Epoch 3, Sample 14141: Loss: 2.7331\n",
            "Epoch 3, Sample 14142: Loss: 0.1250\n",
            "Epoch 3, Sample 14143: Loss: 0.3247\n",
            "Epoch 3, Sample 14144: Loss: 0.0938\n",
            "Epoch 3, Sample 14145: Loss: 0.3949\n",
            "Epoch 3, Sample 14146: Loss: 0.5858\n",
            "Epoch 3, Sample 14147: Loss: 0.2759\n",
            "Epoch 3, Sample 14148: Loss: 0.4032\n",
            "Epoch 3, Sample 14149: Loss: 0.3399\n",
            "Epoch 3, Sample 14150: Loss: 0.6092\n",
            "Epoch 3, Sample 14151: Loss: 0.1250\n",
            "Epoch 3, Sample 14152: Loss: 0.0144\n",
            "Epoch 3, Sample 14153: Loss: 0.1773\n",
            "Epoch 3, Sample 14154: Loss: 0.4930\n",
            "Epoch 3, Sample 14155: Loss: 0.0947\n",
            "Epoch 3, Sample 14156: Loss: 0.0306\n",
            "Epoch 3, Sample 14157: Loss: 0.0108\n",
            "Epoch 3, Sample 14158: Loss: 0.1250\n",
            "Epoch 3, Sample 14159: Loss: 0.0026\n",
            "Epoch 3, Sample 14160: Loss: 0.2687\n",
            "Epoch 3, Sample 14161: Loss: 0.4799\n",
            "Epoch 3, Sample 14162: Loss: 1.6207\n",
            "Epoch 3, Sample 14163: Loss: 0.0558\n",
            "Epoch 3, Sample 14164: Loss: 0.2044\n",
            "Epoch 3, Sample 14165: Loss: 0.1031\n",
            "Epoch 3, Sample 14166: Loss: 0.2032\n",
            "Epoch 3, Sample 14167: Loss: 0.0018\n",
            "Epoch 3, Sample 14168: Loss: 1.0524\n",
            "Epoch 3, Sample 14169: Loss: 0.0103\n",
            "Epoch 3, Sample 14170: Loss: 0.5375\n",
            "Epoch 3, Sample 14171: Loss: 0.0001\n",
            "Epoch 3, Sample 14172: Loss: 0.1335\n",
            "Epoch 3, Sample 14173: Loss: 0.4799\n",
            "Epoch 3, Sample 14174: Loss: 0.0082\n",
            "Epoch 3, Sample 14175: Loss: 0.1246\n",
            "Epoch 3, Sample 14176: Loss: 0.4032\n",
            "Epoch 3, Sample 14177: Loss: 0.2832\n",
            "Epoch 3, Sample 14178: Loss: 0.2044\n",
            "Epoch 3, Sample 14179: Loss: 0.2034\n",
            "Epoch 3, Sample 14180: Loss: 0.2290\n",
            "Epoch 3, Sample 14181: Loss: 0.5858\n",
            "Epoch 3, Sample 14182: Loss: 0.5972\n",
            "Epoch 3, Sample 14183: Loss: 0.0088\n",
            "Epoch 3, Sample 14184: Loss: 0.3441\n",
            "Epoch 3, Sample 14185: Loss: 0.1372\n",
            "Epoch 3, Sample 14186: Loss: 0.2832\n",
            "Epoch 3, Sample 14187: Loss: 0.0829\n",
            "Epoch 3, Sample 14188: Loss: 0.1559\n",
            "Epoch 3, Sample 14189: Loss: 0.2699\n",
            "Epoch 3, Sample 14190: Loss: 0.3450\n",
            "Epoch 3, Sample 14191: Loss: 0.1246\n",
            "Epoch 3, Sample 14192: Loss: 0.0026\n",
            "Epoch 3, Sample 14193: Loss: 0.3584\n",
            "Epoch 3, Sample 14194: Loss: 0.1170\n",
            "Epoch 3, Sample 14195: Loss: 0.6092\n",
            "Epoch 3, Sample 14196: Loss: 0.6139\n",
            "Epoch 3, Sample 14197: Loss: 1.0524\n",
            "Epoch 3, Sample 14198: Loss: 0.1938\n",
            "Epoch 3, Sample 14199: Loss: 0.0808\n",
            "Epoch 3, Sample 14200: Loss: 0.0168\n",
            "Epoch 3, Sample 14201: Loss: 0.0590\n",
            "Epoch 3, Sample 14202: Loss: 0.0026\n",
            "Epoch 3, Sample 14203: Loss: 0.2044\n",
            "Epoch 3, Sample 14204: Loss: 0.7036\n",
            "Epoch 3, Sample 14205: Loss: 0.2044\n",
            "Epoch 3, Sample 14206: Loss: 0.1113\n",
            "Epoch 3, Sample 14207: Loss: 0.0025\n",
            "Epoch 3, Sample 14208: Loss: 1.0524\n",
            "Epoch 3, Sample 14209: Loss: 2.7331\n",
            "Epoch 3, Sample 14210: Loss: 0.1248\n",
            "Epoch 3, Sample 14211: Loss: 0.4474\n",
            "Epoch 3, Sample 14212: Loss: 1.0524\n",
            "Epoch 3, Sample 14213: Loss: 0.3949\n",
            "Epoch 3, Sample 14214: Loss: 0.4611\n",
            "Epoch 3, Sample 14215: Loss: 0.5089\n",
            "Epoch 3, Sample 14216: Loss: 1.0524\n",
            "Epoch 3, Sample 14217: Loss: 0.0306\n",
            "Epoch 3, Sample 14218: Loss: 1.4187\n",
            "Epoch 3, Sample 14219: Loss: 0.2034\n",
            "Epoch 3, Sample 14220: Loss: 0.0026\n",
            "Epoch 3, Sample 14221: Loss: 0.0026\n",
            "Epoch 3, Sample 14222: Loss: 1.1263\n",
            "Epoch 3, Sample 14223: Loss: 1.5597\n",
            "Epoch 3, Sample 14224: Loss: 0.0963\n",
            "Epoch 3, Sample 14225: Loss: 0.3949\n",
            "Epoch 3, Sample 14226: Loss: 0.2639\n",
            "Epoch 3, Sample 14227: Loss: 0.2879\n",
            "Epoch 3, Sample 14228: Loss: 0.4663\n",
            "Epoch 3, Sample 14229: Loss: 0.2340\n",
            "Epoch 3, Sample 14230: Loss: 1.0530\n",
            "Epoch 3, Sample 14231: Loss: 0.0915\n",
            "Epoch 3, Sample 14232: Loss: 0.4799\n",
            "Epoch 3, Sample 14233: Loss: 1.0524\n",
            "Epoch 3, Sample 14234: Loss: 0.3399\n",
            "Epoch 3, Sample 14235: Loss: 0.2044\n",
            "Epoch 3, Sample 14236: Loss: 0.8951\n",
            "Epoch 3, Sample 14237: Loss: 0.3399\n",
            "Epoch 3, Sample 14238: Loss: 0.0013\n",
            "Epoch 3, Sample 14239: Loss: 0.1364\n",
            "Epoch 3, Sample 14240: Loss: 2.1901\n",
            "Epoch 3, Sample 14241: Loss: 0.0838\n",
            "Epoch 3, Sample 14242: Loss: 0.0604\n",
            "Epoch 3, Sample 14243: Loss: 0.0604\n",
            "Epoch 3, Sample 14244: Loss: 0.8620\n",
            "Epoch 3, Sample 14245: Loss: 0.2112\n",
            "Epoch 3, Sample 14246: Loss: 0.0026\n",
            "Epoch 3, Sample 14247: Loss: 0.2034\n",
            "Epoch 3, Sample 14248: Loss: 0.4611\n",
            "Epoch 3, Sample 14249: Loss: 0.0318\n",
            "Epoch 3, Sample 14250: Loss: 0.0915\n",
            "Epoch 3, Sample 14251: Loss: 1.5597\n",
            "Epoch 3, Sample 14252: Loss: 0.4930\n",
            "Epoch 3, Sample 14253: Loss: 1.8616\n",
            "Epoch 3, Sample 14254: Loss: 2.1055\n",
            "Epoch 3, Sample 14255: Loss: 0.2759\n",
            "Epoch 3, Sample 14256: Loss: 0.0026\n",
            "Epoch 3, Sample 14257: Loss: 0.3568\n",
            "Epoch 3, Sample 14258: Loss: 0.5702\n",
            "Epoch 3, Sample 14259: Loss: 1.4537\n",
            "Epoch 3, Sample 14260: Loss: 0.0018\n",
            "Epoch 3, Sample 14261: Loss: 0.6990\n",
            "Epoch 3, Sample 14262: Loss: 1.0266\n",
            "Epoch 3, Sample 14263: Loss: 2.0225\n",
            "Epoch 3, Sample 14264: Loss: 0.4382\n",
            "Epoch 3, Sample 14265: Loss: 1.5597\n",
            "Epoch 3, Sample 14266: Loss: 0.1559\n",
            "Epoch 3, Sample 14267: Loss: 1.4884\n",
            "Epoch 3, Sample 14268: Loss: 12.0464\n",
            "Epoch 3, Sample 14269: Loss: 0.0018\n",
            "Epoch 3, Sample 14270: Loss: 0.2832\n",
            "Epoch 3, Sample 14271: Loss: 0.3399\n",
            "Epoch 3, Sample 14272: Loss: 0.2639\n",
            "Epoch 3, Sample 14273: Loss: 0.0076\n",
            "Epoch 3, Sample 14274: Loss: 0.9780\n",
            "Epoch 3, Sample 14275: Loss: 0.0084\n",
            "Epoch 3, Sample 14276: Loss: 0.6190\n",
            "Epoch 3, Sample 14277: Loss: 0.0001\n",
            "Epoch 3, Sample 14278: Loss: 0.0303\n",
            "Epoch 3, Sample 14279: Loss: 0.0114\n",
            "Epoch 3, Sample 14280: Loss: 0.6990\n",
            "Epoch 3, Sample 14281: Loss: 0.5799\n",
            "Epoch 3, Sample 14282: Loss: 1.4884\n",
            "Epoch 3, Sample 14283: Loss: 0.0938\n",
            "Epoch 3, Sample 14284: Loss: 0.0938\n",
            "Epoch 3, Sample 14285: Loss: 0.5003\n",
            "Epoch 3, Sample 14286: Loss: 0.2032\n",
            "Epoch 3, Sample 14287: Loss: 0.7910\n",
            "Epoch 3, Sample 14288: Loss: 0.7453\n",
            "Epoch 3, Sample 14289: Loss: 0.2182\n",
            "Epoch 3, Sample 14290: Loss: 0.2132\n",
            "Epoch 3, Sample 14291: Loss: 0.0026\n",
            "Epoch 3, Sample 14292: Loss: 1.0530\n",
            "Epoch 3, Sample 14293: Loss: 0.0001\n",
            "Epoch 3, Sample 14294: Loss: 0.2034\n",
            "Epoch 3, Sample 14295: Loss: 1.3405\n",
            "Epoch 3, Sample 14296: Loss: 0.4799\n",
            "Epoch 3, Sample 14297: Loss: 0.2044\n",
            "Epoch 3, Sample 14298: Loss: 0.0063\n",
            "Epoch 3, Sample 14299: Loss: 0.0018\n",
            "Epoch 3, Sample 14300: Loss: 0.1170\n",
            "Epoch 3, Sample 14301: Loss: 1.0524\n",
            "Epoch 3, Sample 14302: Loss: 0.5858\n",
            "Epoch 3, Sample 14303: Loss: 1.0524\n",
            "Epoch 3, Sample 14304: Loss: 0.3402\n",
            "Epoch 3, Sample 14305: Loss: 0.0063\n",
            "Epoch 3, Sample 14306: Loss: 1.0524\n",
            "Epoch 3, Sample 14307: Loss: 0.1250\n",
            "Epoch 3, Sample 14308: Loss: 0.5871\n",
            "Epoch 3, Sample 14309: Loss: 0.0469\n",
            "Epoch 3, Sample 14310: Loss: 0.0415\n",
            "Epoch 3, Sample 14311: Loss: 0.3399\n",
            "Epoch 3, Sample 14312: Loss: 0.7036\n",
            "Epoch 3, Sample 14313: Loss: 0.2098\n",
            "Epoch 3, Sample 14314: Loss: 0.8951\n",
            "Epoch 3, Sample 14315: Loss: 9.4268\n",
            "Epoch 3, Sample 14316: Loss: 0.3399\n",
            "Epoch 3, Sample 14317: Loss: 0.4930\n",
            "Epoch 3, Sample 14318: Loss: 0.7036\n",
            "Epoch 3, Sample 14319: Loss: 0.2034\n",
            "Epoch 3, Sample 14320: Loss: 0.0640\n",
            "Epoch 3, Sample 14321: Loss: 0.6304\n",
            "Epoch 3, Sample 14322: Loss: 0.0838\n",
            "Epoch 3, Sample 14323: Loss: 0.0039\n",
            "Epoch 3, Sample 14324: Loss: 0.5858\n",
            "Epoch 3, Sample 14325: Loss: 0.2032\n",
            "Epoch 3, Sample 14326: Loss: 0.1250\n",
            "Epoch 3, Sample 14327: Loss: 0.2639\n",
            "Epoch 3, Sample 14328: Loss: 0.2044\n",
            "Epoch 3, Sample 14329: Loss: 0.5972\n",
            "Epoch 3, Sample 14330: Loss: 0.1250\n",
            "Epoch 3, Sample 14331: Loss: 1.0530\n",
            "Epoch 3, Sample 14332: Loss: 0.0001\n",
            "Epoch 3, Sample 14333: Loss: 0.1250\n",
            "Epoch 3, Sample 14334: Loss: 1.0530\n",
            "Epoch 3, Sample 14335: Loss: 0.0001\n",
            "Epoch 3, Sample 14336: Loss: 0.9780\n",
            "Epoch 3, Sample 14337: Loss: 0.6653\n",
            "Epoch 3, Sample 14338: Loss: 0.2832\n",
            "Epoch 3, Sample 14339: Loss: 1.0524\n",
            "Epoch 3, Sample 14340: Loss: 0.3758\n",
            "Epoch 3, Sample 14341: Loss: 0.1246\n",
            "Epoch 3, Sample 14342: Loss: 0.6304\n",
            "Epoch 3, Sample 14343: Loss: 0.0101\n",
            "Epoch 3, Sample 14344: Loss: 0.0063\n",
            "Epoch 3, Sample 14345: Loss: 0.1399\n",
            "Epoch 3, Sample 14346: Loss: 0.0006\n",
            "Epoch 3, Sample 14347: Loss: 1.0530\n",
            "Epoch 3, Sample 14348: Loss: 0.2639\n",
            "Epoch 3, Sample 14349: Loss: 0.7036\n",
            "Epoch 3, Sample 14350: Loss: 0.0005\n",
            "Epoch 3, Sample 14351: Loss: 0.1508\n",
            "Epoch 3, Sample 14352: Loss: 0.6990\n",
            "Epoch 3, Sample 14353: Loss: 2.9274\n",
            "Epoch 3, Sample 14354: Loss: 7.2518\n",
            "Epoch 3, Sample 14355: Loss: 0.0838\n",
            "Epoch 3, Sample 14356: Loss: 2.7331\n",
            "Epoch 3, Sample 14357: Loss: 1.0524\n",
            "Epoch 3, Sample 14358: Loss: 0.0018\n",
            "Epoch 3, Sample 14359: Loss: 0.4474\n",
            "Epoch 3, Sample 14360: Loss: 2.5454\n",
            "Epoch 3, Sample 14361: Loss: 3.5504\n",
            "Epoch 3, Sample 14362: Loss: 0.7453\n",
            "Epoch 3, Sample 14363: Loss: 0.6304\n",
            "Epoch 3, Sample 14364: Loss: 0.0712\n",
            "Epoch 3, Sample 14365: Loss: 0.0744\n",
            "Epoch 3, Sample 14366: Loss: 0.0026\n",
            "Epoch 3, Sample 14367: Loss: 0.5003\n",
            "Epoch 3, Sample 14368: Loss: 0.0026\n",
            "Epoch 3, Sample 14369: Loss: 0.4466\n",
            "Epoch 3, Sample 14370: Loss: 0.2032\n",
            "Epoch 3, Sample 14371: Loss: 0.0026\n",
            "Epoch 3, Sample 14372: Loss: 0.2044\n",
            "Epoch 3, Sample 14373: Loss: 0.5636\n",
            "Epoch 3, Sample 14374: Loss: 0.5000\n",
            "Epoch 3, Sample 14375: Loss: 0.2759\n",
            "Epoch 3, Sample 14376: Loss: 0.8484\n",
            "Epoch 3, Sample 14377: Loss: 1.1569\n",
            "Epoch 3, Sample 14378: Loss: 0.7036\n",
            "Epoch 3, Sample 14379: Loss: 0.0060\n",
            "Epoch 3, Sample 14380: Loss: 1.0530\n",
            "Epoch 3, Sample 14381: Loss: 0.0630\n",
            "Epoch 3, Sample 14382: Loss: 0.0270\n",
            "Epoch 3, Sample 14383: Loss: 0.2044\n",
            "Epoch 3, Sample 14384: Loss: 5.2263\n",
            "Epoch 3, Sample 14385: Loss: 0.0363\n",
            "Epoch 3, Sample 14386: Loss: 1.0070\n",
            "Epoch 3, Sample 14387: Loss: 0.3332\n",
            "Epoch 3, Sample 14388: Loss: 0.4382\n",
            "Epoch 3, Sample 14389: Loss: 0.3805\n",
            "Epoch 3, Sample 14390: Loss: 0.7036\n",
            "Epoch 3, Sample 14391: Loss: 4.7822\n",
            "Epoch 3, Sample 14392: Loss: 0.1559\n",
            "Epoch 3, Sample 14393: Loss: 1.2522\n",
            "Epoch 3, Sample 14394: Loss: 0.5858\n",
            "Epoch 3, Sample 14395: Loss: 0.0792\n",
            "Epoch 3, Sample 14396: Loss: 0.9780\n",
            "Epoch 3, Sample 14397: Loss: 1.0530\n",
            "Epoch 3, Sample 14398: Loss: 1.0524\n",
            "Epoch 3, Sample 14399: Loss: 0.2044\n",
            "Epoch 3, Sample 14400: Loss: 0.0013\n",
            "Epoch 3, Sample 14401: Loss: 0.1250\n",
            "Epoch 3, Sample 14402: Loss: 0.0026\n",
            "Epoch 3, Sample 14403: Loss: 0.5078\n",
            "Epoch 3, Sample 14404: Loss: 2.5454\n",
            "Epoch 3, Sample 14405: Loss: 1.0524\n",
            "Epoch 3, Sample 14406: Loss: 1.6694\n",
            "Epoch 3, Sample 14407: Loss: 1.0524\n",
            "Epoch 3, Sample 14408: Loss: 0.3399\n",
            "Epoch 3, Sample 14409: Loss: 4.4745\n",
            "Epoch 3, Sample 14410: Loss: 0.0018\n",
            "Epoch 3, Sample 14411: Loss: 0.0026\n",
            "Epoch 3, Sample 14412: Loss: 0.0026\n",
            "Epoch 3, Sample 14413: Loss: 0.2032\n",
            "Epoch 3, Sample 14414: Loss: 0.0026\n",
            "Epoch 3, Sample 14415: Loss: 0.5310\n",
            "Epoch 3, Sample 14416: Loss: 1.2192\n",
            "Epoch 3, Sample 14417: Loss: 10.6965\n",
            "Epoch 3, Sample 14418: Loss: 0.2044\n",
            "Epoch 3, Sample 14419: Loss: 3.5504\n",
            "Epoch 3, Sample 14420: Loss: 0.0001\n",
            "Epoch 3, Sample 14421: Loss: 1.8616\n",
            "Epoch 3, Sample 14422: Loss: 0.2759\n",
            "Epoch 3, Sample 14423: Loss: 0.3332\n",
            "Epoch 3, Sample 14424: Loss: 3.5504\n",
            "Epoch 3, Sample 14425: Loss: 0.4799\n",
            "Epoch 3, Sample 14426: Loss: 0.4474\n",
            "Epoch 3, Sample 14427: Loss: 2.2715\n",
            "Epoch 3, Sample 14428: Loss: 0.4841\n",
            "Epoch 3, Sample 14429: Loss: 1.2845\n",
            "Epoch 3, Sample 14430: Loss: 0.2044\n",
            "Epoch 3, Sample 14431: Loss: 0.9780\n",
            "Epoch 3, Sample 14432: Loss: 0.0707\n",
            "Epoch 3, Sample 14433: Loss: 1.5597\n",
            "Epoch 3, Sample 14434: Loss: 0.0018\n",
            "Epoch 3, Sample 14435: Loss: 1.0530\n",
            "Epoch 3, Sample 14436: Loss: 0.1170\n",
            "Epoch 3, Sample 14437: Loss: 0.2832\n",
            "Epoch 3, Sample 14438: Loss: 0.2034\n",
            "Epoch 3, Sample 14439: Loss: 0.3441\n",
            "Epoch 3, Sample 14440: Loss: 0.0026\n",
            "Epoch 3, Sample 14441: Loss: 0.7453\n",
            "Epoch 3, Sample 14442: Loss: 0.2962\n",
            "Epoch 3, Sample 14443: Loss: 0.1523\n",
            "Epoch 3, Sample 14444: Loss: 0.6304\n",
            "Epoch 3, Sample 14445: Loss: 1.0155\n",
            "Epoch 3, Sample 14446: Loss: 5.7798\n",
            "Epoch 3, Sample 14447: Loss: 0.0026\n",
            "Epoch 3, Sample 14448: Loss: 0.2044\n",
            "Epoch 3, Sample 14449: Loss: 0.7036\n",
            "Epoch 3, Sample 14450: Loss: 0.1559\n",
            "Epoch 3, Sample 14451: Loss: 6.0608\n",
            "Epoch 3, Sample 14452: Loss: 0.1170\n",
            "Epoch 3, Sample 14453: Loss: 0.2032\n",
            "Epoch 3, Sample 14454: Loss: 1.0524\n",
            "Epoch 3, Sample 14455: Loss: 0.2639\n",
            "Epoch 3, Sample 14456: Loss: 0.1559\n",
            "Epoch 3, Sample 14457: Loss: 0.7036\n",
            "Epoch 3, Sample 14458: Loss: 0.2112\n",
            "Epoch 3, Sample 14459: Loss: 8.6383\n",
            "Epoch 3, Sample 14460: Loss: 0.2032\n",
            "Epoch 3, Sample 14461: Loss: 0.2970\n",
            "Epoch 3, Sample 14462: Loss: 1.4884\n",
            "Epoch 3, Sample 14463: Loss: 0.2032\n",
            "Epoch 3, Sample 14464: Loss: 1.0524\n",
            "Epoch 3, Sample 14465: Loss: 7.6726\n",
            "Epoch 3, Sample 14466: Loss: 0.5000\n",
            "Epoch 3, Sample 14467: Loss: 0.1465\n",
            "Epoch 3, Sample 14468: Loss: 0.0026\n",
            "Epoch 3, Sample 14469: Loss: 0.1246\n",
            "Epoch 3, Sample 14470: Loss: 0.2832\n",
            "Epoch 3, Sample 14471: Loss: 0.0707\n",
            "Epoch 3, Sample 14472: Loss: 0.2036\n",
            "Epoch 3, Sample 14473: Loss: 0.5000\n",
            "Epoch 3, Sample 14474: Loss: 2.7331\n",
            "Epoch 3, Sample 14475: Loss: 1.5597\n",
            "Epoch 3, Sample 14476: Loss: 4.5364\n",
            "Epoch 3, Sample 14477: Loss: 0.0554\n",
            "Epoch 3, Sample 14478: Loss: 0.7036\n",
            "Epoch 3, Sample 14479: Loss: 0.0919\n",
            "Epoch 3, Sample 14480: Loss: 0.2704\n",
            "Epoch 3, Sample 14481: Loss: 0.2459\n",
            "Epoch 3, Sample 14482: Loss: 2.7331\n",
            "Epoch 3, Sample 14483: Loss: 5.1063\n",
            "Epoch 3, Sample 14484: Loss: 1.0155\n",
            "Epoch 3, Sample 14485: Loss: 0.0062\n",
            "Epoch 3, Sample 14486: Loss: 0.4799\n",
            "Epoch 3, Sample 14487: Loss: 5.1063\n",
            "Epoch 3, Sample 14488: Loss: 4.4745\n",
            "Epoch 3, Sample 14489: Loss: 0.2014\n",
            "Epoch 3, Sample 14490: Loss: 0.1240\n",
            "Epoch 3, Sample 14491: Loss: 0.8696\n",
            "Epoch 3, Sample 14492: Loss: 0.4032\n",
            "Epoch 3, Sample 14493: Loss: 1.0524\n",
            "Epoch 3, Sample 14494: Loss: 0.0915\n",
            "Epoch 3, Sample 14495: Loss: 9.3274\n",
            "Epoch 3, Sample 14496: Loss: 0.2855\n",
            "Epoch 3, Sample 14497: Loss: 0.5003\n",
            "Epoch 3, Sample 14498: Loss: 0.0026\n",
            "Epoch 3, Sample 14499: Loss: 0.2034\n",
            "Epoch 3, Sample 14500: Loss: 0.1225\n",
            "Epoch 3, Sample 14501: Loss: 0.4799\n",
            "Epoch 3, Sample 14502: Loss: 0.3399\n",
            "Epoch 3, Sample 14503: Loss: 0.0067\n",
            "Epoch 3, Sample 14504: Loss: 12.9803\n",
            "Epoch 3, Sample 14505: Loss: 0.0060\n",
            "Epoch 3, Sample 14506: Loss: 0.2034\n",
            "Epoch 3, Sample 14507: Loss: 8.6351\n",
            "Epoch 3, Sample 14508: Loss: 0.2832\n",
            "Epoch 3, Sample 14509: Loss: 9.5046\n",
            "Epoch 3, Sample 14510: Loss: 0.0001\n",
            "Epoch 3, Sample 14511: Loss: 0.1248\n",
            "Epoch 3, Sample 14512: Loss: 0.5858\n",
            "Epoch 3, Sample 14513: Loss: 0.7036\n",
            "Epoch 3, Sample 14514: Loss: 0.2036\n",
            "Epoch 3, Sample 14515: Loss: 1.5597\n",
            "Epoch 3, Sample 14516: Loss: 0.4799\n",
            "Epoch 3, Sample 14517: Loss: 0.0429\n",
            "Epoch 3, Sample 14518: Loss: 0.1170\n",
            "Epoch 3, Sample 14519: Loss: 0.0000\n",
            "Epoch 3, Sample 14520: Loss: 0.0625\n",
            "Epoch 3, Sample 14521: Loss: 0.8951\n",
            "Epoch 3, Sample 14522: Loss: 0.3506\n",
            "Epoch 3, Sample 14523: Loss: 0.4611\n",
            "Epoch 3, Sample 14524: Loss: 1.0524\n",
            "Epoch 3, Sample 14525: Loss: 0.2639\n",
            "Epoch 3, Sample 14526: Loss: 0.2759\n",
            "Epoch 3, Sample 14527: Loss: 0.7036\n",
            "Epoch 3, Sample 14528: Loss: 1.0359\n",
            "Epoch 3, Sample 14529: Loss: 0.0030\n",
            "Epoch 3, Sample 14530: Loss: 0.4611\n",
            "Epoch 3, Sample 14531: Loss: 0.0258\n",
            "Epoch 3, Sample 14532: Loss: 5.2717\n",
            "Epoch 3, Sample 14533: Loss: 0.3399\n",
            "Epoch 3, Sample 14534: Loss: 0.7036\n",
            "Epoch 3, Sample 14535: Loss: 0.0018\n",
            "Epoch 3, Sample 14536: Loss: 0.0258\n",
            "Epoch 3, Sample 14537: Loss: 1.0530\n",
            "Epoch 3, Sample 14538: Loss: 0.5000\n",
            "Epoch 3, Sample 14539: Loss: 0.0034\n",
            "Epoch 3, Sample 14540: Loss: 0.2044\n",
            "Epoch 3, Sample 14541: Loss: 0.2032\n",
            "Epoch 3, Sample 14542: Loss: 0.3441\n",
            "Epoch 3, Sample 14543: Loss: 1.0524\n",
            "Epoch 3, Sample 14544: Loss: 0.3399\n",
            "Epoch 3, Sample 14545: Loss: 0.2036\n",
            "Epoch 3, Sample 14546: Loss: 0.0018\n",
            "Epoch 3, Sample 14547: Loss: 1.0727\n",
            "Epoch 3, Sample 14548: Loss: 0.3441\n",
            "Epoch 3, Sample 14549: Loss: 0.0000\n",
            "Epoch 3, Sample 14550: Loss: 1.5597\n",
            "Epoch 3, Sample 14551: Loss: 0.1170\n",
            "Epoch 3, Sample 14552: Loss: 0.3598\n",
            "Epoch 3, Sample 14553: Loss: 3.5504\n",
            "Epoch 3, Sample 14554: Loss: 0.2494\n",
            "Epoch 3, Sample 14555: Loss: 0.1250\n",
            "Epoch 3, Sample 14556: Loss: 0.0915\n",
            "Epoch 3, Sample 14557: Loss: 0.0630\n",
            "Epoch 3, Sample 14558: Loss: 0.3758\n",
            "Epoch 3, Sample 14559: Loss: 0.4841\n",
            "Epoch 3, Sample 14560: Loss: 0.0145\n",
            "Epoch 3, Sample 14561: Loss: 0.1989\n",
            "Epoch 3, Sample 14562: Loss: 0.2036\n",
            "Epoch 3, Sample 14563: Loss: 1.0524\n",
            "Epoch 3, Sample 14564: Loss: 0.0018\n",
            "Epoch 3, Sample 14565: Loss: 1.0524\n",
            "Epoch 3, Sample 14566: Loss: 0.3568\n",
            "Epoch 3, Sample 14567: Loss: 1.0530\n",
            "Epoch 3, Sample 14568: Loss: 0.7036\n",
            "Epoch 3, Sample 14569: Loss: 0.0001\n",
            "Epoch 3, Sample 14570: Loss: 6.2039\n",
            "Epoch 3, Sample 14571: Loss: 0.2044\n",
            "Epoch 3, Sample 14572: Loss: 0.2044\n",
            "Epoch 3, Sample 14573: Loss: 0.2044\n",
            "Epoch 3, Sample 14574: Loss: 1.0524\n",
            "Epoch 3, Sample 14575: Loss: 0.0067\n",
            "Epoch 3, Sample 14576: Loss: 1.0359\n",
            "Epoch 3, Sample 14577: Loss: 5.6994\n",
            "Epoch 3, Sample 14578: Loss: 0.7036\n",
            "Epoch 3, Sample 14579: Loss: 0.1248\n",
            "Epoch 3, Sample 14580: Loss: 0.0036\n",
            "Epoch 3, Sample 14581: Loss: 0.0025\n",
            "Epoch 3, Sample 14582: Loss: 0.3949\n",
            "Epoch 3, Sample 14583: Loss: 0.0026\n",
            "Epoch 3, Sample 14584: Loss: 0.2112\n",
            "Epoch 3, Sample 14585: Loss: 0.2044\n",
            "Epoch 3, Sample 14586: Loss: 1.0524\n",
            "Epoch 3, Sample 14587: Loss: 0.1335\n",
            "Epoch 3, Sample 14588: Loss: 0.0212\n",
            "Epoch 3, Sample 14589: Loss: 24.7460\n",
            "Epoch 3, Sample 14590: Loss: 0.1248\n",
            "Epoch 3, Sample 14591: Loss: 0.0258\n",
            "Epoch 3, Sample 14592: Loss: 0.1523\n",
            "Epoch 3, Sample 14593: Loss: 0.8944\n",
            "Epoch 3, Sample 14594: Loss: 0.7036\n",
            "Epoch 3, Sample 14595: Loss: 0.0145\n",
            "Epoch 3, Sample 14596: Loss: 0.1250\n",
            "Epoch 3, Sample 14597: Loss: 0.0625\n",
            "Epoch 3, Sample 14598: Loss: 0.0630\n",
            "Epoch 3, Sample 14599: Loss: 0.2664\n",
            "Epoch 3, Sample 14600: Loss: 0.2339\n",
            "Epoch 3, Sample 14601: Loss: 0.0625\n",
            "Epoch 3, Sample 14602: Loss: 0.3399\n",
            "Epoch 3, Sample 14603: Loss: 4.4385\n",
            "Epoch 3, Sample 14604: Loss: 0.1170\n",
            "Epoch 3, Sample 14605: Loss: 1.0956\n",
            "Epoch 3, Sample 14606: Loss: 1.5597\n",
            "Epoch 3, Sample 14607: Loss: 0.0001\n",
            "Epoch 3, Sample 14608: Loss: 0.1419\n",
            "Epoch 3, Sample 14609: Loss: 0.4930\n",
            "Epoch 3, Sample 14610: Loss: 0.8141\n",
            "Epoch 3, Sample 14611: Loss: 0.1248\n",
            "Epoch 3, Sample 14612: Loss: 0.3036\n",
            "Epoch 3, Sample 14613: Loss: 0.0630\n",
            "Epoch 3, Sample 14614: Loss: 0.0027\n",
            "Epoch 3, Sample 14615: Loss: 0.2034\n",
            "Epoch 3, Sample 14616: Loss: 1.8616\n",
            "Epoch 3, Sample 14617: Loss: 0.0630\n",
            "Epoch 3, Sample 14618: Loss: 0.0018\n",
            "Epoch 3, Sample 14619: Loss: 0.0205\n",
            "Epoch 3, Sample 14620: Loss: 0.2759\n",
            "Epoch 3, Sample 14621: Loss: 0.3441\n",
            "Epoch 3, Sample 14622: Loss: 1.0227\n",
            "Epoch 3, Sample 14623: Loss: 0.2036\n",
            "Epoch 3, Sample 14624: Loss: 0.2032\n",
            "Epoch 3, Sample 14625: Loss: 0.4930\n",
            "Epoch 3, Sample 14626: Loss: 1.0524\n",
            "Epoch 3, Sample 14627: Loss: 0.2032\n",
            "Epoch 3, Sample 14628: Loss: 0.7036\n",
            "Epoch 3, Sample 14629: Loss: 0.1337\n",
            "Epoch 3, Sample 14630: Loss: 0.0026\n",
            "Epoch 3, Sample 14631: Loss: 0.0026\n",
            "Epoch 3, Sample 14632: Loss: 8.8908\n",
            "Epoch 3, Sample 14633: Loss: 0.2034\n",
            "Epoch 3, Sample 14634: Loss: 0.6990\n",
            "Epoch 3, Sample 14635: Loss: 0.1248\n",
            "Epoch 3, Sample 14636: Loss: 0.3399\n",
            "Epoch 3, Sample 14637: Loss: 1.5597\n",
            "Epoch 3, Sample 14638: Loss: 0.0630\n",
            "Epoch 3, Sample 14639: Loss: 1.0658\n",
            "Epoch 3, Sample 14640: Loss: 0.0915\n",
            "Epoch 3, Sample 14641: Loss: 0.2759\n",
            "Epoch 3, Sample 14642: Loss: 0.1559\n",
            "Epoch 3, Sample 14643: Loss: 4.7222\n",
            "Epoch 3, Sample 14644: Loss: 0.0026\n",
            "Epoch 3, Sample 14645: Loss: 0.2340\n",
            "Epoch 3, Sample 14646: Loss: 5.7798\n",
            "Epoch 3, Sample 14647: Loss: 1.6144\n",
            "Epoch 3, Sample 14648: Loss: 0.2032\n",
            "Epoch 3, Sample 14649: Loss: 1.1569\n",
            "Epoch 3, Sample 14650: Loss: 0.0013\n",
            "Epoch 3, Sample 14651: Loss: 0.0018\n",
            "Epoch 3, Sample 14652: Loss: 0.1248\n",
            "Epoch 3, Sample 14653: Loss: 1.0155\n",
            "Epoch 3, Sample 14654: Loss: 0.0819\n",
            "Epoch 3, Sample 14655: Loss: 0.7036\n",
            "Epoch 3, Sample 14656: Loss: 0.1092\n",
            "Epoch 3, Sample 14657: Loss: 0.2034\n",
            "Epoch 3, Sample 14658: Loss: 0.1817\n",
            "Epoch 3, Sample 14659: Loss: 0.8484\n",
            "Epoch 3, Sample 14660: Loss: 0.2032\n",
            "Epoch 3, Sample 14661: Loss: 0.2044\n",
            "Epoch 3, Sample 14662: Loss: 2.7331\n",
            "Epoch 3, Sample 14663: Loss: 0.0034\n",
            "Epoch 3, Sample 14664: Loss: 0.2759\n",
            "Epoch 3, Sample 14665: Loss: 7.0971\n",
            "Epoch 3, Sample 14666: Loss: 0.1588\n",
            "Epoch 3, Sample 14667: Loss: 0.2044\n",
            "Epoch 3, Sample 14668: Loss: 0.7036\n",
            "Epoch 3, Sample 14669: Loss: 0.0026\n",
            "Epoch 3, Sample 14670: Loss: 0.4996\n",
            "Epoch 3, Sample 14671: Loss: 0.0026\n",
            "Epoch 3, Sample 14672: Loss: 0.8951\n",
            "Epoch 3, Sample 14673: Loss: 0.1250\n",
            "Epoch 3, Sample 14674: Loss: 4.2335\n",
            "Epoch 3, Sample 14675: Loss: 0.2112\n",
            "Epoch 3, Sample 14676: Loss: 0.0072\n",
            "Epoch 3, Sample 14677: Loss: 0.2639\n",
            "Epoch 3, Sample 14678: Loss: 0.1555\n",
            "Epoch 3, Sample 14679: Loss: 0.0838\n",
            "Epoch 3, Sample 14680: Loss: 0.0938\n",
            "Epoch 3, Sample 14681: Loss: 0.3399\n",
            "Epoch 3, Sample 14682: Loss: 1.0524\n",
            "Epoch 3, Sample 14683: Loss: 0.0838\n",
            "Epoch 3, Sample 14684: Loss: 0.0947\n",
            "Epoch 3, Sample 14685: Loss: 0.1588\n",
            "Epoch 3, Sample 14686: Loss: 0.0108\n",
            "Epoch 3, Sample 14687: Loss: 0.2494\n",
            "Epoch 3, Sample 14688: Loss: 0.1559\n",
            "Epoch 3, Sample 14689: Loss: 0.0001\n",
            "Epoch 3, Sample 14690: Loss: 2.7331\n",
            "Epoch 3, Sample 14691: Loss: 0.0630\n",
            "Epoch 3, Sample 14692: Loss: 0.0026\n",
            "Epoch 3, Sample 14693: Loss: 1.0155\n",
            "Epoch 3, Sample 14694: Loss: 0.5871\n",
            "Epoch 3, Sample 14695: Loss: 0.5000\n",
            "Epoch 3, Sample 14696: Loss: 0.0018\n",
            "Epoch 3, Sample 14697: Loss: 0.5278\n",
            "Epoch 3, Sample 14698: Loss: 0.0630\n",
            "Epoch 3, Sample 14699: Loss: 0.2044\n",
            "Epoch 3, Sample 14700: Loss: 1.5963\n",
            "Epoch 3, Sample 14701: Loss: 0.2044\n",
            "Epoch 3, Sample 14702: Loss: 0.2639\n",
            "Epoch 3, Sample 14703: Loss: 0.1170\n",
            "Epoch 3, Sample 14704: Loss: 0.1250\n",
            "Epoch 3, Sample 14705: Loss: 0.7036\n",
            "Epoch 3, Sample 14706: Loss: 0.0026\n",
            "Epoch 3, Sample 14707: Loss: 1.0524\n",
            "Epoch 3, Sample 14708: Loss: 0.1250\n",
            "Epoch 3, Sample 14709: Loss: 4.4745\n",
            "Epoch 3, Sample 14710: Loss: 1.0227\n",
            "Epoch 3, Sample 14711: Loss: 1.0524\n",
            "Epoch 3, Sample 14712: Loss: 0.2704\n",
            "Epoch 3, Sample 14713: Loss: 0.1337\n",
            "Epoch 3, Sample 14714: Loss: 0.1250\n",
            "Epoch 3, Sample 14715: Loss: 0.2044\n",
            "Epoch 3, Sample 14716: Loss: 1.5597\n",
            "Epoch 3, Sample 14717: Loss: 0.4930\n",
            "Epoch 3, Sample 14718: Loss: 6.9441\n",
            "Epoch 3, Sample 14719: Loss: 0.0022\n",
            "Epoch 3, Sample 14720: Loss: 0.0630\n",
            "Epoch 3, Sample 14721: Loss: 0.2851\n",
            "Epoch 3, Sample 14722: Loss: 0.2044\n",
            "Epoch 3, Sample 14723: Loss: 0.0000\n",
            "Epoch 3, Sample 14724: Loss: 0.1252\n",
            "Epoch 3, Sample 14725: Loss: 0.7036\n",
            "Epoch 3, Sample 14726: Loss: 0.6092\n",
            "Epoch 3, Sample 14727: Loss: 0.2759\n",
            "Epoch 3, Sample 14728: Loss: 1.0524\n",
            "Epoch 3, Sample 14729: Loss: 3.1284\n",
            "Epoch 3, Sample 14730: Loss: 2.7331\n",
            "Epoch 3, Sample 14731: Loss: 0.3633\n",
            "Epoch 3, Sample 14732: Loss: 0.1378\n",
            "Epoch 3, Sample 14733: Loss: 0.0915\n",
            "Epoch 3, Sample 14734: Loss: 0.0009\n",
            "Epoch 3, Sample 14735: Loss: 0.7036\n",
            "Epoch 3, Sample 14736: Loss: 0.5858\n",
            "Epoch 3, Sample 14737: Loss: 0.0212\n",
            "Epoch 3, Sample 14738: Loss: 0.1523\n",
            "Epoch 3, Sample 14739: Loss: 0.0026\n",
            "Epoch 3, Sample 14740: Loss: 0.4032\n",
            "Epoch 3, Sample 14741: Loss: 0.0188\n",
            "Epoch 3, Sample 14742: Loss: 0.0838\n",
            "Epoch 3, Sample 14743: Loss: 0.7036\n",
            "Epoch 3, Sample 14744: Loss: 2.8908\n",
            "Epoch 3, Sample 14745: Loss: 0.2759\n",
            "Epoch 3, Sample 14746: Loss: 0.3441\n",
            "Epoch 3, Sample 14747: Loss: 0.1246\n",
            "Epoch 3, Sample 14748: Loss: 0.1337\n",
            "Epoch 3, Sample 14749: Loss: 0.5871\n",
            "Epoch 3, Sample 14750: Loss: 0.7453\n",
            "Epoch 3, Sample 14751: Loss: 0.0207\n",
            "Epoch 3, Sample 14752: Loss: 0.3399\n",
            "Epoch 3, Sample 14753: Loss: 0.0270\n",
            "Epoch 3, Sample 14754: Loss: 0.2639\n",
            "Epoch 3, Sample 14755: Loss: 0.0026\n",
            "Epoch 3, Sample 14756: Loss: 2.7331\n",
            "Epoch 3, Sample 14757: Loss: 0.0475\n",
            "Epoch 3, Sample 14758: Loss: 0.1246\n",
            "Epoch 3, Sample 14759: Loss: 3.4424\n",
            "Epoch 3, Sample 14760: Loss: 0.9785\n",
            "Epoch 3, Sample 14761: Loss: 0.0363\n",
            "Epoch 3, Sample 14762: Loss: 0.5196\n",
            "Epoch 3, Sample 14763: Loss: 0.2034\n",
            "Epoch 3, Sample 14764: Loss: 1.0266\n",
            "Epoch 3, Sample 14765: Loss: 0.0303\n",
            "Epoch 3, Sample 14766: Loss: 0.1250\n",
            "Epoch 3, Sample 14767: Loss: 0.0306\n",
            "Epoch 3, Sample 14768: Loss: 0.0026\n",
            "Epoch 3, Sample 14769: Loss: 0.2759\n",
            "Epoch 3, Sample 14770: Loss: 0.2962\n",
            "Epoch 3, Sample 14771: Loss: 0.7036\n",
            "Epoch 3, Sample 14772: Loss: 0.1250\n",
            "Epoch 3, Sample 14773: Loss: 0.3399\n",
            "Epoch 3, Sample 14774: Loss: 1.0155\n",
            "Epoch 3, Sample 14775: Loss: 0.0031\n",
            "Epoch 3, Sample 14776: Loss: 1.0524\n",
            "Epoch 3, Sample 14777: Loss: 0.2219\n",
            "Epoch 3, Sample 14778: Loss: 0.7036\n",
            "Epoch 3, Sample 14779: Loss: 0.1250\n",
            "Epoch 3, Sample 14780: Loss: 0.1199\n",
            "Epoch 3, Sample 14781: Loss: 7.0971\n",
            "Epoch 3, Sample 14782: Loss: 0.0025\n",
            "Epoch 3, Sample 14783: Loss: 0.1248\n",
            "Epoch 3, Sample 14784: Loss: 0.2044\n",
            "Epoch 3, Sample 14785: Loss: 0.0084\n",
            "Epoch 3, Sample 14786: Loss: 0.1170\n",
            "Epoch 3, Sample 14787: Loss: 0.0205\n",
            "Epoch 3, Sample 14788: Loss: 0.0915\n",
            "Epoch 3, Sample 14789: Loss: 0.5858\n",
            "Epoch 3, Sample 14790: Loss: 0.1250\n",
            "Epoch 3, Sample 14791: Loss: 1.5597\n",
            "Epoch 3, Sample 14792: Loss: 1.0530\n",
            "Epoch 3, Sample 14793: Loss: 0.2086\n",
            "Epoch 3, Sample 14794: Loss: 0.0415\n",
            "Epoch 3, Sample 14795: Loss: 0.5972\n",
            "Epoch 3, Sample 14796: Loss: 0.3399\n",
            "Epoch 3, Sample 14797: Loss: 0.2558\n",
            "Epoch 3, Sample 14798: Loss: 0.0006\n",
            "Epoch 3, Sample 14799: Loss: 1.0155\n",
            "Epoch 3, Sample 14800: Loss: 0.0026\n",
            "Epoch 3, Sample 14801: Loss: 0.2044\n",
            "Epoch 3, Sample 14802: Loss: 0.6990\n",
            "Epoch 3, Sample 14803: Loss: 0.0018\n",
            "Epoch 3, Sample 14804: Loss: 0.0630\n",
            "Epoch 3, Sample 14805: Loss: 0.0088\n",
            "Epoch 3, Sample 14806: Loss: 0.8484\n",
            "Epoch 3, Sample 14807: Loss: 0.2034\n",
            "Epoch 3, Sample 14808: Loss: 0.2032\n",
            "Epoch 3, Sample 14809: Loss: 0.2759\n",
            "Epoch 3, Sample 14810: Loss: 0.1250\n",
            "Epoch 3, Sample 14811: Loss: 1.0524\n",
            "Epoch 3, Sample 14812: Loss: 1.0155\n",
            "Epoch 3, Sample 14813: Loss: 0.7561\n",
            "Epoch 3, Sample 14814: Loss: 2.1901\n",
            "Epoch 3, Sample 14815: Loss: 0.2989\n",
            "Epoch 3, Sample 14816: Loss: 0.9780\n",
            "Epoch 3, Sample 14817: Loss: 1.0266\n",
            "Epoch 3, Sample 14818: Loss: 0.0838\n",
            "Epoch 3, Sample 14819: Loss: 0.2219\n",
            "Epoch 3, Sample 14820: Loss: 0.3402\n",
            "Epoch 3, Sample 14821: Loss: 0.1248\n",
            "Epoch 3, Sample 14822: Loss: 0.2759\n",
            "Epoch 3, Sample 14823: Loss: 1.0524\n",
            "Epoch 3, Sample 14824: Loss: 0.3949\n",
            "Epoch 3, Sample 14825: Loss: 0.5636\n",
            "Epoch 3, Sample 14826: Loss: 1.0359\n",
            "Epoch 3, Sample 14827: Loss: 1.0359\n",
            "Epoch 3, Sample 14828: Loss: 2.7989\n",
            "Epoch 3, Sample 14829: Loss: 0.7036\n",
            "Epoch 3, Sample 14830: Loss: 5.3707\n",
            "Epoch 3, Sample 14831: Loss: 5.5067\n",
            "Epoch 3, Sample 14832: Loss: 0.0133\n",
            "Epoch 3, Sample 14833: Loss: 0.7453\n",
            "Epoch 3, Sample 14834: Loss: 0.3441\n",
            "Epoch 3, Sample 14835: Loss: 0.1674\n",
            "Epoch 3, Sample 14836: Loss: 0.0554\n",
            "Epoch 3, Sample 14837: Loss: 0.4382\n",
            "Epoch 3, Sample 14838: Loss: 0.2044\n",
            "Epoch 3, Sample 14839: Loss: 0.3399\n",
            "Epoch 3, Sample 14840: Loss: 0.6139\n",
            "Epoch 3, Sample 14841: Loss: 1.0524\n",
            "Epoch 3, Sample 14842: Loss: 0.3441\n",
            "Epoch 3, Sample 14843: Loss: 0.9785\n",
            "Epoch 3, Sample 14844: Loss: 19.9570\n",
            "Epoch 3, Sample 14845: Loss: 0.0313\n",
            "Epoch 3, Sample 14846: Loss: 0.2639\n",
            "Epoch 3, Sample 14847: Loss: 0.0001\n",
            "Epoch 3, Sample 14848: Loss: 3.9991\n",
            "Epoch 3, Sample 14849: Loss: 2.9274\n",
            "Epoch 3, Sample 14850: Loss: 1.0155\n",
            "Epoch 3, Sample 14851: Loss: 0.0026\n",
            "Epoch 3, Sample 14852: Loss: 0.2036\n",
            "Epoch 3, Sample 14853: Loss: 0.0026\n",
            "Epoch 3, Sample 14854: Loss: 1.0956\n",
            "Epoch 3, Sample 14855: Loss: 0.0018\n",
            "Epoch 3, Sample 14856: Loss: 0.0042\n",
            "Epoch 3, Sample 14857: Loss: 0.2832\n",
            "Epoch 3, Sample 14858: Loss: 1.1205\n",
            "Epoch 3, Sample 14859: Loss: 0.0108\n",
            "Epoch 3, Sample 14860: Loss: 0.0318\n",
            "Epoch 3, Sample 14861: Loss: 0.1246\n",
            "Epoch 3, Sample 14862: Loss: 0.3399\n",
            "Epoch 3, Sample 14863: Loss: 1.0359\n",
            "Epoch 3, Sample 14864: Loss: 0.3441\n",
            "Epoch 3, Sample 14865: Loss: 0.0391\n",
            "Epoch 3, Sample 14866: Loss: 0.0477\n",
            "Epoch 3, Sample 14867: Loss: 1.0530\n",
            "Epoch 3, Sample 14868: Loss: 0.0380\n",
            "Epoch 3, Sample 14869: Loss: 3.5504\n",
            "Epoch 3, Sample 14870: Loss: 0.0005\n",
            "Epoch 3, Sample 14871: Loss: 1.5597\n",
            "Epoch 3, Sample 14872: Loss: 0.8951\n",
            "Epoch 3, Sample 14873: Loss: 0.0013\n",
            "Epoch 3, Sample 14874: Loss: 2.1055\n",
            "Epoch 3, Sample 14875: Loss: 0.4607\n",
            "Epoch 3, Sample 14876: Loss: 0.1559\n",
            "Epoch 3, Sample 14877: Loss: 0.0018\n",
            "Epoch 3, Sample 14878: Loss: 0.9367\n",
            "Epoch 3, Sample 14879: Loss: 0.0626\n",
            "Epoch 3, Sample 14880: Loss: 0.7453\n",
            "Epoch 3, Sample 14881: Loss: 0.1248\n",
            "Epoch 3, Sample 14882: Loss: 0.3126\n",
            "Epoch 3, Sample 14883: Loss: 0.5000\n",
            "Epoch 3, Sample 14884: Loss: 0.2036\n",
            "Epoch 3, Sample 14885: Loss: 1.0530\n",
            "Epoch 3, Sample 14886: Loss: 0.1170\n",
            "Epoch 3, Sample 14887: Loss: 0.2044\n",
            "Epoch 3, Sample 14888: Loss: 0.4032\n",
            "Epoch 3, Sample 14889: Loss: 0.3441\n",
            "Epoch 3, Sample 14890: Loss: 0.3399\n",
            "Epoch 3, Sample 14891: Loss: 0.0938\n",
            "Epoch 3, Sample 14892: Loss: 0.7036\n",
            "Epoch 3, Sample 14893: Loss: 8.7194\n",
            "Epoch 3, Sample 14894: Loss: 0.1248\n",
            "Epoch 3, Sample 14895: Loss: 0.0286\n",
            "Epoch 3, Sample 14896: Loss: 0.0034\n",
            "Epoch 3, Sample 14897: Loss: 0.6092\n",
            "Epoch 3, Sample 14898: Loss: 1.0524\n",
            "Epoch 3, Sample 14899: Loss: 1.4187\n",
            "Epoch 3, Sample 14900: Loss: 0.3949\n",
            "Epoch 3, Sample 14901: Loss: 0.6867\n",
            "Epoch 3, Sample 14902: Loss: 0.1056\n",
            "Epoch 3, Sample 14903: Loss: 0.0026\n",
            "Epoch 3, Sample 14904: Loss: 0.3758\n",
            "Epoch 3, Sample 14905: Loss: 1.0524\n",
            "Epoch 3, Sample 14906: Loss: 0.0630\n",
            "Epoch 3, Sample 14907: Loss: 0.2112\n",
            "Epoch 3, Sample 14908: Loss: 0.4644\n",
            "Epoch 3, Sample 14909: Loss: 1.0155\n",
            "Epoch 3, Sample 14910: Loss: 0.0018\n",
            "Epoch 3, Sample 14911: Loss: 0.2044\n",
            "Epoch 3, Sample 14912: Loss: 0.0026\n",
            "Epoch 3, Sample 14913: Loss: 0.0205\n",
            "Epoch 3, Sample 14914: Loss: 0.1260\n",
            "Epoch 3, Sample 14915: Loss: 0.5003\n",
            "Epoch 3, Sample 14916: Loss: 0.0363\n",
            "Epoch 3, Sample 14917: Loss: 0.6990\n",
            "Epoch 3, Sample 14918: Loss: 0.3441\n",
            "Epoch 3, Sample 14919: Loss: 9.7728\n",
            "Epoch 3, Sample 14920: Loss: 0.2032\n",
            "Epoch 3, Sample 14921: Loss: 0.0150\n",
            "Epoch 3, Sample 14922: Loss: 0.1170\n",
            "Epoch 3, Sample 14923: Loss: 0.0062\n",
            "Epoch 3, Sample 14924: Loss: 1.5597\n",
            "Epoch 3, Sample 14925: Loss: 0.0626\n",
            "Epoch 3, Sample 14926: Loss: 0.0001\n",
            "Epoch 3, Sample 14927: Loss: 0.6304\n",
            "Epoch 3, Sample 14928: Loss: 0.0025\n",
            "Epoch 3, Sample 14929: Loss: 0.1246\n",
            "Epoch 3, Sample 14930: Loss: 0.0018\n",
            "Epoch 3, Sample 14931: Loss: 0.0802\n",
            "Epoch 3, Sample 14932: Loss: 0.3399\n",
            "Epoch 3, Sample 14933: Loss: 0.0108\n",
            "Epoch 3, Sample 14934: Loss: 0.2962\n",
            "Epoch 3, Sample 14935: Loss: 0.6190\n",
            "Epoch 3, Sample 14936: Loss: 0.3441\n",
            "Epoch 3, Sample 14937: Loss: 0.2182\n",
            "Epoch 3, Sample 14938: Loss: 0.0013\n",
            "Epoch 3, Sample 14939: Loss: 0.3399\n",
            "Epoch 3, Sample 14940: Loss: 0.6304\n",
            "Epoch 3, Sample 14941: Loss: 1.0359\n",
            "Epoch 3, Sample 14942: Loss: 0.1170\n",
            "Epoch 3, Sample 14943: Loss: 1.0530\n",
            "Epoch 3, Sample 14944: Loss: 1.0956\n",
            "Epoch 3, Sample 14945: Loss: 0.3399\n",
            "Epoch 3, Sample 14946: Loss: 0.4607\n",
            "Epoch 3, Sample 14947: Loss: 0.0630\n",
            "Epoch 3, Sample 14948: Loss: 0.2639\n",
            "Epoch 3, Sample 14949: Loss: 0.0062\n",
            "Epoch 3, Sample 14950: Loss: 0.5858\n",
            "Epoch 3, Sample 14951: Loss: 0.0084\n",
            "Epoch 3, Sample 14952: Loss: 0.0258\n",
            "Epoch 3, Sample 14953: Loss: 0.1397\n",
            "Epoch 3, Sample 14954: Loss: 0.0018\n",
            "Epoch 3, Sample 14955: Loss: 0.1559\n",
            "Epoch 3, Sample 14956: Loss: 0.2032\n",
            "Epoch 3, Sample 14957: Loss: 1.5597\n",
            "Epoch 3, Sample 14958: Loss: 0.3399\n",
            "Epoch 3, Sample 14959: Loss: 1.0956\n",
            "Epoch 3, Sample 14960: Loss: 0.2759\n",
            "Epoch 3, Sample 14961: Loss: 0.2219\n",
            "Epoch 3, Sample 14962: Loss: 4.3888\n",
            "Epoch 3, Sample 14963: Loss: 0.2044\n",
            "Epoch 3, Sample 14964: Loss: 0.0030\n",
            "Epoch 3, Sample 14965: Loss: 0.7036\n",
            "Epoch 3, Sample 14966: Loss: 0.0712\n",
            "Epoch 3, Sample 14967: Loss: 0.1252\n",
            "Epoch 3, Sample 14968: Loss: 0.0026\n",
            "Epoch 3, Sample 14969: Loss: 2.0108\n",
            "Epoch 3, Sample 14970: Loss: 0.0080\n",
            "Epoch 3, Sample 14971: Loss: 0.5003\n",
            "Epoch 3, Sample 14972: Loss: 0.0466\n",
            "Epoch 3, Sample 14973: Loss: 0.1246\n",
            "Epoch 3, Sample 14974: Loss: 1.0524\n",
            "Epoch 3, Sample 14975: Loss: 0.1463\n",
            "Epoch 3, Sample 14976: Loss: 0.0466\n",
            "Epoch 3, Sample 14977: Loss: 1.0524\n",
            "Epoch 3, Sample 14978: Loss: 0.2931\n",
            "Epoch 3, Sample 14979: Loss: 0.0026\n",
            "Epoch 3, Sample 14980: Loss: 0.0026\n",
            "Epoch 3, Sample 14981: Loss: 0.4799\n",
            "Epoch 3, Sample 14982: Loss: 0.8484\n",
            "Epoch 3, Sample 14983: Loss: 0.4930\n",
            "Epoch 3, Sample 14984: Loss: 1.0155\n",
            "Epoch 3, Sample 14985: Loss: 0.0026\n",
            "Epoch 3, Sample 14986: Loss: 0.0026\n",
            "Epoch 3, Sample 14987: Loss: 3.6601\n",
            "Epoch 3, Sample 14988: Loss: 1.0688\n",
            "Epoch 3, Sample 14989: Loss: 1.0359\n",
            "Epoch 3, Sample 14990: Loss: 0.1250\n",
            "Epoch 3, Sample 14991: Loss: 0.1225\n",
            "Epoch 3, Sample 14992: Loss: 1.0524\n",
            "Epoch 3, Sample 14993: Loss: 0.9785\n",
            "Epoch 3, Sample 14994: Loss: 0.4611\n",
            "Epoch 3, Sample 14995: Loss: 0.6990\n",
            "Epoch 3, Sample 14996: Loss: 0.4641\n",
            "Epoch 3, Sample 14997: Loss: 0.6990\n",
            "Epoch 3, Sample 14998: Loss: 0.6867\n",
            "Epoch 3, Sample 14999: Loss: 0.1250\n",
            "Epoch 3, Sample 15000: Loss: 0.3949\n",
            "Epoch 3, Sample 15001: Loss: 0.0018\n",
            "Epoch 3, Sample 15002: Loss: 0.2832\n",
            "Epoch 3, Sample 15003: Loss: 0.1364\n",
            "Epoch 3, Sample 15004: Loss: 0.2182\n",
            "Epoch 3, Sample 15005: Loss: 1.0956\n",
            "Epoch 3, Sample 15006: Loss: 0.1964\n",
            "Epoch 3, Sample 15007: Loss: 0.2032\n",
            "Epoch 3, Sample 15008: Loss: 0.2044\n",
            "Epoch 3, Sample 15009: Loss: 0.2219\n",
            "Epoch 3, Sample 15010: Loss: 0.3949\n",
            "Epoch 3, Sample 15011: Loss: 0.4930\n",
            "Epoch 3, Sample 15012: Loss: 0.2044\n",
            "Epoch 3, Sample 15013: Loss: 0.0006\n",
            "Epoch 3, Sample 15014: Loss: 1.0524\n",
            "Epoch 3, Sample 15015: Loss: 0.3399\n",
            "Epoch 3, Sample 15016: Loss: 0.0018\n",
            "Epoch 3, Sample 15017: Loss: 1.0524\n",
            "Epoch 3, Sample 15018: Loss: 0.7702\n",
            "Epoch 3, Sample 15019: Loss: 2.9775\n",
            "Epoch 3, Sample 15020: Loss: 10.1372\n",
            "Epoch 3, Sample 15021: Loss: 0.3402\n",
            "Epoch 3, Sample 15022: Loss: 0.7702\n",
            "Epoch 3, Sample 15023: Loss: 0.2044\n",
            "Epoch 3, Sample 15024: Loss: 0.1622\n",
            "Epoch 3, Sample 15025: Loss: 1.0155\n",
            "Epoch 3, Sample 15026: Loss: 0.0303\n",
            "Epoch 3, Sample 15027: Loss: 0.1246\n",
            "Epoch 3, Sample 15028: Loss: 1.0070\n",
            "Epoch 3, Sample 15029: Loss: 0.1039\n",
            "Epoch 3, Sample 15030: Loss: 1.0155\n",
            "Epoch 3, Sample 15031: Loss: 13.9327\n",
            "Epoch 3, Sample 15032: Loss: 0.0018\n",
            "Epoch 3, Sample 15033: Loss: 0.3332\n",
            "Epoch 3, Sample 15034: Loss: 0.0026\n",
            "Epoch 3, Sample 15035: Loss: 0.6990\n",
            "Epoch 3, Sample 15036: Loss: 0.1225\n",
            "Epoch 3, Sample 15037: Loss: 2.0225\n",
            "Epoch 3, Sample 15038: Loss: 2.7331\n",
            "Epoch 3, Sample 15039: Loss: 0.2034\n",
            "Epoch 3, Sample 15040: Loss: 0.5858\n",
            "Epoch 3, Sample 15041: Loss: 0.8951\n",
            "Epoch 3, Sample 15042: Loss: 1.0524\n",
            "Epoch 3, Sample 15043: Loss: 1.8616\n",
            "Epoch 3, Sample 15044: Loss: 0.0034\n",
            "Epoch 3, Sample 15045: Loss: 19.0797\n",
            "Epoch 3, Sample 15046: Loss: 1.0524\n",
            "Epoch 3, Sample 15047: Loss: 0.0026\n",
            "Epoch 3, Sample 15048: Loss: 1.5113\n",
            "Epoch 3, Sample 15049: Loss: 0.2558\n",
            "Epoch 3, Sample 15050: Loss: 0.7036\n",
            "Epoch 3, Sample 15051: Loss: 1.0524\n",
            "Epoch 3, Sample 15052: Loss: 0.1040\n",
            "Epoch 3, Sample 15053: Loss: 1.0359\n",
            "Epoch 3, Sample 15054: Loss: 0.2034\n",
            "Epoch 3, Sample 15055: Loss: 0.3399\n",
            "Epoch 3, Sample 15056: Loss: 0.1246\n",
            "Epoch 3, Sample 15057: Loss: 0.3984\n",
            "Epoch 3, Sample 15058: Loss: 21.6888\n",
            "Epoch 3, Sample 15059: Loss: 0.2044\n",
            "Epoch 3, Sample 15060: Loss: 1.0359\n",
            "Epoch 3, Sample 15061: Loss: 2.9274\n",
            "Epoch 3, Sample 15062: Loss: 0.3399\n",
            "Epoch 3, Sample 15063: Loss: 0.5636\n",
            "Epoch 3, Sample 15064: Loss: 0.1364\n",
            "Epoch 3, Sample 15065: Loss: 2.5000\n",
            "Epoch 3, Sample 15066: Loss: 0.3441\n",
            "Epoch 3, Sample 15067: Loss: 0.2032\n",
            "Epoch 3, Sample 15068: Loss: 0.2036\n",
            "Epoch 3, Sample 15069: Loss: 0.1250\n",
            "Epoch 3, Sample 15070: Loss: 1.0530\n",
            "Epoch 3, Sample 15071: Loss: 0.0026\n",
            "Epoch 3, Sample 15072: Loss: 0.0026\n",
            "Epoch 3, Sample 15073: Loss: 1.8616\n",
            "Epoch 3, Sample 15074: Loss: 0.4032\n",
            "Epoch 3, Sample 15075: Loss: 0.0161\n",
            "Epoch 3, Sample 15076: Loss: 0.4799\n",
            "Epoch 3, Sample 15077: Loss: 0.7036\n",
            "Epoch 3, Sample 15078: Loss: 0.0025\n",
            "Epoch 3, Sample 15079: Loss: 0.1240\n",
            "Epoch 3, Sample 15080: Loss: 0.2832\n",
            "Epoch 3, Sample 15081: Loss: 0.1170\n",
            "Epoch 3, Sample 15082: Loss: 0.2935\n",
            "Epoch 3, Sample 15083: Loss: 0.0000\n",
            "Epoch 3, Sample 15084: Loss: 0.0025\n",
            "Epoch 3, Sample 15085: Loss: 0.1055\n",
            "Epoch 3, Sample 15086: Loss: 0.3332\n",
            "Epoch 3, Sample 15087: Loss: 0.1252\n",
            "Epoch 3, Sample 15088: Loss: 0.3441\n",
            "Epoch 3, Sample 15089: Loss: 0.2032\n",
            "Epoch 3, Sample 15090: Loss: 0.0001\n",
            "Epoch 3, Sample 15091: Loss: 0.0637\n",
            "Epoch 3, Sample 15092: Loss: 2.4541\n",
            "Epoch 3, Sample 15093: Loss: 0.6990\n",
            "Epoch 3, Sample 15094: Loss: 0.0026\n",
            "Epoch 3, Sample 15095: Loss: 0.5000\n",
            "Epoch 3, Sample 15096: Loss: 2.7331\n",
            "Epoch 3, Sample 15097: Loss: 0.0026\n",
            "Epoch 3, Sample 15098: Loss: 0.1248\n",
            "Epoch 3, Sample 15099: Loss: 0.0306\n",
            "Epoch 3, Sample 15100: Loss: 0.0026\n",
            "Epoch 3, Sample 15101: Loss: 0.0026\n",
            "Epoch 3, Sample 15102: Loss: 0.7702\n",
            "Epoch 3, Sample 15103: Loss: 0.3949\n",
            "Epoch 3, Sample 15104: Loss: 1.0524\n",
            "Epoch 3, Sample 15105: Loss: 0.5003\n",
            "Epoch 3, Sample 15106: Loss: 0.2044\n",
            "Epoch 3, Sample 15107: Loss: 1.0155\n",
            "Epoch 3, Sample 15108: Loss: 0.6893\n",
            "Epoch 3, Sample 15109: Loss: 0.1248\n",
            "Epoch 3, Sample 15110: Loss: 1.0524\n",
            "Epoch 3, Sample 15111: Loss: 0.1397\n",
            "Epoch 3, Sample 15112: Loss: 0.0005\n",
            "Epoch 3, Sample 15113: Loss: 0.2044\n",
            "Epoch 3, Sample 15114: Loss: 1.8616\n",
            "Epoch 3, Sample 15115: Loss: 3.5504\n",
            "Epoch 3, Sample 15116: Loss: 0.5636\n",
            "Epoch 3, Sample 15117: Loss: 0.3441\n",
            "Epoch 3, Sample 15118: Loss: 1.0688\n",
            "Epoch 3, Sample 15119: Loss: 0.1170\n",
            "Epoch 3, Sample 15120: Loss: 1.0524\n",
            "Epoch 3, Sample 15121: Loss: 1.0524\n",
            "Epoch 3, Sample 15122: Loss: 0.0018\n",
            "Epoch 3, Sample 15123: Loss: 0.1627\n",
            "Epoch 3, Sample 15124: Loss: 0.2778\n",
            "Epoch 3, Sample 15125: Loss: 0.0630\n",
            "Epoch 3, Sample 15126: Loss: 0.0466\n",
            "Epoch 3, Sample 15127: Loss: 2.7989\n",
            "Epoch 3, Sample 15128: Loss: 0.2044\n",
            "Epoch 3, Sample 15129: Loss: 0.2034\n",
            "Epoch 3, Sample 15130: Loss: 0.4799\n",
            "Epoch 3, Sample 15131: Loss: 0.2759\n",
            "Epoch 3, Sample 15132: Loss: 0.1225\n",
            "Epoch 3, Sample 15133: Loss: 7.3306\n",
            "Epoch 3, Sample 15134: Loss: 0.0001\n",
            "Epoch 3, Sample 15135: Loss: 0.2086\n",
            "Epoch 3, Sample 15136: Loss: 0.2962\n",
            "Epoch 3, Sample 15137: Loss: 0.3872\n",
            "Epoch 3, Sample 15138: Loss: 0.1250\n",
            "Epoch 3, Sample 15139: Loss: 1.0524\n",
            "Epoch 3, Sample 15140: Loss: 0.3568\n",
            "Epoch 3, Sample 15141: Loss: 0.2044\n",
            "Epoch 3, Sample 15142: Loss: 1.0524\n",
            "Epoch 3, Sample 15143: Loss: 0.0023\n",
            "Epoch 3, Sample 15144: Loss: 0.0001\n",
            "Epoch 3, Sample 15145: Loss: 0.0026\n",
            "Epoch 3, Sample 15146: Loss: 1.0524\n",
            "Epoch 3, Sample 15147: Loss: 0.0026\n",
            "Epoch 3, Sample 15148: Loss: 0.6092\n",
            "Epoch 3, Sample 15149: Loss: 9.1485\n",
            "Epoch 3, Sample 15150: Loss: 1.5597\n",
            "Epoch 3, Sample 15151: Loss: 0.7036\n",
            "Epoch 3, Sample 15152: Loss: 0.5078\n",
            "Epoch 3, Sample 15153: Loss: 0.0625\n",
            "Epoch 3, Sample 15154: Loss: 0.1114\n",
            "Epoch 3, Sample 15155: Loss: 0.7036\n",
            "Epoch 3, Sample 15156: Loss: 0.0062\n",
            "Epoch 3, Sample 15157: Loss: 0.1252\n",
            "Epoch 3, Sample 15158: Loss: 0.0150\n",
            "Epoch 3, Sample 15159: Loss: 0.0476\n",
            "Epoch 3, Sample 15160: Loss: 6.9441\n",
            "Epoch 3, Sample 15161: Loss: 0.0258\n",
            "Epoch 3, Sample 15162: Loss: 0.4930\n",
            "Epoch 3, Sample 15163: Loss: 1.0524\n",
            "Epoch 3, Sample 15164: Loss: 1.9213\n",
            "Epoch 3, Sample 15165: Loss: 0.4588\n",
            "Epoch 3, Sample 15166: Loss: 0.1246\n",
            "Epoch 3, Sample 15167: Loss: 0.2759\n",
            "Epoch 3, Sample 15168: Loss: 0.2941\n",
            "Epoch 3, Sample 15169: Loss: 0.1924\n",
            "Epoch 3, Sample 15170: Loss: 0.5858\n",
            "Epoch 3, Sample 15171: Loss: 0.0000\n",
            "Epoch 3, Sample 15172: Loss: 0.0027\n",
            "Epoch 3, Sample 15173: Loss: 3.5504\n",
            "Epoch 3, Sample 15174: Loss: 0.0001\n",
            "Epoch 3, Sample 15175: Loss: 0.1523\n",
            "Epoch 3, Sample 15176: Loss: 0.3367\n",
            "Epoch 3, Sample 15177: Loss: 1.0524\n",
            "Epoch 3, Sample 15178: Loss: 0.3399\n",
            "Epoch 3, Sample 15179: Loss: 0.4032\n",
            "Epoch 3, Sample 15180: Loss: 0.1238\n",
            "Epoch 3, Sample 15181: Loss: 0.2034\n",
            "Epoch 3, Sample 15182: Loss: 0.1170\n",
            "Epoch 3, Sample 15183: Loss: 0.0018\n",
            "Epoch 3, Sample 15184: Loss: 0.6990\n",
            "Epoch 3, Sample 15185: Loss: 0.0212\n",
            "Epoch 3, Sample 15186: Loss: 0.4799\n",
            "Epoch 3, Sample 15187: Loss: 0.2494\n",
            "Epoch 3, Sample 15188: Loss: 0.1248\n",
            "Epoch 3, Sample 15189: Loss: 2.1901\n",
            "Epoch 3, Sample 15190: Loss: 1.0530\n",
            "Epoch 3, Sample 15191: Loss: 0.2044\n",
            "Epoch 3, Sample 15192: Loss: 0.2032\n",
            "Epoch 3, Sample 15193: Loss: 0.2032\n",
            "Epoch 3, Sample 15194: Loss: 0.2219\n",
            "Epoch 3, Sample 15195: Loss: 41.5700\n",
            "Epoch 3, Sample 15196: Loss: 0.4996\n",
            "Epoch 3, Sample 15197: Loss: 0.6304\n",
            "Epoch 3, Sample 15198: Loss: 0.0915\n",
            "Epoch 3, Sample 15199: Loss: 0.1170\n",
            "Epoch 3, Sample 15200: Loss: 1.0530\n",
            "Epoch 3, Sample 15201: Loss: 0.0049\n",
            "Epoch 3, Sample 15202: Loss: 0.1248\n",
            "Epoch 3, Sample 15203: Loss: 0.2132\n",
            "Epoch 3, Sample 15204: Loss: 0.2034\n",
            "Epoch 3, Sample 15205: Loss: 0.0915\n",
            "Epoch 3, Sample 15206: Loss: 0.0915\n",
            "Epoch 3, Sample 15207: Loss: 0.2219\n",
            "Epoch 3, Sample 15208: Loss: 0.1250\n",
            "Epoch 3, Sample 15209: Loss: 4.5881\n",
            "Epoch 3, Sample 15210: Loss: 0.0084\n",
            "Epoch 3, Sample 15211: Loss: 0.3949\n",
            "Epoch 3, Sample 15212: Loss: 6.2039\n",
            "Epoch 3, Sample 15213: Loss: 0.2112\n",
            "Epoch 3, Sample 15214: Loss: 0.3399\n",
            "Epoch 3, Sample 15215: Loss: 1.0524\n",
            "Epoch 3, Sample 15216: Loss: 0.3477\n",
            "Epoch 3, Sample 15217: Loss: 0.0415\n",
            "Epoch 3, Sample 15218: Loss: 5.8208\n",
            "Epoch 3, Sample 15219: Loss: 3.6056\n",
            "Epoch 3, Sample 15220: Loss: 1.0359\n",
            "Epoch 3, Sample 15221: Loss: 0.2759\n",
            "Epoch 3, Sample 15222: Loss: 0.3399\n",
            "Epoch 3, Sample 15223: Loss: 2.7331\n",
            "Epoch 3, Sample 15224: Loss: 0.2034\n",
            "Epoch 3, Sample 15225: Loss: 0.0630\n",
            "Epoch 3, Sample 15226: Loss: 0.0212\n",
            "Epoch 3, Sample 15227: Loss: 1.2192\n",
            "Epoch 3, Sample 15228: Loss: 1.0524\n",
            "Epoch 3, Sample 15229: Loss: 0.7036\n",
            "Epoch 3, Sample 15230: Loss: 0.2034\n",
            "Epoch 3, Sample 15231: Loss: 0.1559\n",
            "Epoch 3, Sample 15232: Loss: 0.0802\n",
            "Epoch 3, Sample 15233: Loss: 0.0938\n",
            "Epoch 3, Sample 15234: Loss: 0.1817\n",
            "Epoch 3, Sample 15235: Loss: 1.0524\n",
            "Epoch 3, Sample 15236: Loss: 0.2452\n",
            "Epoch 3, Sample 15237: Loss: 0.1248\n",
            "Epoch 3, Sample 15238: Loss: 1.0524\n",
            "Epoch 3, Sample 15239: Loss: 0.3949\n",
            "Epoch 3, Sample 15240: Loss: 0.0751\n",
            "Epoch 3, Sample 15241: Loss: 0.4607\n",
            "Epoch 3, Sample 15242: Loss: 0.3441\n",
            "Epoch 3, Sample 15243: Loss: 1.0524\n",
            "Epoch 3, Sample 15244: Loss: 0.1472\n",
            "Epoch 3, Sample 15245: Loss: 0.1170\n",
            "Epoch 3, Sample 15246: Loss: 0.7036\n",
            "Epoch 3, Sample 15247: Loss: 1.5597\n",
            "Epoch 3, Sample 15248: Loss: 0.2032\n",
            "Epoch 3, Sample 15249: Loss: 0.8951\n",
            "Epoch 3, Sample 15250: Loss: 1.0524\n",
            "Epoch 3, Sample 15251: Loss: 0.2034\n",
            "Epoch 3, Sample 15252: Loss: 0.0042\n",
            "Epoch 3, Sample 15253: Loss: 0.0026\n",
            "Epoch 3, Sample 15254: Loss: 0.6139\n",
            "Epoch 3, Sample 15255: Loss: 1.9820\n",
            "Epoch 3, Sample 15256: Loss: 1.0155\n",
            "Epoch 3, Sample 15257: Loss: 0.0067\n",
            "Epoch 3, Sample 15258: Loss: 0.1039\n",
            "Epoch 3, Sample 15259: Loss: 0.2759\n",
            "Epoch 3, Sample 15260: Loss: 0.5858\n",
            "Epoch 3, Sample 15261: Loss: 0.3441\n",
            "Epoch 3, Sample 15262: Loss: 1.0524\n",
            "Epoch 3, Sample 15263: Loss: 1.0530\n",
            "Epoch 3, Sample 15264: Loss: 0.4611\n",
            "Epoch 3, Sample 15265: Loss: 0.2759\n",
            "Epoch 3, Sample 15266: Loss: 0.0337\n",
            "Epoch 3, Sample 15267: Loss: 0.5636\n",
            "Epoch 3, Sample 15268: Loss: 0.2032\n",
            "Epoch 3, Sample 15269: Loss: 0.0682\n",
            "Epoch 3, Sample 15270: Loss: 0.1248\n",
            "Epoch 3, Sample 15271: Loss: 0.0026\n",
            "Epoch 3, Sample 15272: Loss: 1.0524\n",
            "Epoch 3, Sample 15273: Loss: 0.0000\n",
            "Epoch 3, Sample 15274: Loss: 0.2032\n",
            "Epoch 3, Sample 15275: Loss: 3.8563\n",
            "Epoch 3, Sample 15276: Loss: 0.1170\n",
            "Epoch 3, Sample 15277: Loss: 2.0351\n",
            "Epoch 3, Sample 15278: Loss: 0.1968\n",
            "Epoch 3, Sample 15279: Loss: 0.1264\n",
            "Epoch 3, Sample 15280: Loss: 0.9785\n",
            "Epoch 3, Sample 15281: Loss: 1.1569\n",
            "Epoch 3, Sample 15282: Loss: 0.0945\n",
            "Epoch 3, Sample 15283: Loss: 0.3418\n",
            "Epoch 3, Sample 15284: Loss: 1.5597\n",
            "Epoch 3, Sample 15285: Loss: 0.9780\n",
            "Epoch 3, Sample 15286: Loss: 0.0270\n",
            "Epoch 3, Sample 15287: Loss: 1.5597\n",
            "Epoch 3, Sample 15288: Loss: 0.3441\n",
            "Epoch 3, Sample 15289: Loss: 0.2044\n",
            "Epoch 3, Sample 15290: Loss: 3.1802\n",
            "Epoch 3, Sample 15291: Loss: 0.2034\n",
            "Epoch 3, Sample 15292: Loss: 0.2034\n",
            "Epoch 3, Sample 15293: Loss: 0.4799\n",
            "Epoch 3, Sample 15294: Loss: 0.1036\n",
            "Epoch 3, Sample 15295: Loss: 0.0025\n",
            "Epoch 3, Sample 15296: Loss: 0.2036\n",
            "Epoch 3, Sample 15297: Loss: 0.1397\n",
            "Epoch 3, Sample 15298: Loss: 0.1170\n",
            "Epoch 3, Sample 15299: Loss: 0.9785\n",
            "Epoch 3, Sample 15300: Loss: 0.1246\n",
            "Epoch 3, Sample 15301: Loss: 2.8489\n",
            "Epoch 3, Sample 15302: Loss: 0.0170\n",
            "Epoch 3, Sample 15303: Loss: 0.0001\n",
            "Epoch 3, Sample 15304: Loss: 1.2845\n",
            "Epoch 3, Sample 15305: Loss: 0.1040\n",
            "Epoch 3, Sample 15306: Loss: 0.3399\n",
            "Epoch 3, Sample 15307: Loss: 0.0626\n",
            "Epoch 3, Sample 15308: Loss: 0.1465\n",
            "Epoch 3, Sample 15309: Loss: 0.0819\n",
            "Epoch 3, Sample 15310: Loss: 10.3220\n",
            "Epoch 3, Sample 15311: Loss: 0.0466\n",
            "Epoch 3, Sample 15312: Loss: 1.0524\n",
            "Epoch 3, Sample 15313: Loss: 0.2639\n",
            "Epoch 3, Sample 15314: Loss: 0.3288\n",
            "Epoch 3, Sample 15315: Loss: 0.3477\n",
            "Epoch 3, Sample 15316: Loss: 0.6990\n",
            "Epoch 3, Sample 15317: Loss: 0.2044\n",
            "Epoch 3, Sample 15318: Loss: 1.5597\n",
            "Epoch 3, Sample 15319: Loss: 1.4537\n",
            "Epoch 3, Sample 15320: Loss: 1.0524\n",
            "Epoch 3, Sample 15321: Loss: 0.5799\n",
            "Epoch 3, Sample 15322: Loss: 0.4996\n",
            "Epoch 3, Sample 15323: Loss: 1.0155\n",
            "Epoch 3, Sample 15324: Loss: 0.0802\n",
            "Epoch 3, Sample 15325: Loss: 1.0524\n",
            "Epoch 3, Sample 15326: Loss: 0.0082\n",
            "Epoch 3, Sample 15327: Loss: 0.2032\n",
            "Epoch 3, Sample 15328: Loss: 0.3399\n",
            "Epoch 3, Sample 15329: Loss: 1.0524\n",
            "Epoch 3, Sample 15330: Loss: 1.0524\n",
            "Epoch 3, Sample 15331: Loss: 0.2034\n",
            "Epoch 3, Sample 15332: Loss: 3.2314\n",
            "Epoch 3, Sample 15333: Loss: 0.1546\n",
            "Epoch 3, Sample 15334: Loss: 0.1005\n",
            "Epoch 3, Sample 15335: Loss: 0.0018\n",
            "Epoch 3, Sample 15336: Loss: 0.0001\n",
            "Epoch 3, Sample 15337: Loss: 14.5870\n",
            "Epoch 3, Sample 15338: Loss: 0.0630\n",
            "Epoch 3, Sample 15339: Loss: 0.1039\n",
            "Epoch 3, Sample 15340: Loss: 0.0460\n",
            "Epoch 3, Sample 15341: Loss: 0.0270\n",
            "Epoch 3, Sample 15342: Loss: 0.7203\n",
            "Epoch 3, Sample 15343: Loss: 0.0640\n",
            "Epoch 3, Sample 15344: Loss: 0.7036\n",
            "Epoch 3, Sample 15345: Loss: 1.0524\n",
            "Epoch 3, Sample 15346: Loss: 1.0359\n",
            "Epoch 3, Sample 15347: Loss: 0.0426\n",
            "Epoch 3, Sample 15348: Loss: 3.7714\n",
            "Epoch 3, Sample 15349: Loss: 0.1246\n",
            "Epoch 3, Sample 15350: Loss: 0.2219\n",
            "Epoch 3, Sample 15351: Loss: 0.2036\n",
            "Epoch 3, Sample 15352: Loss: 5.8208\n",
            "Epoch 3, Sample 15353: Loss: 0.1559\n",
            "Epoch 3, Sample 15354: Loss: 1.0524\n",
            "Epoch 3, Sample 15355: Loss: 0.3949\n",
            "Epoch 3, Sample 15356: Loss: 0.1170\n",
            "Epoch 3, Sample 15357: Loss: 5.1724\n",
            "Epoch 3, Sample 15358: Loss: 0.0286\n",
            "Epoch 3, Sample 15359: Loss: 0.3399\n",
            "Epoch 3, Sample 15360: Loss: 7.8073\n",
            "Epoch 3, Sample 15361: Loss: 0.0001\n",
            "Epoch 3, Sample 15362: Loss: 0.3399\n",
            "Epoch 3, Sample 15363: Loss: 4.2335\n",
            "Epoch 3, Sample 15364: Loss: 1.5542\n",
            "Epoch 3, Sample 15365: Loss: 0.6990\n",
            "Epoch 3, Sample 15366: Loss: 1.6326\n",
            "Epoch 3, Sample 15367: Loss: 0.2759\n",
            "Epoch 3, Sample 15368: Loss: 0.3598\n",
            "Epoch 3, Sample 15369: Loss: 0.0915\n",
            "Epoch 3, Sample 15370: Loss: 0.7036\n",
            "Epoch 3, Sample 15371: Loss: 0.1246\n",
            "Epoch 3, Sample 15372: Loss: 3.6601\n",
            "Epoch 3, Sample 15373: Loss: 1.0530\n",
            "Epoch 3, Sample 15374: Loss: 0.2044\n",
            "Epoch 3, Sample 15375: Loss: 0.2044\n",
            "Epoch 3, Sample 15376: Loss: 0.0532\n",
            "Epoch 3, Sample 15377: Loss: 27.2501\n",
            "Epoch 3, Sample 15378: Loss: 0.6990\n",
            "Epoch 3, Sample 15379: Loss: 0.2044\n",
            "Epoch 3, Sample 15380: Loss: 0.1989\n",
            "Epoch 3, Sample 15381: Loss: 1.0524\n",
            "Epoch 3, Sample 15382: Loss: 0.5058\n",
            "Epoch 3, Sample 15383: Loss: 0.0005\n",
            "Epoch 3, Sample 15384: Loss: 0.3367\n",
            "Epoch 3, Sample 15385: Loss: 0.5000\n",
            "Epoch 3, Sample 15386: Loss: 0.9367\n",
            "Epoch 3, Sample 15387: Loss: 0.0026\n",
            "Epoch 3, Sample 15388: Loss: 18.7901\n",
            "Epoch 3, Sample 15389: Loss: 0.0063\n",
            "Epoch 3, Sample 15390: Loss: 1.0524\n",
            "Epoch 3, Sample 15391: Loss: 6.3986\n",
            "Epoch 3, Sample 15392: Loss: 0.4799\n",
            "Epoch 3, Sample 15393: Loss: 0.2778\n",
            "Epoch 3, Sample 15394: Loss: 0.0630\n",
            "Epoch 3, Sample 15395: Loss: 0.0063\n",
            "Epoch 3, Sample 15396: Loss: 0.0230\n",
            "Epoch 3, Sample 15397: Loss: 0.6092\n",
            "Epoch 3, Sample 15398: Loss: 0.0039\n",
            "Epoch 3, Sample 15399: Loss: 0.4996\n",
            "Epoch 3, Sample 15400: Loss: 0.5636\n",
            "Epoch 3, Sample 15401: Loss: 1.2845\n",
            "Epoch 3, Sample 15402: Loss: 1.0530\n",
            "Epoch 3, Sample 15403: Loss: 0.0001\n",
            "Epoch 3, Sample 15404: Loss: 0.0026\n",
            "Epoch 3, Sample 15405: Loss: 1.5597\n",
            "Epoch 3, Sample 15406: Loss: 0.5000\n",
            "Epoch 3, Sample 15407: Loss: 0.0838\n",
            "Epoch 3, Sample 15408: Loss: 0.0460\n",
            "Epoch 3, Sample 15409: Loss: 0.0001\n",
            "Epoch 3, Sample 15410: Loss: 0.1171\n",
            "Epoch 3, Sample 15411: Loss: 2.8294\n",
            "Epoch 3, Sample 15412: Loss: 0.7036\n",
            "Epoch 3, Sample 15413: Loss: 0.7453\n",
            "Epoch 3, Sample 15414: Loss: 0.2032\n",
            "Epoch 3, Sample 15415: Loss: 1.0524\n",
            "Epoch 3, Sample 15416: Loss: 0.7486\n",
            "Epoch 3, Sample 15417: Loss: 0.1170\n",
            "Epoch 3, Sample 15418: Loss: 0.5799\n",
            "Epoch 3, Sample 15419: Loss: 0.0026\n",
            "Epoch 3, Sample 15420: Loss: 0.5078\n",
            "Epoch 3, Sample 15421: Loss: 3.9991\n",
            "Epoch 3, Sample 15422: Loss: 1.0524\n",
            "Epoch 3, Sample 15423: Loss: 0.3062\n",
            "Epoch 3, Sample 15424: Loss: 0.0270\n",
            "Epoch 3, Sample 15425: Loss: 0.2032\n",
            "Epoch 3, Sample 15426: Loss: 0.0018\n",
            "Epoch 3, Sample 15427: Loss: 1.5893\n",
            "Epoch 3, Sample 15428: Loss: 1.5597\n",
            "Epoch 3, Sample 15429: Loss: 0.2329\n",
            "Epoch 3, Sample 15430: Loss: 1.0359\n",
            "Epoch 3, Sample 15431: Loss: 0.0013\n",
            "Epoch 3, Sample 15432: Loss: 0.4032\n",
            "Epoch 3, Sample 15433: Loss: 0.0915\n",
            "Epoch 3, Sample 15434: Loss: 0.2639\n",
            "Epoch 3, Sample 15435: Loss: 0.1559\n",
            "Epoch 3, Sample 15436: Loss: 0.0286\n",
            "Epoch 3, Sample 15437: Loss: 1.7843\n",
            "Epoch 3, Sample 15438: Loss: 0.8951\n",
            "Epoch 3, Sample 15439: Loss: 0.1588\n",
            "Epoch 3, Sample 15440: Loss: 0.1326\n",
            "Epoch 3, Sample 15441: Loss: 1.0524\n",
            "Epoch 3, Sample 15442: Loss: 0.5858\n",
            "Epoch 3, Sample 15443: Loss: 0.1248\n",
            "Epoch 3, Sample 15444: Loss: 0.2639\n",
            "Epoch 3, Sample 15445: Loss: 1.5597\n",
            "Epoch 3, Sample 15446: Loss: 1.0530\n",
            "Epoch 3, Sample 15447: Loss: 6.9441\n",
            "Epoch 3, Sample 15448: Loss: 0.2044\n",
            "Epoch 3, Sample 15449: Loss: 0.1170\n",
            "Epoch 3, Sample 15450: Loss: 0.0026\n",
            "Epoch 3, Sample 15451: Loss: 0.3399\n",
            "Epoch 3, Sample 15452: Loss: 0.3332\n",
            "Epoch 3, Sample 15453: Loss: 0.0625\n",
            "Epoch 3, Sample 15454: Loss: 0.7036\n",
            "Epoch 3, Sample 15455: Loss: 1.0359\n",
            "Epoch 3, Sample 15456: Loss: 1.4884\n",
            "Epoch 3, Sample 15457: Loss: 2.7331\n",
            "Epoch 3, Sample 15458: Loss: 2.7331\n",
            "Epoch 3, Sample 15459: Loss: 0.7036\n",
            "Epoch 3, Sample 15460: Loss: 9.6835\n",
            "Epoch 3, Sample 15461: Loss: 0.0630\n",
            "Epoch 3, Sample 15462: Loss: 0.0062\n",
            "Epoch 3, Sample 15463: Loss: 1.7843\n",
            "Epoch 3, Sample 15464: Loss: 0.3450\n",
            "Epoch 3, Sample 15465: Loss: 1.2553\n",
            "Epoch 3, Sample 15466: Loss: 0.0630\n",
            "Epoch 3, Sample 15467: Loss: 0.2044\n",
            "Epoch 3, Sample 15468: Loss: 0.5058\n",
            "Epoch 3, Sample 15469: Loss: 0.1248\n",
            "Epoch 3, Sample 15470: Loss: 0.2034\n",
            "Epoch 3, Sample 15471: Loss: 0.1417\n",
            "Epoch 3, Sample 15472: Loss: 0.4930\n",
            "Epoch 3, Sample 15473: Loss: 0.1559\n",
            "Epoch 3, Sample 15474: Loss: 2.8294\n",
            "Epoch 3, Sample 15475: Loss: 0.8951\n",
            "Epoch 3, Sample 15476: Loss: 0.0026\n",
            "Epoch 3, Sample 15477: Loss: 0.3584\n",
            "Epoch 3, Sample 15478: Loss: 1.0155\n",
            "Epoch 3, Sample 15479: Loss: 0.0220\n",
            "Epoch 3, Sample 15480: Loss: 0.5003\n",
            "Epoch 3, Sample 15481: Loss: 1.0155\n",
            "Epoch 3, Sample 15482: Loss: 0.7036\n",
            "Epoch 3, Sample 15483: Loss: 0.0313\n",
            "Epoch 3, Sample 15484: Loss: 0.6867\n",
            "Epoch 3, Sample 15485: Loss: 0.1399\n",
            "Epoch 3, Sample 15486: Loss: 0.3332\n",
            "Epoch 3, Sample 15487: Loss: 0.0640\n",
            "Epoch 3, Sample 15488: Loss: 1.3405\n",
            "Epoch 3, Sample 15489: Loss: 0.3418\n",
            "Epoch 3, Sample 15490: Loss: 1.5597\n",
            "Epoch 3, Sample 15491: Loss: 1.0524\n",
            "Epoch 3, Sample 15492: Loss: 1.0227\n",
            "Epoch 3, Sample 15493: Loss: 0.5000\n",
            "Epoch 3, Sample 15494: Loss: 0.5871\n",
            "Epoch 3, Sample 15495: Loss: 0.1225\n",
            "Epoch 3, Sample 15496: Loss: 0.0022\n",
            "Epoch 3, Sample 15497: Loss: 0.2355\n",
            "Epoch 3, Sample 15498: Loss: 0.1401\n",
            "Epoch 3, Sample 15499: Loss: 0.0018\n",
            "Epoch 3, Sample 15500: Loss: 1.0524\n",
            "Epoch 3, Sample 15501: Loss: 0.0001\n",
            "Epoch 3, Sample 15502: Loss: 0.7453\n",
            "Epoch 3, Sample 15503: Loss: 0.9780\n",
            "Epoch 3, Sample 15504: Loss: 0.2759\n",
            "Epoch 3, Sample 15505: Loss: 3.6601\n",
            "Epoch 3, Sample 15506: Loss: 0.1335\n",
            "Epoch 3, Sample 15507: Loss: 0.0270\n",
            "Epoch 3, Sample 15508: Loss: 0.1246\n",
            "Epoch 3, Sample 15509: Loss: 0.9367\n",
            "Epoch 3, Sample 15510: Loss: 1.0524\n",
            "Epoch 3, Sample 15511: Loss: 0.0018\n",
            "Epoch 3, Sample 15512: Loss: 0.2832\n",
            "Epoch 3, Sample 15513: Loss: 0.7036\n",
            "Epoch 3, Sample 15514: Loss: 10.5084\n",
            "Epoch 3, Sample 15515: Loss: 0.0364\n",
            "Epoch 3, Sample 15516: Loss: 0.0018\n",
            "Epoch 3, Sample 15517: Loss: 0.3441\n",
            "Epoch 3, Sample 15518: Loss: 0.2832\n",
            "Epoch 3, Sample 15519: Loss: 0.2175\n",
            "Epoch 3, Sample 15520: Loss: 0.2032\n",
            "Epoch 3, Sample 15521: Loss: 0.0240\n",
            "Epoch 3, Sample 15522: Loss: 3.5504\n",
            "Epoch 3, Sample 15523: Loss: 0.7036\n",
            "Epoch 3, Sample 15524: Loss: 0.3441\n",
            "Epoch 3, Sample 15525: Loss: 0.0212\n",
            "Epoch 3, Sample 15526: Loss: 1.0530\n",
            "Epoch 3, Sample 15527: Loss: 0.0212\n",
            "Epoch 3, Sample 15528: Loss: 0.1248\n",
            "Epoch 3, Sample 15529: Loss: 0.7036\n",
            "Epoch 3, Sample 15530: Loss: 2.2981\n",
            "Epoch 3, Sample 15531: Loss: 0.2704\n",
            "Epoch 3, Sample 15532: Loss: 2.0642\n",
            "Epoch 3, Sample 15533: Loss: 0.1588\n",
            "Epoch 3, Sample 15534: Loss: 0.3949\n",
            "Epoch 3, Sample 15535: Loss: 2.1901\n",
            "Epoch 3, Sample 15536: Loss: 0.1397\n",
            "Epoch 3, Sample 15537: Loss: 0.0026\n",
            "Epoch 3, Sample 15538: Loss: 1.0524\n",
            "Epoch 3, Sample 15539: Loss: 0.1546\n",
            "Epoch 3, Sample 15540: Loss: 0.0501\n",
            "Epoch 3, Sample 15541: Loss: 0.2851\n",
            "Epoch 3, Sample 15542: Loss: 0.3402\n",
            "Epoch 3, Sample 15543: Loss: 0.2759\n",
            "Epoch 3, Sample 15544: Loss: 0.2044\n",
            "Epoch 3, Sample 15545: Loss: 0.9367\n",
            "Epoch 3, Sample 15546: Loss: 0.2639\n",
            "Epoch 3, Sample 15547: Loss: 1.0524\n",
            "Epoch 3, Sample 15548: Loss: 0.1250\n",
            "Epoch 3, Sample 15549: Loss: 9.7728\n",
            "Epoch 3, Sample 15550: Loss: 0.0270\n",
            "Epoch 3, Sample 15551: Loss: 0.2962\n",
            "Epoch 3, Sample 15552: Loss: 0.0005\n",
            "Epoch 3, Sample 15553: Loss: 0.9780\n",
            "Epoch 3, Sample 15554: Loss: 0.8951\n",
            "Epoch 3, Sample 15555: Loss: 0.2759\n",
            "Epoch 3, Sample 15556: Loss: 0.0938\n",
            "Epoch 3, Sample 15557: Loss: 1.0266\n",
            "Epoch 3, Sample 15558: Loss: 0.0026\n",
            "Epoch 3, Sample 15559: Loss: 2.7331\n",
            "Epoch 3, Sample 15560: Loss: 1.0524\n",
            "Epoch 3, Sample 15561: Loss: 0.0145\n",
            "Epoch 3, Sample 15562: Loss: 0.3441\n",
            "Epoch 3, Sample 15563: Loss: 0.0026\n",
            "Epoch 3, Sample 15564: Loss: 0.1250\n",
            "Epoch 3, Sample 15565: Loss: 1.0524\n",
            "Epoch 3, Sample 15566: Loss: 0.1559\n",
            "Epoch 3, Sample 15567: Loss: 1.0359\n",
            "Epoch 3, Sample 15568: Loss: 0.2032\n",
            "Epoch 3, Sample 15569: Loss: 0.0915\n",
            "Epoch 3, Sample 15570: Loss: 0.2759\n",
            "Epoch 3, Sample 15571: Loss: 1.0524\n",
            "Epoch 3, Sample 15572: Loss: 0.3758\n",
            "Epoch 3, Sample 15573: Loss: 0.6139\n",
            "Epoch 3, Sample 15574: Loss: 1.0524\n",
            "Epoch 3, Sample 15575: Loss: 0.0018\n",
            "Epoch 3, Sample 15576: Loss: 1.1789\n",
            "Epoch 3, Sample 15577: Loss: 0.6190\n",
            "Epoch 3, Sample 15578: Loss: 0.1248\n",
            "Epoch 3, Sample 15579: Loss: 1.0524\n",
            "Epoch 3, Sample 15580: Loss: 0.2044\n",
            "Epoch 3, Sample 15581: Loss: 2.7331\n",
            "Epoch 3, Sample 15582: Loss: 0.2759\n",
            "Epoch 3, Sample 15583: Loss: 0.0630\n",
            "Epoch 3, Sample 15584: Loss: 0.1170\n",
            "Epoch 3, Sample 15585: Loss: 0.0001\n",
            "Epoch 3, Sample 15586: Loss: 0.2036\n",
            "Epoch 3, Sample 15587: Loss: 0.0018\n",
            "Epoch 3, Sample 15588: Loss: 1.0530\n",
            "Epoch 3, Sample 15589: Loss: 1.0524\n",
            "Epoch 3, Sample 15590: Loss: 4.3531\n",
            "Epoch 3, Sample 15591: Loss: 0.1248\n",
            "Epoch 3, Sample 15592: Loss: 0.0505\n",
            "Epoch 3, Sample 15593: Loss: 0.0207\n",
            "Epoch 3, Sample 15594: Loss: 0.4611\n",
            "Epoch 3, Sample 15595: Loss: 0.0630\n",
            "Epoch 3, Sample 15596: Loss: 1.0524\n",
            "Epoch 3, Sample 15597: Loss: 3.5504\n",
            "Epoch 3, Sample 15598: Loss: 0.9780\n",
            "Epoch 3, Sample 15599: Loss: 0.1248\n",
            "Epoch 3, Sample 15600: Loss: 0.2879\n",
            "Epoch 3, Sample 15601: Loss: 0.2832\n",
            "Epoch 3, Sample 15602: Loss: 0.1482\n",
            "Epoch 3, Sample 15603: Loss: 0.1250\n",
            "Epoch 3, Sample 15604: Loss: 0.9651\n",
            "Epoch 3, Sample 15605: Loss: 0.3247\n",
            "Epoch 3, Sample 15606: Loss: 1.0524\n",
            "Epoch 3, Sample 15607: Loss: 0.1924\n",
            "Epoch 3, Sample 15608: Loss: 0.0532\n",
            "Epoch 3, Sample 15609: Loss: 0.0026\n",
            "Epoch 3, Sample 15610: Loss: 0.4466\n",
            "Epoch 3, Sample 15611: Loss: 1.0524\n",
            "Epoch 3, Sample 15612: Loss: 0.7036\n",
            "Epoch 3, Sample 15613: Loss: 0.2044\n",
            "Epoch 3, Sample 15614: Loss: 0.4996\n",
            "Epoch 3, Sample 15615: Loss: 0.2034\n",
            "Epoch 3, Sample 15616: Loss: 0.4102\n",
            "Epoch 3, Sample 15617: Loss: 0.2639\n",
            "Epoch 3, Sample 15618: Loss: 0.6092\n",
            "Epoch 3, Sample 15619: Loss: 0.2044\n",
            "Epoch 3, Sample 15620: Loss: 0.2032\n",
            "Epoch 3, Sample 15621: Loss: 0.0838\n",
            "Epoch 3, Sample 15622: Loss: 0.1627\n",
            "Epoch 3, Sample 15623: Loss: 0.2639\n",
            "Epoch 3, Sample 15624: Loss: 0.5871\n",
            "Epoch 3, Sample 15625: Loss: 5.1063\n",
            "Epoch 3, Sample 15626: Loss: 0.3399\n",
            "Epoch 3, Sample 15627: Loss: 1.0524\n",
            "Epoch 3, Sample 15628: Loss: 0.0026\n",
            "Epoch 3, Sample 15629: Loss: 0.0026\n",
            "Epoch 3, Sample 15630: Loss: 0.1170\n",
            "Epoch 3, Sample 15631: Loss: 0.1989\n",
            "Epoch 3, Sample 15632: Loss: 0.1559\n",
            "Epoch 3, Sample 15633: Loss: 0.4611\n",
            "Epoch 3, Sample 15634: Loss: 0.4663\n",
            "Epoch 3, Sample 15635: Loss: 0.2032\n",
            "Epoch 3, Sample 15636: Loss: 0.2759\n",
            "Epoch 3, Sample 15637: Loss: 0.1337\n",
            "Epoch 3, Sample 15638: Loss: 0.5989\n",
            "Epoch 3, Sample 15639: Loss: 0.4930\n",
            "Epoch 3, Sample 15640: Loss: 0.2034\n",
            "Epoch 3, Sample 15641: Loss: 1.0524\n",
            "Epoch 3, Sample 15642: Loss: 0.1559\n",
            "Epoch 3, Sample 15643: Loss: 0.5019\n",
            "Epoch 3, Sample 15644: Loss: 1.0155\n",
            "Epoch 3, Sample 15645: Loss: 0.0145\n",
            "Epoch 3, Sample 15646: Loss: 0.3399\n",
            "Epoch 3, Sample 15647: Loss: 0.0938\n",
            "Epoch 3, Sample 15648: Loss: 2.8693\n",
            "Epoch 3, Sample 15649: Loss: 0.1170\n",
            "Epoch 3, Sample 15650: Loss: 0.7036\n",
            "Epoch 3, Sample 15651: Loss: 0.0145\n",
            "Epoch 3, Sample 15652: Loss: 0.7036\n",
            "Epoch 3, Sample 15653: Loss: 0.1170\n",
            "Epoch 3, Sample 15654: Loss: 0.5858\n",
            "Epoch 3, Sample 15655: Loss: 4.7222\n",
            "Epoch 3, Sample 15656: Loss: 0.7036\n",
            "Epoch 3, Sample 15657: Loss: 0.1336\n",
            "Epoch 3, Sample 15658: Loss: 0.0915\n",
            "Epoch 3, Sample 15659: Loss: 0.5000\n",
            "Epoch 3, Sample 15660: Loss: 0.2044\n",
            "Epoch 3, Sample 15661: Loss: 2.7331\n",
            "Epoch 3, Sample 15662: Loss: 0.1248\n",
            "Epoch 3, Sample 15663: Loss: 1.8616\n",
            "Epoch 3, Sample 15664: Loss: 0.4611\n",
            "Epoch 3, Sample 15665: Loss: 2.5454\n",
            "Epoch 3, Sample 15666: Loss: 0.7203\n",
            "Epoch 3, Sample 15667: Loss: 1.0155\n",
            "Epoch 3, Sample 15668: Loss: 1.0266\n",
            "Epoch 3, Sample 15669: Loss: 1.9743\n",
            "Epoch 3, Sample 15670: Loss: 0.0026\n",
            "Epoch 3, Sample 15671: Loss: 0.0972\n",
            "Epoch 3, Sample 15672: Loss: 0.1250\n",
            "Epoch 3, Sample 15673: Loss: 0.2989\n",
            "Epoch 3, Sample 15674: Loss: 0.0025\n",
            "Epoch 3, Sample 15675: Loss: 1.0956\n",
            "Epoch 3, Sample 15676: Loss: 0.4930\n",
            "Epoch 3, Sample 15677: Loss: 1.0524\n",
            "Epoch 3, Sample 15678: Loss: 0.3402\n",
            "Epoch 3, Sample 15679: Loss: 0.2112\n",
            "Epoch 3, Sample 15680: Loss: 1.0524\n",
            "Epoch 3, Sample 15681: Loss: 0.0025\n",
            "Epoch 3, Sample 15682: Loss: 0.3568\n",
            "Epoch 3, Sample 15683: Loss: 0.4611\n",
            "Epoch 3, Sample 15684: Loss: 0.1817\n",
            "Epoch 3, Sample 15685: Loss: 0.1036\n",
            "Epoch 3, Sample 15686: Loss: 0.0027\n",
            "Epoch 3, Sample 15687: Loss: 2.7331\n",
            "Epoch 3, Sample 15688: Loss: 3.2960\n",
            "Epoch 3, Sample 15689: Loss: 3.1294\n",
            "Epoch 3, Sample 15690: Loss: 0.2044\n",
            "Epoch 3, Sample 15691: Loss: 0.1625\n",
            "Epoch 3, Sample 15692: Loss: 0.2044\n",
            "Epoch 3, Sample 15693: Loss: 15.2563\n",
            "Epoch 3, Sample 15694: Loss: 1.0524\n",
            "Epoch 3, Sample 15695: Loss: 0.4550\n",
            "Epoch 3, Sample 15696: Loss: 0.7036\n",
            "Epoch 3, Sample 15697: Loss: 0.7453\n",
            "Epoch 3, Sample 15698: Loss: 0.3399\n",
            "Epoch 3, Sample 15699: Loss: 0.0026\n",
            "Epoch 3, Sample 15700: Loss: 0.0630\n",
            "Epoch 3, Sample 15701: Loss: 0.0026\n",
            "Epoch 3, Sample 15702: Loss: 2.9274\n",
            "Epoch 3, Sample 15703: Loss: 0.3247\n",
            "Epoch 3, Sample 15704: Loss: 0.0625\n",
            "Epoch 3, Sample 15705: Loss: 0.6990\n",
            "Epoch 3, Sample 15706: Loss: 0.3402\n",
            "Epoch 3, Sample 15707: Loss: 1.6326\n",
            "Epoch 3, Sample 15708: Loss: 2.8731\n",
            "Epoch 3, Sample 15709: Loss: 3.6601\n",
            "Epoch 3, Sample 15710: Loss: 0.3441\n",
            "Epoch 3, Sample 15711: Loss: 0.2759\n",
            "Epoch 3, Sample 15712: Loss: 1.8616\n",
            "Epoch 3, Sample 15713: Loss: 2.0351\n",
            "Epoch 3, Sample 15714: Loss: 0.6990\n",
            "Epoch 3, Sample 15715: Loss: 0.3399\n",
            "Epoch 3, Sample 15716: Loss: 3.5504\n",
            "Epoch 3, Sample 15717: Loss: 2.7331\n",
            "Epoch 3, Sample 15718: Loss: 0.1250\n",
            "Epoch 3, Sample 15719: Loss: 0.3805\n",
            "Epoch 3, Sample 15720: Loss: 0.1941\n",
            "Epoch 3, Sample 15721: Loss: 2.1901\n",
            "Epoch 3, Sample 15722: Loss: 0.0306\n",
            "Epoch 3, Sample 15723: Loss: 0.3949\n",
            "Epoch 3, Sample 15724: Loss: 2.9718\n",
            "Epoch 3, Sample 15725: Loss: 0.1246\n",
            "Epoch 3, Sample 15726: Loss: 0.2755\n",
            "Epoch 3, Sample 15727: Loss: 0.3332\n",
            "Epoch 3, Sample 15728: Loss: 1.0155\n",
            "Epoch 3, Sample 15729: Loss: 0.3949\n",
            "Epoch 3, Sample 15730: Loss: 0.6139\n",
            "Epoch 3, Sample 15731: Loss: 0.1559\n",
            "Epoch 3, Sample 15732: Loss: 2.2434\n",
            "Epoch 3, Sample 15733: Loss: 0.3332\n",
            "Epoch 3, Sample 15734: Loss: 0.1170\n",
            "Epoch 3, Sample 15735: Loss: 0.0505\n",
            "Epoch 3, Sample 15736: Loss: 1.5597\n",
            "Epoch 3, Sample 15737: Loss: 0.8951\n",
            "Epoch 3, Sample 15738: Loss: 0.4996\n",
            "Epoch 3, Sample 15739: Loss: 0.2219\n",
            "Epoch 3, Sample 15740: Loss: 0.2032\n",
            "Epoch 3, Sample 15741: Loss: 0.2044\n",
            "Epoch 3, Sample 15742: Loss: 0.4996\n",
            "Epoch 3, Sample 15743: Loss: 0.2219\n",
            "Epoch 3, Sample 15744: Loss: 0.3399\n",
            "Epoch 3, Sample 15745: Loss: 0.0460\n",
            "Epoch 3, Sample 15746: Loss: 0.1559\n",
            "Epoch 3, Sample 15747: Loss: 0.0630\n",
            "Epoch 3, Sample 15748: Loss: 0.1250\n",
            "Epoch 3, Sample 15749: Loss: 0.7486\n",
            "Epoch 3, Sample 15750: Loss: 2.7331\n",
            "Epoch 3, Sample 15751: Loss: 0.2044\n",
            "Epoch 3, Sample 15752: Loss: 0.1559\n",
            "Epoch 3, Sample 15753: Loss: 0.0018\n",
            "Epoch 3, Sample 15754: Loss: 0.0590\n",
            "Epoch 3, Sample 15755: Loss: 0.5000\n",
            "Epoch 3, Sample 15756: Loss: 0.0026\n",
            "Epoch 3, Sample 15757: Loss: 0.9780\n",
            "Epoch 3, Sample 15758: Loss: 0.1246\n",
            "Epoch 3, Sample 15759: Loss: 0.9367\n",
            "Epoch 3, Sample 15760: Loss: 0.1170\n",
            "Epoch 3, Sample 15761: Loss: 0.8141\n",
            "Epoch 3, Sample 15762: Loss: 0.4799\n",
            "Epoch 3, Sample 15763: Loss: 0.7453\n",
            "Epoch 3, Sample 15764: Loss: 0.6990\n",
            "Epoch 3, Sample 15765: Loss: 0.5003\n",
            "Epoch 3, Sample 15766: Loss: 1.0155\n",
            "Epoch 3, Sample 15767: Loss: 1.0524\n",
            "Epoch 3, Sample 15768: Loss: 0.3441\n",
            "Epoch 3, Sample 15769: Loss: 0.1219\n",
            "Epoch 3, Sample 15770: Loss: 0.9780\n",
            "Epoch 3, Sample 15771: Loss: 0.3539\n",
            "Epoch 3, Sample 15772: Loss: 0.6990\n",
            "Epoch 3, Sample 15773: Loss: 0.0042\n",
            "Epoch 3, Sample 15774: Loss: 0.7036\n",
            "Epoch 3, Sample 15775: Loss: 0.5871\n",
            "Epoch 3, Sample 15776: Loss: 0.3949\n",
            "Epoch 3, Sample 15777: Loss: 0.3441\n",
            "Epoch 3, Sample 15778: Loss: 0.0144\n",
            "Epoch 3, Sample 15779: Loss: 1.1569\n",
            "Epoch 3, Sample 15780: Loss: 0.1399\n",
            "Epoch 3, Sample 15781: Loss: 0.7036\n",
            "Epoch 3, Sample 15782: Loss: 0.1968\n",
            "Epoch 3, Sample 15783: Loss: 0.1397\n",
            "Epoch 3, Sample 15784: Loss: 3.6601\n",
            "Epoch 3, Sample 15785: Loss: 0.5003\n",
            "Epoch 3, Sample 15786: Loss: 2.1901\n",
            "Epoch 3, Sample 15787: Loss: 0.2034\n",
            "Epoch 3, Sample 15788: Loss: 1.0530\n",
            "Epoch 3, Sample 15789: Loss: 0.3441\n",
            "Epoch 3, Sample 15790: Loss: 0.1654\n",
            "Epoch 3, Sample 15791: Loss: 0.3399\n",
            "Epoch 3, Sample 15792: Loss: 0.4611\n",
            "Epoch 3, Sample 15793: Loss: 1.0524\n",
            "Epoch 3, Sample 15794: Loss: 1.0524\n",
            "Epoch 3, Sample 15795: Loss: 1.0524\n",
            "Epoch 3, Sample 15796: Loss: 2.7331\n",
            "Epoch 3, Sample 15797: Loss: 0.7486\n",
            "Epoch 3, Sample 15798: Loss: 0.1250\n",
            "Epoch 3, Sample 15799: Loss: 0.0026\n",
            "Epoch 3, Sample 15800: Loss: 1.0524\n",
            "Epoch 3, Sample 15801: Loss: 0.2034\n",
            "Epoch 3, Sample 15802: Loss: 0.3441\n",
            "Epoch 3, Sample 15803: Loss: 0.0838\n",
            "Epoch 3, Sample 15804: Loss: 0.4930\n",
            "Epoch 3, Sample 15805: Loss: 0.0475\n",
            "Epoch 3, Sample 15806: Loss: 1.7195\n",
            "Epoch 3, Sample 15807: Loss: 3.2314\n",
            "Epoch 3, Sample 15808: Loss: 1.0524\n",
            "Epoch 3, Sample 15809: Loss: 1.0956\n",
            "Epoch 3, Sample 15810: Loss: 0.0554\n",
            "Epoch 3, Sample 15811: Loss: 0.7036\n",
            "Epoch 3, Sample 15812: Loss: 0.1625\n",
            "Epoch 3, Sample 15813: Loss: 0.0145\n",
            "Epoch 3, Sample 15814: Loss: 0.2034\n",
            "Epoch 3, Sample 15815: Loss: 0.3441\n",
            "Epoch 3, Sample 15816: Loss: 2.6860\n",
            "Epoch 3, Sample 15817: Loss: 0.0018\n",
            "Epoch 3, Sample 15818: Loss: 0.0212\n",
            "Epoch 3, Sample 15819: Loss: 1.1205\n",
            "Epoch 3, Sample 15820: Loss: 0.0026\n",
            "Epoch 3, Sample 15821: Loss: 3.5504\n",
            "Epoch 3, Sample 15822: Loss: 0.4032\n",
            "Epoch 3, Sample 15823: Loss: 0.2989\n",
            "Epoch 3, Sample 15824: Loss: 0.2340\n",
            "Epoch 3, Sample 15825: Loss: 0.0026\n",
            "Epoch 3, Sample 15826: Loss: 0.0026\n",
            "Epoch 3, Sample 15827: Loss: 0.9785\n",
            "Epoch 3, Sample 15828: Loss: 15.2563\n",
            "Epoch 3, Sample 15829: Loss: 4.2937\n",
            "Epoch 3, Sample 15830: Loss: 0.9367\n",
            "Epoch 3, Sample 15831: Loss: 1.0524\n",
            "Epoch 3, Sample 15832: Loss: 0.2044\n",
            "Epoch 3, Sample 15833: Loss: 0.1170\n",
            "Epoch 3, Sample 15834: Loss: 0.0460\n",
            "Epoch 3, Sample 15835: Loss: 0.2935\n",
            "Epoch 3, Sample 15836: Loss: 2.7331\n",
            "Epoch 3, Sample 15837: Loss: 0.2044\n",
            "Epoch 3, Sample 15838: Loss: 0.2704\n",
            "Epoch 3, Sample 15839: Loss: 0.6139\n",
            "Epoch 3, Sample 15840: Loss: 2.6860\n",
            "Epoch 3, Sample 15841: Loss: 15.3704\n",
            "Epoch 3, Sample 15842: Loss: 0.1250\n",
            "Epoch 3, Sample 15843: Loss: 0.1170\n",
            "Epoch 3, Sample 15844: Loss: 0.0608\n",
            "Epoch 3, Sample 15845: Loss: 0.7036\n",
            "Epoch 3, Sample 15846: Loss: 0.4799\n",
            "Epoch 3, Sample 15847: Loss: 0.0026\n",
            "Epoch 3, Sample 15848: Loss: 0.2759\n",
            "Epoch 3, Sample 15849: Loss: 0.3949\n",
            "Epoch 3, Sample 15850: Loss: 1.5597\n",
            "Epoch 3, Sample 15851: Loss: 1.4884\n",
            "Epoch 3, Sample 15852: Loss: 0.0013\n",
            "Epoch 3, Sample 15853: Loss: 0.0018\n",
            "Epoch 3, Sample 15854: Loss: 0.8951\n",
            "Epoch 3, Sample 15855: Loss: 0.4382\n",
            "Epoch 3, Sample 15856: Loss: 0.3758\n",
            "Epoch 3, Sample 15857: Loss: 0.0018\n",
            "Epoch 3, Sample 15858: Loss: 0.0026\n",
            "Epoch 3, Sample 15859: Loss: 0.4902\n",
            "Epoch 3, Sample 15860: Loss: 0.2034\n",
            "Epoch 3, Sample 15861: Loss: 0.1250\n",
            "Epoch 3, Sample 15862: Loss: 0.3399\n",
            "Epoch 3, Sample 15863: Loss: 4.9130\n",
            "Epoch 3, Sample 15864: Loss: 0.2032\n",
            "Epoch 3, Sample 15865: Loss: 0.9367\n",
            "Epoch 3, Sample 15866: Loss: 0.2036\n",
            "Epoch 3, Sample 15867: Loss: 0.2970\n",
            "Epoch 3, Sample 15868: Loss: 2.1901\n",
            "Epoch 3, Sample 15869: Loss: 0.2032\n",
            "Epoch 3, Sample 15870: Loss: 0.8951\n",
            "Epoch 3, Sample 15871: Loss: 0.1250\n",
            "Epoch 3, Sample 15872: Loss: 1.0359\n",
            "Epoch 3, Sample 15873: Loss: 0.3441\n",
            "Epoch 3, Sample 15874: Loss: 0.1399\n",
            "Epoch 3, Sample 15875: Loss: 0.1807\n",
            "Epoch 3, Sample 15876: Loss: 3.5504\n",
            "Epoch 3, Sample 15877: Loss: 0.2759\n",
            "Epoch 3, Sample 15878: Loss: 0.0026\n",
            "Epoch 3, Sample 15879: Loss: 0.1559\n",
            "Epoch 3, Sample 15880: Loss: 0.1233\n",
            "Epoch 3, Sample 15881: Loss: 0.2034\n",
            "Epoch 3, Sample 15882: Loss: 0.1170\n",
            "Epoch 3, Sample 15883: Loss: 0.1863\n",
            "Epoch 3, Sample 15884: Loss: 0.8951\n",
            "Epoch 3, Sample 15885: Loss: 0.2759\n",
            "Epoch 3, Sample 15886: Loss: 0.1170\n",
            "Epoch 3, Sample 15887: Loss: 0.1170\n",
            "Epoch 3, Sample 15888: Loss: 0.2832\n",
            "Epoch 3, Sample 15889: Loss: 4.7858\n",
            "Epoch 3, Sample 15890: Loss: 0.3347\n",
            "Epoch 3, Sample 15891: Loss: 0.2340\n",
            "Epoch 3, Sample 15892: Loss: 2.7331\n",
            "Epoch 3, Sample 15893: Loss: 0.2044\n",
            "Epoch 3, Sample 15894: Loss: 0.2778\n",
            "Epoch 3, Sample 15895: Loss: 1.0155\n",
            "Epoch 3, Sample 15896: Loss: 0.4799\n",
            "Epoch 3, Sample 15897: Loss: 0.0026\n",
            "Epoch 3, Sample 15898: Loss: 0.0001\n",
            "Epoch 3, Sample 15899: Loss: 0.1248\n",
            "Epoch 3, Sample 15900: Loss: 0.3399\n",
            "Epoch 3, Sample 15901: Loss: 0.6304\n",
            "Epoch 3, Sample 15902: Loss: 2.4095\n",
            "Epoch 3, Sample 15903: Loss: 1.6256\n",
            "Epoch 3, Sample 15904: Loss: 0.5858\n",
            "Epoch 3, Sample 15905: Loss: 0.2034\n",
            "Epoch 3, Sample 15906: Loss: 0.0205\n",
            "Epoch 3, Sample 15907: Loss: 0.6990\n",
            "Epoch 3, Sample 15908: Loss: 0.5858\n",
            "Epoch 3, Sample 15909: Loss: 0.8951\n",
            "Epoch 3, Sample 15910: Loss: 0.2121\n",
            "Epoch 3, Sample 15911: Loss: 0.0625\n",
            "Epoch 3, Sample 15912: Loss: 0.0036\n",
            "Epoch 3, Sample 15913: Loss: 0.0001\n",
            "Epoch 3, Sample 15914: Loss: 24.7460\n",
            "Epoch 3, Sample 15915: Loss: 0.0630\n",
            "Epoch 3, Sample 15916: Loss: 0.0108\n",
            "Epoch 3, Sample 15917: Loss: 0.2032\n",
            "Epoch 3, Sample 15918: Loss: 0.2428\n",
            "Epoch 3, Sample 15919: Loss: 2.7331\n",
            "Epoch 3, Sample 15920: Loss: 0.5196\n",
            "Epoch 3, Sample 15921: Loss: 0.3126\n",
            "Epoch 3, Sample 15922: Loss: 0.7036\n",
            "Epoch 3, Sample 15923: Loss: 0.7036\n",
            "Epoch 3, Sample 15924: Loss: 0.4799\n",
            "Epoch 3, Sample 15925: Loss: 0.0026\n",
            "Epoch 3, Sample 15926: Loss: 0.0014\n",
            "Epoch 3, Sample 15927: Loss: 1.0530\n",
            "Epoch 3, Sample 15928: Loss: 0.0838\n",
            "Epoch 3, Sample 15929: Loss: 0.9780\n",
            "Epoch 3, Sample 15930: Loss: 0.3758\n",
            "Epoch 3, Sample 15931: Loss: 0.0306\n",
            "Epoch 3, Sample 15932: Loss: 0.3450\n",
            "Epoch 3, Sample 15933: Loss: 1.2845\n",
            "Epoch 3, Sample 15934: Loss: 0.0001\n",
            "Epoch 3, Sample 15935: Loss: 1.5597\n",
            "Epoch 3, Sample 15936: Loss: 0.6190\n",
            "Epoch 3, Sample 15937: Loss: 0.5089\n",
            "Epoch 3, Sample 15938: Loss: 0.7007\n",
            "Epoch 3, Sample 15939: Loss: 0.0626\n",
            "Epoch 3, Sample 15940: Loss: 0.6990\n",
            "Epoch 3, Sample 15941: Loss: 0.2759\n",
            "Epoch 3, Sample 15942: Loss: 0.1588\n",
            "Epoch 3, Sample 15943: Loss: 0.2935\n",
            "Epoch 3, Sample 15944: Loss: 0.3399\n",
            "Epoch 3, Sample 15945: Loss: 1.0956\n",
            "Epoch 3, Sample 15946: Loss: 0.1252\n",
            "Epoch 3, Sample 15947: Loss: 1.3405\n",
            "Epoch 3, Sample 15948: Loss: 0.0062\n",
            "Epoch 3, Sample 15949: Loss: 0.0303\n",
            "Epoch 3, Sample 15950: Loss: 3.6328\n",
            "Epoch 3, Sample 15951: Loss: 1.0524\n",
            "Epoch 3, Sample 15952: Loss: 0.2759\n",
            "Epoch 3, Sample 15953: Loss: 0.1627\n",
            "Epoch 3, Sample 15954: Loss: 1.5597\n",
            "Epoch 3, Sample 15955: Loss: 0.3399\n",
            "Epoch 3, Sample 15956: Loss: 0.6867\n",
            "Epoch 3, Sample 15957: Loss: 0.0270\n",
            "Epoch 3, Sample 15958: Loss: 1.5597\n",
            "Epoch 3, Sample 15959: Loss: 0.1250\n",
            "Epoch 3, Sample 15960: Loss: 0.2340\n",
            "Epoch 3, Sample 15961: Loss: 0.9785\n",
            "Epoch 3, Sample 15962: Loss: 6.1915\n",
            "Epoch 3, Sample 15963: Loss: 1.0530\n",
            "Epoch 3, Sample 15964: Loss: 0.9780\n",
            "Epoch 3, Sample 15965: Loss: 0.3332\n",
            "Epoch 3, Sample 15966: Loss: 0.6139\n",
            "Epoch 3, Sample 15967: Loss: 0.2962\n",
            "Epoch 3, Sample 15968: Loss: 0.2755\n",
            "Epoch 3, Sample 15969: Loss: 2.1901\n",
            "Epoch 3, Sample 15970: Loss: 0.1999\n",
            "Epoch 3, Sample 15971: Loss: 6.4949\n",
            "Epoch 3, Sample 15972: Loss: 0.0026\n",
            "Epoch 3, Sample 15973: Loss: 0.0972\n",
            "Epoch 3, Sample 15974: Loss: 0.3399\n",
            "Epoch 3, Sample 15975: Loss: 2.8693\n",
            "Epoch 3, Sample 15976: Loss: 1.0524\n",
            "Epoch 3, Sample 15977: Loss: 0.6867\n",
            "Epoch 3, Sample 15978: Loss: 0.2044\n",
            "Epoch 3, Sample 15979: Loss: 0.0630\n",
            "Epoch 3, Sample 15980: Loss: 0.8951\n",
            "Epoch 3, Sample 15981: Loss: 0.3441\n",
            "Epoch 3, Sample 15982: Loss: 0.3399\n",
            "Epoch 3, Sample 15983: Loss: 1.0524\n",
            "Epoch 3, Sample 15984: Loss: 0.0018\n",
            "Epoch 3, Sample 15985: Loss: 0.8951\n",
            "Epoch 3, Sample 15986: Loss: 1.1569\n",
            "Epoch 3, Sample 15987: Loss: 0.0026\n",
            "Epoch 3, Sample 15988: Loss: 0.0026\n",
            "Epoch 3, Sample 15989: Loss: 1.0155\n",
            "Epoch 3, Sample 15990: Loss: 0.4641\n",
            "Epoch 3, Sample 15991: Loss: 1.5597\n",
            "Epoch 3, Sample 15992: Loss: 0.1219\n",
            "Epoch 3, Sample 15993: Loss: 0.2182\n",
            "Epoch 3, Sample 15994: Loss: 0.1246\n",
            "Epoch 3, Sample 15995: Loss: 0.6139\n",
            "Epoch 3, Sample 15996: Loss: 7.6726\n",
            "Epoch 3, Sample 15997: Loss: 0.9780\n",
            "Epoch 3, Sample 15998: Loss: 0.5972\n",
            "Epoch 3, Sample 15999: Loss: 2.7331\n",
            "Epoch 3, Sample 16000: Loss: 0.6867\n",
            "\n",
            "Epoch 3 Average Loss: 1.0000\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd Iteration with different settings for hyperparameters"
      ],
      "metadata": {
        "id": "ky3brznDxtga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For second trial we chose these settings\n",
        "epochs = 3\n",
        "learning_rate = .01\n",
        "input_size = 20\n",
        "Neurons = 50\n",
        "activation_input = 50\n",
        "activation function = relu\n",
        "output = 1"
      ],
      "metadata": {
        "id": "ZhGUlpnuGci8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "learning_rate = .01\n",
        "\n",
        "\n",
        "# Initializing Parameters\n",
        "w = 50\n",
        "\n",
        "loss_set = {}\n",
        "\n",
        "# 1. Creating a FeedForwardNetwork\n",
        "# 1.1 Structure (Architecture) of NN\n",
        "model_net2 = torch.nn.Sequential(torch.nn.Linear(20,50),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(0.33),\n",
        "\n",
        "                                 torch.nn.Linear(50,1),\n",
        "                                 torch.nn.ReLU(),\n",
        "\n",
        "                                 );\n",
        "\n",
        "# 1.2 Loss Function\n",
        "loss_mse = torch.nn.MSELoss()\n",
        "\n",
        "# 1.3 Optmization Approch\n",
        "optimizer = torch.optim.SGD(model_net2.parameters(), lr=learning_rate)\n",
        "\n",
        "w_his = []\n",
        "w_his.append(w)\n",
        "# Loop over the number of epochs\n",
        "for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over each sample in the dataset\n",
        "    for i in range(tensor_data_X.size(0)):\n",
        "\n",
        "      # 2. Forward Pass\n",
        "      output = model_net2.forward(tensor_data_X[i].reshape(-1))\n",
        "\n",
        "      # 3. FeedForward Evaluation\n",
        "      loss = loss_mse(output, tensor_data_Y[i].reshape(-1))\n",
        "      optimizer.zero_grad();\n",
        "\n",
        "      # 4. Backward Pass / Gradient Calculation\n",
        "      loss.backward()\n",
        "\n",
        "      # Store the loss for each epoch\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # 5. Back Propagation / Update Weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store the weight value for each sample of data\n",
        "      w_his.append(float(model_net2[0].weight.data[0][0]))\n",
        "\n",
        "      # Display the loss for the current sample\n",
        "      print(f\"Epoch {epoch+1}, Sample {i+1}: Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # Calculate and display average loss for the epoch\n",
        "    epoch_loss /= tensor_data_X.size(0)\n",
        "\n",
        "    # Store the loss for each sample of data\n",
        "    loss_set[epoch] = epoch_loss\n",
        "    print(f\"\\nEpoch {epoch+1} Average Loss: {epoch_loss:.4f}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "id": "67VHQHgBB7Jn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1b6a43a52eb248848d20929e868eee1b",
            "bed8a0513ae543869c7cafa7998381fd",
            "1613e52ec3324d8f9967b37656e8e451",
            "52d6ebbcb0e24767bf16c2ebffdd2938",
            "0de17172e400486ba64ae454ed94b372",
            "11bee05cd71649068861db2111821960",
            "5f4011a59eee428eb2e64bb550f10400",
            "69906c2f595543d383fb2b281470a4b9",
            "c6b6cb388b0b4f7fbf46fb71a6435d35",
            "b96c0ac20e2447b5a00d2e4d2eaffbb4",
            "7bb7532926424400b24511a151284b66"
          ]
        },
        "outputId": "f65a4a1c-f594-4a3b-9928-1d5007c894cd"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-269-19b664e51985>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b6a43a52eb248848d20929e868eee1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 11005: Loss: 0.2832\n",
            "Epoch 3, Sample 11006: Loss: 0.1425\n",
            "Epoch 3, Sample 11007: Loss: 0.2293\n",
            "Epoch 3, Sample 11008: Loss: 0.7036\n",
            "Epoch 3, Sample 11009: Loss: 0.0864\n",
            "Epoch 3, Sample 11010: Loss: 0.0008\n",
            "Epoch 3, Sample 11011: Loss: 1.2137\n",
            "Epoch 3, Sample 11012: Loss: 0.7453\n",
            "Epoch 3, Sample 11013: Loss: 0.4425\n",
            "Epoch 3, Sample 11014: Loss: 0.2032\n",
            "Epoch 3, Sample 11015: Loss: 0.1357\n",
            "Epoch 3, Sample 11016: Loss: 0.3399\n",
            "Epoch 3, Sample 11017: Loss: 0.2339\n",
            "Epoch 3, Sample 11018: Loss: 0.2539\n",
            "Epoch 3, Sample 11019: Loss: 0.0505\n",
            "Epoch 3, Sample 11020: Loss: 0.1170\n",
            "Epoch 3, Sample 11021: Loss: 0.4663\n",
            "Epoch 3, Sample 11022: Loss: 1.6418\n",
            "Epoch 3, Sample 11023: Loss: 0.2750\n",
            "Epoch 3, Sample 11024: Loss: 0.9367\n",
            "Epoch 3, Sample 11025: Loss: 0.0025\n",
            "Epoch 3, Sample 11026: Loss: 1.1265\n",
            "Epoch 3, Sample 11027: Loss: 1.0155\n",
            "Epoch 3, Sample 11028: Loss: 0.7036\n",
            "Epoch 3, Sample 11029: Loss: 0.5871\n",
            "Epoch 3, Sample 11030: Loss: 0.0212\n",
            "Epoch 3, Sample 11031: Loss: 0.0505\n",
            "Epoch 3, Sample 11032: Loss: 1.0524\n",
            "Epoch 3, Sample 11033: Loss: 0.3857\n",
            "Epoch 3, Sample 11034: Loss: 0.1838\n",
            "Epoch 3, Sample 11035: Loss: 0.0189\n",
            "Epoch 3, Sample 11036: Loss: 0.8844\n",
            "Epoch 3, Sample 11037: Loss: 0.2098\n",
            "Epoch 3, Sample 11038: Loss: 0.5511\n",
            "Epoch 3, Sample 11039: Loss: 1.0155\n",
            "Epoch 3, Sample 11040: Loss: 1.0524\n",
            "Epoch 3, Sample 11041: Loss: 0.0391\n",
            "Epoch 3, Sample 11042: Loss: 1.9336\n",
            "Epoch 3, Sample 11043: Loss: 0.0287\n",
            "Epoch 3, Sample 11044: Loss: 0.2639\n",
            "Epoch 3, Sample 11045: Loss: 0.0630\n",
            "Epoch 3, Sample 11046: Loss: 0.3441\n",
            "Epoch 3, Sample 11047: Loss: 0.1074\n",
            "Epoch 3, Sample 11048: Loss: 0.9367\n",
            "Epoch 3, Sample 11049: Loss: 0.2759\n",
            "Epoch 3, Sample 11050: Loss: 0.0084\n",
            "Epoch 3, Sample 11051: Loss: 0.0001\n",
            "Epoch 3, Sample 11052: Loss: 1.7510\n",
            "Epoch 3, Sample 11053: Loss: 0.2032\n",
            "Epoch 3, Sample 11054: Loss: 0.0554\n",
            "Epoch 3, Sample 11055: Loss: 0.0035\n",
            "Epoch 3, Sample 11056: Loss: 0.0018\n",
            "Epoch 3, Sample 11057: Loss: 0.0001\n",
            "Epoch 3, Sample 11058: Loss: 2.6734\n",
            "Epoch 3, Sample 11059: Loss: 0.9845\n",
            "Epoch 3, Sample 11060: Loss: 0.2210\n",
            "Epoch 3, Sample 11061: Loss: 3.1372\n",
            "Epoch 3, Sample 11062: Loss: 0.0234\n",
            "Epoch 3, Sample 11063: Loss: 0.2044\n",
            "Epoch 3, Sample 11064: Loss: 0.9017\n",
            "Epoch 3, Sample 11065: Loss: 0.7036\n",
            "Epoch 3, Sample 11066: Loss: 0.1111\n",
            "Epoch 3, Sample 11067: Loss: 0.1380\n",
            "Epoch 3, Sample 11068: Loss: 1.0530\n",
            "Epoch 3, Sample 11069: Loss: 0.7036\n",
            "Epoch 3, Sample 11070: Loss: 0.2639\n",
            "Epoch 3, Sample 11071: Loss: 0.7036\n",
            "Epoch 3, Sample 11072: Loss: 0.5858\n",
            "Epoch 3, Sample 11073: Loss: 0.0598\n",
            "Epoch 3, Sample 11074: Loss: 0.0429\n",
            "Epoch 3, Sample 11075: Loss: 0.0026\n",
            "Epoch 3, Sample 11076: Loss: 1.2136\n",
            "Epoch 3, Sample 11077: Loss: 0.4367\n",
            "Epoch 3, Sample 11078: Loss: 0.2412\n",
            "Epoch 3, Sample 11079: Loss: 0.3399\n",
            "Epoch 3, Sample 11080: Loss: 0.7942\n",
            "Epoch 3, Sample 11081: Loss: 0.0145\n",
            "Epoch 3, Sample 11082: Loss: 0.0026\n",
            "Epoch 3, Sample 11083: Loss: 0.2639\n",
            "Epoch 3, Sample 11084: Loss: 0.0205\n",
            "Epoch 3, Sample 11085: Loss: 1.0524\n",
            "Epoch 3, Sample 11086: Loss: 0.3399\n",
            "Epoch 3, Sample 11087: Loss: 0.1559\n",
            "Epoch 3, Sample 11088: Loss: 1.0155\n",
            "Epoch 3, Sample 11089: Loss: 0.0022\n",
            "Epoch 3, Sample 11090: Loss: 0.0630\n",
            "Epoch 3, Sample 11091: Loss: 0.2044\n",
            "Epoch 3, Sample 11092: Loss: 0.0018\n",
            "Epoch 3, Sample 11093: Loss: 0.1162\n",
            "Epoch 3, Sample 11094: Loss: 0.0026\n",
            "Epoch 3, Sample 11095: Loss: 1.0524\n",
            "Epoch 3, Sample 11096: Loss: 0.2340\n",
            "Epoch 3, Sample 11097: Loss: 0.5078\n",
            "Epoch 3, Sample 11098: Loss: 0.0108\n",
            "Epoch 3, Sample 11099: Loss: 0.2295\n",
            "Epoch 3, Sample 11100: Loss: 0.2044\n",
            "Epoch 3, Sample 11101: Loss: 0.1170\n",
            "Epoch 3, Sample 11102: Loss: 0.2036\n",
            "Epoch 3, Sample 11103: Loss: 0.5858\n",
            "Epoch 3, Sample 11104: Loss: 0.2034\n",
            "Epoch 3, Sample 11105: Loss: 0.7374\n",
            "Epoch 3, Sample 11106: Loss: 0.2032\n",
            "Epoch 3, Sample 11107: Loss: 0.5793\n",
            "Epoch 3, Sample 11108: Loss: 0.0630\n",
            "Epoch 3, Sample 11109: Loss: 0.2340\n",
            "Epoch 3, Sample 11110: Loss: 1.0524\n",
            "Epoch 3, Sample 11111: Loss: 0.2032\n",
            "Epoch 3, Sample 11112: Loss: 0.0136\n",
            "Epoch 3, Sample 11113: Loss: 1.0524\n",
            "Epoch 3, Sample 11114: Loss: 1.0155\n",
            "Epoch 3, Sample 11115: Loss: 0.1250\n",
            "Epoch 3, Sample 11116: Loss: 0.4607\n",
            "Epoch 3, Sample 11117: Loss: 1.0524\n",
            "Epoch 3, Sample 11118: Loss: 0.0034\n",
            "Epoch 3, Sample 11119: Loss: 1.0524\n",
            "Epoch 3, Sample 11120: Loss: 0.7036\n",
            "Epoch 3, Sample 11121: Loss: 0.2044\n",
            "Epoch 3, Sample 11122: Loss: 0.1170\n",
            "Epoch 3, Sample 11123: Loss: 0.5278\n",
            "Epoch 3, Sample 11124: Loss: 0.2759\n",
            "Epoch 3, Sample 11125: Loss: 0.0630\n",
            "Epoch 3, Sample 11126: Loss: 0.7036\n",
            "Epoch 3, Sample 11127: Loss: 1.4049\n",
            "Epoch 3, Sample 11128: Loss: 0.4930\n",
            "Epoch 3, Sample 11129: Loss: 0.9367\n",
            "Epoch 3, Sample 11130: Loss: 0.0154\n",
            "Epoch 3, Sample 11131: Loss: 0.1250\n",
            "Epoch 3, Sample 11132: Loss: 1.0524\n",
            "Epoch 3, Sample 11133: Loss: 0.1240\n",
            "Epoch 3, Sample 11134: Loss: 0.0460\n",
            "Epoch 3, Sample 11135: Loss: 0.2036\n",
            "Epoch 3, Sample 11136: Loss: 0.0018\n",
            "Epoch 3, Sample 11137: Loss: 0.8033\n",
            "Epoch 3, Sample 11138: Loss: 0.3976\n",
            "Epoch 3, Sample 11139: Loss: 0.0001\n",
            "Epoch 3, Sample 11140: Loss: 0.7169\n",
            "Epoch 3, Sample 11141: Loss: 0.2759\n",
            "Epoch 3, Sample 11142: Loss: 0.4611\n",
            "Epoch 3, Sample 11143: Loss: 0.2032\n",
            "Epoch 3, Sample 11144: Loss: 0.2219\n",
            "Epoch 3, Sample 11145: Loss: 0.7036\n",
            "Epoch 3, Sample 11146: Loss: 0.0062\n",
            "Epoch 3, Sample 11147: Loss: 0.9383\n",
            "Epoch 3, Sample 11148: Loss: 0.0003\n",
            "Epoch 3, Sample 11149: Loss: 0.7036\n",
            "Epoch 3, Sample 11150: Loss: 0.3632\n",
            "Epoch 3, Sample 11151: Loss: 0.2036\n",
            "Epoch 3, Sample 11152: Loss: 0.0086\n",
            "Epoch 3, Sample 11153: Loss: 0.6990\n",
            "Epoch 3, Sample 11154: Loss: 0.0802\n",
            "Epoch 3, Sample 11155: Loss: 0.1250\n",
            "Epoch 3, Sample 11156: Loss: 0.6304\n",
            "Epoch 3, Sample 11157: Loss: 0.9785\n",
            "Epoch 3, Sample 11158: Loss: 0.8951\n",
            "Epoch 3, Sample 11159: Loss: 0.2044\n",
            "Epoch 3, Sample 11160: Loss: 0.2349\n",
            "Epoch 3, Sample 11161: Loss: 0.0437\n",
            "Epoch 3, Sample 11162: Loss: 0.0026\n",
            "Epoch 3, Sample 11163: Loss: 0.2112\n",
            "Epoch 3, Sample 11164: Loss: 0.0453\n",
            "Epoch 3, Sample 11165: Loss: 0.0144\n",
            "Epoch 3, Sample 11166: Loss: 0.2032\n",
            "Epoch 3, Sample 11167: Loss: 0.7036\n",
            "Epoch 3, Sample 11168: Loss: 0.3873\n",
            "Epoch 3, Sample 11169: Loss: 1.8685\n",
            "Epoch 3, Sample 11170: Loss: 0.1720\n",
            "Epoch 3, Sample 11171: Loss: 1.0530\n",
            "Epoch 3, Sample 11172: Loss: 0.0026\n",
            "Epoch 3, Sample 11173: Loss: 0.2036\n",
            "Epoch 3, Sample 11174: Loss: 0.1523\n",
            "Epoch 3, Sample 11175: Loss: 0.2759\n",
            "Epoch 3, Sample 11176: Loss: 0.0637\n",
            "Epoch 3, Sample 11177: Loss: 3.7763\n",
            "Epoch 3, Sample 11178: Loss: 0.8951\n",
            "Epoch 3, Sample 11179: Loss: 0.1616\n",
            "Epoch 3, Sample 11180: Loss: 0.5000\n",
            "Epoch 3, Sample 11181: Loss: 0.3155\n",
            "Epoch 3, Sample 11182: Loss: 1.0155\n",
            "Epoch 3, Sample 11183: Loss: 0.0445\n",
            "Epoch 3, Sample 11184: Loss: 1.0524\n",
            "Epoch 3, Sample 11185: Loss: 0.2056\n",
            "Epoch 3, Sample 11186: Loss: 0.4611\n",
            "Epoch 3, Sample 11187: Loss: 0.2682\n",
            "Epoch 3, Sample 11188: Loss: 0.2032\n",
            "Epoch 3, Sample 11189: Loss: 1.0155\n",
            "Epoch 3, Sample 11190: Loss: 1.6644\n",
            "Epoch 3, Sample 11191: Loss: 0.3399\n",
            "Epoch 3, Sample 11192: Loss: 0.7036\n",
            "Epoch 3, Sample 11193: Loss: 0.2639\n",
            "Epoch 3, Sample 11194: Loss: 0.2034\n",
            "Epoch 3, Sample 11195: Loss: 0.7036\n",
            "Epoch 3, Sample 11196: Loss: 0.2036\n",
            "Epoch 3, Sample 11197: Loss: 1.0524\n",
            "Epoch 3, Sample 11198: Loss: 0.0626\n",
            "Epoch 3, Sample 11199: Loss: 1.0530\n",
            "Epoch 3, Sample 11200: Loss: 2.6384\n",
            "Epoch 3, Sample 11201: Loss: 0.2639\n",
            "Epoch 3, Sample 11202: Loss: 0.0683\n",
            "Epoch 3, Sample 11203: Loss: 0.2034\n",
            "Epoch 3, Sample 11204: Loss: 0.8359\n",
            "Epoch 3, Sample 11205: Loss: 0.4611\n",
            "Epoch 3, Sample 11206: Loss: 1.0524\n",
            "Epoch 3, Sample 11207: Loss: 1.0524\n",
            "Epoch 3, Sample 11208: Loss: 0.1626\n",
            "Epoch 3, Sample 11209: Loss: 0.0630\n",
            "Epoch 3, Sample 11210: Loss: 0.0026\n",
            "Epoch 3, Sample 11211: Loss: 0.2044\n",
            "Epoch 3, Sample 11212: Loss: 0.2832\n",
            "Epoch 3, Sample 11213: Loss: 0.3441\n",
            "Epoch 3, Sample 11214: Loss: 0.4996\n",
            "Epoch 3, Sample 11215: Loss: 0.5375\n",
            "Epoch 3, Sample 11216: Loss: 0.0460\n",
            "Epoch 3, Sample 11217: Loss: 0.4031\n",
            "Epoch 3, Sample 11218: Loss: 0.2878\n",
            "Epoch 3, Sample 11219: Loss: 1.0524\n",
            "Epoch 3, Sample 11220: Loss: 0.0027\n",
            "Epoch 3, Sample 11221: Loss: 0.0108\n",
            "Epoch 3, Sample 11222: Loss: 1.0155\n",
            "Epoch 3, Sample 11223: Loss: 0.0026\n",
            "Epoch 3, Sample 11224: Loss: 0.1170\n",
            "Epoch 3, Sample 11225: Loss: 0.0018\n",
            "Epoch 3, Sample 11226: Loss: 0.2034\n",
            "Epoch 3, Sample 11227: Loss: 0.2340\n",
            "Epoch 3, Sample 11228: Loss: 0.2573\n",
            "Epoch 3, Sample 11229: Loss: 0.1225\n",
            "Epoch 3, Sample 11230: Loss: 0.1674\n",
            "Epoch 3, Sample 11231: Loss: 1.0155\n",
            "Epoch 3, Sample 11232: Loss: 0.3402\n",
            "Epoch 3, Sample 11233: Loss: 0.2340\n",
            "Epoch 3, Sample 11234: Loss: 0.0026\n",
            "Epoch 3, Sample 11235: Loss: 0.1463\n",
            "Epoch 3, Sample 11236: Loss: 0.8951\n",
            "Epoch 3, Sample 11237: Loss: 0.2044\n",
            "Epoch 3, Sample 11238: Loss: 0.4032\n",
            "Epoch 3, Sample 11239: Loss: 0.8584\n",
            "Epoch 3, Sample 11240: Loss: 0.4032\n",
            "Epoch 3, Sample 11241: Loss: 0.0234\n",
            "Epoch 3, Sample 11242: Loss: 0.6990\n",
            "Epoch 3, Sample 11243: Loss: 0.0363\n",
            "Epoch 3, Sample 11244: Loss: 0.1655\n",
            "Epoch 3, Sample 11245: Loss: 0.0625\n",
            "Epoch 3, Sample 11246: Loss: 0.5671\n",
            "Epoch 3, Sample 11247: Loss: 0.1546\n",
            "Epoch 3, Sample 11248: Loss: 0.0191\n",
            "Epoch 3, Sample 11249: Loss: 0.2098\n",
            "Epoch 3, Sample 11250: Loss: 1.0155\n",
            "Epoch 3, Sample 11251: Loss: 0.0915\n",
            "Epoch 3, Sample 11252: Loss: 0.9367\n",
            "Epoch 3, Sample 11253: Loss: 1.1714\n",
            "Epoch 3, Sample 11254: Loss: 0.1559\n",
            "Epoch 3, Sample 11255: Loss: 0.3399\n",
            "Epoch 3, Sample 11256: Loss: 0.3402\n",
            "Epoch 3, Sample 11257: Loss: 0.1084\n",
            "Epoch 3, Sample 11258: Loss: 0.1315\n",
            "Epoch 3, Sample 11259: Loss: 0.6990\n",
            "Epoch 3, Sample 11260: Loss: 1.0524\n",
            "Epoch 3, Sample 11261: Loss: 0.0138\n",
            "Epoch 3, Sample 11262: Loss: 0.0026\n",
            "Epoch 3, Sample 11263: Loss: 0.0391\n",
            "Epoch 3, Sample 11264: Loss: 0.3441\n",
            "Epoch 3, Sample 11265: Loss: 0.8951\n",
            "Epoch 3, Sample 11266: Loss: 1.4650\n",
            "Epoch 3, Sample 11267: Loss: 0.0001\n",
            "Epoch 3, Sample 11268: Loss: 0.2759\n",
            "Epoch 3, Sample 11269: Loss: 0.6304\n",
            "Epoch 3, Sample 11270: Loss: 0.2759\n",
            "Epoch 3, Sample 11271: Loss: 0.2034\n",
            "Epoch 3, Sample 11272: Loss: 0.5858\n",
            "Epoch 3, Sample 11273: Loss: 0.0018\n",
            "Epoch 3, Sample 11274: Loss: 0.3399\n",
            "Epoch 3, Sample 11275: Loss: 1.0266\n",
            "Epoch 3, Sample 11276: Loss: 0.0526\n",
            "Epoch 3, Sample 11277: Loss: 0.0915\n",
            "Epoch 3, Sample 11278: Loss: 0.2044\n",
            "Epoch 3, Sample 11279: Loss: 0.7036\n",
            "Epoch 3, Sample 11280: Loss: 0.3399\n",
            "Epoch 3, Sample 11281: Loss: 2.2434\n",
            "Epoch 3, Sample 11282: Loss: 0.0070\n",
            "Epoch 3, Sample 11283: Loss: 1.2203\n",
            "Epoch 3, Sample 11284: Loss: 0.0018\n",
            "Epoch 3, Sample 11285: Loss: 0.4930\n",
            "Epoch 3, Sample 11286: Loss: 1.4884\n",
            "Epoch 3, Sample 11287: Loss: 0.2030\n",
            "Epoch 3, Sample 11288: Loss: 0.4032\n",
            "Epoch 3, Sample 11289: Loss: 0.2759\n",
            "Epoch 3, Sample 11290: Loss: 0.7383\n",
            "Epoch 3, Sample 11291: Loss: 0.4032\n",
            "Epoch 3, Sample 11292: Loss: 0.1863\n",
            "Epoch 3, Sample 11293: Loss: 0.5871\n",
            "Epoch 3, Sample 11294: Loss: 0.3399\n",
            "Epoch 3, Sample 11295: Loss: 0.0260\n",
            "Epoch 3, Sample 11296: Loss: 0.0630\n",
            "Epoch 3, Sample 11297: Loss: 0.4032\n",
            "Epoch 3, Sample 11298: Loss: 0.2044\n",
            "Epoch 3, Sample 11299: Loss: 0.4867\n",
            "Epoch 3, Sample 11300: Loss: 0.0739\n",
            "Epoch 3, Sample 11301: Loss: 0.4607\n",
            "Epoch 3, Sample 11302: Loss: 0.2044\n",
            "Epoch 3, Sample 11303: Loss: 0.1559\n",
            "Epoch 3, Sample 11304: Loss: 0.2659\n",
            "Epoch 3, Sample 11305: Loss: 6.5443\n",
            "Epoch 3, Sample 11306: Loss: 0.0212\n",
            "Epoch 3, Sample 11307: Loss: 0.9835\n",
            "Epoch 3, Sample 11308: Loss: 2.7331\n",
            "Epoch 3, Sample 11309: Loss: 0.6990\n",
            "Epoch 3, Sample 11310: Loss: 0.7603\n",
            "Epoch 3, Sample 11311: Loss: 0.6243\n",
            "Epoch 3, Sample 11312: Loss: 0.0212\n",
            "Epoch 3, Sample 11313: Loss: 0.2182\n",
            "Epoch 3, Sample 11314: Loss: 0.3399\n",
            "Epoch 3, Sample 11315: Loss: 0.3399\n",
            "Epoch 3, Sample 11316: Loss: 0.0915\n",
            "Epoch 3, Sample 11317: Loss: 0.7036\n",
            "Epoch 3, Sample 11318: Loss: 0.0576\n",
            "Epoch 3, Sample 11319: Loss: 0.4611\n",
            "Epoch 3, Sample 11320: Loss: 0.6092\n",
            "Epoch 3, Sample 11321: Loss: 0.1523\n",
            "Epoch 3, Sample 11322: Loss: 0.3949\n",
            "Epoch 3, Sample 11323: Loss: 0.2738\n",
            "Epoch 3, Sample 11324: Loss: 0.9367\n",
            "Epoch 3, Sample 11325: Loss: 0.1040\n",
            "Epoch 3, Sample 11326: Loss: 1.0524\n",
            "Epoch 3, Sample 11327: Loss: 0.3949\n",
            "Epoch 3, Sample 11328: Loss: 0.1264\n",
            "Epoch 3, Sample 11329: Loss: 0.0013\n",
            "Epoch 3, Sample 11330: Loss: 0.2044\n",
            "Epoch 3, Sample 11331: Loss: 0.0455\n",
            "Epoch 3, Sample 11332: Loss: 0.3399\n",
            "Epoch 3, Sample 11333: Loss: 0.0052\n",
            "Epoch 3, Sample 11334: Loss: 0.0501\n",
            "Epoch 3, Sample 11335: Loss: 0.3257\n",
            "Epoch 3, Sample 11336: Loss: 0.5799\n",
            "Epoch 3, Sample 11337: Loss: 0.2729\n",
            "Epoch 3, Sample 11338: Loss: 0.4761\n",
            "Epoch 3, Sample 11339: Loss: 0.0466\n",
            "Epoch 3, Sample 11340: Loss: 0.3332\n",
            "Epoch 3, Sample 11341: Loss: 0.2044\n",
            "Epoch 3, Sample 11342: Loss: 0.7036\n",
            "Epoch 3, Sample 11343: Loss: 0.2079\n",
            "Epoch 3, Sample 11344: Loss: 0.1250\n",
            "Epoch 3, Sample 11345: Loss: 0.2014\n",
            "Epoch 3, Sample 11346: Loss: 6.2570\n",
            "Epoch 3, Sample 11347: Loss: 0.2832\n",
            "Epoch 3, Sample 11348: Loss: 0.5019\n",
            "Epoch 3, Sample 11349: Loss: 0.7858\n",
            "Epoch 3, Sample 11350: Loss: 0.3399\n",
            "Epoch 3, Sample 11351: Loss: 1.4305\n",
            "Epoch 3, Sample 11352: Loss: 0.9651\n",
            "Epoch 3, Sample 11353: Loss: 0.8951\n",
            "Epoch 3, Sample 11354: Loss: 1.4898\n",
            "Epoch 3, Sample 11355: Loss: 0.6679\n",
            "Epoch 3, Sample 11356: Loss: 0.0914\n",
            "Epoch 3, Sample 11357: Loss: 0.5972\n",
            "Epoch 3, Sample 11358: Loss: 0.2044\n",
            "Epoch 3, Sample 11359: Loss: 0.1627\n",
            "Epoch 3, Sample 11360: Loss: 1.0788\n",
            "Epoch 3, Sample 11361: Loss: 0.1225\n",
            "Epoch 3, Sample 11362: Loss: 3.1707\n",
            "Epoch 3, Sample 11363: Loss: 0.0026\n",
            "Epoch 3, Sample 11364: Loss: 0.0068\n",
            "Epoch 3, Sample 11365: Loss: 1.0687\n",
            "Epoch 3, Sample 11366: Loss: 0.2034\n",
            "Epoch 3, Sample 11367: Loss: 0.4032\n",
            "Epoch 3, Sample 11368: Loss: 0.5858\n",
            "Epoch 3, Sample 11369: Loss: 0.2949\n",
            "Epoch 3, Sample 11370: Loss: 0.1250\n",
            "Epoch 3, Sample 11371: Loss: 0.0161\n",
            "Epoch 3, Sample 11372: Loss: 0.0144\n",
            "Epoch 3, Sample 11373: Loss: 0.0001\n",
            "Epoch 3, Sample 11374: Loss: 1.0524\n",
            "Epoch 3, Sample 11375: Loss: 0.2759\n",
            "Epoch 3, Sample 11376: Loss: 0.2084\n",
            "Epoch 3, Sample 11377: Loss: 0.0043\n",
            "Epoch 3, Sample 11378: Loss: 0.0729\n",
            "Epoch 3, Sample 11379: Loss: 0.2962\n",
            "Epoch 3, Sample 11380: Loss: 0.0460\n",
            "Epoch 3, Sample 11381: Loss: 1.0524\n",
            "Epoch 3, Sample 11382: Loss: 0.0838\n",
            "Epoch 3, Sample 11383: Loss: 0.7036\n",
            "Epoch 3, Sample 11384: Loss: 2.6598\n",
            "Epoch 3, Sample 11385: Loss: 0.2079\n",
            "Epoch 3, Sample 11386: Loss: 0.1250\n",
            "Epoch 3, Sample 11387: Loss: 0.0834\n",
            "Epoch 3, Sample 11388: Loss: 0.0972\n",
            "Epoch 3, Sample 11389: Loss: 0.4090\n",
            "Epoch 3, Sample 11390: Loss: 0.5871\n",
            "Epoch 3, Sample 11391: Loss: 1.0266\n",
            "Epoch 3, Sample 11392: Loss: 0.6099\n",
            "Epoch 3, Sample 11393: Loss: 0.0700\n",
            "Epoch 3, Sample 11394: Loss: 0.3441\n",
            "Epoch 3, Sample 11395: Loss: 0.1496\n",
            "Epoch 3, Sample 11396: Loss: 1.0524\n",
            "Epoch 3, Sample 11397: Loss: 0.0567\n",
            "Epoch 3, Sample 11398: Loss: 0.0668\n",
            "Epoch 3, Sample 11399: Loss: 0.4792\n",
            "Epoch 3, Sample 11400: Loss: 0.1219\n",
            "Epoch 3, Sample 11401: Loss: 0.2044\n",
            "Epoch 3, Sample 11402: Loss: 0.0313\n",
            "Epoch 3, Sample 11403: Loss: 0.0626\n",
            "Epoch 3, Sample 11404: Loss: 0.2759\n",
            "Epoch 3, Sample 11405: Loss: 1.0524\n",
            "Epoch 3, Sample 11406: Loss: 1.0524\n",
            "Epoch 3, Sample 11407: Loss: 1.0155\n",
            "Epoch 3, Sample 11408: Loss: 1.8616\n",
            "Epoch 3, Sample 11409: Loss: 0.0018\n",
            "Epoch 3, Sample 11410: Loss: 0.0018\n",
            "Epoch 3, Sample 11411: Loss: 0.2044\n",
            "Epoch 3, Sample 11412: Loss: 0.8951\n",
            "Epoch 3, Sample 11413: Loss: 0.0101\n",
            "Epoch 3, Sample 11414: Loss: 0.2832\n",
            "Epoch 3, Sample 11415: Loss: 0.0777\n",
            "Epoch 3, Sample 11416: Loss: 0.3402\n",
            "Epoch 3, Sample 11417: Loss: 0.0081\n",
            "Epoch 3, Sample 11418: Loss: 0.0001\n",
            "Epoch 3, Sample 11419: Loss: 0.2044\n",
            "Epoch 3, Sample 11420: Loss: 0.9024\n",
            "Epoch 3, Sample 11421: Loss: 0.7453\n",
            "Epoch 3, Sample 11422: Loss: 0.2759\n",
            "Epoch 3, Sample 11423: Loss: 0.7036\n",
            "Epoch 3, Sample 11424: Loss: 0.0286\n",
            "Epoch 3, Sample 11425: Loss: 0.2034\n",
            "Epoch 3, Sample 11426: Loss: 0.2044\n",
            "Epoch 3, Sample 11427: Loss: 0.5858\n",
            "Epoch 3, Sample 11428: Loss: 1.0524\n",
            "Epoch 3, Sample 11429: Loss: 0.0018\n",
            "Epoch 3, Sample 11430: Loss: 0.5871\n",
            "Epoch 3, Sample 11431: Loss: 0.2494\n",
            "Epoch 3, Sample 11432: Loss: 0.2044\n",
            "Epoch 3, Sample 11433: Loss: 0.0026\n",
            "Epoch 3, Sample 11434: Loss: 0.1463\n",
            "Epoch 3, Sample 11435: Loss: 0.0838\n",
            "Epoch 3, Sample 11436: Loss: 0.6304\n",
            "Epoch 3, Sample 11437: Loss: 0.2239\n",
            "Epoch 3, Sample 11438: Loss: 0.2044\n",
            "Epoch 3, Sample 11439: Loss: 0.0640\n",
            "Epoch 3, Sample 11440: Loss: 0.8625\n",
            "Epoch 3, Sample 11441: Loss: 0.8799\n",
            "Epoch 3, Sample 11442: Loss: 1.4806\n",
            "Epoch 3, Sample 11443: Loss: 0.0002\n",
            "Epoch 3, Sample 11444: Loss: 1.0524\n",
            "Epoch 3, Sample 11445: Loss: 0.2308\n",
            "Epoch 3, Sample 11446: Loss: 0.3441\n",
            "Epoch 3, Sample 11447: Loss: 0.8951\n",
            "Epoch 3, Sample 11448: Loss: 0.5078\n",
            "Epoch 3, Sample 11449: Loss: 1.0524\n",
            "Epoch 3, Sample 11450: Loss: 0.9780\n",
            "Epoch 3, Sample 11451: Loss: 0.2840\n",
            "Epoch 3, Sample 11452: Loss: 0.2340\n",
            "Epoch 3, Sample 11453: Loss: 0.2832\n",
            "Epoch 3, Sample 11454: Loss: 5.5741\n",
            "Epoch 3, Sample 11455: Loss: 0.0018\n",
            "Epoch 3, Sample 11456: Loss: 0.0776\n",
            "Epoch 3, Sample 11457: Loss: 0.1210\n",
            "Epoch 3, Sample 11458: Loss: 1.0155\n",
            "Epoch 3, Sample 11459: Loss: 0.3949\n",
            "Epoch 3, Sample 11460: Loss: 0.4644\n",
            "Epoch 3, Sample 11461: Loss: 0.8484\n",
            "Epoch 3, Sample 11462: Loss: 0.1170\n",
            "Epoch 3, Sample 11463: Loss: 0.9367\n",
            "Epoch 3, Sample 11464: Loss: 0.2032\n",
            "Epoch 3, Sample 11465: Loss: 0.0022\n",
            "Epoch 3, Sample 11466: Loss: 1.4320\n",
            "Epoch 3, Sample 11467: Loss: 0.0119\n",
            "Epoch 3, Sample 11468: Loss: 0.0001\n",
            "Epoch 3, Sample 11469: Loss: 0.2639\n",
            "Epoch 3, Sample 11470: Loss: 0.5858\n",
            "Epoch 3, Sample 11471: Loss: 1.0530\n",
            "Epoch 3, Sample 11472: Loss: 0.5972\n",
            "Epoch 3, Sample 11473: Loss: 0.6075\n",
            "Epoch 3, Sample 11474: Loss: 0.0007\n",
            "Epoch 3, Sample 11475: Loss: 1.0204\n",
            "Epoch 3, Sample 11476: Loss: 0.0630\n",
            "Epoch 3, Sample 11477: Loss: 0.8951\n",
            "Epoch 3, Sample 11478: Loss: 0.7036\n",
            "Epoch 3, Sample 11479: Loss: 0.0108\n",
            "Epoch 3, Sample 11480: Loss: 0.0625\n",
            "Epoch 3, Sample 11481: Loss: 0.3441\n",
            "Epoch 3, Sample 11482: Loss: 0.0063\n",
            "Epoch 3, Sample 11483: Loss: 6.9849\n",
            "Epoch 3, Sample 11484: Loss: 0.2759\n",
            "Epoch 3, Sample 11485: Loss: 0.5972\n",
            "Epoch 3, Sample 11486: Loss: 0.0078\n",
            "Epoch 3, Sample 11487: Loss: 0.0466\n",
            "Epoch 3, Sample 11488: Loss: 0.0026\n",
            "Epoch 3, Sample 11489: Loss: 0.2034\n",
            "Epoch 3, Sample 11490: Loss: 0.0029\n",
            "Epoch 3, Sample 11491: Loss: 0.1822\n",
            "Epoch 3, Sample 11492: Loss: 0.1559\n",
            "Epoch 3, Sample 11493: Loss: 1.7711\n",
            "Epoch 3, Sample 11494: Loss: 0.4930\n",
            "Epoch 3, Sample 11495: Loss: 0.0116\n",
            "Epoch 3, Sample 11496: Loss: 0.7036\n",
            "Epoch 3, Sample 11497: Loss: 0.7036\n",
            "Epoch 3, Sample 11498: Loss: 0.2036\n",
            "Epoch 3, Sample 11499: Loss: 0.4831\n",
            "Epoch 3, Sample 11500: Loss: 0.2699\n",
            "Epoch 3, Sample 11501: Loss: 0.0110\n",
            "Epoch 3, Sample 11502: Loss: 0.3007\n",
            "Epoch 3, Sample 11503: Loss: 1.0524\n",
            "Epoch 3, Sample 11504: Loss: 0.3598\n",
            "Epoch 3, Sample 11505: Loss: 0.7036\n",
            "Epoch 3, Sample 11506: Loss: 0.0026\n",
            "Epoch 3, Sample 11507: Loss: 0.0013\n",
            "Epoch 3, Sample 11508: Loss: 0.3399\n",
            "Epoch 3, Sample 11509: Loss: 0.3441\n",
            "Epoch 3, Sample 11510: Loss: 0.0026\n",
            "Epoch 3, Sample 11511: Loss: 0.9367\n",
            "Epoch 3, Sample 11512: Loss: 2.7331\n",
            "Epoch 3, Sample 11513: Loss: 1.4672\n",
            "Epoch 3, Sample 11514: Loss: 0.0258\n",
            "Epoch 3, Sample 11515: Loss: 0.2044\n",
            "Epoch 3, Sample 11516: Loss: 1.8391\n",
            "Epoch 3, Sample 11517: Loss: 0.1588\n",
            "Epoch 3, Sample 11518: Loss: 0.0212\n",
            "Epoch 3, Sample 11519: Loss: 0.2832\n",
            "Epoch 3, Sample 11520: Loss: 0.2329\n",
            "Epoch 3, Sample 11521: Loss: 0.3399\n",
            "Epoch 3, Sample 11522: Loss: 1.9368\n",
            "Epoch 3, Sample 11523: Loss: 0.0074\n",
            "Epoch 3, Sample 11524: Loss: 0.2112\n",
            "Epoch 3, Sample 11525: Loss: 0.0025\n",
            "Epoch 3, Sample 11526: Loss: 2.0184\n",
            "Epoch 3, Sample 11527: Loss: 0.0083\n",
            "Epoch 3, Sample 11528: Loss: 0.8951\n",
            "Epoch 3, Sample 11529: Loss: 1.0155\n",
            "Epoch 3, Sample 11530: Loss: 1.0524\n",
            "Epoch 3, Sample 11531: Loss: 0.3399\n",
            "Epoch 3, Sample 11532: Loss: 0.0854\n",
            "Epoch 3, Sample 11533: Loss: 0.0084\n",
            "Epoch 3, Sample 11534: Loss: 0.0630\n",
            "Epoch 3, Sample 11535: Loss: 1.4753\n",
            "Epoch 3, Sample 11536: Loss: 0.5180\n",
            "Epoch 3, Sample 11537: Loss: 0.2558\n",
            "Epoch 3, Sample 11538: Loss: 1.0524\n",
            "Epoch 3, Sample 11539: Loss: 0.3029\n",
            "Epoch 3, Sample 11540: Loss: 0.0836\n",
            "Epoch 3, Sample 11541: Loss: 0.0018\n",
            "Epoch 3, Sample 11542: Loss: 0.7036\n",
            "Epoch 3, Sample 11543: Loss: 0.2034\n",
            "Epoch 3, Sample 11544: Loss: 0.0258\n",
            "Epoch 3, Sample 11545: Loss: 1.2424\n",
            "Epoch 3, Sample 11546: Loss: 0.1559\n",
            "Epoch 3, Sample 11547: Loss: 1.0524\n",
            "Epoch 3, Sample 11548: Loss: 1.0524\n",
            "Epoch 3, Sample 11549: Loss: 1.0155\n",
            "Epoch 3, Sample 11550: Loss: 0.6990\n",
            "Epoch 3, Sample 11551: Loss: 1.0133\n",
            "Epoch 3, Sample 11552: Loss: 0.3441\n",
            "Epoch 3, Sample 11553: Loss: 0.5766\n",
            "Epoch 3, Sample 11554: Loss: 0.7036\n",
            "Epoch 3, Sample 11555: Loss: 0.0018\n",
            "Epoch 3, Sample 11556: Loss: 0.5003\n",
            "Epoch 3, Sample 11557: Loss: 1.0155\n",
            "Epoch 3, Sample 11558: Loss: 0.2044\n",
            "Epoch 3, Sample 11559: Loss: 0.1838\n",
            "Epoch 3, Sample 11560: Loss: 0.0626\n",
            "Epoch 3, Sample 11561: Loss: 0.2759\n",
            "Epoch 3, Sample 11562: Loss: 0.5310\n",
            "Epoch 3, Sample 11563: Loss: 0.3544\n",
            "Epoch 3, Sample 11564: Loss: 0.2221\n",
            "Epoch 3, Sample 11565: Loss: 0.2112\n",
            "Epoch 3, Sample 11566: Loss: 0.2989\n",
            "Epoch 3, Sample 11567: Loss: 0.0786\n",
            "Epoch 3, Sample 11568: Loss: 0.2699\n",
            "Epoch 3, Sample 11569: Loss: 1.0524\n",
            "Epoch 3, Sample 11570: Loss: 0.2044\n",
            "Epoch 3, Sample 11571: Loss: 0.5858\n",
            "Epoch 3, Sample 11572: Loss: 0.0466\n",
            "Epoch 3, Sample 11573: Loss: 0.1817\n",
            "Epoch 3, Sample 11574: Loss: 0.1559\n",
            "Epoch 3, Sample 11575: Loss: 0.2032\n",
            "Epoch 3, Sample 11576: Loss: 0.6893\n",
            "Epoch 3, Sample 11577: Loss: 1.0524\n",
            "Epoch 3, Sample 11578: Loss: 0.2044\n",
            "Epoch 3, Sample 11579: Loss: 0.0508\n",
            "Epoch 3, Sample 11580: Loss: 0.7036\n",
            "Epoch 3, Sample 11581: Loss: 0.5394\n",
            "Epoch 3, Sample 11582: Loss: 4.3362\n",
            "Epoch 3, Sample 11583: Loss: 0.1523\n",
            "Epoch 3, Sample 11584: Loss: 1.0155\n",
            "Epoch 3, Sample 11585: Loss: 0.1654\n",
            "Epoch 3, Sample 11586: Loss: 0.5858\n",
            "Epoch 3, Sample 11587: Loss: 0.5858\n",
            "Epoch 3, Sample 11588: Loss: 0.0212\n",
            "Epoch 3, Sample 11589: Loss: 0.0501\n",
            "Epoch 3, Sample 11590: Loss: 0.0630\n",
            "Epoch 3, Sample 11591: Loss: 0.1248\n",
            "Epoch 3, Sample 11592: Loss: 0.2032\n",
            "Epoch 3, Sample 11593: Loss: 0.0018\n",
            "Epoch 3, Sample 11594: Loss: 0.2340\n",
            "Epoch 3, Sample 11595: Loss: 0.4453\n",
            "Epoch 3, Sample 11596: Loss: 0.3399\n",
            "Epoch 3, Sample 11597: Loss: 0.2034\n",
            "Epoch 3, Sample 11598: Loss: 0.0449\n",
            "Epoch 3, Sample 11599: Loss: 0.0834\n",
            "Epoch 3, Sample 11600: Loss: 0.1984\n",
            "Epoch 3, Sample 11601: Loss: 0.2044\n",
            "Epoch 3, Sample 11602: Loss: 0.3638\n",
            "Epoch 3, Sample 11603: Loss: 1.0155\n",
            "Epoch 3, Sample 11604: Loss: 0.0466\n",
            "Epoch 3, Sample 11605: Loss: 1.5291\n",
            "Epoch 3, Sample 11606: Loss: 0.3568\n",
            "Epoch 3, Sample 11607: Loss: 0.2361\n",
            "Epoch 3, Sample 11608: Loss: 0.0026\n",
            "Epoch 3, Sample 11609: Loss: 0.6092\n",
            "Epoch 3, Sample 11610: Loss: 0.3062\n",
            "Epoch 3, Sample 11611: Loss: 0.4996\n",
            "Epoch 3, Sample 11612: Loss: 1.0530\n",
            "Epoch 3, Sample 11613: Loss: 0.0470\n",
            "Epoch 3, Sample 11614: Loss: 1.0155\n",
            "Epoch 3, Sample 11615: Loss: 0.0477\n",
            "Epoch 3, Sample 11616: Loss: 7.7131\n",
            "Epoch 3, Sample 11617: Loss: 0.2044\n",
            "Epoch 3, Sample 11618: Loss: 0.2459\n",
            "Epoch 3, Sample 11619: Loss: 0.7036\n",
            "Epoch 3, Sample 11620: Loss: 0.7702\n",
            "Epoch 3, Sample 11621: Loss: 0.4996\n",
            "Epoch 3, Sample 11622: Loss: 0.2032\n",
            "Epoch 3, Sample 11623: Loss: 0.5000\n",
            "Epoch 3, Sample 11624: Loss: 0.1170\n",
            "Epoch 3, Sample 11625: Loss: 0.0460\n",
            "Epoch 3, Sample 11626: Loss: 0.2363\n",
            "Epoch 3, Sample 11627: Loss: 2.8440\n",
            "Epoch 3, Sample 11628: Loss: 0.2044\n",
            "Epoch 3, Sample 11629: Loss: 1.5437\n",
            "Epoch 3, Sample 11630: Loss: 1.0155\n",
            "Epoch 3, Sample 11631: Loss: 1.0155\n",
            "Epoch 3, Sample 11632: Loss: 0.1250\n",
            "Epoch 3, Sample 11633: Loss: 0.6139\n",
            "Epoch 3, Sample 11634: Loss: 0.0630\n",
            "Epoch 3, Sample 11635: Loss: 0.0034\n",
            "Epoch 3, Sample 11636: Loss: 0.7036\n",
            "Epoch 3, Sample 11637: Loss: 0.2032\n",
            "Epoch 3, Sample 11638: Loss: 0.2339\n",
            "Epoch 3, Sample 11639: Loss: 0.2044\n",
            "Epoch 3, Sample 11640: Loss: 0.3399\n",
            "Epoch 3, Sample 11641: Loss: 0.3399\n",
            "Epoch 3, Sample 11642: Loss: 0.0018\n",
            "Epoch 3, Sample 11643: Loss: 0.0234\n",
            "Epoch 3, Sample 11644: Loss: 0.0147\n",
            "Epoch 3, Sample 11645: Loss: 0.7036\n",
            "Epoch 3, Sample 11646: Loss: 0.0059\n",
            "Epoch 3, Sample 11647: Loss: 0.0026\n",
            "Epoch 3, Sample 11648: Loss: 0.7036\n",
            "Epoch 3, Sample 11649: Loss: 0.0018\n",
            "Epoch 3, Sample 11650: Loss: 0.5858\n",
            "Epoch 3, Sample 11651: Loss: 0.5858\n",
            "Epoch 3, Sample 11652: Loss: 0.0026\n",
            "Epoch 3, Sample 11653: Loss: 0.7036\n",
            "Epoch 3, Sample 11654: Loss: 0.1313\n",
            "Epoch 3, Sample 11655: Loss: 0.0018\n",
            "Epoch 3, Sample 11656: Loss: 0.3399\n",
            "Epoch 3, Sample 11657: Loss: 0.4032\n",
            "Epoch 3, Sample 11658: Loss: 0.0026\n",
            "Epoch 3, Sample 11659: Loss: 0.0150\n",
            "Epoch 3, Sample 11660: Loss: 0.2639\n",
            "Epoch 3, Sample 11661: Loss: 0.0531\n",
            "Epoch 3, Sample 11662: Loss: 0.5196\n",
            "Epoch 3, Sample 11663: Loss: 0.3441\n",
            "Epoch 3, Sample 11664: Loss: 1.0155\n",
            "Epoch 3, Sample 11665: Loss: 0.1170\n",
            "Epoch 3, Sample 11666: Loss: 0.2036\n",
            "Epoch 3, Sample 11667: Loss: 0.5078\n",
            "Epoch 3, Sample 11668: Loss: 0.4032\n",
            "Epoch 3, Sample 11669: Loss: 0.2832\n",
            "Epoch 3, Sample 11670: Loss: 0.2044\n",
            "Epoch 3, Sample 11671: Loss: 0.0026\n",
            "Epoch 3, Sample 11672: Loss: 0.2709\n",
            "Epoch 3, Sample 11673: Loss: 0.0001\n",
            "Epoch 3, Sample 11674: Loss: 0.6916\n",
            "Epoch 3, Sample 11675: Loss: 0.5078\n",
            "Epoch 3, Sample 11676: Loss: 0.0460\n",
            "Epoch 3, Sample 11677: Loss: 2.6384\n",
            "Epoch 3, Sample 11678: Loss: 0.0020\n",
            "Epoch 3, Sample 11679: Loss: 0.2044\n",
            "Epoch 3, Sample 11680: Loss: 0.0212\n",
            "Epoch 3, Sample 11681: Loss: 1.0524\n",
            "Epoch 3, Sample 11682: Loss: 0.5078\n",
            "Epoch 3, Sample 11683: Loss: 0.4799\n",
            "Epoch 3, Sample 11684: Loss: 1.2926\n",
            "Epoch 3, Sample 11685: Loss: 0.1170\n",
            "Epoch 3, Sample 11686: Loss: 0.0026\n",
            "Epoch 3, Sample 11687: Loss: 0.0018\n",
            "Epoch 3, Sample 11688: Loss: 0.2219\n",
            "Epoch 3, Sample 11689: Loss: 0.3033\n",
            "Epoch 3, Sample 11690: Loss: 0.0006\n",
            "Epoch 3, Sample 11691: Loss: 0.2044\n",
            "Epoch 3, Sample 11692: Loss: 0.0026\n",
            "Epoch 3, Sample 11693: Loss: 0.0498\n",
            "Epoch 3, Sample 11694: Loss: 0.5000\n",
            "Epoch 3, Sample 11695: Loss: 0.3399\n",
            "Epoch 3, Sample 11696: Loss: 0.2759\n",
            "Epoch 3, Sample 11697: Loss: 0.1791\n",
            "Epoch 3, Sample 11698: Loss: 1.0975\n",
            "Epoch 3, Sample 11699: Loss: 0.0026\n",
            "Epoch 3, Sample 11700: Loss: 0.2036\n",
            "Epoch 3, Sample 11701: Loss: 0.0082\n",
            "Epoch 3, Sample 11702: Loss: 0.2278\n",
            "Epoch 3, Sample 11703: Loss: 0.0554\n",
            "Epoch 3, Sample 11704: Loss: 0.1250\n",
            "Epoch 3, Sample 11705: Loss: 0.2396\n",
            "Epoch 3, Sample 11706: Loss: 4.8044\n",
            "Epoch 3, Sample 11707: Loss: 0.0133\n",
            "Epoch 3, Sample 11708: Loss: 2.9652\n",
            "Epoch 3, Sample 11709: Loss: 0.0001\n",
            "Epoch 3, Sample 11710: Loss: 0.3381\n",
            "Epoch 3, Sample 11711: Loss: 0.0502\n",
            "Epoch 3, Sample 11712: Loss: 0.0187\n",
            "Epoch 3, Sample 11713: Loss: 0.2759\n",
            "Epoch 3, Sample 11714: Loss: 0.2759\n",
            "Epoch 3, Sample 11715: Loss: 0.5858\n",
            "Epoch 3, Sample 11716: Loss: 1.0524\n",
            "Epoch 3, Sample 11717: Loss: 0.0630\n",
            "Epoch 3, Sample 11718: Loss: 0.5000\n",
            "Epoch 3, Sample 11719: Loss: 0.3450\n",
            "Epoch 3, Sample 11720: Loss: 1.0155\n",
            "Epoch 3, Sample 11721: Loss: 0.1250\n",
            "Epoch 3, Sample 11722: Loss: 0.2112\n",
            "Epoch 3, Sample 11723: Loss: 1.0070\n",
            "Epoch 3, Sample 11724: Loss: 0.1803\n",
            "Epoch 3, Sample 11725: Loss: 0.2112\n",
            "Epoch 3, Sample 11726: Loss: 0.2044\n",
            "Epoch 3, Sample 11727: Loss: 0.2759\n",
            "Epoch 3, Sample 11728: Loss: 0.4841\n",
            "Epoch 3, Sample 11729: Loss: 0.1559\n",
            "Epoch 3, Sample 11730: Loss: 0.3007\n",
            "Epoch 3, Sample 11731: Loss: 0.0018\n",
            "Epoch 3, Sample 11732: Loss: 0.0507\n",
            "Epoch 3, Sample 11733: Loss: 0.2904\n",
            "Epoch 3, Sample 11734: Loss: 0.3399\n",
            "Epoch 3, Sample 11735: Loss: 0.2784\n",
            "Epoch 3, Sample 11736: Loss: 1.2573\n",
            "Epoch 3, Sample 11737: Loss: 0.0026\n",
            "Epoch 3, Sample 11738: Loss: 0.0013\n",
            "Epoch 3, Sample 11739: Loss: 0.7453\n",
            "Epoch 3, Sample 11740: Loss: 0.0394\n",
            "Epoch 3, Sample 11741: Loss: 0.0553\n",
            "Epoch 3, Sample 11742: Loss: 0.4122\n",
            "Epoch 3, Sample 11743: Loss: 0.9367\n",
            "Epoch 3, Sample 11744: Loss: 0.1170\n",
            "Epoch 3, Sample 11745: Loss: 0.3441\n",
            "Epoch 3, Sample 11746: Loss: 0.5196\n",
            "Epoch 3, Sample 11747: Loss: 0.0032\n",
            "Epoch 3, Sample 11748: Loss: 0.0072\n",
            "Epoch 3, Sample 11749: Loss: 0.0630\n",
            "Epoch 3, Sample 11750: Loss: 0.1250\n",
            "Epoch 3, Sample 11751: Loss: 0.1326\n",
            "Epoch 3, Sample 11752: Loss: 0.1797\n",
            "Epoch 3, Sample 11753: Loss: 0.2832\n",
            "Epoch 3, Sample 11754: Loss: 0.0097\n",
            "Epoch 3, Sample 11755: Loss: 0.0084\n",
            "Epoch 3, Sample 11756: Loss: 1.6150\n",
            "Epoch 3, Sample 11757: Loss: 0.2036\n",
            "Epoch 3, Sample 11758: Loss: 0.4644\n",
            "Epoch 3, Sample 11759: Loss: 0.2032\n",
            "Epoch 3, Sample 11760: Loss: 0.6990\n",
            "Epoch 3, Sample 11761: Loss: 0.0125\n",
            "Epoch 3, Sample 11762: Loss: 0.0775\n",
            "Epoch 3, Sample 11763: Loss: 0.1250\n",
            "Epoch 3, Sample 11764: Loss: 0.0306\n",
            "Epoch 3, Sample 11765: Loss: 0.4377\n",
            "Epoch 3, Sample 11766: Loss: 0.0018\n",
            "Epoch 3, Sample 11767: Loss: 0.0744\n",
            "Epoch 3, Sample 11768: Loss: 0.1523\n",
            "Epoch 3, Sample 11769: Loss: 1.0155\n",
            "Epoch 3, Sample 11770: Loss: 0.5989\n",
            "Epoch 3, Sample 11771: Loss: 0.3399\n",
            "Epoch 3, Sample 11772: Loss: 1.0155\n",
            "Epoch 3, Sample 11773: Loss: 0.0179\n",
            "Epoch 3, Sample 11774: Loss: 0.1250\n",
            "Epoch 3, Sample 11775: Loss: 0.0007\n",
            "Epoch 3, Sample 11776: Loss: 1.0524\n",
            "Epoch 3, Sample 11777: Loss: 0.7638\n",
            "Epoch 3, Sample 11778: Loss: 0.2044\n",
            "Epoch 3, Sample 11779: Loss: 0.2759\n",
            "Epoch 3, Sample 11780: Loss: 0.0626\n",
            "Epoch 3, Sample 11781: Loss: 0.5000\n",
            "Epoch 3, Sample 11782: Loss: 1.0227\n",
            "Epoch 3, Sample 11783: Loss: 0.2032\n",
            "Epoch 3, Sample 11784: Loss: 0.6304\n",
            "Epoch 3, Sample 11785: Loss: 0.4841\n",
            "Epoch 3, Sample 11786: Loss: 1.0155\n",
            "Epoch 3, Sample 11787: Loss: 0.2941\n",
            "Epoch 3, Sample 11788: Loss: 1.6069\n",
            "Epoch 3, Sample 11789: Loss: 0.3949\n",
            "Epoch 3, Sample 11790: Loss: 0.0039\n",
            "Epoch 3, Sample 11791: Loss: 0.0026\n",
            "Epoch 3, Sample 11792: Loss: 0.0630\n",
            "Epoch 3, Sample 11793: Loss: 1.0155\n",
            "Epoch 3, Sample 11794: Loss: 0.0018\n",
            "Epoch 3, Sample 11795: Loss: 0.0461\n",
            "Epoch 3, Sample 11796: Loss: 0.2044\n",
            "Epoch 3, Sample 11797: Loss: 0.7453\n",
            "Epoch 3, Sample 11798: Loss: 2.6651\n",
            "Epoch 3, Sample 11799: Loss: 0.2832\n",
            "Epoch 3, Sample 11800: Loss: 0.2034\n",
            "Epoch 3, Sample 11801: Loss: 0.0630\n",
            "Epoch 3, Sample 11802: Loss: 0.0027\n",
            "Epoch 3, Sample 11803: Loss: 3.5544\n",
            "Epoch 3, Sample 11804: Loss: 0.5003\n",
            "Epoch 3, Sample 11805: Loss: 0.0002\n",
            "Epoch 3, Sample 11806: Loss: 0.0212\n",
            "Epoch 3, Sample 11807: Loss: 0.0001\n",
            "Epoch 3, Sample 11808: Loss: 0.0168\n",
            "Epoch 3, Sample 11809: Loss: 3.0081\n",
            "Epoch 3, Sample 11810: Loss: 0.3610\n",
            "Epoch 3, Sample 11811: Loss: 0.0026\n",
            "Epoch 3, Sample 11812: Loss: 0.2044\n",
            "Epoch 3, Sample 11813: Loss: 0.0981\n",
            "Epoch 3, Sample 11814: Loss: 0.2941\n",
            "Epoch 3, Sample 11815: Loss: 0.1546\n",
            "Epoch 3, Sample 11816: Loss: 0.1559\n",
            "Epoch 3, Sample 11817: Loss: 0.5858\n",
            "Epoch 3, Sample 11818: Loss: 0.3399\n",
            "Epoch 3, Sample 11819: Loss: 0.4032\n",
            "Epoch 3, Sample 11820: Loss: 0.2036\n",
            "Epoch 3, Sample 11821: Loss: 0.2639\n",
            "Epoch 3, Sample 11822: Loss: 4.6021\n",
            "Epoch 3, Sample 11823: Loss: 0.0202\n",
            "Epoch 3, Sample 11824: Loss: 0.2639\n",
            "Epoch 3, Sample 11825: Loss: 0.7036\n",
            "Epoch 3, Sample 11826: Loss: 1.4392\n",
            "Epoch 3, Sample 11827: Loss: 0.2055\n",
            "Epoch 3, Sample 11828: Loss: 0.0295\n",
            "Epoch 3, Sample 11829: Loss: 1.0530\n",
            "Epoch 3, Sample 11830: Loss: 0.2044\n",
            "Epoch 3, Sample 11831: Loss: 0.0240\n",
            "Epoch 3, Sample 11832: Loss: 1.3693\n",
            "Epoch 3, Sample 11833: Loss: 0.2044\n",
            "Epoch 3, Sample 11834: Loss: 0.2044\n",
            "Epoch 3, Sample 11835: Loss: 0.3399\n",
            "Epoch 3, Sample 11836: Loss: 0.0875\n",
            "Epoch 3, Sample 11837: Loss: 0.1997\n",
            "Epoch 3, Sample 11838: Loss: 0.2041\n",
            "Epoch 3, Sample 11839: Loss: 0.3441\n",
            "Epoch 3, Sample 11840: Loss: 0.1465\n",
            "Epoch 3, Sample 11841: Loss: 3.0934\n",
            "Epoch 3, Sample 11842: Loss: 0.7036\n",
            "Epoch 3, Sample 11843: Loss: 0.7036\n",
            "Epoch 3, Sample 11844: Loss: 0.1512\n",
            "Epoch 3, Sample 11845: Loss: 0.3584\n",
            "Epoch 3, Sample 11846: Loss: 0.3949\n",
            "Epoch 3, Sample 11847: Loss: 0.0121\n",
            "Epoch 3, Sample 11848: Loss: 0.2759\n",
            "Epoch 3, Sample 11849: Loss: 0.2759\n",
            "Epoch 3, Sample 11850: Loss: 0.2759\n",
            "Epoch 3, Sample 11851: Loss: 0.0081\n",
            "Epoch 3, Sample 11852: Loss: 0.0007\n",
            "Epoch 3, Sample 11853: Loss: 7.6726\n",
            "Epoch 3, Sample 11854: Loss: 0.8951\n",
            "Epoch 3, Sample 11855: Loss: 0.2375\n",
            "Epoch 3, Sample 11856: Loss: 0.0938\n",
            "Epoch 3, Sample 11857: Loss: 0.0018\n",
            "Epoch 3, Sample 11858: Loss: 0.0455\n",
            "Epoch 3, Sample 11859: Loss: 0.1627\n",
            "Epoch 3, Sample 11860: Loss: 0.7269\n",
            "Epoch 3, Sample 11861: Loss: 0.5375\n",
            "Epoch 3, Sample 11862: Loss: 1.0511\n",
            "Epoch 3, Sample 11863: Loss: 0.2044\n",
            "Epoch 3, Sample 11864: Loss: 0.0030\n",
            "Epoch 3, Sample 11865: Loss: 8.0426\n",
            "Epoch 3, Sample 11866: Loss: 0.7036\n",
            "Epoch 3, Sample 11867: Loss: 0.0114\n",
            "Epoch 3, Sample 11868: Loss: 0.3092\n",
            "Epoch 3, Sample 11869: Loss: 0.0488\n",
            "Epoch 3, Sample 11870: Loss: 0.0280\n",
            "Epoch 3, Sample 11871: Loss: 0.4588\n",
            "Epoch 3, Sample 11872: Loss: 0.0938\n",
            "Epoch 3, Sample 11873: Loss: 0.0466\n",
            "Epoch 3, Sample 11874: Loss: 3.9272\n",
            "Epoch 3, Sample 11875: Loss: 0.0205\n",
            "Epoch 3, Sample 11876: Loss: 1.0227\n",
            "Epoch 3, Sample 11877: Loss: 0.3399\n",
            "Epoch 3, Sample 11878: Loss: 1.0688\n",
            "Epoch 3, Sample 11879: Loss: 0.5972\n",
            "Epoch 3, Sample 11880: Loss: 0.4485\n",
            "Epoch 3, Sample 11881: Loss: 11.5326\n",
            "Epoch 3, Sample 11882: Loss: 0.5858\n",
            "Epoch 3, Sample 11883: Loss: 0.0505\n",
            "Epoch 3, Sample 11884: Loss: 0.0013\n",
            "Epoch 3, Sample 11885: Loss: 0.7036\n",
            "Epoch 3, Sample 11886: Loss: 1.0155\n",
            "Epoch 3, Sample 11887: Loss: 0.2034\n",
            "Epoch 3, Sample 11888: Loss: 0.5141\n",
            "Epoch 3, Sample 11889: Loss: 0.7036\n",
            "Epoch 3, Sample 11890: Loss: 0.2686\n",
            "Epoch 3, Sample 11891: Loss: 0.6990\n",
            "Epoch 3, Sample 11892: Loss: 0.1170\n",
            "Epoch 3, Sample 11893: Loss: 0.0026\n",
            "Epoch 3, Sample 11894: Loss: 0.2032\n",
            "Epoch 3, Sample 11895: Loss: 0.5858\n",
            "Epoch 3, Sample 11896: Loss: 0.1154\n",
            "Epoch 3, Sample 11897: Loss: 0.2639\n",
            "Epoch 3, Sample 11898: Loss: 0.4545\n",
            "Epoch 3, Sample 11899: Loss: 0.3399\n",
            "Epoch 3, Sample 11900: Loss: 8.7194\n",
            "Epoch 3, Sample 11901: Loss: 0.5003\n",
            "Epoch 3, Sample 11902: Loss: 0.3092\n",
            "Epoch 3, Sample 11903: Loss: 0.1250\n",
            "Epoch 3, Sample 11904: Loss: 0.0134\n",
            "Epoch 3, Sample 11905: Loss: 0.2832\n",
            "Epoch 3, Sample 11906: Loss: 0.3441\n",
            "Epoch 3, Sample 11907: Loss: 0.0205\n",
            "Epoch 3, Sample 11908: Loss: 0.2792\n",
            "Epoch 3, Sample 11909: Loss: 0.0026\n",
            "Epoch 3, Sample 11910: Loss: 0.3399\n",
            "Epoch 3, Sample 11911: Loss: 0.9414\n",
            "Epoch 3, Sample 11912: Loss: 0.1399\n",
            "Epoch 3, Sample 11913: Loss: 0.0625\n",
            "Epoch 3, Sample 11914: Loss: 0.2639\n",
            "Epoch 3, Sample 11915: Loss: 0.2034\n",
            "Epoch 3, Sample 11916: Loss: 0.0591\n",
            "Epoch 3, Sample 11917: Loss: 0.0148\n",
            "Epoch 3, Sample 11918: Loss: 0.6023\n",
            "Epoch 3, Sample 11919: Loss: 0.0630\n",
            "Epoch 3, Sample 11920: Loss: 0.0005\n",
            "Epoch 3, Sample 11921: Loss: 0.6990\n",
            "Epoch 3, Sample 11922: Loss: 0.3441\n",
            "Epoch 3, Sample 11923: Loss: 0.3399\n",
            "Epoch 3, Sample 11924: Loss: 0.5000\n",
            "Epoch 3, Sample 11925: Loss: 0.0630\n",
            "Epoch 3, Sample 11926: Loss: 0.6856\n",
            "Epoch 3, Sample 11927: Loss: 0.2340\n",
            "Epoch 3, Sample 11928: Loss: 0.3624\n",
            "Epoch 3, Sample 11929: Loss: 0.1322\n",
            "Epoch 3, Sample 11930: Loss: 0.4367\n",
            "Epoch 3, Sample 11931: Loss: 0.0060\n",
            "Epoch 3, Sample 11932: Loss: 0.0119\n",
            "Epoch 3, Sample 11933: Loss: 0.0554\n",
            "Epoch 3, Sample 11934: Loss: 0.9651\n",
            "Epoch 3, Sample 11935: Loss: 0.4930\n",
            "Epoch 3, Sample 11936: Loss: 0.0026\n",
            "Epoch 3, Sample 11937: Loss: 0.2145\n",
            "Epoch 3, Sample 11938: Loss: 0.1372\n",
            "Epoch 3, Sample 11939: Loss: 0.2044\n",
            "Epoch 3, Sample 11940: Loss: 1.0524\n",
            "Epoch 3, Sample 11941: Loss: 0.2044\n",
            "Epoch 3, Sample 11942: Loss: 0.1250\n",
            "Epoch 3, Sample 11943: Loss: 0.7702\n",
            "Epoch 3, Sample 11944: Loss: 0.0025\n",
            "Epoch 3, Sample 11945: Loss: 0.5858\n",
            "Epoch 3, Sample 11946: Loss: 1.0524\n",
            "Epoch 3, Sample 11947: Loss: 0.1170\n",
            "Epoch 3, Sample 11948: Loss: 0.0212\n",
            "Epoch 3, Sample 11949: Loss: 0.2036\n",
            "Epoch 3, Sample 11950: Loss: 3.7450\n",
            "Epoch 3, Sample 11951: Loss: 0.8217\n",
            "Epoch 3, Sample 11952: Loss: 0.5000\n",
            "Epoch 3, Sample 11953: Loss: 0.0838\n",
            "Epoch 3, Sample 11954: Loss: 0.0032\n",
            "Epoch 3, Sample 11955: Loss: 0.1337\n",
            "Epoch 3, Sample 11956: Loss: 0.4799\n",
            "Epoch 3, Sample 11957: Loss: 0.3137\n",
            "Epoch 3, Sample 11958: Loss: 0.4155\n",
            "Epoch 3, Sample 11959: Loss: 1.1934\n",
            "Epoch 3, Sample 11960: Loss: 0.3007\n",
            "Epoch 3, Sample 11961: Loss: 0.2759\n",
            "Epoch 3, Sample 11962: Loss: 0.3306\n",
            "Epoch 3, Sample 11963: Loss: 0.0083\n",
            "Epoch 3, Sample 11964: Loss: 0.7702\n",
            "Epoch 3, Sample 11965: Loss: 0.0018\n",
            "Epoch 3, Sample 11966: Loss: 0.2034\n",
            "Epoch 3, Sample 11967: Loss: 0.0640\n",
            "Epoch 3, Sample 11968: Loss: 5.5159\n",
            "Epoch 3, Sample 11969: Loss: 0.6990\n",
            "Epoch 3, Sample 11970: Loss: 1.3740\n",
            "Epoch 3, Sample 11971: Loss: 0.3399\n",
            "Epoch 3, Sample 11972: Loss: 0.0062\n",
            "Epoch 3, Sample 11973: Loss: 0.4799\n",
            "Epoch 3, Sample 11974: Loss: 0.4611\n",
            "Epoch 3, Sample 11975: Loss: 1.0524\n",
            "Epoch 3, Sample 11976: Loss: 0.5871\n",
            "Epoch 3, Sample 11977: Loss: 1.0524\n",
            "Epoch 3, Sample 11978: Loss: 0.2044\n",
            "Epoch 3, Sample 11979: Loss: 0.1060\n",
            "Epoch 3, Sample 11980: Loss: 0.6867\n",
            "Epoch 3, Sample 11981: Loss: 0.0000\n",
            "Epoch 3, Sample 11982: Loss: 0.5000\n",
            "Epoch 3, Sample 11983: Loss: 0.0018\n",
            "Epoch 3, Sample 11984: Loss: 0.1508\n",
            "Epoch 3, Sample 11985: Loss: 0.3506\n",
            "Epoch 3, Sample 11986: Loss: 1.4391\n",
            "Epoch 3, Sample 11987: Loss: 1.0826\n",
            "Epoch 3, Sample 11988: Loss: 0.0110\n",
            "Epoch 3, Sample 11989: Loss: 0.3980\n",
            "Epoch 3, Sample 11990: Loss: 0.2034\n",
            "Epoch 3, Sample 11991: Loss: 0.2034\n",
            "Epoch 3, Sample 11992: Loss: 0.5003\n",
            "Epoch 3, Sample 11993: Loss: 0.3598\n",
            "Epoch 3, Sample 11994: Loss: 0.0536\n",
            "Epoch 3, Sample 11995: Loss: 1.0524\n",
            "Epoch 3, Sample 11996: Loss: 0.1091\n",
            "Epoch 3, Sample 11997: Loss: 0.2036\n",
            "Epoch 3, Sample 11998: Loss: 0.3896\n",
            "Epoch 3, Sample 11999: Loss: 8.7405\n",
            "Epoch 3, Sample 12000: Loss: 0.0018\n",
            "Epoch 3, Sample 12001: Loss: 0.6447\n",
            "Epoch 3, Sample 12002: Loss: 0.0306\n",
            "Epoch 3, Sample 12003: Loss: 0.0001\n",
            "Epoch 3, Sample 12004: Loss: 0.0005\n",
            "Epoch 3, Sample 12005: Loss: 0.7344\n",
            "Epoch 3, Sample 12006: Loss: 0.1890\n",
            "Epoch 3, Sample 12007: Loss: 1.5542\n",
            "Epoch 3, Sample 12008: Loss: 0.0001\n",
            "Epoch 3, Sample 12009: Loss: 0.4288\n",
            "Epoch 3, Sample 12010: Loss: 0.0476\n",
            "Epoch 3, Sample 12011: Loss: 0.4607\n",
            "Epoch 3, Sample 12012: Loss: 0.0000\n",
            "Epoch 3, Sample 12013: Loss: 0.4930\n",
            "Epoch 3, Sample 12014: Loss: 0.1114\n",
            "Epoch 3, Sample 12015: Loss: 0.3598\n",
            "Epoch 3, Sample 12016: Loss: 0.2044\n",
            "Epoch 3, Sample 12017: Loss: 0.1933\n",
            "Epoch 3, Sample 12018: Loss: 0.0626\n",
            "Epoch 3, Sample 12019: Loss: 0.2044\n",
            "Epoch 3, Sample 12020: Loss: 0.7390\n",
            "Epoch 3, Sample 12021: Loss: 0.3949\n",
            "Epoch 3, Sample 12022: Loss: 0.3949\n",
            "Epoch 3, Sample 12023: Loss: 0.1250\n",
            "Epoch 3, Sample 12024: Loss: 1.0524\n",
            "Epoch 3, Sample 12025: Loss: 1.0524\n",
            "Epoch 3, Sample 12026: Loss: 0.2759\n",
            "Epoch 3, Sample 12027: Loss: 0.0060\n",
            "Epoch 3, Sample 12028: Loss: 1.1368\n",
            "Epoch 3, Sample 12029: Loss: 0.2219\n",
            "Epoch 3, Sample 12030: Loss: 0.4382\n",
            "Epoch 3, Sample 12031: Loss: 0.0006\n",
            "Epoch 3, Sample 12032: Loss: 0.3441\n",
            "Epoch 3, Sample 12033: Loss: 5.7079\n",
            "Epoch 3, Sample 12034: Loss: 0.3441\n",
            "Epoch 3, Sample 12035: Loss: 0.2459\n",
            "Epoch 3, Sample 12036: Loss: 0.1039\n",
            "Epoch 3, Sample 12037: Loss: 0.0018\n",
            "Epoch 3, Sample 12038: Loss: 1.6579\n",
            "Epoch 3, Sample 12039: Loss: 0.4663\n",
            "Epoch 3, Sample 12040: Loss: 0.6349\n",
            "Epoch 3, Sample 12041: Loss: 0.3367\n",
            "Epoch 3, Sample 12042: Loss: 0.0558\n",
            "Epoch 3, Sample 12043: Loss: 0.0247\n",
            "Epoch 3, Sample 12044: Loss: 0.7036\n",
            "Epoch 3, Sample 12045: Loss: 0.0026\n",
            "Epoch 3, Sample 12046: Loss: 0.2034\n",
            "Epoch 3, Sample 12047: Loss: 0.0009\n",
            "Epoch 3, Sample 12048: Loss: 0.6139\n",
            "Epoch 3, Sample 12049: Loss: 0.1559\n",
            "Epoch 3, Sample 12050: Loss: 0.5003\n",
            "Epoch 3, Sample 12051: Loss: 0.0012\n",
            "Epoch 3, Sample 12052: Loss: 0.0026\n",
            "Epoch 3, Sample 12053: Loss: 0.3584\n",
            "Epoch 3, Sample 12054: Loss: 0.1250\n",
            "Epoch 3, Sample 12055: Loss: 0.0625\n",
            "Epoch 3, Sample 12056: Loss: 0.5019\n",
            "Epoch 3, Sample 12057: Loss: 0.0913\n",
            "Epoch 3, Sample 12058: Loss: 0.0025\n",
            "Epoch 3, Sample 12059: Loss: 0.2034\n",
            "Epoch 3, Sample 12060: Loss: 0.6990\n",
            "Epoch 3, Sample 12061: Loss: 0.0389\n",
            "Epoch 3, Sample 12062: Loss: 0.0018\n",
            "Epoch 3, Sample 12063: Loss: 0.3441\n",
            "Epoch 3, Sample 12064: Loss: 0.3399\n",
            "Epoch 3, Sample 12065: Loss: 0.0201\n",
            "Epoch 3, Sample 12066: Loss: 0.0505\n",
            "Epoch 3, Sample 12067: Loss: 0.0002\n",
            "Epoch 3, Sample 12068: Loss: 0.0025\n",
            "Epoch 3, Sample 12069: Loss: 0.2032\n",
            "Epoch 3, Sample 12070: Loss: 1.8616\n",
            "Epoch 3, Sample 12071: Loss: 1.0730\n",
            "Epoch 3, Sample 12072: Loss: 6.1358\n",
            "Epoch 3, Sample 12073: Loss: 1.0155\n",
            "Epoch 3, Sample 12074: Loss: 0.7036\n",
            "Epoch 3, Sample 12075: Loss: 0.1170\n",
            "Epoch 3, Sample 12076: Loss: 0.0020\n",
            "Epoch 3, Sample 12077: Loss: 0.2044\n",
            "Epoch 3, Sample 12078: Loss: 0.0026\n",
            "Epoch 3, Sample 12079: Loss: 1.7558\n",
            "Epoch 3, Sample 12080: Loss: 0.7453\n",
            "Epoch 3, Sample 12081: Loss: 0.6867\n",
            "Epoch 3, Sample 12082: Loss: 0.7036\n",
            "Epoch 3, Sample 12083: Loss: 0.6304\n",
            "Epoch 3, Sample 12084: Loss: 0.1399\n",
            "Epoch 3, Sample 12085: Loss: 0.2759\n",
            "Epoch 3, Sample 12086: Loss: 0.8951\n",
            "Epoch 3, Sample 12087: Loss: 0.7036\n",
            "Epoch 3, Sample 12088: Loss: 1.0524\n",
            "Epoch 3, Sample 12089: Loss: 0.2044\n",
            "Epoch 3, Sample 12090: Loss: 0.3428\n",
            "Epoch 3, Sample 12091: Loss: 0.2639\n",
            "Epoch 3, Sample 12092: Loss: 0.2044\n",
            "Epoch 3, Sample 12093: Loss: 0.5314\n",
            "Epoch 3, Sample 12094: Loss: 0.0018\n",
            "Epoch 3, Sample 12095: Loss: 0.7036\n",
            "Epoch 3, Sample 12096: Loss: 0.6990\n",
            "Epoch 3, Sample 12097: Loss: 0.7036\n",
            "Epoch 3, Sample 12098: Loss: 0.0108\n",
            "Epoch 3, Sample 12099: Loss: 0.4028\n",
            "Epoch 3, Sample 12100: Loss: 0.8341\n",
            "Epoch 3, Sample 12101: Loss: 0.2036\n",
            "Epoch 3, Sample 12102: Loss: 0.2044\n",
            "Epoch 3, Sample 12103: Loss: 0.3441\n",
            "Epoch 3, Sample 12104: Loss: 0.2032\n",
            "Epoch 3, Sample 12105: Loss: 1.1368\n",
            "Epoch 3, Sample 12106: Loss: 1.0530\n",
            "Epoch 3, Sample 12107: Loss: 0.0063\n",
            "Epoch 3, Sample 12108: Loss: 0.1397\n",
            "Epoch 3, Sample 12109: Loss: 0.0116\n",
            "Epoch 3, Sample 12110: Loss: 0.3352\n",
            "Epoch 3, Sample 12111: Loss: 0.1559\n",
            "Epoch 3, Sample 12112: Loss: 0.2375\n",
            "Epoch 3, Sample 12113: Loss: 1.0524\n",
            "Epoch 3, Sample 12114: Loss: 0.7036\n",
            "Epoch 3, Sample 12115: Loss: 1.7017\n",
            "Epoch 3, Sample 12116: Loss: 1.2592\n",
            "Epoch 3, Sample 12117: Loss: 0.5972\n",
            "Epoch 3, Sample 12118: Loss: 6.5661\n",
            "Epoch 3, Sample 12119: Loss: 1.1284\n",
            "Epoch 3, Sample 12120: Loss: 0.3399\n",
            "Epoch 3, Sample 12121: Loss: 0.5196\n",
            "Epoch 3, Sample 12122: Loss: 0.2832\n",
            "Epoch 3, Sample 12123: Loss: 0.6990\n",
            "Epoch 3, Sample 12124: Loss: 0.1056\n",
            "Epoch 3, Sample 12125: Loss: 0.0145\n",
            "Epoch 3, Sample 12126: Loss: 0.0018\n",
            "Epoch 3, Sample 12127: Loss: 0.0282\n",
            "Epoch 3, Sample 12128: Loss: 0.2044\n",
            "Epoch 3, Sample 12129: Loss: 1.0530\n",
            "Epoch 3, Sample 12130: Loss: 0.0630\n",
            "Epoch 3, Sample 12131: Loss: 0.8951\n",
            "Epoch 3, Sample 12132: Loss: 0.1647\n",
            "Epoch 3, Sample 12133: Loss: 1.0618\n",
            "Epoch 3, Sample 12134: Loss: 0.2034\n",
            "Epoch 3, Sample 12135: Loss: 0.2044\n",
            "Epoch 3, Sample 12136: Loss: 0.1130\n",
            "Epoch 3, Sample 12137: Loss: 0.2759\n",
            "Epoch 3, Sample 12138: Loss: 0.1822\n",
            "Epoch 3, Sample 12139: Loss: 0.2759\n",
            "Epoch 3, Sample 12140: Loss: 0.2044\n",
            "Epoch 3, Sample 12141: Loss: 0.0144\n",
            "Epoch 3, Sample 12142: Loss: 0.0782\n",
            "Epoch 3, Sample 12143: Loss: 1.0155\n",
            "Epoch 3, Sample 12144: Loss: 0.2759\n",
            "Epoch 3, Sample 12145: Loss: 0.3402\n",
            "Epoch 3, Sample 12146: Loss: 0.5062\n",
            "Epoch 3, Sample 12147: Loss: 0.1170\n",
            "Epoch 3, Sample 12148: Loss: 0.1300\n",
            "Epoch 3, Sample 12149: Loss: 0.0626\n",
            "Epoch 3, Sample 12150: Loss: 0.1559\n",
            "Epoch 3, Sample 12151: Loss: 0.0026\n",
            "Epoch 3, Sample 12152: Loss: 0.3564\n",
            "Epoch 3, Sample 12153: Loss: 0.1250\n",
            "Epoch 3, Sample 12154: Loss: 0.5919\n",
            "Epoch 3, Sample 12155: Loss: 0.2044\n",
            "Epoch 3, Sample 12156: Loss: 0.1170\n",
            "Epoch 3, Sample 12157: Loss: 1.0530\n",
            "Epoch 3, Sample 12158: Loss: 0.0819\n",
            "Epoch 3, Sample 12159: Loss: 0.2044\n",
            "Epoch 3, Sample 12160: Loss: 0.2044\n",
            "Epoch 3, Sample 12161: Loss: 0.3399\n",
            "Epoch 3, Sample 12162: Loss: 0.0206\n",
            "Epoch 3, Sample 12163: Loss: 0.0018\n",
            "Epoch 3, Sample 12164: Loss: 0.3399\n",
            "Epoch 3, Sample 12165: Loss: 0.9780\n",
            "Epoch 3, Sample 12166: Loss: 1.0947\n",
            "Epoch 3, Sample 12167: Loss: 0.2056\n",
            "Epoch 3, Sample 12168: Loss: 4.0508\n",
            "Epoch 3, Sample 12169: Loss: 0.0212\n",
            "Epoch 3, Sample 12170: Loss: 0.7036\n",
            "Epoch 3, Sample 12171: Loss: 0.3399\n",
            "Epoch 3, Sample 12172: Loss: 0.2044\n",
            "Epoch 3, Sample 12173: Loss: 0.0013\n",
            "Epoch 3, Sample 12174: Loss: 0.1170\n",
            "Epoch 3, Sample 12175: Loss: 0.7036\n",
            "Epoch 3, Sample 12176: Loss: 0.0830\n",
            "Epoch 3, Sample 12177: Loss: 1.0524\n",
            "Epoch 3, Sample 12178: Loss: 0.0026\n",
            "Epoch 3, Sample 12179: Loss: 0.1050\n",
            "Epoch 3, Sample 12180: Loss: 0.7036\n",
            "Epoch 3, Sample 12181: Loss: 1.0524\n",
            "Epoch 3, Sample 12182: Loss: 0.0838\n",
            "Epoch 3, Sample 12183: Loss: 0.7036\n",
            "Epoch 3, Sample 12184: Loss: 0.7036\n",
            "Epoch 3, Sample 12185: Loss: 0.0034\n",
            "Epoch 3, Sample 12186: Loss: 0.4514\n",
            "Epoch 3, Sample 12187: Loss: 0.0607\n",
            "Epoch 3, Sample 12188: Loss: 0.2036\n",
            "Epoch 3, Sample 12189: Loss: 1.0524\n",
            "Epoch 3, Sample 12190: Loss: 0.0838\n",
            "Epoch 3, Sample 12191: Loss: 0.0127\n",
            "Epoch 3, Sample 12192: Loss: 0.2962\n",
            "Epoch 3, Sample 12193: Loss: 0.0020\n",
            "Epoch 3, Sample 12194: Loss: 0.0026\n",
            "Epoch 3, Sample 12195: Loss: 0.3399\n",
            "Epoch 3, Sample 12196: Loss: 0.3402\n",
            "Epoch 3, Sample 12197: Loss: 0.3441\n",
            "Epoch 3, Sample 12198: Loss: 1.3669\n",
            "Epoch 3, Sample 12199: Loss: 0.0018\n",
            "Epoch 3, Sample 12200: Loss: 0.1863\n",
            "Epoch 3, Sample 12201: Loss: 0.3399\n",
            "Epoch 3, Sample 12202: Loss: 0.1559\n",
            "Epoch 3, Sample 12203: Loss: 0.2219\n",
            "Epoch 3, Sample 12204: Loss: 0.2044\n",
            "Epoch 3, Sample 12205: Loss: 0.2759\n",
            "Epoch 3, Sample 12206: Loss: 0.5858\n",
            "Epoch 3, Sample 12207: Loss: 1.0593\n",
            "Epoch 3, Sample 12208: Loss: 0.0026\n",
            "Epoch 3, Sample 12209: Loss: 0.1216\n",
            "Epoch 3, Sample 12210: Loss: 0.1248\n",
            "Epoch 3, Sample 12211: Loss: 0.0030\n",
            "Epoch 3, Sample 12212: Loss: 0.0157\n",
            "Epoch 3, Sample 12213: Loss: 0.9119\n",
            "Epoch 3, Sample 12214: Loss: 0.5858\n",
            "Epoch 3, Sample 12215: Loss: 0.3399\n",
            "Epoch 3, Sample 12216: Loss: 0.0108\n",
            "Epoch 3, Sample 12217: Loss: 0.0026\n",
            "Epoch 3, Sample 12218: Loss: 0.3441\n",
            "Epoch 3, Sample 12219: Loss: 1.0524\n",
            "Epoch 3, Sample 12220: Loss: 0.6990\n",
            "Epoch 3, Sample 12221: Loss: 0.2044\n",
            "Epoch 3, Sample 12222: Loss: 1.2139\n",
            "Epoch 3, Sample 12223: Loss: 0.0306\n",
            "Epoch 3, Sample 12224: Loss: 0.2340\n",
            "Epoch 3, Sample 12225: Loss: 0.2034\n",
            "Epoch 3, Sample 12226: Loss: 1.0551\n",
            "Epoch 3, Sample 12227: Loss: 0.1248\n",
            "Epoch 3, Sample 12228: Loss: 0.2219\n",
            "Epoch 3, Sample 12229: Loss: 0.0519\n",
            "Epoch 3, Sample 12230: Loss: 0.1185\n",
            "Epoch 3, Sample 12231: Loss: 0.4761\n",
            "Epoch 3, Sample 12232: Loss: 0.0505\n",
            "Epoch 3, Sample 12233: Loss: 0.0000\n",
            "Epoch 3, Sample 12234: Loss: 0.2832\n",
            "Epoch 3, Sample 12235: Loss: 0.9367\n",
            "Epoch 3, Sample 12236: Loss: 0.1250\n",
            "Epoch 3, Sample 12237: Loss: 0.0948\n",
            "Epoch 3, Sample 12238: Loss: 0.0238\n",
            "Epoch 3, Sample 12239: Loss: 0.3441\n",
            "Epoch 3, Sample 12240: Loss: 0.0676\n",
            "Epoch 3, Sample 12241: Loss: 3.9629\n",
            "Epoch 3, Sample 12242: Loss: 0.6867\n",
            "Epoch 3, Sample 12243: Loss: 0.0060\n",
            "Epoch 3, Sample 12244: Loss: 0.2044\n",
            "Epoch 3, Sample 12245: Loss: 1.0155\n",
            "Epoch 3, Sample 12246: Loss: 0.2084\n",
            "Epoch 3, Sample 12247: Loss: 1.8108\n",
            "Epoch 3, Sample 12248: Loss: 0.3441\n",
            "Epoch 3, Sample 12249: Loss: 0.2112\n",
            "Epoch 3, Sample 12250: Loss: 0.7036\n",
            "Epoch 3, Sample 12251: Loss: 0.0145\n",
            "Epoch 3, Sample 12252: Loss: 0.0067\n",
            "Epoch 3, Sample 12253: Loss: 1.0524\n",
            "Epoch 3, Sample 12254: Loss: 0.0303\n",
            "Epoch 3, Sample 12255: Loss: 0.2832\n",
            "Epoch 3, Sample 12256: Loss: 2.4541\n",
            "Epoch 3, Sample 12257: Loss: 0.2032\n",
            "Epoch 3, Sample 12258: Loss: 1.0524\n",
            "Epoch 3, Sample 12259: Loss: 0.2036\n",
            "Epoch 3, Sample 12260: Loss: 0.0321\n",
            "Epoch 3, Sample 12261: Loss: 0.8951\n",
            "Epoch 3, Sample 12262: Loss: 0.5972\n",
            "Epoch 3, Sample 12263: Loss: 0.0630\n",
            "Epoch 3, Sample 12264: Loss: 0.1252\n",
            "Epoch 3, Sample 12265: Loss: 0.0238\n",
            "Epoch 3, Sample 12266: Loss: 0.4930\n",
            "Epoch 3, Sample 12267: Loss: 3.0201\n",
            "Epoch 3, Sample 12268: Loss: 0.2044\n",
            "Epoch 3, Sample 12269: Loss: 0.1170\n",
            "Epoch 3, Sample 12270: Loss: 1.0524\n",
            "Epoch 3, Sample 12271: Loss: 0.5849\n",
            "Epoch 3, Sample 12272: Loss: 1.0524\n",
            "Epoch 3, Sample 12273: Loss: 0.4485\n",
            "Epoch 3, Sample 12274: Loss: 0.4434\n",
            "Epoch 3, Sample 12275: Loss: 0.0626\n",
            "Epoch 3, Sample 12276: Loss: 1.9726\n",
            "Epoch 3, Sample 12277: Loss: 0.8484\n",
            "Epoch 3, Sample 12278: Loss: 1.0524\n",
            "Epoch 3, Sample 12279: Loss: 1.8615\n",
            "Epoch 3, Sample 12280: Loss: 0.0270\n",
            "Epoch 3, Sample 12281: Loss: 0.2032\n",
            "Epoch 3, Sample 12282: Loss: 0.0053\n",
            "Epoch 3, Sample 12283: Loss: 0.0048\n",
            "Epoch 3, Sample 12284: Loss: 0.5972\n",
            "Epoch 3, Sample 12285: Loss: 1.0155\n",
            "Epoch 3, Sample 12286: Loss: 0.5712\n",
            "Epoch 3, Sample 12287: Loss: 0.2759\n",
            "Epoch 3, Sample 12288: Loss: 0.0387\n",
            "Epoch 3, Sample 12289: Loss: 0.0026\n",
            "Epoch 3, Sample 12290: Loss: 0.0082\n",
            "Epoch 3, Sample 12291: Loss: 0.3441\n",
            "Epoch 3, Sample 12292: Loss: 0.1273\n",
            "Epoch 3, Sample 12293: Loss: 0.7036\n",
            "Epoch 3, Sample 12294: Loss: 0.3828\n",
            "Epoch 3, Sample 12295: Loss: 0.1446\n",
            "Epoch 3, Sample 12296: Loss: 0.3294\n",
            "Epoch 3, Sample 12297: Loss: 0.0580\n",
            "Epoch 3, Sample 12298: Loss: 1.0524\n",
            "Epoch 3, Sample 12299: Loss: 0.3879\n",
            "Epoch 3, Sample 12300: Loss: 1.2597\n",
            "Epoch 3, Sample 12301: Loss: 0.1113\n",
            "Epoch 3, Sample 12302: Loss: 0.4799\n",
            "Epoch 3, Sample 12303: Loss: 0.5000\n",
            "Epoch 3, Sample 12304: Loss: 0.5858\n",
            "Epoch 3, Sample 12305: Loss: 0.2938\n",
            "Epoch 3, Sample 12306: Loss: 0.0630\n",
            "Epoch 3, Sample 12307: Loss: 0.0005\n",
            "Epoch 3, Sample 12308: Loss: 0.3259\n",
            "Epoch 3, Sample 12309: Loss: 1.0530\n",
            "Epoch 3, Sample 12310: Loss: 0.7036\n",
            "Epoch 3, Sample 12311: Loss: 0.1170\n",
            "Epoch 3, Sample 12312: Loss: 0.1843\n",
            "Epoch 3, Sample 12313: Loss: 0.3399\n",
            "Epoch 3, Sample 12314: Loss: 0.7451\n",
            "Epoch 3, Sample 12315: Loss: 0.1170\n",
            "Epoch 3, Sample 12316: Loss: 0.1248\n",
            "Epoch 3, Sample 12317: Loss: 0.2044\n",
            "Epoch 3, Sample 12318: Loss: 0.1248\n",
            "Epoch 3, Sample 12319: Loss: 0.6990\n",
            "Epoch 3, Sample 12320: Loss: 0.2032\n",
            "Epoch 3, Sample 12321: Loss: 0.5062\n",
            "Epoch 3, Sample 12322: Loss: 1.0524\n",
            "Epoch 3, Sample 12323: Loss: 0.2962\n",
            "Epoch 3, Sample 12324: Loss: 1.0524\n",
            "Epoch 3, Sample 12325: Loss: 1.0524\n",
            "Epoch 3, Sample 12326: Loss: 0.0623\n",
            "Epoch 3, Sample 12327: Loss: 1.0530\n",
            "Epoch 3, Sample 12328: Loss: 0.1372\n",
            "Epoch 3, Sample 12329: Loss: 0.1559\n",
            "Epoch 3, Sample 12330: Loss: 0.0005\n",
            "Epoch 3, Sample 12331: Loss: 0.0031\n",
            "Epoch 3, Sample 12332: Loss: 0.2067\n",
            "Epoch 3, Sample 12333: Loss: 0.9024\n",
            "Epoch 3, Sample 12334: Loss: 0.0000\n",
            "Epoch 3, Sample 12335: Loss: 0.2483\n",
            "Epoch 3, Sample 12336: Loss: 0.1039\n",
            "Epoch 3, Sample 12337: Loss: 0.8111\n",
            "Epoch 3, Sample 12338: Loss: 1.1117\n",
            "Epoch 3, Sample 12339: Loss: 0.6867\n",
            "Epoch 3, Sample 12340: Loss: 0.3949\n",
            "Epoch 3, Sample 12341: Loss: 0.0026\n",
            "Epoch 3, Sample 12342: Loss: 1.0155\n",
            "Epoch 3, Sample 12343: Loss: 21.5392\n",
            "Epoch 3, Sample 12344: Loss: 0.7036\n",
            "Epoch 3, Sample 12345: Loss: 0.0001\n",
            "Epoch 3, Sample 12346: Loss: 0.4930\n",
            "Epoch 3, Sample 12347: Loss: 0.7036\n",
            "Epoch 3, Sample 12348: Loss: 0.5196\n",
            "Epoch 3, Sample 12349: Loss: 0.2036\n",
            "Epoch 3, Sample 12350: Loss: 0.1559\n",
            "Epoch 3, Sample 12351: Loss: 1.0155\n",
            "Epoch 3, Sample 12352: Loss: 0.1463\n",
            "Epoch 3, Sample 12353: Loss: 0.6092\n",
            "Epoch 3, Sample 12354: Loss: 3.8097\n",
            "Epoch 3, Sample 12355: Loss: 0.0062\n",
            "Epoch 3, Sample 12356: Loss: 0.2832\n",
            "Epoch 3, Sample 12357: Loss: 0.5858\n",
            "Epoch 3, Sample 12358: Loss: 0.3949\n",
            "Epoch 3, Sample 12359: Loss: 0.0415\n",
            "Epoch 3, Sample 12360: Loss: 2.1641\n",
            "Epoch 3, Sample 12361: Loss: 0.0026\n",
            "Epoch 3, Sample 12362: Loss: 0.7036\n",
            "Epoch 3, Sample 12363: Loss: 0.0630\n",
            "Epoch 3, Sample 12364: Loss: 1.0266\n",
            "Epoch 3, Sample 12365: Loss: 0.0848\n",
            "Epoch 3, Sample 12366: Loss: 0.3402\n",
            "Epoch 3, Sample 12367: Loss: 0.0009\n",
            "Epoch 3, Sample 12368: Loss: 0.0280\n",
            "Epoch 3, Sample 12369: Loss: 1.0524\n",
            "Epoch 3, Sample 12370: Loss: 1.0155\n",
            "Epoch 3, Sample 12371: Loss: 0.1478\n",
            "Epoch 3, Sample 12372: Loss: 0.3399\n",
            "Epoch 3, Sample 12373: Loss: 0.6120\n",
            "Epoch 3, Sample 12374: Loss: 0.1508\n",
            "Epoch 3, Sample 12375: Loss: 0.0306\n",
            "Epoch 3, Sample 12376: Loss: 0.2034\n",
            "Epoch 3, Sample 12377: Loss: 0.2044\n",
            "Epoch 3, Sample 12378: Loss: 0.8484\n",
            "Epoch 3, Sample 12379: Loss: 7.6710\n",
            "Epoch 3, Sample 12380: Loss: 0.0026\n",
            "Epoch 3, Sample 12381: Loss: 0.2034\n",
            "Epoch 3, Sample 12382: Loss: 1.6616\n",
            "Epoch 3, Sample 12383: Loss: 0.0075\n",
            "Epoch 3, Sample 12384: Loss: 0.0013\n",
            "Epoch 3, Sample 12385: Loss: 0.8039\n",
            "Epoch 3, Sample 12386: Loss: 1.0818\n",
            "Epoch 3, Sample 12387: Loss: 0.7036\n",
            "Epoch 3, Sample 12388: Loss: 0.5972\n",
            "Epoch 3, Sample 12389: Loss: 0.4799\n",
            "Epoch 3, Sample 12390: Loss: 0.0018\n",
            "Epoch 3, Sample 12391: Loss: 0.3441\n",
            "Epoch 3, Sample 12392: Loss: 0.7036\n",
            "Epoch 3, Sample 12393: Loss: 0.5272\n",
            "Epoch 3, Sample 12394: Loss: 0.0237\n",
            "Epoch 3, Sample 12395: Loss: 1.0524\n",
            "Epoch 3, Sample 12396: Loss: 0.4841\n",
            "Epoch 3, Sample 12397: Loss: 0.2204\n",
            "Epoch 3, Sample 12398: Loss: 0.2759\n",
            "Epoch 3, Sample 12399: Loss: 0.0024\n",
            "Epoch 3, Sample 12400: Loss: 1.0155\n",
            "Epoch 3, Sample 12401: Loss: 0.0105\n",
            "Epoch 3, Sample 12402: Loss: 0.7702\n",
            "Epoch 3, Sample 12403: Loss: 0.0026\n",
            "Epoch 3, Sample 12404: Loss: 0.2989\n",
            "Epoch 3, Sample 12405: Loss: 0.1170\n",
            "Epoch 3, Sample 12406: Loss: 0.0860\n",
            "Epoch 3, Sample 12407: Loss: 1.0524\n",
            "Epoch 3, Sample 12408: Loss: 0.1588\n",
            "Epoch 3, Sample 12409: Loss: 0.0026\n",
            "Epoch 3, Sample 12410: Loss: 1.7195\n",
            "Epoch 3, Sample 12411: Loss: 0.1250\n",
            "Epoch 3, Sample 12412: Loss: 0.3561\n",
            "Epoch 3, Sample 12413: Loss: 1.0524\n",
            "Epoch 3, Sample 12414: Loss: 0.0018\n",
            "Epoch 3, Sample 12415: Loss: 0.4489\n",
            "Epoch 3, Sample 12416: Loss: 0.1250\n",
            "Epoch 3, Sample 12417: Loss: 0.5858\n",
            "Epoch 3, Sample 12418: Loss: 1.0530\n",
            "Epoch 3, Sample 12419: Loss: 0.4466\n",
            "Epoch 3, Sample 12420: Loss: 0.0915\n",
            "Epoch 3, Sample 12421: Loss: 1.2198\n",
            "Epoch 3, Sample 12422: Loss: 0.2699\n",
            "Epoch 3, Sample 12423: Loss: 0.1559\n",
            "Epoch 3, Sample 12424: Loss: 0.7036\n",
            "Epoch 3, Sample 12425: Loss: 0.0091\n",
            "Epoch 3, Sample 12426: Loss: 1.5148\n",
            "Epoch 3, Sample 12427: Loss: 0.0630\n",
            "Epoch 3, Sample 12428: Loss: 0.1372\n",
            "Epoch 3, Sample 12429: Loss: 0.2034\n",
            "Epoch 3, Sample 12430: Loss: 0.5972\n",
            "Epoch 3, Sample 12431: Loss: 0.0343\n",
            "Epoch 3, Sample 12432: Loss: 0.3399\n",
            "Epoch 3, Sample 12433: Loss: 0.5839\n",
            "Epoch 3, Sample 12434: Loss: 0.7036\n",
            "Epoch 3, Sample 12435: Loss: 0.4841\n",
            "Epoch 3, Sample 12436: Loss: 0.1559\n",
            "Epoch 3, Sample 12437: Loss: 0.2032\n",
            "Epoch 3, Sample 12438: Loss: 0.0026\n",
            "Epoch 3, Sample 12439: Loss: 0.0009\n",
            "Epoch 3, Sample 12440: Loss: 1.0155\n",
            "Epoch 3, Sample 12441: Loss: 1.0524\n",
            "Epoch 3, Sample 12442: Loss: 0.2200\n",
            "Epoch 3, Sample 12443: Loss: 0.0513\n",
            "Epoch 3, Sample 12444: Loss: 2.9709\n",
            "Epoch 3, Sample 12445: Loss: 0.7875\n",
            "Epoch 3, Sample 12446: Loss: 0.5003\n",
            "Epoch 3, Sample 12447: Loss: 0.7088\n",
            "Epoch 3, Sample 12448: Loss: 0.0147\n",
            "Epoch 3, Sample 12449: Loss: 1.0524\n",
            "Epoch 3, Sample 12450: Loss: 0.4032\n",
            "Epoch 3, Sample 12451: Loss: 0.0063\n",
            "Epoch 3, Sample 12452: Loss: 0.3949\n",
            "Epoch 3, Sample 12453: Loss: 0.8951\n",
            "Epoch 3, Sample 12454: Loss: 4.0002\n",
            "Epoch 3, Sample 12455: Loss: 0.8952\n",
            "Epoch 3, Sample 12456: Loss: 0.0005\n",
            "Epoch 3, Sample 12457: Loss: 0.2182\n",
            "Epoch 3, Sample 12458: Loss: 0.7036\n",
            "Epoch 3, Sample 12459: Loss: 0.8951\n",
            "Epoch 3, Sample 12460: Loss: 0.3949\n",
            "Epoch 3, Sample 12461: Loss: 0.6372\n",
            "Epoch 3, Sample 12462: Loss: 0.5972\n",
            "Epoch 3, Sample 12463: Loss: 0.5000\n",
            "Epoch 3, Sample 12464: Loss: 0.3616\n",
            "Epoch 3, Sample 12465: Loss: 0.6304\n",
            "Epoch 3, Sample 12466: Loss: 0.0205\n",
            "Epoch 3, Sample 12467: Loss: 0.2219\n",
            "Epoch 3, Sample 12468: Loss: 0.7737\n",
            "Epoch 3, Sample 12469: Loss: 0.0452\n",
            "Epoch 3, Sample 12470: Loss: 0.2034\n",
            "Epoch 3, Sample 12471: Loss: 0.6867\n",
            "Epoch 3, Sample 12472: Loss: 0.2044\n",
            "Epoch 3, Sample 12473: Loss: 0.2036\n",
            "Epoch 3, Sample 12474: Loss: 0.0041\n",
            "Epoch 3, Sample 12475: Loss: 0.9367\n",
            "Epoch 3, Sample 12476: Loss: 0.7453\n",
            "Epoch 3, Sample 12477: Loss: 0.0364\n",
            "Epoch 3, Sample 12478: Loss: 0.1044\n",
            "Epoch 3, Sample 12479: Loss: 0.0744\n",
            "Epoch 3, Sample 12480: Loss: 0.2112\n",
            "Epoch 3, Sample 12481: Loss: 4.0769\n",
            "Epoch 3, Sample 12482: Loss: 0.4367\n",
            "Epoch 3, Sample 12483: Loss: 0.2036\n",
            "Epoch 3, Sample 12484: Loss: 0.3402\n",
            "Epoch 3, Sample 12485: Loss: 0.8814\n",
            "Epoch 3, Sample 12486: Loss: 0.4906\n",
            "Epoch 3, Sample 12487: Loss: 0.0316\n",
            "Epoch 3, Sample 12488: Loss: 0.1664\n",
            "Epoch 3, Sample 12489: Loss: 0.7721\n",
            "Epoch 3, Sample 12490: Loss: 0.7036\n",
            "Epoch 3, Sample 12491: Loss: 0.0108\n",
            "Epoch 3, Sample 12492: Loss: 0.7036\n",
            "Epoch 3, Sample 12493: Loss: 0.2044\n",
            "Epoch 3, Sample 12494: Loss: 1.0530\n",
            "Epoch 3, Sample 12495: Loss: 0.2759\n",
            "Epoch 3, Sample 12496: Loss: 1.2044\n",
            "Epoch 3, Sample 12497: Loss: 0.1170\n",
            "Epoch 3, Sample 12498: Loss: 0.2034\n",
            "Epoch 3, Sample 12499: Loss: 0.7036\n",
            "Epoch 3, Sample 12500: Loss: 0.0026\n",
            "Epoch 3, Sample 12501: Loss: 0.0018\n",
            "Epoch 3, Sample 12502: Loss: 0.6026\n",
            "Epoch 3, Sample 12503: Loss: 0.1594\n",
            "Epoch 3, Sample 12504: Loss: 0.6766\n",
            "Epoch 3, Sample 12505: Loss: 0.0108\n",
            "Epoch 3, Sample 12506: Loss: 0.1219\n",
            "Epoch 3, Sample 12507: Loss: 0.1248\n",
            "Epoch 3, Sample 12508: Loss: 0.2941\n",
            "Epoch 3, Sample 12509: Loss: 0.2044\n",
            "Epoch 3, Sample 12510: Loss: 0.4611\n",
            "Epoch 3, Sample 12511: Loss: 0.2340\n",
            "Epoch 3, Sample 12512: Loss: 0.1180\n",
            "Epoch 3, Sample 12513: Loss: 0.1056\n",
            "Epoch 3, Sample 12514: Loss: 0.7036\n",
            "Epoch 3, Sample 12515: Loss: 1.0524\n",
            "Epoch 3, Sample 12516: Loss: 0.0026\n",
            "Epoch 3, Sample 12517: Loss: 0.0661\n",
            "Epoch 3, Sample 12518: Loss: 0.0006\n",
            "Epoch 3, Sample 12519: Loss: 0.1027\n",
            "Epoch 3, Sample 12520: Loss: 0.1248\n",
            "Epoch 3, Sample 12521: Loss: 0.1340\n",
            "Epoch 3, Sample 12522: Loss: 0.0031\n",
            "Epoch 3, Sample 12523: Loss: 0.0001\n",
            "Epoch 3, Sample 12524: Loss: 0.3399\n",
            "Epoch 3, Sample 12525: Loss: 0.9367\n",
            "Epoch 3, Sample 12526: Loss: 2.2964\n",
            "Epoch 3, Sample 12527: Loss: 1.0524\n",
            "Epoch 3, Sample 12528: Loss: 0.3399\n",
            "Epoch 3, Sample 12529: Loss: 5.6993\n",
            "Epoch 3, Sample 12530: Loss: 0.2363\n",
            "Epoch 3, Sample 12531: Loss: 0.3450\n",
            "Epoch 3, Sample 12532: Loss: 0.0212\n",
            "Epoch 3, Sample 12533: Loss: 0.0027\n",
            "Epoch 3, Sample 12534: Loss: 1.0155\n",
            "Epoch 3, Sample 12535: Loss: 0.0625\n",
            "Epoch 3, Sample 12536: Loss: 0.3539\n",
            "Epoch 3, Sample 12537: Loss: 0.3402\n",
            "Epoch 3, Sample 12538: Loss: 0.8951\n",
            "Epoch 3, Sample 12539: Loss: 0.1170\n",
            "Epoch 3, Sample 12540: Loss: 0.2855\n",
            "Epoch 3, Sample 12541: Loss: 0.4271\n",
            "Epoch 3, Sample 12542: Loss: 0.0005\n",
            "Epoch 3, Sample 12543: Loss: 0.0938\n",
            "Epoch 3, Sample 12544: Loss: 0.7036\n",
            "Epoch 3, Sample 12545: Loss: 1.0524\n",
            "Epoch 3, Sample 12546: Loss: 1.2926\n",
            "Epoch 3, Sample 12547: Loss: 0.0938\n",
            "Epoch 3, Sample 12548: Loss: 0.1355\n",
            "Epoch 3, Sample 12549: Loss: 0.0562\n",
            "Epoch 3, Sample 12550: Loss: 0.0000\n",
            "Epoch 3, Sample 12551: Loss: 0.1058\n",
            "Epoch 3, Sample 12552: Loss: 0.0013\n",
            "Epoch 3, Sample 12553: Loss: 0.2044\n",
            "Epoch 3, Sample 12554: Loss: 0.0189\n",
            "Epoch 3, Sample 12555: Loss: 0.1460\n",
            "Epoch 3, Sample 12556: Loss: 0.0026\n",
            "Epoch 3, Sample 12557: Loss: 0.1233\n",
            "Epoch 3, Sample 12558: Loss: 0.1250\n",
            "Epoch 3, Sample 12559: Loss: 0.4827\n",
            "Epoch 3, Sample 12560: Loss: 0.8516\n",
            "Epoch 3, Sample 12561: Loss: 0.1250\n",
            "Epoch 3, Sample 12562: Loss: 1.2916\n",
            "Epoch 3, Sample 12563: Loss: 0.5010\n",
            "Epoch 3, Sample 12564: Loss: 0.0421\n",
            "Epoch 3, Sample 12565: Loss: 0.9429\n",
            "Epoch 3, Sample 12566: Loss: 0.1463\n",
            "Epoch 3, Sample 12567: Loss: 0.1508\n",
            "Epoch 3, Sample 12568: Loss: 0.7036\n",
            "Epoch 3, Sample 12569: Loss: 0.6111\n",
            "Epoch 3, Sample 12570: Loss: 0.0108\n",
            "Epoch 3, Sample 12571: Loss: 0.0007\n",
            "Epoch 3, Sample 12572: Loss: 0.0106\n",
            "Epoch 3, Sample 12573: Loss: 0.1408\n",
            "Epoch 3, Sample 12574: Loss: 3.1042\n",
            "Epoch 3, Sample 12575: Loss: 0.2034\n",
            "Epoch 3, Sample 12576: Loss: 0.4891\n",
            "Epoch 3, Sample 12577: Loss: 0.0466\n",
            "Epoch 3, Sample 12578: Loss: 0.9300\n",
            "Epoch 3, Sample 12579: Loss: 0.0205\n",
            "Epoch 3, Sample 12580: Loss: 0.0108\n",
            "Epoch 3, Sample 12581: Loss: 0.2989\n",
            "Epoch 3, Sample 12582: Loss: 0.0063\n",
            "Epoch 3, Sample 12583: Loss: 1.0524\n",
            "Epoch 3, Sample 12584: Loss: 0.0026\n",
            "Epoch 3, Sample 12585: Loss: 0.3250\n",
            "Epoch 3, Sample 12586: Loss: 0.1415\n",
            "Epoch 3, Sample 12587: Loss: 0.6356\n",
            "Epoch 3, Sample 12588: Loss: 1.0524\n",
            "Epoch 3, Sample 12589: Loss: 0.1250\n",
            "Epoch 3, Sample 12590: Loss: 0.0052\n",
            "Epoch 3, Sample 12591: Loss: 0.0630\n",
            "Epoch 3, Sample 12592: Loss: 0.4003\n",
            "Epoch 3, Sample 12593: Loss: 0.3621\n",
            "Epoch 3, Sample 12594: Loss: 0.9367\n",
            "Epoch 3, Sample 12595: Loss: 0.7628\n",
            "Epoch 3, Sample 12596: Loss: 0.2034\n",
            "Epoch 3, Sample 12597: Loss: 2.4326\n",
            "Epoch 3, Sample 12598: Loss: 0.2759\n",
            "Epoch 3, Sample 12599: Loss: 0.7453\n",
            "Epoch 3, Sample 12600: Loss: 0.4444\n",
            "Epoch 3, Sample 12601: Loss: 0.0022\n",
            "Epoch 3, Sample 12602: Loss: 1.0524\n",
            "Epoch 3, Sample 12603: Loss: 8.6505\n",
            "Epoch 3, Sample 12604: Loss: 0.0026\n",
            "Epoch 3, Sample 12605: Loss: 0.7036\n",
            "Epoch 3, Sample 12606: Loss: 0.4227\n",
            "Epoch 3, Sample 12607: Loss: 0.7755\n",
            "Epoch 3, Sample 12608: Loss: 0.1225\n",
            "Epoch 3, Sample 12609: Loss: 0.5282\n",
            "Epoch 3, Sample 12610: Loss: 1.3987\n",
            "Epoch 3, Sample 12611: Loss: 0.0205\n",
            "Epoch 3, Sample 12612: Loss: 0.2034\n",
            "Epoch 3, Sample 12613: Loss: 0.0025\n",
            "Epoch 3, Sample 12614: Loss: 0.0604\n",
            "Epoch 3, Sample 12615: Loss: 0.2159\n",
            "Epoch 3, Sample 12616: Loss: 1.7669\n",
            "Epoch 3, Sample 12617: Loss: 0.6110\n",
            "Epoch 3, Sample 12618: Loss: 0.2811\n",
            "Epoch 3, Sample 12619: Loss: 0.1170\n",
            "Epoch 3, Sample 12620: Loss: 0.2759\n",
            "Epoch 3, Sample 12621: Loss: 0.2044\n",
            "Epoch 3, Sample 12622: Loss: 0.5858\n",
            "Epoch 3, Sample 12623: Loss: 0.0306\n",
            "Epoch 3, Sample 12624: Loss: 2.1678\n",
            "Epoch 3, Sample 12625: Loss: 0.2962\n",
            "Epoch 3, Sample 12626: Loss: 0.3441\n",
            "Epoch 3, Sample 12627: Loss: 0.0258\n",
            "Epoch 3, Sample 12628: Loss: 0.1549\n",
            "Epoch 3, Sample 12629: Loss: 0.2032\n",
            "Epoch 3, Sample 12630: Loss: 0.1248\n",
            "Epoch 3, Sample 12631: Loss: 0.9367\n",
            "Epoch 3, Sample 12632: Loss: 0.2034\n",
            "Epoch 3, Sample 12633: Loss: 0.0099\n",
            "Epoch 3, Sample 12634: Loss: 0.0363\n",
            "Epoch 3, Sample 12635: Loss: 0.1523\n",
            "Epoch 3, Sample 12636: Loss: 0.0513\n",
            "Epoch 3, Sample 12637: Loss: 0.1417\n",
            "Epoch 3, Sample 12638: Loss: 0.7409\n",
            "Epoch 3, Sample 12639: Loss: 0.2209\n",
            "Epoch 3, Sample 12640: Loss: 0.0063\n",
            "Epoch 3, Sample 12641: Loss: 0.7910\n",
            "Epoch 3, Sample 12642: Loss: 0.1777\n",
            "Epoch 3, Sample 12643: Loss: 0.4163\n",
            "Epoch 3, Sample 12644: Loss: 1.0524\n",
            "Epoch 3, Sample 12645: Loss: 0.3568\n",
            "Epoch 3, Sample 12646: Loss: 0.7453\n",
            "Epoch 3, Sample 12647: Loss: 0.0062\n",
            "Epoch 3, Sample 12648: Loss: 0.0205\n",
            "Epoch 3, Sample 12649: Loss: 0.0630\n",
            "Epoch 3, Sample 12650: Loss: 0.4611\n",
            "Epoch 3, Sample 12651: Loss: 0.1692\n",
            "Epoch 3, Sample 12652: Loss: 0.2044\n",
            "Epoch 3, Sample 12653: Loss: 0.0005\n",
            "Epoch 3, Sample 12654: Loss: 1.0155\n",
            "Epoch 3, Sample 12655: Loss: 1.7100\n",
            "Epoch 3, Sample 12656: Loss: 3.2629\n",
            "Epoch 3, Sample 12657: Loss: 0.3441\n",
            "Epoch 3, Sample 12658: Loss: 0.4841\n",
            "Epoch 3, Sample 12659: Loss: 0.1546\n",
            "Epoch 3, Sample 12660: Loss: 0.4930\n",
            "Epoch 3, Sample 12661: Loss: 0.0018\n",
            "Epoch 3, Sample 12662: Loss: 1.5159\n",
            "Epoch 3, Sample 12663: Loss: 0.0212\n",
            "Epoch 3, Sample 12664: Loss: 0.0769\n",
            "Epoch 3, Sample 12665: Loss: 0.3399\n",
            "Epoch 3, Sample 12666: Loss: 0.2044\n",
            "Epoch 3, Sample 12667: Loss: 1.0530\n",
            "Epoch 3, Sample 12668: Loss: 0.0084\n",
            "Epoch 3, Sample 12669: Loss: 0.0849\n",
            "Epoch 3, Sample 12670: Loss: 0.0028\n",
            "Epoch 3, Sample 12671: Loss: 0.5858\n",
            "Epoch 3, Sample 12672: Loss: 0.0264\n",
            "Epoch 3, Sample 12673: Loss: 0.7453\n",
            "Epoch 3, Sample 12674: Loss: 0.0001\n",
            "Epoch 3, Sample 12675: Loss: 0.5799\n",
            "Epoch 3, Sample 12676: Loss: 0.5017\n",
            "Epoch 3, Sample 12677: Loss: 0.6523\n",
            "Epoch 3, Sample 12678: Loss: 0.3399\n",
            "Epoch 3, Sample 12679: Loss: 0.2032\n",
            "Epoch 3, Sample 12680: Loss: 5.1383\n",
            "Epoch 3, Sample 12681: Loss: 1.0524\n",
            "Epoch 3, Sample 12682: Loss: 0.3441\n",
            "Epoch 3, Sample 12683: Loss: 0.1863\n",
            "Epoch 3, Sample 12684: Loss: 0.0840\n",
            "Epoch 3, Sample 12685: Loss: 0.1555\n",
            "Epoch 3, Sample 12686: Loss: 10.6983\n",
            "Epoch 3, Sample 12687: Loss: 0.0634\n",
            "Epoch 3, Sample 12688: Loss: 0.2032\n",
            "Epoch 3, Sample 12689: Loss: 1.0524\n",
            "Epoch 3, Sample 12690: Loss: 0.2032\n",
            "Epoch 3, Sample 12691: Loss: 0.2521\n",
            "Epoch 3, Sample 12692: Loss: 0.0234\n",
            "Epoch 3, Sample 12693: Loss: 0.2219\n",
            "Epoch 3, Sample 12694: Loss: 0.2962\n",
            "Epoch 3, Sample 12695: Loss: 0.9367\n",
            "Epoch 3, Sample 12696: Loss: 0.5858\n",
            "Epoch 3, Sample 12697: Loss: 0.2044\n",
            "Epoch 3, Sample 12698: Loss: 5.1637\n",
            "Epoch 3, Sample 12699: Loss: 0.4799\n",
            "Epoch 3, Sample 12700: Loss: 0.2036\n",
            "Epoch 3, Sample 12701: Loss: 0.0032\n",
            "Epoch 3, Sample 12702: Loss: 8.1565\n",
            "Epoch 3, Sample 12703: Loss: 0.3345\n",
            "Epoch 3, Sample 12704: Loss: 1.0530\n",
            "Epoch 3, Sample 12705: Loss: 0.1248\n",
            "Epoch 3, Sample 12706: Loss: 0.2832\n",
            "Epoch 3, Sample 12707: Loss: 0.8951\n",
            "Epoch 3, Sample 12708: Loss: 0.1890\n",
            "Epoch 3, Sample 12709: Loss: 0.1394\n",
            "Epoch 3, Sample 12710: Loss: 0.2034\n",
            "Epoch 3, Sample 12711: Loss: 0.0630\n",
            "Epoch 3, Sample 12712: Loss: 0.2935\n",
            "Epoch 3, Sample 12713: Loss: 0.2485\n",
            "Epoch 3, Sample 12714: Loss: 0.0018\n",
            "Epoch 3, Sample 12715: Loss: 0.2044\n",
            "Epoch 3, Sample 12716: Loss: 1.0314\n",
            "Epoch 3, Sample 12717: Loss: 0.6990\n",
            "Epoch 3, Sample 12718: Loss: 1.0524\n",
            "Epoch 3, Sample 12719: Loss: 0.7702\n",
            "Epoch 3, Sample 12720: Loss: 0.0002\n",
            "Epoch 3, Sample 12721: Loss: 3.4979\n",
            "Epoch 3, Sample 12722: Loss: 0.4220\n",
            "Epoch 3, Sample 12723: Loss: 0.2750\n",
            "Epoch 3, Sample 12724: Loss: 0.5019\n",
            "Epoch 3, Sample 12725: Loss: 0.7036\n",
            "Epoch 3, Sample 12726: Loss: 0.7453\n",
            "Epoch 3, Sample 12727: Loss: 0.0182\n",
            "Epoch 3, Sample 12728: Loss: 0.1967\n",
            "Epoch 3, Sample 12729: Loss: 1.0155\n",
            "Epoch 3, Sample 12730: Loss: 1.0901\n",
            "Epoch 3, Sample 12731: Loss: 0.3284\n",
            "Epoch 3, Sample 12732: Loss: 0.6752\n",
            "Epoch 3, Sample 12733: Loss: 0.0460\n",
            "Epoch 3, Sample 12734: Loss: 0.2944\n",
            "Epoch 3, Sample 12735: Loss: 0.0558\n",
            "Epoch 3, Sample 12736: Loss: 0.9343\n",
            "Epoch 3, Sample 12737: Loss: 0.0640\n",
            "Epoch 3, Sample 12738: Loss: 0.6115\n",
            "Epoch 3, Sample 12739: Loss: 0.1498\n",
            "Epoch 3, Sample 12740: Loss: 0.4442\n",
            "Epoch 3, Sample 12741: Loss: 0.2832\n",
            "Epoch 3, Sample 12742: Loss: 0.2639\n",
            "Epoch 3, Sample 12743: Loss: 0.0027\n",
            "Epoch 3, Sample 12744: Loss: 1.0524\n",
            "Epoch 3, Sample 12745: Loss: 0.0580\n",
            "Epoch 3, Sample 12746: Loss: 0.0026\n",
            "Epoch 3, Sample 12747: Loss: 0.9172\n",
            "Epoch 3, Sample 12748: Loss: 0.0731\n",
            "Epoch 3, Sample 12749: Loss: 0.0018\n",
            "Epoch 3, Sample 12750: Loss: 1.0155\n",
            "Epoch 3, Sample 12751: Loss: 0.5858\n",
            "Epoch 3, Sample 12752: Loss: 0.1250\n",
            "Epoch 3, Sample 12753: Loss: 0.2499\n",
            "Epoch 3, Sample 12754: Loss: 3.4349\n",
            "Epoch 3, Sample 12755: Loss: 0.3399\n",
            "Epoch 3, Sample 12756: Loss: 0.1040\n",
            "Epoch 3, Sample 12757: Loss: 0.0590\n",
            "Epoch 3, Sample 12758: Loss: 1.0511\n",
            "Epoch 3, Sample 12759: Loss: 0.1337\n",
            "Epoch 3, Sample 12760: Loss: 0.1170\n",
            "Epoch 3, Sample 12761: Loss: 0.2112\n",
            "Epoch 3, Sample 12762: Loss: 0.4309\n",
            "Epoch 3, Sample 12763: Loss: 0.2132\n",
            "Epoch 3, Sample 12764: Loss: 0.2034\n",
            "Epoch 3, Sample 12765: Loss: 1.9658\n",
            "Epoch 3, Sample 12766: Loss: 0.0002\n",
            "Epoch 3, Sample 12767: Loss: 7.5663\n",
            "Epoch 3, Sample 12768: Loss: 0.2044\n",
            "Epoch 3, Sample 12769: Loss: 0.0205\n",
            "Epoch 3, Sample 12770: Loss: 0.0274\n",
            "Epoch 3, Sample 12771: Loss: 1.0155\n",
            "Epoch 3, Sample 12772: Loss: 0.0289\n",
            "Epoch 3, Sample 12773: Loss: 0.3399\n",
            "Epoch 3, Sample 12774: Loss: 0.3092\n",
            "Epoch 3, Sample 12775: Loss: 0.2036\n",
            "Epoch 3, Sample 12776: Loss: 0.6304\n",
            "Epoch 3, Sample 12777: Loss: 1.0530\n",
            "Epoch 3, Sample 12778: Loss: 0.5858\n",
            "Epoch 3, Sample 12779: Loss: 0.5858\n",
            "Epoch 3, Sample 12780: Loss: 1.9973\n",
            "Epoch 3, Sample 12781: Loss: 0.8889\n",
            "Epoch 3, Sample 12782: Loss: 1.0155\n",
            "Epoch 3, Sample 12783: Loss: 0.3568\n",
            "Epoch 3, Sample 12784: Loss: 0.0799\n",
            "Epoch 3, Sample 12785: Loss: 0.2175\n",
            "Epoch 3, Sample 12786: Loss: 0.2832\n",
            "Epoch 3, Sample 12787: Loss: 1.3085\n",
            "Epoch 3, Sample 12788: Loss: 0.7036\n",
            "Epoch 3, Sample 12789: Loss: 0.7036\n",
            "Epoch 3, Sample 12790: Loss: 1.0530\n",
            "Epoch 3, Sample 12791: Loss: 0.2204\n",
            "Epoch 3, Sample 12792: Loss: 0.9367\n",
            "Epoch 3, Sample 12793: Loss: 0.5196\n",
            "Epoch 3, Sample 12794: Loss: 0.2759\n",
            "Epoch 3, Sample 12795: Loss: 0.7036\n",
            "Epoch 3, Sample 12796: Loss: 0.0018\n",
            "Epoch 3, Sample 12797: Loss: 0.1252\n",
            "Epoch 3, Sample 12798: Loss: 0.2044\n",
            "Epoch 3, Sample 12799: Loss: 0.7036\n",
            "Epoch 3, Sample 12800: Loss: 0.2036\n",
            "Epoch 3, Sample 12801: Loss: 0.3402\n",
            "Epoch 3, Sample 12802: Loss: 0.3367\n",
            "Epoch 3, Sample 12803: Loss: 0.0067\n",
            "Epoch 3, Sample 12804: Loss: 0.2639\n",
            "Epoch 3, Sample 12805: Loss: 0.0927\n",
            "Epoch 3, Sample 12806: Loss: 0.1188\n",
            "Epoch 3, Sample 12807: Loss: 0.2032\n",
            "Epoch 3, Sample 12808: Loss: 0.2219\n",
            "Epoch 3, Sample 12809: Loss: 0.0024\n",
            "Epoch 3, Sample 12810: Loss: 0.3758\n",
            "Epoch 3, Sample 12811: Loss: 0.2034\n",
            "Epoch 3, Sample 12812: Loss: 0.5858\n",
            "Epoch 3, Sample 12813: Loss: 0.2890\n",
            "Epoch 3, Sample 12814: Loss: 0.2032\n",
            "Epoch 3, Sample 12815: Loss: 0.8951\n",
            "Epoch 3, Sample 12816: Loss: 0.4032\n",
            "Epoch 3, Sample 12817: Loss: 1.0155\n",
            "Epoch 3, Sample 12818: Loss: 0.0205\n",
            "Epoch 3, Sample 12819: Loss: 0.0108\n",
            "Epoch 3, Sample 12820: Loss: 0.2074\n",
            "Epoch 3, Sample 12821: Loss: 0.0812\n",
            "Epoch 3, Sample 12822: Loss: 0.2032\n",
            "Epoch 3, Sample 12823: Loss: 0.1199\n",
            "Epoch 3, Sample 12824: Loss: 0.1508\n",
            "Epoch 3, Sample 12825: Loss: 0.0714\n",
            "Epoch 3, Sample 12826: Loss: 0.2340\n",
            "Epoch 3, Sample 12827: Loss: 0.2032\n",
            "Epoch 3, Sample 12828: Loss: 0.2832\n",
            "Epoch 3, Sample 12829: Loss: 0.5858\n",
            "Epoch 3, Sample 12830: Loss: 0.0026\n",
            "Epoch 3, Sample 12831: Loss: 0.3925\n",
            "Epoch 3, Sample 12832: Loss: 0.0004\n",
            "Epoch 3, Sample 12833: Loss: 0.0031\n",
            "Epoch 3, Sample 12834: Loss: 0.0026\n",
            "Epoch 3, Sample 12835: Loss: 0.2290\n",
            "Epoch 3, Sample 12836: Loss: 0.0324\n",
            "Epoch 3, Sample 12837: Loss: 1.0289\n",
            "Epoch 3, Sample 12838: Loss: 0.0280\n",
            "Epoch 3, Sample 12839: Loss: 0.3945\n",
            "Epoch 3, Sample 12840: Loss: 0.2935\n",
            "Epoch 3, Sample 12841: Loss: 0.5520\n",
            "Epoch 3, Sample 12842: Loss: 0.2833\n",
            "Epoch 3, Sample 12843: Loss: 0.2032\n",
            "Epoch 3, Sample 12844: Loss: 0.0026\n",
            "Epoch 3, Sample 12845: Loss: 0.7036\n",
            "Epoch 3, Sample 12846: Loss: 0.5972\n",
            "Epoch 3, Sample 12847: Loss: 0.1559\n",
            "Epoch 3, Sample 12848: Loss: 0.0391\n",
            "Epoch 3, Sample 12849: Loss: 0.0915\n",
            "Epoch 3, Sample 12850: Loss: 0.4032\n",
            "Epoch 3, Sample 12851: Loss: 0.0306\n",
            "Epoch 3, Sample 12852: Loss: 2.1572\n",
            "Epoch 3, Sample 12853: Loss: 0.0766\n",
            "Epoch 3, Sample 12854: Loss: 0.2044\n",
            "Epoch 3, Sample 12855: Loss: 0.3441\n",
            "Epoch 3, Sample 12856: Loss: 0.0380\n",
            "Epoch 3, Sample 12857: Loss: 0.2032\n",
            "Epoch 3, Sample 12858: Loss: 0.4996\n",
            "Epoch 3, Sample 12859: Loss: 0.1252\n",
            "Epoch 3, Sample 12860: Loss: 0.1087\n",
            "Epoch 3, Sample 12861: Loss: 0.0002\n",
            "Epoch 3, Sample 12862: Loss: 0.8951\n",
            "Epoch 3, Sample 12863: Loss: 0.1250\n",
            "Epoch 3, Sample 12864: Loss: 0.0212\n",
            "Epoch 3, Sample 12865: Loss: 0.0680\n",
            "Epoch 3, Sample 12866: Loss: 0.0013\n",
            "Epoch 3, Sample 12867: Loss: 0.2178\n",
            "Epoch 3, Sample 12868: Loss: 0.2935\n",
            "Epoch 3, Sample 12869: Loss: 0.1250\n",
            "Epoch 3, Sample 12870: Loss: 0.8951\n",
            "Epoch 3, Sample 12871: Loss: 0.0205\n",
            "Epoch 3, Sample 12872: Loss: 0.8951\n",
            "Epoch 3, Sample 12873: Loss: 0.2032\n",
            "Epoch 3, Sample 12874: Loss: 0.8961\n",
            "Epoch 3, Sample 12875: Loss: 0.0108\n",
            "Epoch 3, Sample 12876: Loss: 0.3949\n",
            "Epoch 3, Sample 12877: Loss: 2.2765\n",
            "Epoch 3, Sample 12878: Loss: 1.0259\n",
            "Epoch 3, Sample 12879: Loss: 6.6869\n",
            "Epoch 3, Sample 12880: Loss: 0.7453\n",
            "Epoch 3, Sample 12881: Loss: 0.0050\n",
            "Epoch 3, Sample 12882: Loss: 0.4032\n",
            "Epoch 3, Sample 12883: Loss: 0.2034\n",
            "Epoch 3, Sample 12884: Loss: 0.9367\n",
            "Epoch 3, Sample 12885: Loss: 0.1111\n",
            "Epoch 3, Sample 12886: Loss: 0.2044\n",
            "Epoch 3, Sample 12887: Loss: 1.0906\n",
            "Epoch 3, Sample 12888: Loss: 0.7453\n",
            "Epoch 3, Sample 12889: Loss: 0.2832\n",
            "Epoch 3, Sample 12890: Loss: 0.0201\n",
            "Epoch 3, Sample 12891: Loss: 0.5858\n",
            "Epoch 3, Sample 12892: Loss: 0.5989\n",
            "Epoch 3, Sample 12893: Loss: 1.0524\n",
            "Epoch 3, Sample 12894: Loss: 0.0838\n",
            "Epoch 3, Sample 12895: Loss: 0.5663\n",
            "Epoch 3, Sample 12896: Loss: 0.2832\n",
            "Epoch 3, Sample 12897: Loss: 0.0011\n",
            "Epoch 3, Sample 12898: Loss: 0.0052\n",
            "Epoch 3, Sample 12899: Loss: 0.1786\n",
            "Epoch 3, Sample 12900: Loss: 1.0524\n",
            "Epoch 3, Sample 12901: Loss: 0.0372\n",
            "Epoch 3, Sample 12902: Loss: 0.0205\n",
            "Epoch 3, Sample 12903: Loss: 0.0049\n",
            "Epoch 3, Sample 12904: Loss: 0.1482\n",
            "Epoch 3, Sample 12905: Loss: 0.5972\n",
            "Epoch 3, Sample 12906: Loss: 1.0266\n",
            "Epoch 3, Sample 12907: Loss: 0.1979\n",
            "Epoch 3, Sample 12908: Loss: 0.0531\n",
            "Epoch 3, Sample 12909: Loss: 0.0001\n",
            "Epoch 3, Sample 12910: Loss: 0.0215\n",
            "Epoch 3, Sample 12911: Loss: 0.3288\n",
            "Epoch 3, Sample 12912: Loss: 0.1349\n",
            "Epoch 3, Sample 12913: Loss: 0.0705\n",
            "Epoch 3, Sample 12914: Loss: 0.0438\n",
            "Epoch 3, Sample 12915: Loss: 0.1508\n",
            "Epoch 3, Sample 12916: Loss: 0.7036\n",
            "Epoch 3, Sample 12917: Loss: 0.0018\n",
            "Epoch 3, Sample 12918: Loss: 0.0498\n",
            "Epoch 3, Sample 12919: Loss: 0.3247\n",
            "Epoch 3, Sample 12920: Loss: 0.5972\n",
            "Epoch 3, Sample 12921: Loss: 0.2219\n",
            "Epoch 3, Sample 12922: Loss: 0.0472\n",
            "Epoch 3, Sample 12923: Loss: 0.0506\n",
            "Epoch 3, Sample 12924: Loss: 0.0048\n",
            "Epoch 3, Sample 12925: Loss: 0.6349\n",
            "Epoch 3, Sample 12926: Loss: 0.2759\n",
            "Epoch 3, Sample 12927: Loss: 0.6304\n",
            "Epoch 3, Sample 12928: Loss: 0.0287\n",
            "Epoch 3, Sample 12929: Loss: 0.1170\n",
            "Epoch 3, Sample 12930: Loss: 0.1559\n",
            "Epoch 3, Sample 12931: Loss: 0.0001\n",
            "Epoch 3, Sample 12932: Loss: 0.0001\n",
            "Epoch 3, Sample 12933: Loss: 0.2034\n",
            "Epoch 3, Sample 12934: Loss: 1.0155\n",
            "Epoch 3, Sample 12935: Loss: 0.1356\n",
            "Epoch 3, Sample 12936: Loss: 0.4027\n",
            "Epoch 3, Sample 12937: Loss: 0.1195\n",
            "Epoch 3, Sample 12938: Loss: 0.0626\n",
            "Epoch 3, Sample 12939: Loss: 0.1559\n",
            "Epoch 3, Sample 12940: Loss: 0.4607\n",
            "Epoch 3, Sample 12941: Loss: 0.1588\n",
            "Epoch 3, Sample 12942: Loss: 0.1523\n",
            "Epoch 3, Sample 12943: Loss: 0.4799\n",
            "Epoch 3, Sample 12944: Loss: 0.0229\n",
            "Epoch 3, Sample 12945: Loss: 0.0972\n",
            "Epoch 3, Sample 12946: Loss: 0.0589\n",
            "Epoch 3, Sample 12947: Loss: 0.2182\n",
            "Epoch 3, Sample 12948: Loss: 0.4611\n",
            "Epoch 3, Sample 12949: Loss: 0.0108\n",
            "Epoch 3, Sample 12950: Loss: 0.0018\n",
            "Epoch 3, Sample 12951: Loss: 0.0915\n",
            "Epoch 3, Sample 12952: Loss: 0.5858\n",
            "Epoch 3, Sample 12953: Loss: 0.5633\n",
            "Epoch 3, Sample 12954: Loss: 1.0155\n",
            "Epoch 3, Sample 12955: Loss: 0.2490\n",
            "Epoch 3, Sample 12956: Loss: 0.7726\n",
            "Epoch 3, Sample 12957: Loss: 0.0001\n",
            "Epoch 3, Sample 12958: Loss: 0.3441\n",
            "Epoch 3, Sample 12959: Loss: 0.0018\n",
            "Epoch 3, Sample 12960: Loss: 0.2032\n",
            "Epoch 3, Sample 12961: Loss: 0.8951\n",
            "Epoch 3, Sample 12962: Loss: 0.0270\n",
            "Epoch 3, Sample 12963: Loss: 7.6272\n",
            "Epoch 3, Sample 12964: Loss: 0.0728\n",
            "Epoch 3, Sample 12965: Loss: 0.2044\n",
            "Epoch 3, Sample 12966: Loss: 6.2304\n",
            "Epoch 3, Sample 12967: Loss: 0.0062\n",
            "Epoch 3, Sample 12968: Loss: 0.1250\n",
            "Epoch 3, Sample 12969: Loss: 0.0363\n",
            "Epoch 3, Sample 12970: Loss: 0.2032\n",
            "Epoch 3, Sample 12971: Loss: 0.6839\n",
            "Epoch 3, Sample 12972: Loss: 0.2044\n",
            "Epoch 3, Sample 12973: Loss: 0.5858\n",
            "Epoch 3, Sample 12974: Loss: 0.1643\n",
            "Epoch 3, Sample 12975: Loss: 0.4611\n",
            "Epoch 3, Sample 12976: Loss: 0.0287\n",
            "Epoch 3, Sample 12977: Loss: 1.0524\n",
            "Epoch 3, Sample 12978: Loss: 0.2750\n",
            "Epoch 3, Sample 12979: Loss: 0.1170\n",
            "Epoch 3, Sample 12980: Loss: 0.2044\n",
            "Epoch 3, Sample 12981: Loss: 0.6990\n",
            "Epoch 3, Sample 12982: Loss: 0.6408\n",
            "Epoch 3, Sample 12983: Loss: 0.5972\n",
            "Epoch 3, Sample 12984: Loss: 1.0524\n",
            "Epoch 3, Sample 12985: Loss: 0.1250\n",
            "Epoch 3, Sample 12986: Loss: 0.3495\n",
            "Epoch 3, Sample 12987: Loss: 0.0005\n",
            "Epoch 3, Sample 12988: Loss: 0.1687\n",
            "Epoch 3, Sample 12989: Loss: 0.2759\n",
            "Epoch 3, Sample 12990: Loss: 0.6720\n",
            "Epoch 3, Sample 12991: Loss: 0.1250\n",
            "Epoch 3, Sample 12992: Loss: 0.3399\n",
            "Epoch 3, Sample 12993: Loss: 0.2519\n",
            "Epoch 3, Sample 12994: Loss: 0.8090\n",
            "Epoch 3, Sample 12995: Loss: 1.3722\n",
            "Epoch 3, Sample 12996: Loss: 0.7036\n",
            "Epoch 3, Sample 12997: Loss: 0.0026\n",
            "Epoch 3, Sample 12998: Loss: 1.0524\n",
            "Epoch 3, Sample 12999: Loss: 0.0062\n",
            "Epoch 3, Sample 13000: Loss: 0.1559\n",
            "Epoch 3, Sample 13001: Loss: 0.2044\n",
            "Epoch 3, Sample 13002: Loss: 2.5415\n",
            "Epoch 3, Sample 13003: Loss: 1.0155\n",
            "Epoch 3, Sample 13004: Loss: 0.3618\n",
            "Epoch 3, Sample 13005: Loss: 0.0026\n",
            "Epoch 3, Sample 13006: Loss: 0.0026\n",
            "Epoch 3, Sample 13007: Loss: 0.8262\n",
            "Epoch 3, Sample 13008: Loss: 0.2686\n",
            "Epoch 3, Sample 13009: Loss: 1.0524\n",
            "Epoch 3, Sample 13010: Loss: 0.1523\n",
            "Epoch 3, Sample 13011: Loss: 0.0067\n",
            "Epoch 3, Sample 13012: Loss: 0.0574\n",
            "Epoch 3, Sample 13013: Loss: 1.0524\n",
            "Epoch 3, Sample 13014: Loss: 0.2034\n",
            "Epoch 3, Sample 13015: Loss: 0.3399\n",
            "Epoch 3, Sample 13016: Loss: 0.2036\n",
            "Epoch 3, Sample 13017: Loss: 0.0947\n",
            "Epoch 3, Sample 13018: Loss: 1.0524\n",
            "Epoch 3, Sample 13019: Loss: 2.0590\n",
            "Epoch 3, Sample 13020: Loss: 0.1993\n",
            "Epoch 3, Sample 13021: Loss: 0.0166\n",
            "Epoch 3, Sample 13022: Loss: 0.2044\n",
            "Epoch 3, Sample 13023: Loss: 0.2044\n",
            "Epoch 3, Sample 13024: Loss: 0.3477\n",
            "Epoch 3, Sample 13025: Loss: 0.8151\n",
            "Epoch 3, Sample 13026: Loss: 0.5871\n",
            "Epoch 3, Sample 13027: Loss: 1.0155\n",
            "Epoch 3, Sample 13028: Loss: 0.0455\n",
            "Epoch 3, Sample 13029: Loss: 1.0155\n",
            "Epoch 3, Sample 13030: Loss: 0.0455\n",
            "Epoch 3, Sample 13031: Loss: 1.0530\n",
            "Epoch 3, Sample 13032: Loss: 0.0077\n",
            "Epoch 3, Sample 13033: Loss: 0.7560\n",
            "Epoch 3, Sample 13034: Loss: 0.3399\n",
            "Epoch 3, Sample 13035: Loss: 0.3399\n",
            "Epoch 3, Sample 13036: Loss: 0.5858\n",
            "Epoch 3, Sample 13037: Loss: 0.3805\n",
            "Epoch 3, Sample 13038: Loss: 0.3949\n",
            "Epoch 3, Sample 13039: Loss: 0.7036\n",
            "Epoch 3, Sample 13040: Loss: 0.2034\n",
            "Epoch 3, Sample 13041: Loss: 0.4845\n",
            "Epoch 3, Sample 13042: Loss: 1.0524\n",
            "Epoch 3, Sample 13043: Loss: 1.3758\n",
            "Epoch 3, Sample 13044: Loss: 0.0288\n",
            "Epoch 3, Sample 13045: Loss: 0.5871\n",
            "Epoch 3, Sample 13046: Loss: 0.7010\n",
            "Epoch 3, Sample 13047: Loss: 0.0285\n",
            "Epoch 3, Sample 13048: Loss: 0.0630\n",
            "Epoch 3, Sample 13049: Loss: 0.0165\n",
            "Epoch 3, Sample 13050: Loss: 0.2036\n",
            "Epoch 3, Sample 13051: Loss: 0.0000\n",
            "Epoch 3, Sample 13052: Loss: 0.0002\n",
            "Epoch 3, Sample 13053: Loss: 0.2034\n",
            "Epoch 3, Sample 13054: Loss: 0.2832\n",
            "Epoch 3, Sample 13055: Loss: 0.1246\n",
            "Epoch 3, Sample 13056: Loss: 0.1170\n",
            "Epoch 3, Sample 13057: Loss: 0.3441\n",
            "Epoch 3, Sample 13058: Loss: 0.0395\n",
            "Epoch 3, Sample 13059: Loss: 0.7036\n",
            "Epoch 3, Sample 13060: Loss: 0.2759\n",
            "Epoch 3, Sample 13061: Loss: 0.5858\n",
            "Epoch 3, Sample 13062: Loss: 1.0155\n",
            "Epoch 3, Sample 13063: Loss: 0.3949\n",
            "Epoch 3, Sample 13064: Loss: 1.0524\n",
            "Epoch 3, Sample 13065: Loss: 0.5310\n",
            "Epoch 3, Sample 13066: Loss: 0.6058\n",
            "Epoch 3, Sample 13067: Loss: 0.0630\n",
            "Epoch 3, Sample 13068: Loss: 0.3949\n",
            "Epoch 3, Sample 13069: Loss: 0.7036\n",
            "Epoch 3, Sample 13070: Loss: 0.2034\n",
            "Epoch 3, Sample 13071: Loss: 0.0823\n",
            "Epoch 3, Sample 13072: Loss: 0.3399\n",
            "Epoch 3, Sample 13073: Loss: 0.1741\n",
            "Epoch 3, Sample 13074: Loss: 1.0524\n",
            "Epoch 3, Sample 13075: Loss: 0.0205\n",
            "Epoch 3, Sample 13076: Loss: 0.2034\n",
            "Epoch 3, Sample 13077: Loss: 0.7036\n",
            "Epoch 3, Sample 13078: Loss: 0.3450\n",
            "Epoch 3, Sample 13079: Loss: 0.5000\n",
            "Epoch 3, Sample 13080: Loss: 0.6092\n",
            "Epoch 3, Sample 13081: Loss: 0.8280\n",
            "Epoch 3, Sample 13082: Loss: 0.0013\n",
            "Epoch 3, Sample 13083: Loss: 0.6990\n",
            "Epoch 3, Sample 13084: Loss: 0.2044\n",
            "Epoch 3, Sample 13085: Loss: 0.1920\n",
            "Epoch 3, Sample 13086: Loss: 0.5062\n",
            "Epoch 3, Sample 13087: Loss: 0.9651\n",
            "Epoch 3, Sample 13088: Loss: 0.6990\n",
            "Epoch 3, Sample 13089: Loss: 0.7453\n",
            "Epoch 3, Sample 13090: Loss: 0.8528\n",
            "Epoch 3, Sample 13091: Loss: 1.5542\n",
            "Epoch 3, Sample 13092: Loss: 0.1250\n",
            "Epoch 3, Sample 13093: Loss: 0.3399\n",
            "Epoch 3, Sample 13094: Loss: 0.0630\n",
            "Epoch 3, Sample 13095: Loss: 0.2114\n",
            "Epoch 3, Sample 13096: Loss: 0.6867\n",
            "Epoch 3, Sample 13097: Loss: 0.0108\n",
            "Epoch 3, Sample 13098: Loss: 0.5871\n",
            "Epoch 3, Sample 13099: Loss: 0.1248\n",
            "Epoch 3, Sample 13100: Loss: 1.5383\n",
            "Epoch 3, Sample 13101: Loss: 0.4558\n",
            "Epoch 3, Sample 13102: Loss: 0.5871\n",
            "Epoch 3, Sample 13103: Loss: 1.0530\n",
            "Epoch 3, Sample 13104: Loss: 0.0108\n",
            "Epoch 3, Sample 13105: Loss: 0.2044\n",
            "Epoch 3, Sample 13106: Loss: 0.1250\n",
            "Epoch 3, Sample 13107: Loss: 0.2034\n",
            "Epoch 3, Sample 13108: Loss: 0.7036\n",
            "Epoch 3, Sample 13109: Loss: 0.0207\n",
            "Epoch 3, Sample 13110: Loss: 0.2128\n",
            "Epoch 3, Sample 13111: Loss: 3.8754\n",
            "Epoch 3, Sample 13112: Loss: 0.4930\n",
            "Epoch 3, Sample 13113: Loss: 0.0707\n",
            "Epoch 3, Sample 13114: Loss: 0.6981\n",
            "Epoch 3, Sample 13115: Loss: 0.0915\n",
            "Epoch 3, Sample 13116: Loss: 0.0234\n",
            "Epoch 3, Sample 13117: Loss: 0.6990\n",
            "Epoch 3, Sample 13118: Loss: 1.0530\n",
            "Epoch 3, Sample 13119: Loss: 0.9367\n",
            "Epoch 3, Sample 13120: Loss: 0.9937\n",
            "Epoch 3, Sample 13121: Loss: 0.2044\n",
            "Epoch 3, Sample 13122: Loss: 1.2863\n",
            "Epoch 3, Sample 13123: Loss: 0.7453\n",
            "Epoch 3, Sample 13124: Loss: 0.1588\n",
            "Epoch 3, Sample 13125: Loss: 0.1170\n",
            "Epoch 3, Sample 13126: Loss: 0.1114\n",
            "Epoch 3, Sample 13127: Loss: 1.0649\n",
            "Epoch 3, Sample 13128: Loss: 0.2034\n",
            "Epoch 3, Sample 13129: Loss: 0.2034\n",
            "Epoch 3, Sample 13130: Loss: 0.4032\n",
            "Epoch 3, Sample 13131: Loss: 1.0524\n",
            "Epoch 3, Sample 13132: Loss: 0.0270\n",
            "Epoch 3, Sample 13133: Loss: 0.0026\n",
            "Epoch 3, Sample 13134: Loss: 2.8292\n",
            "Epoch 3, Sample 13135: Loss: 0.1250\n",
            "Epoch 3, Sample 13136: Loss: 0.2227\n",
            "Epoch 3, Sample 13137: Loss: 0.2639\n",
            "Epoch 3, Sample 13138: Loss: 0.3399\n",
            "Epoch 3, Sample 13139: Loss: 0.1774\n",
            "Epoch 3, Sample 13140: Loss: 0.0498\n",
            "Epoch 3, Sample 13141: Loss: 0.7453\n",
            "Epoch 3, Sample 13142: Loss: 0.0117\n",
            "Epoch 3, Sample 13143: Loss: 0.4739\n",
            "Epoch 3, Sample 13144: Loss: 0.2494\n",
            "Epoch 3, Sample 13145: Loss: 0.2044\n",
            "Epoch 3, Sample 13146: Loss: 0.1372\n",
            "Epoch 3, Sample 13147: Loss: 0.0425\n",
            "Epoch 3, Sample 13148: Loss: 0.5858\n",
            "Epoch 3, Sample 13149: Loss: 1.0155\n",
            "Epoch 3, Sample 13150: Loss: 0.0018\n",
            "Epoch 3, Sample 13151: Loss: 0.3399\n",
            "Epoch 3, Sample 13152: Loss: 0.0001\n",
            "Epoch 3, Sample 13153: Loss: 0.0001\n",
            "Epoch 3, Sample 13154: Loss: 0.0000\n",
            "Epoch 3, Sample 13155: Loss: 0.8951\n",
            "Epoch 3, Sample 13156: Loss: 6.2712\n",
            "Epoch 3, Sample 13157: Loss: 0.0021\n",
            "Epoch 3, Sample 13158: Loss: 0.0649\n",
            "Epoch 3, Sample 13159: Loss: 0.0122\n",
            "Epoch 3, Sample 13160: Loss: 0.2759\n",
            "Epoch 3, Sample 13161: Loss: 0.1913\n",
            "Epoch 3, Sample 13162: Loss: 0.1250\n",
            "Epoch 3, Sample 13163: Loss: 1.8616\n",
            "Epoch 3, Sample 13164: Loss: 0.2036\n",
            "Epoch 3, Sample 13165: Loss: 0.1250\n",
            "Epoch 3, Sample 13166: Loss: 0.0303\n",
            "Epoch 3, Sample 13167: Loss: 0.0229\n",
            "Epoch 3, Sample 13168: Loss: 0.3285\n",
            "Epoch 3, Sample 13169: Loss: 0.1625\n",
            "Epoch 3, Sample 13170: Loss: 0.3539\n",
            "Epoch 3, Sample 13171: Loss: 0.7036\n",
            "Epoch 3, Sample 13172: Loss: 0.0026\n",
            "Epoch 3, Sample 13173: Loss: 0.0000\n",
            "Epoch 3, Sample 13174: Loss: 0.6223\n",
            "Epoch 3, Sample 13175: Loss: 0.1170\n",
            "Epoch 3, Sample 13176: Loss: 1.0155\n",
            "Epoch 3, Sample 13177: Loss: 1.2983\n",
            "Epoch 3, Sample 13178: Loss: 2.7113\n",
            "Epoch 3, Sample 13179: Loss: 0.0625\n",
            "Epoch 3, Sample 13180: Loss: 0.1170\n",
            "Epoch 3, Sample 13181: Loss: 0.0026\n",
            "Epoch 3, Sample 13182: Loss: 0.1838\n",
            "Epoch 3, Sample 13183: Loss: 0.6990\n",
            "Epoch 3, Sample 13184: Loss: 0.3441\n",
            "Epoch 3, Sample 13185: Loss: 0.0026\n",
            "Epoch 3, Sample 13186: Loss: 0.2160\n",
            "Epoch 3, Sample 13187: Loss: 0.5743\n",
            "Epoch 3, Sample 13188: Loss: 0.0438\n",
            "Epoch 3, Sample 13189: Loss: 0.7036\n",
            "Epoch 3, Sample 13190: Loss: 1.0524\n",
            "Epoch 3, Sample 13191: Loss: 0.0117\n",
            "Epoch 3, Sample 13192: Loss: 0.0006\n",
            "Epoch 3, Sample 13193: Loss: 1.0530\n",
            "Epoch 3, Sample 13194: Loss: 1.0530\n",
            "Epoch 3, Sample 13195: Loss: 0.5000\n",
            "Epoch 3, Sample 13196: Loss: 2.2710\n",
            "Epoch 3, Sample 13197: Loss: 0.4607\n",
            "Epoch 3, Sample 13198: Loss: 0.0640\n",
            "Epoch 3, Sample 13199: Loss: 1.0524\n",
            "Epoch 3, Sample 13200: Loss: 0.0062\n",
            "Epoch 3, Sample 13201: Loss: 1.0530\n",
            "Epoch 3, Sample 13202: Loss: 0.2832\n",
            "Epoch 3, Sample 13203: Loss: 0.0630\n",
            "Epoch 3, Sample 13204: Loss: 0.0110\n",
            "Epoch 3, Sample 13205: Loss: 0.1838\n",
            "Epoch 3, Sample 13206: Loss: 0.3568\n",
            "Epoch 3, Sample 13207: Loss: 0.0077\n",
            "Epoch 3, Sample 13208: Loss: 0.2044\n",
            "Epoch 3, Sample 13209: Loss: 0.2032\n",
            "Epoch 3, Sample 13210: Loss: 6.7167\n",
            "Epoch 3, Sample 13211: Loss: 0.0438\n",
            "Epoch 3, Sample 13212: Loss: 0.0582\n",
            "Epoch 3, Sample 13213: Loss: 0.1721\n",
            "Epoch 3, Sample 13214: Loss: 1.0155\n",
            "Epoch 3, Sample 13215: Loss: 1.3842\n",
            "Epoch 3, Sample 13216: Loss: 0.3370\n",
            "Epoch 3, Sample 13217: Loss: 0.4528\n",
            "Epoch 3, Sample 13218: Loss: 0.7453\n",
            "Epoch 3, Sample 13219: Loss: 0.2003\n",
            "Epoch 3, Sample 13220: Loss: 0.0026\n",
            "Epoch 3, Sample 13221: Loss: 1.0524\n",
            "Epoch 3, Sample 13222: Loss: 5.9530\n",
            "Epoch 3, Sample 13223: Loss: 0.2219\n",
            "Epoch 3, Sample 13224: Loss: 0.0026\n",
            "Epoch 3, Sample 13225: Loss: 0.0212\n",
            "Epoch 3, Sample 13226: Loss: 0.0026\n",
            "Epoch 3, Sample 13227: Loss: 0.7036\n",
            "Epoch 3, Sample 13228: Loss: 1.0482\n",
            "Epoch 3, Sample 13229: Loss: 0.3598\n",
            "Epoch 3, Sample 13230: Loss: 0.0046\n",
            "Epoch 3, Sample 13231: Loss: 0.2639\n",
            "Epoch 3, Sample 13232: Loss: 1.0155\n",
            "Epoch 3, Sample 13233: Loss: 3.9678\n",
            "Epoch 3, Sample 13234: Loss: 0.0001\n",
            "Epoch 3, Sample 13235: Loss: 0.2032\n",
            "Epoch 3, Sample 13236: Loss: 0.0915\n",
            "Epoch 3, Sample 13237: Loss: 0.6092\n",
            "Epoch 3, Sample 13238: Loss: 7.5523\n",
            "Epoch 3, Sample 13239: Loss: 0.1114\n",
            "Epoch 3, Sample 13240: Loss: 6.9441\n",
            "Epoch 3, Sample 13241: Loss: 0.0026\n",
            "Epoch 3, Sample 13242: Loss: 0.0018\n",
            "Epoch 3, Sample 13243: Loss: 0.2044\n",
            "Epoch 3, Sample 13244: Loss: 0.4615\n",
            "Epoch 3, Sample 13245: Loss: 0.1783\n",
            "Epoch 3, Sample 13246: Loss: 0.1559\n",
            "Epoch 3, Sample 13247: Loss: 0.1559\n",
            "Epoch 3, Sample 13248: Loss: 0.5321\n",
            "Epoch 3, Sample 13249: Loss: 0.1250\n",
            "Epoch 3, Sample 13250: Loss: 0.0001\n",
            "Epoch 3, Sample 13251: Loss: 1.0524\n",
            "Epoch 3, Sample 13252: Loss: 4.8322\n",
            "Epoch 3, Sample 13253: Loss: 1.4282\n",
            "Epoch 3, Sample 13254: Loss: 0.7019\n",
            "Epoch 3, Sample 13255: Loss: 0.3399\n",
            "Epoch 3, Sample 13256: Loss: 0.2483\n",
            "Epoch 3, Sample 13257: Loss: 0.1248\n",
            "Epoch 3, Sample 13258: Loss: 0.0915\n",
            "Epoch 3, Sample 13259: Loss: 0.4841\n",
            "Epoch 3, Sample 13260: Loss: 1.0524\n",
            "Epoch 3, Sample 13261: Loss: 0.0026\n",
            "Epoch 3, Sample 13262: Loss: 0.4032\n",
            "Epoch 3, Sample 13263: Loss: 0.3399\n",
            "Epoch 3, Sample 13264: Loss: 0.4611\n",
            "Epoch 3, Sample 13265: Loss: 0.0000\n",
            "Epoch 3, Sample 13266: Loss: 3.8107\n",
            "Epoch 3, Sample 13267: Loss: 0.1114\n",
            "Epoch 3, Sample 13268: Loss: 0.3450\n",
            "Epoch 3, Sample 13269: Loss: 0.5858\n",
            "Epoch 3, Sample 13270: Loss: 0.0000\n",
            "Epoch 3, Sample 13271: Loss: 0.2759\n",
            "Epoch 3, Sample 13272: Loss: 0.1000\n",
            "Epoch 3, Sample 13273: Loss: 0.2759\n",
            "Epoch 3, Sample 13274: Loss: 0.1559\n",
            "Epoch 3, Sample 13275: Loss: 1.0524\n",
            "Epoch 3, Sample 13276: Loss: 0.2603\n",
            "Epoch 3, Sample 13277: Loss: 0.0364\n",
            "Epoch 3, Sample 13278: Loss: 0.3450\n",
            "Epoch 3, Sample 13279: Loss: 1.1569\n",
            "Epoch 3, Sample 13280: Loss: 0.0787\n",
            "Epoch 3, Sample 13281: Loss: 1.0524\n",
            "Epoch 3, Sample 13282: Loss: 0.2759\n",
            "Epoch 3, Sample 13283: Loss: 0.3399\n",
            "Epoch 3, Sample 13284: Loss: 0.6139\n",
            "Epoch 3, Sample 13285: Loss: 1.0155\n",
            "Epoch 3, Sample 13286: Loss: 0.0486\n",
            "Epoch 3, Sample 13287: Loss: 0.3399\n",
            "Epoch 3, Sample 13288: Loss: 0.1687\n",
            "Epoch 3, Sample 13289: Loss: 0.0026\n",
            "Epoch 3, Sample 13290: Loss: 0.2219\n",
            "Epoch 3, Sample 13291: Loss: 1.0524\n",
            "Epoch 3, Sample 13292: Loss: 0.1250\n",
            "Epoch 3, Sample 13293: Loss: 0.2558\n",
            "Epoch 3, Sample 13294: Loss: 0.4906\n",
            "Epoch 3, Sample 13295: Loss: 0.5858\n",
            "Epoch 3, Sample 13296: Loss: 0.3399\n",
            "Epoch 3, Sample 13297: Loss: 0.0833\n",
            "Epoch 3, Sample 13298: Loss: 0.5858\n",
            "Epoch 3, Sample 13299: Loss: 0.0108\n",
            "Epoch 3, Sample 13300: Loss: 0.2639\n",
            "Epoch 3, Sample 13301: Loss: 0.2941\n",
            "Epoch 3, Sample 13302: Loss: 0.2044\n",
            "Epoch 3, Sample 13303: Loss: 0.0018\n",
            "Epoch 3, Sample 13304: Loss: 0.4799\n",
            "Epoch 3, Sample 13305: Loss: 0.1791\n",
            "Epoch 3, Sample 13306: Loss: 0.2935\n",
            "Epoch 3, Sample 13307: Loss: 0.0505\n",
            "Epoch 3, Sample 13308: Loss: 0.8951\n",
            "Epoch 3, Sample 13309: Loss: 0.5427\n",
            "Epoch 3, Sample 13310: Loss: 0.7071\n",
            "Epoch 3, Sample 13311: Loss: 1.1218\n",
            "Epoch 3, Sample 13312: Loss: 1.0070\n",
            "Epoch 3, Sample 13313: Loss: 0.2044\n",
            "Epoch 3, Sample 13314: Loss: 0.2044\n",
            "Epoch 3, Sample 13315: Loss: 0.2044\n",
            "Epoch 3, Sample 13316: Loss: 0.3166\n",
            "Epoch 3, Sample 13317: Loss: 1.7449\n",
            "Epoch 3, Sample 13318: Loss: 0.0001\n",
            "Epoch 3, Sample 13319: Loss: 0.4930\n",
            "Epoch 3, Sample 13320: Loss: 0.0126\n",
            "Epoch 3, Sample 13321: Loss: 4.5318\n",
            "Epoch 3, Sample 13322: Loss: 2.5980\n",
            "Epoch 3, Sample 13323: Loss: 10.4593\n",
            "Epoch 3, Sample 13324: Loss: 1.0524\n",
            "Epoch 3, Sample 13325: Loss: 0.7036\n",
            "Epoch 3, Sample 13326: Loss: 0.3357\n",
            "Epoch 3, Sample 13327: Loss: 0.0026\n",
            "Epoch 3, Sample 13328: Loss: 0.0205\n",
            "Epoch 3, Sample 13329: Loss: 0.1729\n",
            "Epoch 3, Sample 13330: Loss: 0.0235\n",
            "Epoch 3, Sample 13331: Loss: 6.5695\n",
            "Epoch 3, Sample 13332: Loss: 0.3949\n",
            "Epoch 3, Sample 13333: Loss: 0.2759\n",
            "Epoch 3, Sample 13334: Loss: 1.0530\n",
            "Epoch 3, Sample 13335: Loss: 0.0018\n",
            "Epoch 3, Sample 13336: Loss: 0.0199\n",
            "Epoch 3, Sample 13337: Loss: 0.8951\n",
            "Epoch 3, Sample 13338: Loss: 1.0155\n",
            "Epoch 3, Sample 13339: Loss: 0.0018\n",
            "Epoch 3, Sample 13340: Loss: 0.2034\n",
            "Epoch 3, Sample 13341: Loss: 0.2832\n",
            "Epoch 3, Sample 13342: Loss: 6.0343\n",
            "Epoch 3, Sample 13343: Loss: 0.6403\n",
            "Epoch 3, Sample 13344: Loss: 1.3239\n",
            "Epoch 3, Sample 13345: Loss: 1.0524\n",
            "Epoch 3, Sample 13346: Loss: 0.6990\n",
            "Epoch 3, Sample 13347: Loss: 3.6632\n",
            "Epoch 3, Sample 13348: Loss: 0.6240\n",
            "Epoch 3, Sample 13349: Loss: 0.0709\n",
            "Epoch 3, Sample 13350: Loss: 0.3441\n",
            "Epoch 3, Sample 13351: Loss: 0.3399\n",
            "Epoch 3, Sample 13352: Loss: 1.0530\n",
            "Epoch 3, Sample 13353: Loss: 0.2713\n",
            "Epoch 3, Sample 13354: Loss: 0.4175\n",
            "Epoch 3, Sample 13355: Loss: 2.9652\n",
            "Epoch 3, Sample 13356: Loss: 1.7368\n",
            "Epoch 3, Sample 13357: Loss: 0.0060\n",
            "Epoch 3, Sample 13358: Loss: 1.3653\n",
            "Epoch 3, Sample 13359: Loss: 0.0726\n",
            "Epoch 3, Sample 13360: Loss: 0.2036\n",
            "Epoch 3, Sample 13361: Loss: 0.5972\n",
            "Epoch 3, Sample 13362: Loss: 0.0018\n",
            "Epoch 3, Sample 13363: Loss: 0.0838\n",
            "Epoch 3, Sample 13364: Loss: 0.1170\n",
            "Epoch 3, Sample 13365: Loss: 0.5858\n",
            "Epoch 3, Sample 13366: Loss: 0.3441\n",
            "Epoch 3, Sample 13367: Loss: 1.0524\n",
            "Epoch 3, Sample 13368: Loss: 0.2759\n",
            "Epoch 3, Sample 13369: Loss: 0.0026\n",
            "Epoch 3, Sample 13370: Loss: 0.5382\n",
            "Epoch 3, Sample 13371: Loss: 1.0124\n",
            "Epoch 3, Sample 13372: Loss: 0.3441\n",
            "Epoch 3, Sample 13373: Loss: 0.2201\n",
            "Epoch 3, Sample 13374: Loss: 0.0630\n",
            "Epoch 3, Sample 13375: Loss: 0.2044\n",
            "Epoch 3, Sample 13376: Loss: 0.0212\n",
            "Epoch 3, Sample 13377: Loss: 0.0026\n",
            "Epoch 3, Sample 13378: Loss: 0.0539\n",
            "Epoch 3, Sample 13379: Loss: 0.3399\n",
            "Epoch 3, Sample 13380: Loss: 0.0108\n",
            "Epoch 3, Sample 13381: Loss: 0.3367\n",
            "Epoch 3, Sample 13382: Loss: 0.7036\n",
            "Epoch 3, Sample 13383: Loss: 0.2044\n",
            "Epoch 3, Sample 13384: Loss: 0.0168\n",
            "Epoch 3, Sample 13385: Loss: 0.4799\n",
            "Epoch 3, Sample 13386: Loss: 0.0401\n",
            "Epoch 3, Sample 13387: Loss: 0.0005\n",
            "Epoch 3, Sample 13388: Loss: 0.0025\n",
            "Epoch 3, Sample 13389: Loss: 0.0640\n",
            "Epoch 3, Sample 13390: Loss: 0.0148\n",
            "Epoch 3, Sample 13391: Loss: 0.3441\n",
            "Epoch 3, Sample 13392: Loss: 0.3399\n",
            "Epoch 3, Sample 13393: Loss: 0.2811\n",
            "Epoch 3, Sample 13394: Loss: 1.0674\n",
            "Epoch 3, Sample 13395: Loss: 0.3949\n",
            "Epoch 3, Sample 13396: Loss: 2.6607\n",
            "Epoch 3, Sample 13397: Loss: 0.3506\n",
            "Epoch 3, Sample 13398: Loss: 0.0021\n",
            "Epoch 3, Sample 13399: Loss: 1.1884\n",
            "Epoch 3, Sample 13400: Loss: 0.9367\n",
            "Epoch 3, Sample 13401: Loss: 2.2763\n",
            "Epoch 3, Sample 13402: Loss: 0.2759\n",
            "Epoch 3, Sample 13403: Loss: 0.3399\n",
            "Epoch 3, Sample 13404: Loss: 0.2981\n",
            "Epoch 3, Sample 13405: Loss: 1.5850\n",
            "Epoch 3, Sample 13406: Loss: 0.2788\n",
            "Epoch 3, Sample 13407: Loss: 0.7036\n",
            "Epoch 3, Sample 13408: Loss: 1.0530\n",
            "Epoch 3, Sample 13409: Loss: 0.3399\n",
            "Epoch 3, Sample 13410: Loss: 0.0303\n",
            "Epoch 3, Sample 13411: Loss: 0.0018\n",
            "Epoch 3, Sample 13412: Loss: 0.1523\n",
            "Epoch 3, Sample 13413: Loss: 0.2044\n",
            "Epoch 3, Sample 13414: Loss: 1.0530\n",
            "Epoch 3, Sample 13415: Loss: 0.2832\n",
            "Epoch 3, Sample 13416: Loss: 1.0530\n",
            "Epoch 3, Sample 13417: Loss: 0.3399\n",
            "Epoch 3, Sample 13418: Loss: 0.2962\n",
            "Epoch 3, Sample 13419: Loss: 0.8211\n",
            "Epoch 3, Sample 13420: Loss: 1.2326\n",
            "Epoch 3, Sample 13421: Loss: 0.1559\n",
            "Epoch 3, Sample 13422: Loss: 1.0155\n",
            "Epoch 3, Sample 13423: Loss: 0.3598\n",
            "Epoch 3, Sample 13424: Loss: 1.0524\n",
            "Epoch 3, Sample 13425: Loss: 0.2483\n",
            "Epoch 3, Sample 13426: Loss: 1.0155\n",
            "Epoch 3, Sample 13427: Loss: 0.4121\n",
            "Epoch 3, Sample 13428: Loss: 0.8760\n",
            "Epoch 3, Sample 13429: Loss: 1.5542\n",
            "Epoch 3, Sample 13430: Loss: 0.1372\n",
            "Epoch 3, Sample 13431: Loss: 0.0018\n",
            "Epoch 3, Sample 13432: Loss: 0.0018\n",
            "Epoch 3, Sample 13433: Loss: 0.2340\n",
            "Epoch 3, Sample 13434: Loss: 3.0659\n",
            "Epoch 3, Sample 13435: Loss: 0.0000\n",
            "Epoch 3, Sample 13436: Loss: 0.1091\n",
            "Epoch 3, Sample 13437: Loss: 0.2034\n",
            "Epoch 3, Sample 13438: Loss: 0.3341\n",
            "Epoch 3, Sample 13439: Loss: 0.0055\n",
            "Epoch 3, Sample 13440: Loss: 2.8708\n",
            "Epoch 3, Sample 13441: Loss: 0.7036\n",
            "Epoch 3, Sample 13442: Loss: 0.3399\n",
            "Epoch 3, Sample 13443: Loss: 1.0524\n",
            "Epoch 3, Sample 13444: Loss: 0.3399\n",
            "Epoch 3, Sample 13445: Loss: 0.0026\n",
            "Epoch 3, Sample 13446: Loss: 0.1080\n",
            "Epoch 3, Sample 13447: Loss: 0.6876\n",
            "Epoch 3, Sample 13448: Loss: 0.0062\n",
            "Epoch 3, Sample 13449: Loss: 0.0117\n",
            "Epoch 3, Sample 13450: Loss: 0.1326\n",
            "Epoch 3, Sample 13451: Loss: 0.2219\n",
            "Epoch 3, Sample 13452: Loss: 0.7036\n",
            "Epoch 3, Sample 13453: Loss: 3.2025\n",
            "Epoch 3, Sample 13454: Loss: 0.2639\n",
            "Epoch 3, Sample 13455: Loss: 0.0630\n",
            "Epoch 3, Sample 13456: Loss: 0.4117\n",
            "Epoch 3, Sample 13457: Loss: 0.0429\n",
            "Epoch 3, Sample 13458: Loss: 2.2809\n",
            "Epoch 3, Sample 13459: Loss: 0.0381\n",
            "Epoch 3, Sample 13460: Loss: 0.0205\n",
            "Epoch 3, Sample 13461: Loss: 2.3826\n",
            "Epoch 3, Sample 13462: Loss: 0.7036\n",
            "Epoch 3, Sample 13463: Loss: 4.5516\n",
            "Epoch 3, Sample 13464: Loss: 0.7036\n",
            "Epoch 3, Sample 13465: Loss: 0.1252\n",
            "Epoch 3, Sample 13466: Loss: 0.3425\n",
            "Epoch 3, Sample 13467: Loss: 0.0915\n",
            "Epoch 3, Sample 13468: Loss: 0.3399\n",
            "Epoch 3, Sample 13469: Loss: 0.0018\n",
            "Epoch 3, Sample 13470: Loss: 0.1577\n",
            "Epoch 3, Sample 13471: Loss: 1.0549\n",
            "Epoch 3, Sample 13472: Loss: 0.4930\n",
            "Epoch 3, Sample 13473: Loss: 0.0103\n",
            "Epoch 3, Sample 13474: Loss: 0.0000\n",
            "Epoch 3, Sample 13475: Loss: 0.0026\n",
            "Epoch 3, Sample 13476: Loss: 0.3126\n",
            "Epoch 3, Sample 13477: Loss: 0.3260\n",
            "Epoch 3, Sample 13478: Loss: 1.0524\n",
            "Epoch 3, Sample 13479: Loss: 0.6990\n",
            "Epoch 3, Sample 13480: Loss: 0.3399\n",
            "Epoch 3, Sample 13481: Loss: 0.7036\n",
            "Epoch 3, Sample 13482: Loss: 0.0306\n",
            "Epoch 3, Sample 13483: Loss: 0.3399\n",
            "Epoch 3, Sample 13484: Loss: 0.0838\n",
            "Epoch 3, Sample 13485: Loss: 0.7036\n",
            "Epoch 3, Sample 13486: Loss: 0.5258\n",
            "Epoch 3, Sample 13487: Loss: 0.2664\n",
            "Epoch 3, Sample 13488: Loss: 0.0099\n",
            "Epoch 3, Sample 13489: Loss: 0.1989\n",
            "Epoch 3, Sample 13490: Loss: 2.3161\n",
            "Epoch 3, Sample 13491: Loss: 1.0155\n",
            "Epoch 3, Sample 13492: Loss: 0.2044\n",
            "Epoch 3, Sample 13493: Loss: 0.2759\n",
            "Epoch 3, Sample 13494: Loss: 0.4136\n",
            "Epoch 3, Sample 13495: Loss: 0.2759\n",
            "Epoch 3, Sample 13496: Loss: 10.6128\n",
            "Epoch 3, Sample 13497: Loss: 0.1170\n",
            "Epoch 3, Sample 13498: Loss: 0.9367\n",
            "Epoch 3, Sample 13499: Loss: 0.0013\n",
            "Epoch 3, Sample 13500: Loss: 0.2044\n",
            "Epoch 3, Sample 13501: Loss: 0.2032\n",
            "Epoch 3, Sample 13502: Loss: 0.6137\n",
            "Epoch 3, Sample 13503: Loss: 0.2044\n",
            "Epoch 3, Sample 13504: Loss: 0.1337\n",
            "Epoch 3, Sample 13505: Loss: 0.2219\n",
            "Epoch 3, Sample 13506: Loss: 0.1250\n",
            "Epoch 3, Sample 13507: Loss: 0.1559\n",
            "Epoch 3, Sample 13508: Loss: 0.6990\n",
            "Epoch 3, Sample 13509: Loss: 0.3441\n",
            "Epoch 3, Sample 13510: Loss: 0.4663\n",
            "Epoch 3, Sample 13511: Loss: 0.2568\n",
            "Epoch 3, Sample 13512: Loss: 0.4799\n",
            "Epoch 3, Sample 13513: Loss: 1.0524\n",
            "Epoch 3, Sample 13514: Loss: 0.2034\n",
            "Epoch 3, Sample 13515: Loss: 0.4930\n",
            "Epoch 3, Sample 13516: Loss: 0.0723\n",
            "Epoch 3, Sample 13517: Loss: 0.4930\n",
            "Epoch 3, Sample 13518: Loss: 0.5695\n",
            "Epoch 3, Sample 13519: Loss: 0.0001\n",
            "Epoch 3, Sample 13520: Loss: 0.0630\n",
            "Epoch 3, Sample 13521: Loss: 0.0212\n",
            "Epoch 3, Sample 13522: Loss: 0.2704\n",
            "Epoch 3, Sample 13523: Loss: 0.5062\n",
            "Epoch 3, Sample 13524: Loss: 4.8067\n",
            "Epoch 3, Sample 13525: Loss: 0.0026\n",
            "Epoch 3, Sample 13526: Loss: 0.1265\n",
            "Epoch 3, Sample 13527: Loss: 0.3949\n",
            "Epoch 3, Sample 13528: Loss: 0.2044\n",
            "Epoch 3, Sample 13529: Loss: 0.3626\n",
            "Epoch 3, Sample 13530: Loss: 0.0018\n",
            "Epoch 3, Sample 13531: Loss: 0.7036\n",
            "Epoch 3, Sample 13532: Loss: 0.5655\n",
            "Epoch 3, Sample 13533: Loss: 0.1248\n",
            "Epoch 3, Sample 13534: Loss: 0.5858\n",
            "Epoch 3, Sample 13535: Loss: 0.0460\n",
            "Epoch 3, Sample 13536: Loss: 0.4799\n",
            "Epoch 3, Sample 13537: Loss: 0.6990\n",
            "Epoch 3, Sample 13538: Loss: 0.0384\n",
            "Epoch 3, Sample 13539: Loss: 0.5871\n",
            "Epoch 3, Sample 13540: Loss: 0.0234\n",
            "Epoch 3, Sample 13541: Loss: 0.0875\n",
            "Epoch 3, Sample 13542: Loss: 0.0258\n",
            "Epoch 3, Sample 13543: Loss: 0.2558\n",
            "Epoch 3, Sample 13544: Loss: 3.1997\n",
            "Epoch 3, Sample 13545: Loss: 1.0524\n",
            "Epoch 3, Sample 13546: Loss: 0.3758\n",
            "Epoch 3, Sample 13547: Loss: 1.0530\n",
            "Epoch 3, Sample 13548: Loss: 0.5000\n",
            "Epoch 3, Sample 13549: Loss: 0.0108\n",
            "Epoch 3, Sample 13550: Loss: 0.3441\n",
            "Epoch 3, Sample 13551: Loss: 0.0001\n",
            "Epoch 3, Sample 13552: Loss: 0.1463\n",
            "Epoch 3, Sample 13553: Loss: 0.4697\n",
            "Epoch 3, Sample 13554: Loss: 0.2044\n",
            "Epoch 3, Sample 13555: Loss: 0.0060\n",
            "Epoch 3, Sample 13556: Loss: 0.2836\n",
            "Epoch 3, Sample 13557: Loss: 0.4185\n",
            "Epoch 3, Sample 13558: Loss: 0.0018\n",
            "Epoch 3, Sample 13559: Loss: 1.0266\n",
            "Epoch 3, Sample 13560: Loss: 0.1250\n",
            "Epoch 3, Sample 13561: Loss: 0.1170\n",
            "Epoch 3, Sample 13562: Loss: 1.0524\n",
            "Epoch 3, Sample 13563: Loss: 0.3506\n",
            "Epoch 3, Sample 13564: Loss: 0.0838\n",
            "Epoch 3, Sample 13565: Loss: 0.1200\n",
            "Epoch 3, Sample 13566: Loss: 0.6152\n",
            "Epoch 3, Sample 13567: Loss: 1.4287\n",
            "Epoch 3, Sample 13568: Loss: 0.0915\n",
            "Epoch 3, Sample 13569: Loss: 0.2044\n",
            "Epoch 3, Sample 13570: Loss: 1.0266\n",
            "Epoch 3, Sample 13571: Loss: 0.0022\n",
            "Epoch 3, Sample 13572: Loss: 0.1248\n",
            "Epoch 3, Sample 13573: Loss: 1.7195\n",
            "Epoch 3, Sample 13574: Loss: 0.5196\n",
            "Epoch 3, Sample 13575: Loss: 0.8951\n",
            "Epoch 3, Sample 13576: Loss: 0.3247\n",
            "Epoch 3, Sample 13577: Loss: 0.0026\n",
            "Epoch 3, Sample 13578: Loss: 0.0000\n",
            "Epoch 3, Sample 13579: Loss: 0.2036\n",
            "Epoch 3, Sample 13580: Loss: 0.0205\n",
            "Epoch 3, Sample 13581: Loss: 0.3399\n",
            "Epoch 3, Sample 13582: Loss: 0.9295\n",
            "Epoch 3, Sample 13583: Loss: 0.2044\n",
            "Epoch 3, Sample 13584: Loss: 0.3399\n",
            "Epoch 3, Sample 13585: Loss: 1.1738\n",
            "Epoch 3, Sample 13586: Loss: 0.1422\n",
            "Epoch 3, Sample 13587: Loss: 0.8951\n",
            "Epoch 3, Sample 13588: Loss: 0.2851\n",
            "Epoch 3, Sample 13589: Loss: 0.1914\n",
            "Epoch 3, Sample 13590: Loss: 0.2759\n",
            "Epoch 3, Sample 13591: Loss: 0.2966\n",
            "Epoch 3, Sample 13592: Loss: 0.7486\n",
            "Epoch 3, Sample 13593: Loss: 1.6010\n",
            "Epoch 3, Sample 13594: Loss: 0.3441\n",
            "Epoch 3, Sample 13595: Loss: 0.2832\n",
            "Epoch 3, Sample 13596: Loss: 0.2034\n",
            "Epoch 3, Sample 13597: Loss: 0.2855\n",
            "Epoch 3, Sample 13598: Loss: 0.7078\n",
            "Epoch 3, Sample 13599: Loss: 0.0148\n",
            "Epoch 3, Sample 13600: Loss: 0.0026\n",
            "Epoch 3, Sample 13601: Loss: 0.4930\n",
            "Epoch 3, Sample 13602: Loss: 0.0001\n",
            "Epoch 3, Sample 13603: Loss: 0.1250\n",
            "Epoch 3, Sample 13604: Loss: 0.0303\n",
            "Epoch 3, Sample 13605: Loss: 0.2777\n",
            "Epoch 3, Sample 13606: Loss: 0.2044\n",
            "Epoch 3, Sample 13607: Loss: 0.1129\n",
            "Epoch 3, Sample 13608: Loss: 0.0084\n",
            "Epoch 3, Sample 13609: Loss: 0.1873\n",
            "Epoch 3, Sample 13610: Loss: 0.2340\n",
            "Epoch 3, Sample 13611: Loss: 0.0026\n",
            "Epoch 3, Sample 13612: Loss: 0.3938\n",
            "Epoch 3, Sample 13613: Loss: 0.0042\n",
            "Epoch 3, Sample 13614: Loss: 0.6388\n",
            "Epoch 3, Sample 13615: Loss: 0.2233\n",
            "Epoch 3, Sample 13616: Loss: 1.0524\n",
            "Epoch 3, Sample 13617: Loss: 0.0630\n",
            "Epoch 3, Sample 13618: Loss: 0.0026\n",
            "Epoch 3, Sample 13619: Loss: 0.2034\n",
            "Epoch 3, Sample 13620: Loss: 3.2527\n",
            "Epoch 3, Sample 13621: Loss: 0.0026\n",
            "Epoch 3, Sample 13622: Loss: 0.1250\n",
            "Epoch 3, Sample 13623: Loss: 0.0102\n",
            "Epoch 3, Sample 13624: Loss: 0.6990\n",
            "Epoch 3, Sample 13625: Loss: 0.4367\n",
            "Epoch 3, Sample 13626: Loss: 0.2056\n",
            "Epoch 3, Sample 13627: Loss: 0.0018\n",
            "Epoch 3, Sample 13628: Loss: 2.7331\n",
            "Epoch 3, Sample 13629: Loss: 0.1508\n",
            "Epoch 3, Sample 13630: Loss: 0.1372\n",
            "Epoch 3, Sample 13631: Loss: 3.3877\n",
            "Epoch 3, Sample 13632: Loss: 0.0002\n",
            "Epoch 3, Sample 13633: Loss: 0.3758\n",
            "Epoch 3, Sample 13634: Loss: 0.3441\n",
            "Epoch 3, Sample 13635: Loss: 0.1250\n",
            "Epoch 3, Sample 13636: Loss: 0.1475\n",
            "Epoch 3, Sample 13637: Loss: 0.1508\n",
            "Epoch 3, Sample 13638: Loss: 1.0524\n",
            "Epoch 3, Sample 13639: Loss: 0.9367\n",
            "Epoch 3, Sample 13640: Loss: 1.0266\n",
            "Epoch 3, Sample 13641: Loss: 1.0524\n",
            "Epoch 3, Sample 13642: Loss: 0.1523\n",
            "Epoch 3, Sample 13643: Loss: 0.3399\n",
            "Epoch 3, Sample 13644: Loss: 1.0524\n",
            "Epoch 3, Sample 13645: Loss: 0.7931\n",
            "Epoch 3, Sample 13646: Loss: 0.7547\n",
            "Epoch 3, Sample 13647: Loss: 0.3441\n",
            "Epoch 3, Sample 13648: Loss: 0.5858\n",
            "Epoch 3, Sample 13649: Loss: 0.0108\n",
            "Epoch 3, Sample 13650: Loss: 0.8951\n",
            "Epoch 3, Sample 13651: Loss: 0.7036\n",
            "Epoch 3, Sample 13652: Loss: 0.0026\n",
            "Epoch 3, Sample 13653: Loss: 0.5000\n",
            "Epoch 3, Sample 13654: Loss: 0.5505\n",
            "Epoch 3, Sample 13655: Loss: 0.0915\n",
            "Epoch 3, Sample 13656: Loss: 1.0524\n",
            "Epoch 3, Sample 13657: Loss: 0.5000\n",
            "Epoch 3, Sample 13658: Loss: 0.1588\n",
            "Epoch 3, Sample 13659: Loss: 0.3450\n",
            "Epoch 3, Sample 13660: Loss: 0.2759\n",
            "Epoch 3, Sample 13661: Loss: 0.0015\n",
            "Epoch 3, Sample 13662: Loss: 0.0026\n",
            "Epoch 3, Sample 13663: Loss: 0.2778\n",
            "Epoch 3, Sample 13664: Loss: 0.0962\n",
            "Epoch 3, Sample 13665: Loss: 0.0000\n",
            "Epoch 3, Sample 13666: Loss: 0.2759\n",
            "Epoch 3, Sample 13667: Loss: 0.4841\n",
            "Epoch 3, Sample 13668: Loss: 0.8951\n",
            "Epoch 3, Sample 13669: Loss: 1.0155\n",
            "Epoch 3, Sample 13670: Loss: 0.0026\n",
            "Epoch 3, Sample 13671: Loss: 0.7295\n",
            "Epoch 3, Sample 13672: Loss: 0.3438\n",
            "Epoch 3, Sample 13673: Loss: 1.7384\n",
            "Epoch 3, Sample 13674: Loss: 1.3161\n",
            "Epoch 3, Sample 13675: Loss: 11.9388\n",
            "Epoch 3, Sample 13676: Loss: 0.7036\n",
            "Epoch 3, Sample 13677: Loss: 0.2112\n",
            "Epoch 3, Sample 13678: Loss: 0.7036\n",
            "Epoch 3, Sample 13679: Loss: 0.4611\n",
            "Epoch 3, Sample 13680: Loss: 0.5196\n",
            "Epoch 3, Sample 13681: Loss: 0.3193\n",
            "Epoch 3, Sample 13682: Loss: 0.2759\n",
            "Epoch 3, Sample 13683: Loss: 11.9753\n",
            "Epoch 3, Sample 13684: Loss: 0.6940\n",
            "Epoch 3, Sample 13685: Loss: 3.2337\n",
            "Epoch 3, Sample 13686: Loss: 0.4799\n",
            "Epoch 3, Sample 13687: Loss: 0.5744\n",
            "Epoch 3, Sample 13688: Loss: 0.5972\n",
            "Epoch 3, Sample 13689: Loss: 0.0026\n",
            "Epoch 3, Sample 13690: Loss: 0.3758\n",
            "Epoch 3, Sample 13691: Loss: 0.3441\n",
            "Epoch 3, Sample 13692: Loss: 0.0026\n",
            "Epoch 3, Sample 13693: Loss: 0.7036\n",
            "Epoch 3, Sample 13694: Loss: 0.3568\n",
            "Epoch 3, Sample 13695: Loss: 0.1627\n",
            "Epoch 3, Sample 13696: Loss: 0.1246\n",
            "Epoch 3, Sample 13697: Loss: 0.2034\n",
            "Epoch 3, Sample 13698: Loss: 0.2219\n",
            "Epoch 3, Sample 13699: Loss: 0.0432\n",
            "Epoch 3, Sample 13700: Loss: 0.0915\n",
            "Epoch 3, Sample 13701: Loss: 0.4032\n",
            "Epoch 3, Sample 13702: Loss: 0.3402\n",
            "Epoch 3, Sample 13703: Loss: 0.7036\n",
            "Epoch 3, Sample 13704: Loss: 0.6189\n",
            "Epoch 3, Sample 13705: Loss: 0.2034\n",
            "Epoch 3, Sample 13706: Loss: 0.0006\n",
            "Epoch 3, Sample 13707: Loss: 0.0005\n",
            "Epoch 3, Sample 13708: Loss: 0.4902\n",
            "Epoch 3, Sample 13709: Loss: 0.7036\n",
            "Epoch 3, Sample 13710: Loss: 1.0524\n",
            "Epoch 3, Sample 13711: Loss: 0.6092\n",
            "Epoch 3, Sample 13712: Loss: 0.2044\n",
            "Epoch 3, Sample 13713: Loss: 0.3399\n",
            "Epoch 3, Sample 13714: Loss: 0.3441\n",
            "Epoch 3, Sample 13715: Loss: 0.2044\n",
            "Epoch 3, Sample 13716: Loss: 0.2832\n",
            "Epoch 3, Sample 13717: Loss: 0.1326\n",
            "Epoch 3, Sample 13718: Loss: 0.0640\n",
            "Epoch 3, Sample 13719: Loss: 0.2989\n",
            "Epoch 3, Sample 13720: Loss: 0.0004\n",
            "Epoch 3, Sample 13721: Loss: 1.0530\n",
            "Epoch 3, Sample 13722: Loss: 0.4996\n",
            "Epoch 3, Sample 13723: Loss: 0.2044\n",
            "Epoch 3, Sample 13724: Loss: 0.4206\n",
            "Epoch 3, Sample 13725: Loss: 1.0155\n",
            "Epoch 3, Sample 13726: Loss: 1.0155\n",
            "Epoch 3, Sample 13727: Loss: 0.0482\n",
            "Epoch 3, Sample 13728: Loss: 0.2851\n",
            "Epoch 3, Sample 13729: Loss: 0.2034\n",
            "Epoch 3, Sample 13730: Loss: 0.1091\n",
            "Epoch 3, Sample 13731: Loss: 0.1270\n",
            "Epoch 3, Sample 13732: Loss: 2.8644\n",
            "Epoch 3, Sample 13733: Loss: 0.1817\n",
            "Epoch 3, Sample 13734: Loss: 0.7036\n",
            "Epoch 3, Sample 13735: Loss: 0.0001\n",
            "Epoch 3, Sample 13736: Loss: 1.0155\n",
            "Epoch 3, Sample 13737: Loss: 0.1770\n",
            "Epoch 3, Sample 13738: Loss: 6.5585\n",
            "Epoch 3, Sample 13739: Loss: 0.2036\n",
            "Epoch 3, Sample 13740: Loss: 0.1465\n",
            "Epoch 3, Sample 13741: Loss: 0.0205\n",
            "Epoch 3, Sample 13742: Loss: 0.2989\n",
            "Epoch 3, Sample 13743: Loss: 1.0524\n",
            "Epoch 3, Sample 13744: Loss: 1.0155\n",
            "Epoch 3, Sample 13745: Loss: 0.8484\n",
            "Epoch 3, Sample 13746: Loss: 0.4032\n",
            "Epoch 3, Sample 13747: Loss: 0.2759\n",
            "Epoch 3, Sample 13748: Loss: 0.2851\n",
            "Epoch 3, Sample 13749: Loss: 0.2036\n",
            "Epoch 3, Sample 13750: Loss: 0.6546\n",
            "Epoch 3, Sample 13751: Loss: 0.5927\n",
            "Epoch 3, Sample 13752: Loss: 1.0524\n",
            "Epoch 3, Sample 13753: Loss: 1.8503\n",
            "Epoch 3, Sample 13754: Loss: 0.2044\n",
            "Epoch 3, Sample 13755: Loss: 0.0391\n",
            "Epoch 3, Sample 13756: Loss: 0.0744\n",
            "Epoch 3, Sample 13757: Loss: 3.2748\n",
            "Epoch 3, Sample 13758: Loss: 0.2044\n",
            "Epoch 3, Sample 13759: Loss: 0.0026\n",
            "Epoch 3, Sample 13760: Loss: 1.6932\n",
            "Epoch 3, Sample 13761: Loss: 0.3949\n",
            "Epoch 3, Sample 13762: Loss: 0.5000\n",
            "Epoch 3, Sample 13763: Loss: 0.0630\n",
            "Epoch 3, Sample 13764: Loss: 2.0820\n",
            "Epoch 3, Sample 13765: Loss: 0.8951\n",
            "Epoch 3, Sample 13766: Loss: 3.1570\n",
            "Epoch 3, Sample 13767: Loss: 0.2036\n",
            "Epoch 3, Sample 13768: Loss: 0.7313\n",
            "Epoch 3, Sample 13769: Loss: 0.0026\n",
            "Epoch 3, Sample 13770: Loss: 0.8951\n",
            "Epoch 3, Sample 13771: Loss: 0.5078\n",
            "Epoch 3, Sample 13772: Loss: 0.0915\n",
            "Epoch 3, Sample 13773: Loss: 0.1706\n",
            "Epoch 3, Sample 13774: Loss: 0.4611\n",
            "Epoch 3, Sample 13775: Loss: 0.7036\n",
            "Epoch 3, Sample 13776: Loss: 0.0475\n",
            "Epoch 3, Sample 13777: Loss: 0.2044\n",
            "Epoch 3, Sample 13778: Loss: 3.7381\n",
            "Epoch 3, Sample 13779: Loss: 4.9876\n",
            "Epoch 3, Sample 13780: Loss: 0.3135\n",
            "Epoch 3, Sample 13781: Loss: 2.0189\n",
            "Epoch 3, Sample 13782: Loss: 0.0239\n",
            "Epoch 3, Sample 13783: Loss: 0.0062\n",
            "Epoch 3, Sample 13784: Loss: 0.3399\n",
            "Epoch 3, Sample 13785: Loss: 0.0625\n",
            "Epoch 3, Sample 13786: Loss: 0.7036\n",
            "Epoch 3, Sample 13787: Loss: 0.0026\n",
            "Epoch 3, Sample 13788: Loss: 1.2192\n",
            "Epoch 3, Sample 13789: Loss: 0.5698\n",
            "Epoch 3, Sample 13790: Loss: 1.1548\n",
            "Epoch 3, Sample 13791: Loss: 0.6058\n",
            "Epoch 3, Sample 13792: Loss: 0.0145\n",
            "Epoch 3, Sample 13793: Loss: 0.3441\n",
            "Epoch 3, Sample 13794: Loss: 0.4858\n",
            "Epoch 3, Sample 13795: Loss: 0.3399\n",
            "Epoch 3, Sample 13796: Loss: 0.1516\n",
            "Epoch 3, Sample 13797: Loss: 0.0019\n",
            "Epoch 3, Sample 13798: Loss: 0.0202\n",
            "Epoch 3, Sample 13799: Loss: 1.0155\n",
            "Epoch 3, Sample 13800: Loss: 0.0209\n",
            "Epoch 3, Sample 13801: Loss: 0.0084\n",
            "Epoch 3, Sample 13802: Loss: 0.0067\n",
            "Epoch 3, Sample 13803: Loss: 0.4010\n",
            "Epoch 3, Sample 13804: Loss: 0.3399\n",
            "Epoch 3, Sample 13805: Loss: 1.0524\n",
            "Epoch 3, Sample 13806: Loss: 0.1250\n",
            "Epoch 3, Sample 13807: Loss: 0.2238\n",
            "Epoch 3, Sample 13808: Loss: 0.5858\n",
            "Epoch 3, Sample 13809: Loss: 0.2879\n",
            "Epoch 3, Sample 13810: Loss: 0.3441\n",
            "Epoch 3, Sample 13811: Loss: 0.5000\n",
            "Epoch 3, Sample 13812: Loss: 0.9178\n",
            "Epoch 3, Sample 13813: Loss: 0.7004\n",
            "Epoch 3, Sample 13814: Loss: 0.0018\n",
            "Epoch 3, Sample 13815: Loss: 1.0530\n",
            "Epoch 3, Sample 13816: Loss: 0.2044\n",
            "Epoch 3, Sample 13817: Loss: 0.2044\n",
            "Epoch 3, Sample 13818: Loss: 1.0524\n",
            "Epoch 3, Sample 13819: Loss: 0.4799\n",
            "Epoch 3, Sample 13820: Loss: 0.6058\n",
            "Epoch 3, Sample 13821: Loss: 0.6328\n",
            "Epoch 3, Sample 13822: Loss: 0.2034\n",
            "Epoch 3, Sample 13823: Loss: 0.0286\n",
            "Epoch 3, Sample 13824: Loss: 0.2725\n",
            "Epoch 3, Sample 13825: Loss: 0.0626\n",
            "Epoch 3, Sample 13826: Loss: 0.2832\n",
            "Epoch 3, Sample 13827: Loss: 0.3023\n",
            "Epoch 3, Sample 13828: Loss: 0.1218\n",
            "Epoch 3, Sample 13829: Loss: 0.1170\n",
            "Epoch 3, Sample 13830: Loss: 1.0524\n",
            "Epoch 3, Sample 13831: Loss: 0.2044\n",
            "Epoch 3, Sample 13832: Loss: 0.1170\n",
            "Epoch 3, Sample 13833: Loss: 0.2920\n",
            "Epoch 3, Sample 13834: Loss: 0.0774\n",
            "Epoch 3, Sample 13835: Loss: 0.7702\n",
            "Epoch 3, Sample 13836: Loss: 0.0267\n",
            "Epoch 3, Sample 13837: Loss: 1.0524\n",
            "Epoch 3, Sample 13838: Loss: 0.0475\n",
            "Epoch 3, Sample 13839: Loss: 2.6851\n",
            "Epoch 3, Sample 13840: Loss: 0.3024\n",
            "Epoch 3, Sample 13841: Loss: 0.1252\n",
            "Epoch 3, Sample 13842: Loss: 1.0524\n",
            "Epoch 3, Sample 13843: Loss: 0.0373\n",
            "Epoch 3, Sample 13844: Loss: 0.1170\n",
            "Epoch 3, Sample 13845: Loss: 0.5000\n",
            "Epoch 3, Sample 13846: Loss: 0.0060\n",
            "Epoch 3, Sample 13847: Loss: 0.2034\n",
            "Epoch 3, Sample 13848: Loss: 0.2832\n",
            "Epoch 3, Sample 13849: Loss: 0.2219\n",
            "Epoch 3, Sample 13850: Loss: 0.4841\n",
            "Epoch 3, Sample 13851: Loss: 1.2378\n",
            "Epoch 3, Sample 13852: Loss: 0.5871\n",
            "Epoch 3, Sample 13853: Loss: 1.0530\n",
            "Epoch 3, Sample 13854: Loss: 0.0026\n",
            "Epoch 3, Sample 13855: Loss: 1.2877\n",
            "Epoch 3, Sample 13856: Loss: 0.6304\n",
            "Epoch 3, Sample 13857: Loss: 0.1326\n",
            "Epoch 3, Sample 13858: Loss: 1.0524\n",
            "Epoch 3, Sample 13859: Loss: 0.0026\n",
            "Epoch 3, Sample 13860: Loss: 6.9441\n",
            "Epoch 3, Sample 13861: Loss: 0.0047\n",
            "Epoch 3, Sample 13862: Loss: 1.0524\n",
            "Epoch 3, Sample 13863: Loss: 0.2978\n",
            "Epoch 3, Sample 13864: Loss: 0.7820\n",
            "Epoch 3, Sample 13865: Loss: 0.2759\n",
            "Epoch 3, Sample 13866: Loss: 1.0155\n",
            "Epoch 3, Sample 13867: Loss: 0.0306\n",
            "Epoch 3, Sample 13868: Loss: 0.5871\n",
            "Epoch 3, Sample 13869: Loss: 0.0303\n",
            "Epoch 3, Sample 13870: Loss: 1.0524\n",
            "Epoch 3, Sample 13871: Loss: 0.2044\n",
            "Epoch 3, Sample 13872: Loss: 0.0630\n",
            "Epoch 3, Sample 13873: Loss: 0.9367\n",
            "Epoch 3, Sample 13874: Loss: 0.0000\n",
            "Epoch 3, Sample 13875: Loss: 0.0001\n",
            "Epoch 3, Sample 13876: Loss: 0.1091\n",
            "Epoch 3, Sample 13877: Loss: 0.0018\n",
            "Epoch 3, Sample 13878: Loss: 0.0795\n",
            "Epoch 3, Sample 13879: Loss: 0.0000\n",
            "Epoch 3, Sample 13880: Loss: 0.2195\n",
            "Epoch 3, Sample 13881: Loss: 0.1852\n",
            "Epoch 3, Sample 13882: Loss: 1.2926\n",
            "Epoch 3, Sample 13883: Loss: 0.5089\n",
            "Epoch 3, Sample 13884: Loss: 0.1252\n",
            "Epoch 3, Sample 13885: Loss: 0.6092\n",
            "Epoch 3, Sample 13886: Loss: 1.3307\n",
            "Epoch 3, Sample 13887: Loss: 0.0433\n",
            "Epoch 3, Sample 13888: Loss: 0.2036\n",
            "Epoch 3, Sample 13889: Loss: 0.8398\n",
            "Epoch 3, Sample 13890: Loss: 0.0025\n",
            "Epoch 3, Sample 13891: Loss: 0.2112\n",
            "Epoch 3, Sample 13892: Loss: 0.1482\n",
            "Epoch 3, Sample 13893: Loss: 0.7036\n",
            "Epoch 3, Sample 13894: Loss: 1.2095\n",
            "Epoch 3, Sample 13895: Loss: 0.6092\n",
            "Epoch 3, Sample 13896: Loss: 0.0630\n",
            "Epoch 3, Sample 13897: Loss: 0.0744\n",
            "Epoch 3, Sample 13898: Loss: 0.0787\n",
            "Epoch 3, Sample 13899: Loss: 0.2032\n",
            "Epoch 3, Sample 13900: Loss: 1.0155\n",
            "Epoch 3, Sample 13901: Loss: 8.2219\n",
            "Epoch 3, Sample 13902: Loss: 0.0013\n",
            "Epoch 3, Sample 13903: Loss: 0.7036\n",
            "Epoch 3, Sample 13904: Loss: 0.5201\n",
            "Epoch 3, Sample 13905: Loss: 0.3861\n",
            "Epoch 3, Sample 13906: Loss: 1.2043\n",
            "Epoch 3, Sample 13907: Loss: 0.4799\n",
            "Epoch 3, Sample 13908: Loss: 0.3399\n",
            "Epoch 3, Sample 13909: Loss: 0.0033\n",
            "Epoch 3, Sample 13910: Loss: 0.3348\n",
            "Epoch 3, Sample 13911: Loss: 0.1250\n",
            "Epoch 3, Sample 13912: Loss: 0.3598\n",
            "Epoch 3, Sample 13913: Loss: 0.2034\n",
            "Epoch 3, Sample 13914: Loss: 0.1337\n",
            "Epoch 3, Sample 13915: Loss: 0.0234\n",
            "Epoch 3, Sample 13916: Loss: 1.5465\n",
            "Epoch 3, Sample 13917: Loss: 0.0093\n",
            "Epoch 3, Sample 13918: Loss: 0.4930\n",
            "Epoch 3, Sample 13919: Loss: 0.2044\n",
            "Epoch 3, Sample 13920: Loss: 0.0426\n",
            "Epoch 3, Sample 13921: Loss: 0.7036\n",
            "Epoch 3, Sample 13922: Loss: 0.1627\n",
            "Epoch 3, Sample 13923: Loss: 0.0915\n",
            "Epoch 3, Sample 13924: Loss: 0.0026\n",
            "Epoch 3, Sample 13925: Loss: 0.3399\n",
            "Epoch 3, Sample 13926: Loss: 1.0524\n",
            "Epoch 3, Sample 13927: Loss: 0.5636\n",
            "Epoch 3, Sample 13928: Loss: 0.3399\n",
            "Epoch 3, Sample 13929: Loss: 0.0102\n",
            "Epoch 3, Sample 13930: Loss: 0.2034\n",
            "Epoch 3, Sample 13931: Loss: 1.0155\n",
            "Epoch 3, Sample 13932: Loss: 0.0018\n",
            "Epoch 3, Sample 13933: Loss: 0.1925\n",
            "Epoch 3, Sample 13934: Loss: 0.0026\n",
            "Epoch 3, Sample 13935: Loss: 0.1555\n",
            "Epoch 3, Sample 13936: Loss: 1.8443\n",
            "Epoch 3, Sample 13937: Loss: 0.1336\n",
            "Epoch 3, Sample 13938: Loss: 0.2034\n",
            "Epoch 3, Sample 13939: Loss: 0.2759\n",
            "Epoch 3, Sample 13940: Loss: 0.4611\n",
            "Epoch 3, Sample 13941: Loss: 0.0630\n",
            "Epoch 3, Sample 13942: Loss: 0.0353\n",
            "Epoch 3, Sample 13943: Loss: 0.3949\n",
            "Epoch 3, Sample 13944: Loss: 1.0155\n",
            "Epoch 3, Sample 13945: Loss: 0.1559\n",
            "Epoch 3, Sample 13946: Loss: 1.0524\n",
            "Epoch 3, Sample 13947: Loss: 0.2044\n",
            "Epoch 3, Sample 13948: Loss: 0.3568\n",
            "Epoch 3, Sample 13949: Loss: 0.4588\n",
            "Epoch 3, Sample 13950: Loss: 0.5003\n",
            "Epoch 3, Sample 13951: Loss: 0.2032\n",
            "Epoch 3, Sample 13952: Loss: 0.2896\n",
            "Epoch 3, Sample 13953: Loss: 0.1108\n",
            "Epoch 3, Sample 13954: Loss: 0.2032\n",
            "Epoch 3, Sample 13955: Loss: 1.4482\n",
            "Epoch 3, Sample 13956: Loss: 0.6867\n",
            "Epoch 3, Sample 13957: Loss: 0.3949\n",
            "Epoch 3, Sample 13958: Loss: 0.2699\n",
            "Epoch 3, Sample 13959: Loss: 0.7453\n",
            "Epoch 3, Sample 13960: Loss: 1.0155\n",
            "Epoch 3, Sample 13961: Loss: 0.3399\n",
            "Epoch 3, Sample 13962: Loss: 0.8730\n",
            "Epoch 3, Sample 13963: Loss: 0.5972\n",
            "Epoch 3, Sample 13964: Loss: 0.0000\n",
            "Epoch 3, Sample 13965: Loss: 0.4607\n",
            "Epoch 3, Sample 13966: Loss: 0.3441\n",
            "Epoch 3, Sample 13967: Loss: 0.2639\n",
            "Epoch 3, Sample 13968: Loss: 0.0595\n",
            "Epoch 3, Sample 13969: Loss: 1.1569\n",
            "Epoch 3, Sample 13970: Loss: 0.7453\n",
            "Epoch 3, Sample 13971: Loss: 0.2044\n",
            "Epoch 3, Sample 13972: Loss: 0.5078\n",
            "Epoch 3, Sample 13973: Loss: 8.9254\n",
            "Epoch 3, Sample 13974: Loss: 0.9367\n",
            "Epoch 3, Sample 13975: Loss: 0.0264\n",
            "Epoch 3, Sample 13976: Loss: 0.3399\n",
            "Epoch 3, Sample 13977: Loss: 0.2044\n",
            "Epoch 3, Sample 13978: Loss: 0.0303\n",
            "Epoch 3, Sample 13979: Loss: 0.0026\n",
            "Epoch 3, Sample 13980: Loss: 0.9367\n",
            "Epoch 3, Sample 13981: Loss: 0.5972\n",
            "Epoch 3, Sample 13982: Loss: 0.1250\n",
            "Epoch 3, Sample 13983: Loss: 0.0630\n",
            "Epoch 3, Sample 13984: Loss: 0.2726\n",
            "Epoch 3, Sample 13985: Loss: 0.0630\n",
            "Epoch 3, Sample 13986: Loss: 0.0117\n",
            "Epoch 3, Sample 13987: Loss: 0.1838\n",
            "Epoch 3, Sample 13988: Loss: 4.2554\n",
            "Epoch 3, Sample 13989: Loss: 0.2074\n",
            "Epoch 3, Sample 13990: Loss: 0.3332\n",
            "Epoch 3, Sample 13991: Loss: 0.2032\n",
            "Epoch 3, Sample 13992: Loss: 0.3402\n",
            "Epoch 3, Sample 13993: Loss: 0.2034\n",
            "Epoch 3, Sample 13994: Loss: 1.0524\n",
            "Epoch 3, Sample 13995: Loss: 0.4032\n",
            "Epoch 3, Sample 13996: Loss: 0.0469\n",
            "Epoch 3, Sample 13997: Loss: 0.6990\n",
            "Epoch 3, Sample 13998: Loss: 0.0026\n",
            "Epoch 3, Sample 13999: Loss: 0.0364\n",
            "Epoch 3, Sample 14000: Loss: 1.0155\n",
            "Epoch 3, Sample 14001: Loss: 0.0838\n",
            "Epoch 3, Sample 14002: Loss: 0.3460\n",
            "Epoch 3, Sample 14003: Loss: 0.0000\n",
            "Epoch 3, Sample 14004: Loss: 0.0001\n",
            "Epoch 3, Sample 14005: Loss: 0.0299\n",
            "Epoch 3, Sample 14006: Loss: 0.2036\n",
            "Epoch 3, Sample 14007: Loss: 0.0026\n",
            "Epoch 3, Sample 14008: Loss: 0.0084\n",
            "Epoch 3, Sample 14009: Loss: 0.1399\n",
            "Epoch 3, Sample 14010: Loss: 0.7036\n",
            "Epoch 3, Sample 14011: Loss: 0.4849\n",
            "Epoch 3, Sample 14012: Loss: 0.9780\n",
            "Epoch 3, Sample 14013: Loss: 0.3441\n",
            "Epoch 3, Sample 14014: Loss: 0.4799\n",
            "Epoch 3, Sample 14015: Loss: 2.1073\n",
            "Epoch 3, Sample 14016: Loss: 1.0155\n",
            "Epoch 3, Sample 14017: Loss: 0.1013\n",
            "Epoch 3, Sample 14018: Loss: 0.0504\n",
            "Epoch 3, Sample 14019: Loss: 1.8360\n",
            "Epoch 3, Sample 14020: Loss: 9.1182\n",
            "Epoch 3, Sample 14021: Loss: 0.3399\n",
            "Epoch 3, Sample 14022: Loss: 1.0524\n",
            "Epoch 3, Sample 14023: Loss: 1.0524\n",
            "Epoch 3, Sample 14024: Loss: 0.0915\n",
            "Epoch 3, Sample 14025: Loss: 0.3399\n",
            "Epoch 3, Sample 14026: Loss: 0.0466\n",
            "Epoch 3, Sample 14027: Loss: 0.3418\n",
            "Epoch 3, Sample 14028: Loss: 0.1559\n",
            "Epoch 3, Sample 14029: Loss: 0.5278\n",
            "Epoch 3, Sample 14030: Loss: 0.9785\n",
            "Epoch 3, Sample 14031: Loss: 0.9367\n",
            "Epoch 3, Sample 14032: Loss: 0.4032\n",
            "Epoch 3, Sample 14033: Loss: 0.3702\n",
            "Epoch 3, Sample 14034: Loss: 0.5003\n",
            "Epoch 3, Sample 14035: Loss: 0.0915\n",
            "Epoch 3, Sample 14036: Loss: 1.0070\n",
            "Epoch 3, Sample 14037: Loss: 0.8951\n",
            "Epoch 3, Sample 14038: Loss: 0.4382\n",
            "Epoch 3, Sample 14039: Loss: 0.1246\n",
            "Epoch 3, Sample 14040: Loss: 0.2494\n",
            "Epoch 3, Sample 14041: Loss: 2.0129\n",
            "Epoch 3, Sample 14042: Loss: 0.1610\n",
            "Epoch 3, Sample 14043: Loss: 0.1559\n",
            "Epoch 3, Sample 14044: Loss: 0.3743\n",
            "Epoch 3, Sample 14045: Loss: 0.0522\n",
            "Epoch 3, Sample 14046: Loss: 0.5977\n",
            "Epoch 3, Sample 14047: Loss: 0.6990\n",
            "Epoch 3, Sample 14048: Loss: 0.3598\n",
            "Epoch 3, Sample 14049: Loss: 0.2044\n",
            "Epoch 3, Sample 14050: Loss: 0.0062\n",
            "Epoch 3, Sample 14051: Loss: 0.4841\n",
            "Epoch 3, Sample 14052: Loss: 0.3288\n",
            "Epoch 3, Sample 14053: Loss: 0.9367\n",
            "Epoch 3, Sample 14054: Loss: 0.1989\n",
            "Epoch 3, Sample 14055: Loss: 0.2036\n",
            "Epoch 3, Sample 14056: Loss: 1.0524\n",
            "Epoch 3, Sample 14057: Loss: 0.2036\n",
            "Epoch 3, Sample 14058: Loss: 1.0524\n",
            "Epoch 3, Sample 14059: Loss: 0.6127\n",
            "Epoch 3, Sample 14060: Loss: 0.2044\n",
            "Epoch 3, Sample 14061: Loss: 0.4611\n",
            "Epoch 3, Sample 14062: Loss: 0.3539\n",
            "Epoch 3, Sample 14063: Loss: 1.0530\n",
            "Epoch 3, Sample 14064: Loss: 0.0176\n",
            "Epoch 3, Sample 14065: Loss: 0.0018\n",
            "Epoch 3, Sample 14066: Loss: 0.1170\n",
            "Epoch 3, Sample 14067: Loss: 0.0915\n",
            "Epoch 3, Sample 14068: Loss: 0.2219\n",
            "Epoch 3, Sample 14069: Loss: 0.0063\n",
            "Epoch 3, Sample 14070: Loss: 0.0630\n",
            "Epoch 3, Sample 14071: Loss: 0.2271\n",
            "Epoch 3, Sample 14072: Loss: 0.7036\n",
            "Epoch 3, Sample 14073: Loss: 0.3661\n",
            "Epoch 3, Sample 14074: Loss: 0.0625\n",
            "Epoch 3, Sample 14075: Loss: 0.8951\n",
            "Epoch 3, Sample 14076: Loss: 0.8951\n",
            "Epoch 3, Sample 14077: Loss: 0.6092\n",
            "Epoch 3, Sample 14078: Loss: 0.7591\n",
            "Epoch 3, Sample 14079: Loss: 0.5509\n",
            "Epoch 3, Sample 14080: Loss: 0.1605\n",
            "Epoch 3, Sample 14081: Loss: 0.0520\n",
            "Epoch 3, Sample 14082: Loss: 3.8896\n",
            "Epoch 3, Sample 14083: Loss: 0.2750\n",
            "Epoch 3, Sample 14084: Loss: 0.0915\n",
            "Epoch 3, Sample 14085: Loss: 0.0873\n",
            "Epoch 3, Sample 14086: Loss: 7.9989\n",
            "Epoch 3, Sample 14087: Loss: 0.3399\n",
            "Epoch 3, Sample 14088: Loss: 0.0168\n",
            "Epoch 3, Sample 14089: Loss: 0.3441\n",
            "Epoch 3, Sample 14090: Loss: 0.2044\n",
            "Epoch 3, Sample 14091: Loss: 0.1225\n",
            "Epoch 3, Sample 14092: Loss: 0.0915\n",
            "Epoch 3, Sample 14093: Loss: 0.0041\n",
            "Epoch 3, Sample 14094: Loss: 2.6579\n",
            "Epoch 3, Sample 14095: Loss: 0.3402\n",
            "Epoch 3, Sample 14096: Loss: 1.0530\n",
            "Epoch 3, Sample 14097: Loss: 0.1170\n",
            "Epoch 3, Sample 14098: Loss: 0.1091\n",
            "Epoch 3, Sample 14099: Loss: 0.2188\n",
            "Epoch 3, Sample 14100: Loss: 0.2034\n",
            "Epoch 3, Sample 14101: Loss: 0.2044\n",
            "Epoch 3, Sample 14102: Loss: 1.0524\n",
            "Epoch 3, Sample 14103: Loss: 0.3399\n",
            "Epoch 3, Sample 14104: Loss: 2.8636\n",
            "Epoch 3, Sample 14105: Loss: 0.7036\n",
            "Epoch 3, Sample 14106: Loss: 1.0524\n",
            "Epoch 3, Sample 14107: Loss: 0.2759\n",
            "Epoch 3, Sample 14108: Loss: 0.8951\n",
            "Epoch 3, Sample 14109: Loss: 0.1092\n",
            "Epoch 3, Sample 14110: Loss: 1.4320\n",
            "Epoch 3, Sample 14111: Loss: 0.2219\n",
            "Epoch 3, Sample 14112: Loss: 0.2846\n",
            "Epoch 3, Sample 14113: Loss: 0.1248\n",
            "Epoch 3, Sample 14114: Loss: 0.3949\n",
            "Epoch 3, Sample 14115: Loss: 0.4902\n",
            "Epoch 3, Sample 14116: Loss: 0.1364\n",
            "Epoch 3, Sample 14117: Loss: 0.0229\n",
            "Epoch 3, Sample 14118: Loss: 6.4257\n",
            "Epoch 3, Sample 14119: Loss: 0.0731\n",
            "Epoch 3, Sample 14120: Loss: 0.3399\n",
            "Epoch 3, Sample 14121: Loss: 1.0511\n",
            "Epoch 3, Sample 14122: Loss: 0.0140\n",
            "Epoch 3, Sample 14123: Loss: 0.3402\n",
            "Epoch 3, Sample 14124: Loss: 0.9788\n",
            "Epoch 3, Sample 14125: Loss: 0.2832\n",
            "Epoch 3, Sample 14126: Loss: 0.7675\n",
            "Epoch 3, Sample 14127: Loss: 0.3441\n",
            "Epoch 3, Sample 14128: Loss: 0.2044\n",
            "Epoch 3, Sample 14129: Loss: 0.2938\n",
            "Epoch 3, Sample 14130: Loss: 0.0303\n",
            "Epoch 3, Sample 14131: Loss: 1.1789\n",
            "Epoch 3, Sample 14132: Loss: 0.0002\n",
            "Epoch 3, Sample 14133: Loss: 0.2307\n",
            "Epoch 3, Sample 14134: Loss: 0.0363\n",
            "Epoch 3, Sample 14135: Loss: 0.5972\n",
            "Epoch 3, Sample 14136: Loss: 0.0915\n",
            "Epoch 3, Sample 14137: Loss: 0.1005\n",
            "Epoch 3, Sample 14138: Loss: 0.3399\n",
            "Epoch 3, Sample 14139: Loss: 1.0530\n",
            "Epoch 3, Sample 14140: Loss: 0.4841\n",
            "Epoch 3, Sample 14141: Loss: 0.5849\n",
            "Epoch 3, Sample 14142: Loss: 0.1250\n",
            "Epoch 3, Sample 14143: Loss: 0.3247\n",
            "Epoch 3, Sample 14144: Loss: 2.2357\n",
            "Epoch 3, Sample 14145: Loss: 0.3949\n",
            "Epoch 3, Sample 14146: Loss: 0.5858\n",
            "Epoch 3, Sample 14147: Loss: 0.2759\n",
            "Epoch 3, Sample 14148: Loss: 0.4032\n",
            "Epoch 3, Sample 14149: Loss: 0.3399\n",
            "Epoch 3, Sample 14150: Loss: 0.6092\n",
            "Epoch 3, Sample 14151: Loss: 0.1250\n",
            "Epoch 3, Sample 14152: Loss: 0.0144\n",
            "Epoch 3, Sample 14153: Loss: 0.1773\n",
            "Epoch 3, Sample 14154: Loss: 0.4930\n",
            "Epoch 3, Sample 14155: Loss: 0.8056\n",
            "Epoch 3, Sample 14156: Loss: 0.0306\n",
            "Epoch 3, Sample 14157: Loss: 0.0108\n",
            "Epoch 3, Sample 14158: Loss: 0.9744\n",
            "Epoch 3, Sample 14159: Loss: 0.0026\n",
            "Epoch 3, Sample 14160: Loss: 0.2687\n",
            "Epoch 3, Sample 14161: Loss: 0.4799\n",
            "Epoch 3, Sample 14162: Loss: 0.1134\n",
            "Epoch 3, Sample 14163: Loss: 1.0393\n",
            "Epoch 3, Sample 14164: Loss: 0.2044\n",
            "Epoch 3, Sample 14165: Loss: 0.1031\n",
            "Epoch 3, Sample 14166: Loss: 0.2032\n",
            "Epoch 3, Sample 14167: Loss: 0.0018\n",
            "Epoch 3, Sample 14168: Loss: 1.0524\n",
            "Epoch 3, Sample 14169: Loss: 0.0103\n",
            "Epoch 3, Sample 14170: Loss: 0.5375\n",
            "Epoch 3, Sample 14171: Loss: 0.0001\n",
            "Epoch 3, Sample 14172: Loss: 2.4636\n",
            "Epoch 3, Sample 14173: Loss: 0.4799\n",
            "Epoch 3, Sample 14174: Loss: 1.6274\n",
            "Epoch 3, Sample 14175: Loss: 0.0216\n",
            "Epoch 3, Sample 14176: Loss: 0.4032\n",
            "Epoch 3, Sample 14177: Loss: 0.2832\n",
            "Epoch 3, Sample 14178: Loss: 0.2044\n",
            "Epoch 3, Sample 14179: Loss: 0.2034\n",
            "Epoch 3, Sample 14180: Loss: 0.2290\n",
            "Epoch 3, Sample 14181: Loss: 0.5858\n",
            "Epoch 3, Sample 14182: Loss: 0.5972\n",
            "Epoch 3, Sample 14183: Loss: 0.0088\n",
            "Epoch 3, Sample 14184: Loss: 0.3441\n",
            "Epoch 3, Sample 14185: Loss: 0.1372\n",
            "Epoch 3, Sample 14186: Loss: 0.2832\n",
            "Epoch 3, Sample 14187: Loss: 0.0829\n",
            "Epoch 3, Sample 14188: Loss: 0.1559\n",
            "Epoch 3, Sample 14189: Loss: 0.2699\n",
            "Epoch 3, Sample 14190: Loss: 0.3450\n",
            "Epoch 3, Sample 14191: Loss: 0.1246\n",
            "Epoch 3, Sample 14192: Loss: 0.0026\n",
            "Epoch 3, Sample 14193: Loss: 0.3584\n",
            "Epoch 3, Sample 14194: Loss: 0.1170\n",
            "Epoch 3, Sample 14195: Loss: 0.6092\n",
            "Epoch 3, Sample 14196: Loss: 0.6139\n",
            "Epoch 3, Sample 14197: Loss: 1.0524\n",
            "Epoch 3, Sample 14198: Loss: 0.0405\n",
            "Epoch 3, Sample 14199: Loss: 0.0808\n",
            "Epoch 3, Sample 14200: Loss: 0.0168\n",
            "Epoch 3, Sample 14201: Loss: 0.0590\n",
            "Epoch 3, Sample 14202: Loss: 0.0026\n",
            "Epoch 3, Sample 14203: Loss: 0.2044\n",
            "Epoch 3, Sample 14204: Loss: 0.7036\n",
            "Epoch 3, Sample 14205: Loss: 0.2044\n",
            "Epoch 3, Sample 14206: Loss: 0.1113\n",
            "Epoch 3, Sample 14207: Loss: 0.0025\n",
            "Epoch 3, Sample 14208: Loss: 1.0524\n",
            "Epoch 3, Sample 14209: Loss: 0.0229\n",
            "Epoch 3, Sample 14210: Loss: 0.0538\n",
            "Epoch 3, Sample 14211: Loss: 0.4474\n",
            "Epoch 3, Sample 14212: Loss: 1.0524\n",
            "Epoch 3, Sample 14213: Loss: 0.3949\n",
            "Epoch 3, Sample 14214: Loss: 0.4611\n",
            "Epoch 3, Sample 14215: Loss: 0.5089\n",
            "Epoch 3, Sample 14216: Loss: 1.0524\n",
            "Epoch 3, Sample 14217: Loss: 0.0306\n",
            "Epoch 3, Sample 14218: Loss: 1.4187\n",
            "Epoch 3, Sample 14219: Loss: 0.2034\n",
            "Epoch 3, Sample 14220: Loss: 0.0026\n",
            "Epoch 3, Sample 14221: Loss: 0.0026\n",
            "Epoch 3, Sample 14222: Loss: 0.5793\n",
            "Epoch 3, Sample 14223: Loss: 0.0300\n",
            "Epoch 3, Sample 14224: Loss: 0.6761\n",
            "Epoch 3, Sample 14225: Loss: 0.3949\n",
            "Epoch 3, Sample 14226: Loss: 0.2639\n",
            "Epoch 3, Sample 14227: Loss: 0.2879\n",
            "Epoch 3, Sample 14228: Loss: 0.4663\n",
            "Epoch 3, Sample 14229: Loss: 0.2340\n",
            "Epoch 3, Sample 14230: Loss: 1.0530\n",
            "Epoch 3, Sample 14231: Loss: 0.0915\n",
            "Epoch 3, Sample 14232: Loss: 0.4799\n",
            "Epoch 3, Sample 14233: Loss: 1.0524\n",
            "Epoch 3, Sample 14234: Loss: 0.3399\n",
            "Epoch 3, Sample 14235: Loss: 0.2044\n",
            "Epoch 3, Sample 14236: Loss: 0.8951\n",
            "Epoch 3, Sample 14237: Loss: 0.3399\n",
            "Epoch 3, Sample 14238: Loss: 0.0013\n",
            "Epoch 3, Sample 14239: Loss: 0.1364\n",
            "Epoch 3, Sample 14240: Loss: 0.0633\n",
            "Epoch 3, Sample 14241: Loss: 0.0838\n",
            "Epoch 3, Sample 14242: Loss: 0.0604\n",
            "Epoch 3, Sample 14243: Loss: 0.0604\n",
            "Epoch 3, Sample 14244: Loss: 0.8620\n",
            "Epoch 3, Sample 14245: Loss: 0.2112\n",
            "Epoch 3, Sample 14246: Loss: 0.3779\n",
            "Epoch 3, Sample 14247: Loss: 0.2034\n",
            "Epoch 3, Sample 14248: Loss: 0.4611\n",
            "Epoch 3, Sample 14249: Loss: 0.0318\n",
            "Epoch 3, Sample 14250: Loss: 0.0915\n",
            "Epoch 3, Sample 14251: Loss: 0.4128\n",
            "Epoch 3, Sample 14252: Loss: 0.4930\n",
            "Epoch 3, Sample 14253: Loss: 0.0849\n",
            "Epoch 3, Sample 14254: Loss: 2.1055\n",
            "Epoch 3, Sample 14255: Loss: 0.2759\n",
            "Epoch 3, Sample 14256: Loss: 0.0026\n",
            "Epoch 3, Sample 14257: Loss: 0.3568\n",
            "Epoch 3, Sample 14258: Loss: 0.4158\n",
            "Epoch 3, Sample 14259: Loss: 0.1739\n",
            "Epoch 3, Sample 14260: Loss: 0.0018\n",
            "Epoch 3, Sample 14261: Loss: 0.6990\n",
            "Epoch 3, Sample 14262: Loss: 1.0266\n",
            "Epoch 3, Sample 14263: Loss: 0.2572\n",
            "Epoch 3, Sample 14264: Loss: 0.4382\n",
            "Epoch 3, Sample 14265: Loss: 0.8378\n",
            "Epoch 3, Sample 14266: Loss: 0.1559\n",
            "Epoch 3, Sample 14267: Loss: 0.9166\n",
            "Epoch 3, Sample 14268: Loss: 12.0464\n",
            "Epoch 3, Sample 14269: Loss: 0.0018\n",
            "Epoch 3, Sample 14270: Loss: 0.2832\n",
            "Epoch 3, Sample 14271: Loss: 0.3399\n",
            "Epoch 3, Sample 14272: Loss: 0.2639\n",
            "Epoch 3, Sample 14273: Loss: 0.3775\n",
            "Epoch 3, Sample 14274: Loss: 0.9780\n",
            "Epoch 3, Sample 14275: Loss: 0.0084\n",
            "Epoch 3, Sample 14276: Loss: 0.2792\n",
            "Epoch 3, Sample 14277: Loss: 0.0001\n",
            "Epoch 3, Sample 14278: Loss: 0.0303\n",
            "Epoch 3, Sample 14279: Loss: 0.0114\n",
            "Epoch 3, Sample 14280: Loss: 0.6990\n",
            "Epoch 3, Sample 14281: Loss: 0.5799\n",
            "Epoch 3, Sample 14282: Loss: 0.1186\n",
            "Epoch 3, Sample 14283: Loss: 3.2054\n",
            "Epoch 3, Sample 14284: Loss: 0.0938\n",
            "Epoch 3, Sample 14285: Loss: 0.5003\n",
            "Epoch 3, Sample 14286: Loss: 0.2032\n",
            "Epoch 3, Sample 14287: Loss: 0.1013\n",
            "Epoch 3, Sample 14288: Loss: 0.7453\n",
            "Epoch 3, Sample 14289: Loss: 0.2182\n",
            "Epoch 3, Sample 14290: Loss: 0.2132\n",
            "Epoch 3, Sample 14291: Loss: 0.0026\n",
            "Epoch 3, Sample 14292: Loss: 1.0530\n",
            "Epoch 3, Sample 14293: Loss: 0.0001\n",
            "Epoch 3, Sample 14294: Loss: 0.2034\n",
            "Epoch 3, Sample 14295: Loss: 0.0807\n",
            "Epoch 3, Sample 14296: Loss: 0.4799\n",
            "Epoch 3, Sample 14297: Loss: 0.2044\n",
            "Epoch 3, Sample 14298: Loss: 0.0063\n",
            "Epoch 3, Sample 14299: Loss: 0.0018\n",
            "Epoch 3, Sample 14300: Loss: 0.1170\n",
            "Epoch 3, Sample 14301: Loss: 1.0524\n",
            "Epoch 3, Sample 14302: Loss: 0.5858\n",
            "Epoch 3, Sample 14303: Loss: 1.0524\n",
            "Epoch 3, Sample 14304: Loss: 0.3402\n",
            "Epoch 3, Sample 14305: Loss: 0.0063\n",
            "Epoch 3, Sample 14306: Loss: 1.0524\n",
            "Epoch 3, Sample 14307: Loss: 0.1250\n",
            "Epoch 3, Sample 14308: Loss: 0.5871\n",
            "Epoch 3, Sample 14309: Loss: 0.0469\n",
            "Epoch 3, Sample 14310: Loss: 0.0415\n",
            "Epoch 3, Sample 14311: Loss: 0.3399\n",
            "Epoch 3, Sample 14312: Loss: 0.7036\n",
            "Epoch 3, Sample 14313: Loss: 0.2098\n",
            "Epoch 3, Sample 14314: Loss: 0.8951\n",
            "Epoch 3, Sample 14315: Loss: 0.7179\n",
            "Epoch 3, Sample 14316: Loss: 0.3399\n",
            "Epoch 3, Sample 14317: Loss: 0.4930\n",
            "Epoch 3, Sample 14318: Loss: 0.7036\n",
            "Epoch 3, Sample 14319: Loss: 0.2034\n",
            "Epoch 3, Sample 14320: Loss: 0.0640\n",
            "Epoch 3, Sample 14321: Loss: 0.6304\n",
            "Epoch 3, Sample 14322: Loss: 0.0838\n",
            "Epoch 3, Sample 14323: Loss: 0.0039\n",
            "Epoch 3, Sample 14324: Loss: 0.5858\n",
            "Epoch 3, Sample 14325: Loss: 0.2032\n",
            "Epoch 3, Sample 14326: Loss: 0.1250\n",
            "Epoch 3, Sample 14327: Loss: 0.2639\n",
            "Epoch 3, Sample 14328: Loss: 0.2044\n",
            "Epoch 3, Sample 14329: Loss: 0.5972\n",
            "Epoch 3, Sample 14330: Loss: 0.0070\n",
            "Epoch 3, Sample 14331: Loss: 1.0530\n",
            "Epoch 3, Sample 14332: Loss: 0.0001\n",
            "Epoch 3, Sample 14333: Loss: 0.0439\n",
            "Epoch 3, Sample 14334: Loss: 1.0530\n",
            "Epoch 3, Sample 14335: Loss: 0.0001\n",
            "Epoch 3, Sample 14336: Loss: 0.3129\n",
            "Epoch 3, Sample 14337: Loss: 0.0005\n",
            "Epoch 3, Sample 14338: Loss: 0.6114\n",
            "Epoch 3, Sample 14339: Loss: 1.0524\n",
            "Epoch 3, Sample 14340: Loss: 0.3758\n",
            "Epoch 3, Sample 14341: Loss: 0.3787\n",
            "Epoch 3, Sample 14342: Loss: 0.6304\n",
            "Epoch 3, Sample 14343: Loss: 0.0101\n",
            "Epoch 3, Sample 14344: Loss: 0.0063\n",
            "Epoch 3, Sample 14345: Loss: 0.1770\n",
            "Epoch 3, Sample 14346: Loss: 0.0006\n",
            "Epoch 3, Sample 14347: Loss: 1.0530\n",
            "Epoch 3, Sample 14348: Loss: 0.2639\n",
            "Epoch 3, Sample 14349: Loss: 0.7036\n",
            "Epoch 3, Sample 14350: Loss: 0.1032\n",
            "Epoch 3, Sample 14351: Loss: 0.1508\n",
            "Epoch 3, Sample 14352: Loss: 0.6990\n",
            "Epoch 3, Sample 14353: Loss: 0.0490\n",
            "Epoch 3, Sample 14354: Loss: 2.7699\n",
            "Epoch 3, Sample 14355: Loss: 0.0838\n",
            "Epoch 3, Sample 14356: Loss: 0.1106\n",
            "Epoch 3, Sample 14357: Loss: 1.0524\n",
            "Epoch 3, Sample 14358: Loss: 0.0018\n",
            "Epoch 3, Sample 14359: Loss: 0.4474\n",
            "Epoch 3, Sample 14360: Loss: 0.5252\n",
            "Epoch 3, Sample 14361: Loss: 0.1601\n",
            "Epoch 3, Sample 14362: Loss: 0.7453\n",
            "Epoch 3, Sample 14363: Loss: 0.6304\n",
            "Epoch 3, Sample 14364: Loss: 0.0712\n",
            "Epoch 3, Sample 14365: Loss: 0.0744\n",
            "Epoch 3, Sample 14366: Loss: 0.3393\n",
            "Epoch 3, Sample 14367: Loss: 0.5003\n",
            "Epoch 3, Sample 14368: Loss: 0.6316\n",
            "Epoch 3, Sample 14369: Loss: 0.4466\n",
            "Epoch 3, Sample 14370: Loss: 0.2032\n",
            "Epoch 3, Sample 14371: Loss: 0.1476\n",
            "Epoch 3, Sample 14372: Loss: 0.2044\n",
            "Epoch 3, Sample 14373: Loss: 0.5595\n",
            "Epoch 3, Sample 14374: Loss: 0.5000\n",
            "Epoch 3, Sample 14375: Loss: 0.2759\n",
            "Epoch 3, Sample 14376: Loss: 0.8484\n",
            "Epoch 3, Sample 14377: Loss: 0.9940\n",
            "Epoch 3, Sample 14378: Loss: 0.7036\n",
            "Epoch 3, Sample 14379: Loss: 0.0060\n",
            "Epoch 3, Sample 14380: Loss: 1.0530\n",
            "Epoch 3, Sample 14381: Loss: 0.0630\n",
            "Epoch 3, Sample 14382: Loss: 0.0270\n",
            "Epoch 3, Sample 14383: Loss: 0.2044\n",
            "Epoch 3, Sample 14384: Loss: 0.7161\n",
            "Epoch 3, Sample 14385: Loss: 0.0363\n",
            "Epoch 3, Sample 14386: Loss: 1.0070\n",
            "Epoch 3, Sample 14387: Loss: 0.3332\n",
            "Epoch 3, Sample 14388: Loss: 0.4382\n",
            "Epoch 3, Sample 14389: Loss: 0.3805\n",
            "Epoch 3, Sample 14390: Loss: 0.7036\n",
            "Epoch 3, Sample 14391: Loss: 1.0928\n",
            "Epoch 3, Sample 14392: Loss: 0.1559\n",
            "Epoch 3, Sample 14393: Loss: 0.4575\n",
            "Epoch 3, Sample 14394: Loss: 0.5858\n",
            "Epoch 3, Sample 14395: Loss: 1.4742\n",
            "Epoch 3, Sample 14396: Loss: 0.0051\n",
            "Epoch 3, Sample 14397: Loss: 1.0530\n",
            "Epoch 3, Sample 14398: Loss: 1.0524\n",
            "Epoch 3, Sample 14399: Loss: 0.5155\n",
            "Epoch 3, Sample 14400: Loss: 0.0013\n",
            "Epoch 3, Sample 14401: Loss: 0.2996\n",
            "Epoch 3, Sample 14402: Loss: 0.0026\n",
            "Epoch 3, Sample 14403: Loss: 0.5078\n",
            "Epoch 3, Sample 14404: Loss: 2.5443\n",
            "Epoch 3, Sample 14405: Loss: 1.0524\n",
            "Epoch 3, Sample 14406: Loss: 1.6694\n",
            "Epoch 3, Sample 14407: Loss: 1.0524\n",
            "Epoch 3, Sample 14408: Loss: 0.3399\n",
            "Epoch 3, Sample 14409: Loss: 1.7201\n",
            "Epoch 3, Sample 14410: Loss: 0.0018\n",
            "Epoch 3, Sample 14411: Loss: 0.0026\n",
            "Epoch 3, Sample 14412: Loss: 0.0026\n",
            "Epoch 3, Sample 14413: Loss: 0.2032\n",
            "Epoch 3, Sample 14414: Loss: 2.5380\n",
            "Epoch 3, Sample 14415: Loss: 0.5310\n",
            "Epoch 3, Sample 14416: Loss: 0.3181\n",
            "Epoch 3, Sample 14417: Loss: 2.6683\n",
            "Epoch 3, Sample 14418: Loss: 0.2044\n",
            "Epoch 3, Sample 14419: Loss: 0.0174\n",
            "Epoch 3, Sample 14420: Loss: 0.0001\n",
            "Epoch 3, Sample 14421: Loss: 0.0056\n",
            "Epoch 3, Sample 14422: Loss: 0.2759\n",
            "Epoch 3, Sample 14423: Loss: 0.3332\n",
            "Epoch 3, Sample 14424: Loss: 0.0062\n",
            "Epoch 3, Sample 14425: Loss: 0.4799\n",
            "Epoch 3, Sample 14426: Loss: 0.4474\n",
            "Epoch 3, Sample 14427: Loss: 0.5594\n",
            "Epoch 3, Sample 14428: Loss: 0.4841\n",
            "Epoch 3, Sample 14429: Loss: 0.5266\n",
            "Epoch 3, Sample 14430: Loss: 0.6766\n",
            "Epoch 3, Sample 14431: Loss: 0.0651\n",
            "Epoch 3, Sample 14432: Loss: 0.0707\n",
            "Epoch 3, Sample 14433: Loss: 0.0138\n",
            "Epoch 3, Sample 14434: Loss: 0.0018\n",
            "Epoch 3, Sample 14435: Loss: 1.0530\n",
            "Epoch 3, Sample 14436: Loss: 0.1170\n",
            "Epoch 3, Sample 14437: Loss: 0.2832\n",
            "Epoch 3, Sample 14438: Loss: 0.2034\n",
            "Epoch 3, Sample 14439: Loss: 0.3441\n",
            "Epoch 3, Sample 14440: Loss: 0.0026\n",
            "Epoch 3, Sample 14441: Loss: 0.7453\n",
            "Epoch 3, Sample 14442: Loss: 0.2962\n",
            "Epoch 3, Sample 14443: Loss: 0.1523\n",
            "Epoch 3, Sample 14444: Loss: 0.6304\n",
            "Epoch 3, Sample 14445: Loss: 1.0155\n",
            "Epoch 3, Sample 14446: Loss: 1.4588\n",
            "Epoch 3, Sample 14447: Loss: 0.0026\n",
            "Epoch 3, Sample 14448: Loss: 0.2044\n",
            "Epoch 3, Sample 14449: Loss: 0.7036\n",
            "Epoch 3, Sample 14450: Loss: 0.1559\n",
            "Epoch 3, Sample 14451: Loss: 0.6938\n",
            "Epoch 3, Sample 14452: Loss: 0.1170\n",
            "Epoch 3, Sample 14453: Loss: 0.2032\n",
            "Epoch 3, Sample 14454: Loss: 1.0524\n",
            "Epoch 3, Sample 14455: Loss: 0.2639\n",
            "Epoch 3, Sample 14456: Loss: 0.1559\n",
            "Epoch 3, Sample 14457: Loss: 0.7036\n",
            "Epoch 3, Sample 14458: Loss: 0.2112\n",
            "Epoch 3, Sample 14459: Loss: 4.1377\n",
            "Epoch 3, Sample 14460: Loss: 0.2032\n",
            "Epoch 3, Sample 14461: Loss: 0.2970\n",
            "Epoch 3, Sample 14462: Loss: 1.4842\n",
            "Epoch 3, Sample 14463: Loss: 0.2032\n",
            "Epoch 3, Sample 14464: Loss: 1.0524\n",
            "Epoch 3, Sample 14465: Loss: 0.5290\n",
            "Epoch 3, Sample 14466: Loss: 0.5000\n",
            "Epoch 3, Sample 14467: Loss: 0.1465\n",
            "Epoch 3, Sample 14468: Loss: 0.0026\n",
            "Epoch 3, Sample 14469: Loss: 0.3638\n",
            "Epoch 3, Sample 14470: Loss: 0.2832\n",
            "Epoch 3, Sample 14471: Loss: 0.0707\n",
            "Epoch 3, Sample 14472: Loss: 0.2036\n",
            "Epoch 3, Sample 14473: Loss: 0.5000\n",
            "Epoch 3, Sample 14474: Loss: 0.0725\n",
            "Epoch 3, Sample 14475: Loss: 0.0280\n",
            "Epoch 3, Sample 14476: Loss: 0.0358\n",
            "Epoch 3, Sample 14477: Loss: 0.0554\n",
            "Epoch 3, Sample 14478: Loss: 0.7036\n",
            "Epoch 3, Sample 14479: Loss: 0.0919\n",
            "Epoch 3, Sample 14480: Loss: 0.2704\n",
            "Epoch 3, Sample 14481: Loss: 0.2459\n",
            "Epoch 3, Sample 14482: Loss: 0.0627\n",
            "Epoch 3, Sample 14483: Loss: 0.3756\n",
            "Epoch 3, Sample 14484: Loss: 1.0155\n",
            "Epoch 3, Sample 14485: Loss: 0.0062\n",
            "Epoch 3, Sample 14486: Loss: 0.4799\n",
            "Epoch 3, Sample 14487: Loss: 0.2872\n",
            "Epoch 3, Sample 14488: Loss: 0.0592\n",
            "Epoch 3, Sample 14489: Loss: 0.2014\n",
            "Epoch 3, Sample 14490: Loss: 1.8268\n",
            "Epoch 3, Sample 14491: Loss: 0.0566\n",
            "Epoch 3, Sample 14492: Loss: 0.4032\n",
            "Epoch 3, Sample 14493: Loss: 1.0524\n",
            "Epoch 3, Sample 14494: Loss: 0.0915\n",
            "Epoch 3, Sample 14495: Loss: 1.3072\n",
            "Epoch 3, Sample 14496: Loss: 0.2855\n",
            "Epoch 3, Sample 14497: Loss: 0.5003\n",
            "Epoch 3, Sample 14498: Loss: 1.3933\n",
            "Epoch 3, Sample 14499: Loss: 0.2034\n",
            "Epoch 3, Sample 14500: Loss: 0.1225\n",
            "Epoch 3, Sample 14501: Loss: 0.4799\n",
            "Epoch 3, Sample 14502: Loss: 0.3399\n",
            "Epoch 3, Sample 14503: Loss: 0.0067\n",
            "Epoch 3, Sample 14504: Loss: 2.6211\n",
            "Epoch 3, Sample 14505: Loss: 1.8546\n",
            "Epoch 3, Sample 14506: Loss: 0.2034\n",
            "Epoch 3, Sample 14507: Loss: 1.1103\n",
            "Epoch 3, Sample 14508: Loss: 0.2832\n",
            "Epoch 3, Sample 14509: Loss: 0.8850\n",
            "Epoch 3, Sample 14510: Loss: 0.0001\n",
            "Epoch 3, Sample 14511: Loss: 0.1248\n",
            "Epoch 3, Sample 14512: Loss: 0.5858\n",
            "Epoch 3, Sample 14513: Loss: 0.7036\n",
            "Epoch 3, Sample 14514: Loss: 0.2036\n",
            "Epoch 3, Sample 14515: Loss: 0.0353\n",
            "Epoch 3, Sample 14516: Loss: 0.4799\n",
            "Epoch 3, Sample 14517: Loss: 0.0429\n",
            "Epoch 3, Sample 14518: Loss: 0.1170\n",
            "Epoch 3, Sample 14519: Loss: 0.0000\n",
            "Epoch 3, Sample 14520: Loss: 0.0625\n",
            "Epoch 3, Sample 14521: Loss: 0.8951\n",
            "Epoch 3, Sample 14522: Loss: 0.3506\n",
            "Epoch 3, Sample 14523: Loss: 0.4611\n",
            "Epoch 3, Sample 14524: Loss: 1.0524\n",
            "Epoch 3, Sample 14525: Loss: 0.2639\n",
            "Epoch 3, Sample 14526: Loss: 0.2759\n",
            "Epoch 3, Sample 14527: Loss: 0.7036\n",
            "Epoch 3, Sample 14528: Loss: 0.5585\n",
            "Epoch 3, Sample 14529: Loss: 0.0030\n",
            "Epoch 3, Sample 14530: Loss: 0.4611\n",
            "Epoch 3, Sample 14531: Loss: 0.0258\n",
            "Epoch 3, Sample 14532: Loss: 0.1826\n",
            "Epoch 3, Sample 14533: Loss: 0.3399\n",
            "Epoch 3, Sample 14534: Loss: 0.7036\n",
            "Epoch 3, Sample 14535: Loss: 0.0018\n",
            "Epoch 3, Sample 14536: Loss: 0.0258\n",
            "Epoch 3, Sample 14537: Loss: 1.0530\n",
            "Epoch 3, Sample 14538: Loss: 0.5000\n",
            "Epoch 3, Sample 14539: Loss: 0.0034\n",
            "Epoch 3, Sample 14540: Loss: 0.2044\n",
            "Epoch 3, Sample 14541: Loss: 0.2032\n",
            "Epoch 3, Sample 14542: Loss: 0.3441\n",
            "Epoch 3, Sample 14543: Loss: 1.0524\n",
            "Epoch 3, Sample 14544: Loss: 0.3399\n",
            "Epoch 3, Sample 14545: Loss: 0.2036\n",
            "Epoch 3, Sample 14546: Loss: 0.0018\n",
            "Epoch 3, Sample 14547: Loss: 0.6619\n",
            "Epoch 3, Sample 14548: Loss: 0.3441\n",
            "Epoch 3, Sample 14549: Loss: 0.0000\n",
            "Epoch 3, Sample 14550: Loss: 0.3224\n",
            "Epoch 3, Sample 14551: Loss: 0.1170\n",
            "Epoch 3, Sample 14552: Loss: 0.3598\n",
            "Epoch 3, Sample 14553: Loss: 0.0365\n",
            "Epoch 3, Sample 14554: Loss: 0.2494\n",
            "Epoch 3, Sample 14555: Loss: 0.1250\n",
            "Epoch 3, Sample 14556: Loss: 0.0915\n",
            "Epoch 3, Sample 14557: Loss: 0.0630\n",
            "Epoch 3, Sample 14558: Loss: 0.3758\n",
            "Epoch 3, Sample 14559: Loss: 0.4841\n",
            "Epoch 3, Sample 14560: Loss: 0.0145\n",
            "Epoch 3, Sample 14561: Loss: 0.1989\n",
            "Epoch 3, Sample 14562: Loss: 0.2036\n",
            "Epoch 3, Sample 14563: Loss: 1.0524\n",
            "Epoch 3, Sample 14564: Loss: 0.0018\n",
            "Epoch 3, Sample 14565: Loss: 1.0524\n",
            "Epoch 3, Sample 14566: Loss: 0.3568\n",
            "Epoch 3, Sample 14567: Loss: 1.0530\n",
            "Epoch 3, Sample 14568: Loss: 0.7036\n",
            "Epoch 3, Sample 14569: Loss: 0.0001\n",
            "Epoch 3, Sample 14570: Loss: 1.1982\n",
            "Epoch 3, Sample 14571: Loss: 0.2044\n",
            "Epoch 3, Sample 14572: Loss: 0.2044\n",
            "Epoch 3, Sample 14573: Loss: 0.2044\n",
            "Epoch 3, Sample 14574: Loss: 1.0524\n",
            "Epoch 3, Sample 14575: Loss: 0.0067\n",
            "Epoch 3, Sample 14576: Loss: 0.9460\n",
            "Epoch 3, Sample 14577: Loss: 0.0013\n",
            "Epoch 3, Sample 14578: Loss: 0.7036\n",
            "Epoch 3, Sample 14579: Loss: 0.0999\n",
            "Epoch 3, Sample 14580: Loss: 0.0036\n",
            "Epoch 3, Sample 14581: Loss: 0.0025\n",
            "Epoch 3, Sample 14582: Loss: 0.3949\n",
            "Epoch 3, Sample 14583: Loss: 0.0026\n",
            "Epoch 3, Sample 14584: Loss: 0.2112\n",
            "Epoch 3, Sample 14585: Loss: 0.2044\n",
            "Epoch 3, Sample 14586: Loss: 1.0524\n",
            "Epoch 3, Sample 14587: Loss: 2.4123\n",
            "Epoch 3, Sample 14588: Loss: 0.0212\n",
            "Epoch 3, Sample 14589: Loss: 12.6777\n",
            "Epoch 3, Sample 14590: Loss: 0.1395\n",
            "Epoch 3, Sample 14591: Loss: 0.4858\n",
            "Epoch 3, Sample 14592: Loss: 0.1523\n",
            "Epoch 3, Sample 14593: Loss: 0.8944\n",
            "Epoch 3, Sample 14594: Loss: 0.7036\n",
            "Epoch 3, Sample 14595: Loss: 0.0145\n",
            "Epoch 3, Sample 14596: Loss: 0.4901\n",
            "Epoch 3, Sample 14597: Loss: 1.0421\n",
            "Epoch 3, Sample 14598: Loss: 0.0630\n",
            "Epoch 3, Sample 14599: Loss: 0.2664\n",
            "Epoch 3, Sample 14600: Loss: 0.2339\n",
            "Epoch 3, Sample 14601: Loss: 0.0625\n",
            "Epoch 3, Sample 14602: Loss: 0.3399\n",
            "Epoch 3, Sample 14603: Loss: 1.3983\n",
            "Epoch 3, Sample 14604: Loss: 0.1170\n",
            "Epoch 3, Sample 14605: Loss: 0.1180\n",
            "Epoch 3, Sample 14606: Loss: 0.0788\n",
            "Epoch 3, Sample 14607: Loss: 0.0001\n",
            "Epoch 3, Sample 14608: Loss: 0.1419\n",
            "Epoch 3, Sample 14609: Loss: 0.4930\n",
            "Epoch 3, Sample 14610: Loss: 0.5156\n",
            "Epoch 3, Sample 14611: Loss: 0.0267\n",
            "Epoch 3, Sample 14612: Loss: 0.3036\n",
            "Epoch 3, Sample 14613: Loss: 0.0630\n",
            "Epoch 3, Sample 14614: Loss: 0.0027\n",
            "Epoch 3, Sample 14615: Loss: 0.2034\n",
            "Epoch 3, Sample 14616: Loss: 0.0082\n",
            "Epoch 3, Sample 14617: Loss: 0.0630\n",
            "Epoch 3, Sample 14618: Loss: 0.0018\n",
            "Epoch 3, Sample 14619: Loss: 0.0205\n",
            "Epoch 3, Sample 14620: Loss: 0.2759\n",
            "Epoch 3, Sample 14621: Loss: 0.3441\n",
            "Epoch 3, Sample 14622: Loss: 1.0227\n",
            "Epoch 3, Sample 14623: Loss: 0.2036\n",
            "Epoch 3, Sample 14624: Loss: 0.2032\n",
            "Epoch 3, Sample 14625: Loss: 0.4930\n",
            "Epoch 3, Sample 14626: Loss: 1.0524\n",
            "Epoch 3, Sample 14627: Loss: 0.2032\n",
            "Epoch 3, Sample 14628: Loss: 0.7036\n",
            "Epoch 3, Sample 14629: Loss: 0.1337\n",
            "Epoch 3, Sample 14630: Loss: 0.0026\n",
            "Epoch 3, Sample 14631: Loss: 1.1312\n",
            "Epoch 3, Sample 14632: Loss: 2.8243\n",
            "Epoch 3, Sample 14633: Loss: 0.2034\n",
            "Epoch 3, Sample 14634: Loss: 0.6990\n",
            "Epoch 3, Sample 14635: Loss: 0.1248\n",
            "Epoch 3, Sample 14636: Loss: 0.3399\n",
            "Epoch 3, Sample 14637: Loss: 0.3243\n",
            "Epoch 3, Sample 14638: Loss: 0.0630\n",
            "Epoch 3, Sample 14639: Loss: 0.9064\n",
            "Epoch 3, Sample 14640: Loss: 0.0915\n",
            "Epoch 3, Sample 14641: Loss: 1.2924\n",
            "Epoch 3, Sample 14642: Loss: 0.1559\n",
            "Epoch 3, Sample 14643: Loss: 0.7399\n",
            "Epoch 3, Sample 14644: Loss: 0.0026\n",
            "Epoch 3, Sample 14645: Loss: 0.2340\n",
            "Epoch 3, Sample 14646: Loss: 5.7798\n",
            "Epoch 3, Sample 14647: Loss: 0.1301\n",
            "Epoch 3, Sample 14648: Loss: 0.2032\n",
            "Epoch 3, Sample 14649: Loss: 1.1569\n",
            "Epoch 3, Sample 14650: Loss: 0.0013\n",
            "Epoch 3, Sample 14651: Loss: 0.0018\n",
            "Epoch 3, Sample 14652: Loss: 0.4477\n",
            "Epoch 3, Sample 14653: Loss: 1.0155\n",
            "Epoch 3, Sample 14654: Loss: 0.0819\n",
            "Epoch 3, Sample 14655: Loss: 0.7036\n",
            "Epoch 3, Sample 14656: Loss: 0.1092\n",
            "Epoch 3, Sample 14657: Loss: 0.2034\n",
            "Epoch 3, Sample 14658: Loss: 0.1817\n",
            "Epoch 3, Sample 14659: Loss: 0.8484\n",
            "Epoch 3, Sample 14660: Loss: 0.2032\n",
            "Epoch 3, Sample 14661: Loss: 0.2044\n",
            "Epoch 3, Sample 14662: Loss: 0.1296\n",
            "Epoch 3, Sample 14663: Loss: 0.0034\n",
            "Epoch 3, Sample 14664: Loss: 0.8473\n",
            "Epoch 3, Sample 14665: Loss: 0.4918\n",
            "Epoch 3, Sample 14666: Loss: 0.1588\n",
            "Epoch 3, Sample 14667: Loss: 0.2044\n",
            "Epoch 3, Sample 14668: Loss: 0.7036\n",
            "Epoch 3, Sample 14669: Loss: 1.5854\n",
            "Epoch 3, Sample 14670: Loss: 0.4996\n",
            "Epoch 3, Sample 14671: Loss: 0.0026\n",
            "Epoch 3, Sample 14672: Loss: 0.8951\n",
            "Epoch 3, Sample 14673: Loss: 0.1250\n",
            "Epoch 3, Sample 14674: Loss: 0.1555\n",
            "Epoch 3, Sample 14675: Loss: 0.2112\n",
            "Epoch 3, Sample 14676: Loss: 0.0072\n",
            "Epoch 3, Sample 14677: Loss: 0.2639\n",
            "Epoch 3, Sample 14678: Loss: 0.1555\n",
            "Epoch 3, Sample 14679: Loss: 0.0838\n",
            "Epoch 3, Sample 14680: Loss: 0.0938\n",
            "Epoch 3, Sample 14681: Loss: 0.3399\n",
            "Epoch 3, Sample 14682: Loss: 1.0524\n",
            "Epoch 3, Sample 14683: Loss: 0.3726\n",
            "Epoch 3, Sample 14684: Loss: 0.0947\n",
            "Epoch 3, Sample 14685: Loss: 0.1588\n",
            "Epoch 3, Sample 14686: Loss: 0.0108\n",
            "Epoch 3, Sample 14687: Loss: 0.2494\n",
            "Epoch 3, Sample 14688: Loss: 0.1559\n",
            "Epoch 3, Sample 14689: Loss: 0.0001\n",
            "Epoch 3, Sample 14690: Loss: 2.7331\n",
            "Epoch 3, Sample 14691: Loss: 0.0630\n",
            "Epoch 3, Sample 14692: Loss: 1.2422\n",
            "Epoch 3, Sample 14693: Loss: 1.0155\n",
            "Epoch 3, Sample 14694: Loss: 0.5871\n",
            "Epoch 3, Sample 14695: Loss: 0.5000\n",
            "Epoch 3, Sample 14696: Loss: 0.0018\n",
            "Epoch 3, Sample 14697: Loss: 0.5278\n",
            "Epoch 3, Sample 14698: Loss: 0.0630\n",
            "Epoch 3, Sample 14699: Loss: 0.2044\n",
            "Epoch 3, Sample 14700: Loss: 0.0152\n",
            "Epoch 3, Sample 14701: Loss: 0.2044\n",
            "Epoch 3, Sample 14702: Loss: 0.2639\n",
            "Epoch 3, Sample 14703: Loss: 0.1170\n",
            "Epoch 3, Sample 14704: Loss: 0.1250\n",
            "Epoch 3, Sample 14705: Loss: 0.7036\n",
            "Epoch 3, Sample 14706: Loss: 0.8992\n",
            "Epoch 3, Sample 14707: Loss: 1.0524\n",
            "Epoch 3, Sample 14708: Loss: 0.1250\n",
            "Epoch 3, Sample 14709: Loss: 0.0213\n",
            "Epoch 3, Sample 14710: Loss: 1.0227\n",
            "Epoch 3, Sample 14711: Loss: 1.0524\n",
            "Epoch 3, Sample 14712: Loss: 0.2704\n",
            "Epoch 3, Sample 14713: Loss: 0.1337\n",
            "Epoch 3, Sample 14714: Loss: 0.1250\n",
            "Epoch 3, Sample 14715: Loss: 0.2044\n",
            "Epoch 3, Sample 14716: Loss: 0.0138\n",
            "Epoch 3, Sample 14717: Loss: 0.4930\n",
            "Epoch 3, Sample 14718: Loss: 2.0103\n",
            "Epoch 3, Sample 14719: Loss: 0.0022\n",
            "Epoch 3, Sample 14720: Loss: 0.0630\n",
            "Epoch 3, Sample 14721: Loss: 0.2851\n",
            "Epoch 3, Sample 14722: Loss: 0.2044\n",
            "Epoch 3, Sample 14723: Loss: 0.0000\n",
            "Epoch 3, Sample 14724: Loss: 0.1252\n",
            "Epoch 3, Sample 14725: Loss: 0.7036\n",
            "Epoch 3, Sample 14726: Loss: 0.6092\n",
            "Epoch 3, Sample 14727: Loss: 0.2759\n",
            "Epoch 3, Sample 14728: Loss: 1.0524\n",
            "Epoch 3, Sample 14729: Loss: 0.5220\n",
            "Epoch 3, Sample 14730: Loss: 0.0184\n",
            "Epoch 3, Sample 14731: Loss: 0.0036\n",
            "Epoch 3, Sample 14732: Loss: 0.1378\n",
            "Epoch 3, Sample 14733: Loss: 0.0915\n",
            "Epoch 3, Sample 14734: Loss: 0.0009\n",
            "Epoch 3, Sample 14735: Loss: 0.7036\n",
            "Epoch 3, Sample 14736: Loss: 0.5858\n",
            "Epoch 3, Sample 14737: Loss: 0.0212\n",
            "Epoch 3, Sample 14738: Loss: 0.1523\n",
            "Epoch 3, Sample 14739: Loss: 0.0026\n",
            "Epoch 3, Sample 14740: Loss: 0.4032\n",
            "Epoch 3, Sample 14741: Loss: 0.7034\n",
            "Epoch 3, Sample 14742: Loss: 0.0838\n",
            "Epoch 3, Sample 14743: Loss: 0.7036\n",
            "Epoch 3, Sample 14744: Loss: 0.5150\n",
            "Epoch 3, Sample 14745: Loss: 0.2759\n",
            "Epoch 3, Sample 14746: Loss: 0.3441\n",
            "Epoch 3, Sample 14747: Loss: 1.0705\n",
            "Epoch 3, Sample 14748: Loss: 0.1337\n",
            "Epoch 3, Sample 14749: Loss: 0.5871\n",
            "Epoch 3, Sample 14750: Loss: 0.7453\n",
            "Epoch 3, Sample 14751: Loss: 0.0207\n",
            "Epoch 3, Sample 14752: Loss: 0.3399\n",
            "Epoch 3, Sample 14753: Loss: 0.0270\n",
            "Epoch 3, Sample 14754: Loss: 0.2639\n",
            "Epoch 3, Sample 14755: Loss: 0.0026\n",
            "Epoch 3, Sample 14756: Loss: 0.0213\n",
            "Epoch 3, Sample 14757: Loss: 0.0869\n",
            "Epoch 3, Sample 14758: Loss: 0.1125\n",
            "Epoch 3, Sample 14759: Loss: 1.1388\n",
            "Epoch 3, Sample 14760: Loss: 0.6998\n",
            "Epoch 3, Sample 14761: Loss: 0.0363\n",
            "Epoch 3, Sample 14762: Loss: 0.5196\n",
            "Epoch 3, Sample 14763: Loss: 0.2034\n",
            "Epoch 3, Sample 14764: Loss: 1.0266\n",
            "Epoch 3, Sample 14765: Loss: 0.0303\n",
            "Epoch 3, Sample 14766: Loss: 0.6617\n",
            "Epoch 3, Sample 14767: Loss: 0.0306\n",
            "Epoch 3, Sample 14768: Loss: 1.5970\n",
            "Epoch 3, Sample 14769: Loss: 1.6405\n",
            "Epoch 3, Sample 14770: Loss: 0.2962\n",
            "Epoch 3, Sample 14771: Loss: 0.7036\n",
            "Epoch 3, Sample 14772: Loss: 0.1250\n",
            "Epoch 3, Sample 14773: Loss: 0.3399\n",
            "Epoch 3, Sample 14774: Loss: 1.0155\n",
            "Epoch 3, Sample 14775: Loss: 0.0031\n",
            "Epoch 3, Sample 14776: Loss: 1.0524\n",
            "Epoch 3, Sample 14777: Loss: 0.2219\n",
            "Epoch 3, Sample 14778: Loss: 0.7036\n",
            "Epoch 3, Sample 14779: Loss: 0.0060\n",
            "Epoch 3, Sample 14780: Loss: 0.1199\n",
            "Epoch 3, Sample 14781: Loss: 0.7252\n",
            "Epoch 3, Sample 14782: Loss: 0.0025\n",
            "Epoch 3, Sample 14783: Loss: 0.1248\n",
            "Epoch 3, Sample 14784: Loss: 0.2044\n",
            "Epoch 3, Sample 14785: Loss: 0.0084\n",
            "Epoch 3, Sample 14786: Loss: 0.1170\n",
            "Epoch 3, Sample 14787: Loss: 0.0205\n",
            "Epoch 3, Sample 14788: Loss: 0.0915\n",
            "Epoch 3, Sample 14789: Loss: 0.5858\n",
            "Epoch 3, Sample 14790: Loss: 0.1250\n",
            "Epoch 3, Sample 14791: Loss: 0.0000\n",
            "Epoch 3, Sample 14792: Loss: 1.0530\n",
            "Epoch 3, Sample 14793: Loss: 0.2086\n",
            "Epoch 3, Sample 14794: Loss: 1.3992\n",
            "Epoch 3, Sample 14795: Loss: 0.5972\n",
            "Epoch 3, Sample 14796: Loss: 0.3399\n",
            "Epoch 3, Sample 14797: Loss: 0.2558\n",
            "Epoch 3, Sample 14798: Loss: 0.0006\n",
            "Epoch 3, Sample 14799: Loss: 1.0155\n",
            "Epoch 3, Sample 14800: Loss: 0.1615\n",
            "Epoch 3, Sample 14801: Loss: 0.2044\n",
            "Epoch 3, Sample 14802: Loss: 0.6990\n",
            "Epoch 3, Sample 14803: Loss: 0.3182\n",
            "Epoch 3, Sample 14804: Loss: 0.0630\n",
            "Epoch 3, Sample 14805: Loss: 0.0088\n",
            "Epoch 3, Sample 14806: Loss: 0.8484\n",
            "Epoch 3, Sample 14807: Loss: 0.2034\n",
            "Epoch 3, Sample 14808: Loss: 0.2032\n",
            "Epoch 3, Sample 14809: Loss: 0.2759\n",
            "Epoch 3, Sample 14810: Loss: 0.1250\n",
            "Epoch 3, Sample 14811: Loss: 1.0524\n",
            "Epoch 3, Sample 14812: Loss: 1.0155\n",
            "Epoch 3, Sample 14813: Loss: 0.7561\n",
            "Epoch 3, Sample 14814: Loss: 0.0417\n",
            "Epoch 3, Sample 14815: Loss: 0.2989\n",
            "Epoch 3, Sample 14816: Loss: 0.0014\n",
            "Epoch 3, Sample 14817: Loss: 1.0266\n",
            "Epoch 3, Sample 14818: Loss: 0.0838\n",
            "Epoch 3, Sample 14819: Loss: 0.2219\n",
            "Epoch 3, Sample 14820: Loss: 0.3402\n",
            "Epoch 3, Sample 14821: Loss: 0.3445\n",
            "Epoch 3, Sample 14822: Loss: 0.2759\n",
            "Epoch 3, Sample 14823: Loss: 1.0524\n",
            "Epoch 3, Sample 14824: Loss: 0.3949\n",
            "Epoch 3, Sample 14825: Loss: 0.5172\n",
            "Epoch 3, Sample 14826: Loss: 0.5336\n",
            "Epoch 3, Sample 14827: Loss: 0.3660\n",
            "Epoch 3, Sample 14828: Loss: 0.2892\n",
            "Epoch 3, Sample 14829: Loss: 0.7036\n",
            "Epoch 3, Sample 14830: Loss: 0.5458\n",
            "Epoch 3, Sample 14831: Loss: 5.5067\n",
            "Epoch 3, Sample 14832: Loss: 0.0133\n",
            "Epoch 3, Sample 14833: Loss: 0.7453\n",
            "Epoch 3, Sample 14834: Loss: 0.3441\n",
            "Epoch 3, Sample 14835: Loss: 0.1674\n",
            "Epoch 3, Sample 14836: Loss: 0.0554\n",
            "Epoch 3, Sample 14837: Loss: 0.4382\n",
            "Epoch 3, Sample 14838: Loss: 0.2044\n",
            "Epoch 3, Sample 14839: Loss: 0.3399\n",
            "Epoch 3, Sample 14840: Loss: 0.6139\n",
            "Epoch 3, Sample 14841: Loss: 1.0524\n",
            "Epoch 3, Sample 14842: Loss: 0.3441\n",
            "Epoch 3, Sample 14843: Loss: 0.9785\n",
            "Epoch 3, Sample 14844: Loss: 19.9570\n",
            "Epoch 3, Sample 14845: Loss: 0.0313\n",
            "Epoch 3, Sample 14846: Loss: 0.2639\n",
            "Epoch 3, Sample 14847: Loss: 0.0001\n",
            "Epoch 3, Sample 14848: Loss: 0.0453\n",
            "Epoch 3, Sample 14849: Loss: 0.0008\n",
            "Epoch 3, Sample 14850: Loss: 1.0155\n",
            "Epoch 3, Sample 14851: Loss: 0.0026\n",
            "Epoch 3, Sample 14852: Loss: 0.2036\n",
            "Epoch 3, Sample 14853: Loss: 0.0026\n",
            "Epoch 3, Sample 14854: Loss: 0.1440\n",
            "Epoch 3, Sample 14855: Loss: 0.0018\n",
            "Epoch 3, Sample 14856: Loss: 0.0042\n",
            "Epoch 3, Sample 14857: Loss: 0.2832\n",
            "Epoch 3, Sample 14858: Loss: 0.2281\n",
            "Epoch 3, Sample 14859: Loss: 0.0108\n",
            "Epoch 3, Sample 14860: Loss: 0.1782\n",
            "Epoch 3, Sample 14861: Loss: 0.0597\n",
            "Epoch 3, Sample 14862: Loss: 0.3399\n",
            "Epoch 3, Sample 14863: Loss: 1.0359\n",
            "Epoch 3, Sample 14864: Loss: 0.3441\n",
            "Epoch 3, Sample 14865: Loss: 0.0391\n",
            "Epoch 3, Sample 14866: Loss: 0.0477\n",
            "Epoch 3, Sample 14867: Loss: 1.0530\n",
            "Epoch 3, Sample 14868: Loss: 0.0380\n",
            "Epoch 3, Sample 14869: Loss: 2.2596\n",
            "Epoch 3, Sample 14870: Loss: 0.0005\n",
            "Epoch 3, Sample 14871: Loss: 0.2282\n",
            "Epoch 3, Sample 14872: Loss: 0.8951\n",
            "Epoch 3, Sample 14873: Loss: 0.0013\n",
            "Epoch 3, Sample 14874: Loss: 0.0265\n",
            "Epoch 3, Sample 14875: Loss: 0.4607\n",
            "Epoch 3, Sample 14876: Loss: 0.1559\n",
            "Epoch 3, Sample 14877: Loss: 0.0018\n",
            "Epoch 3, Sample 14878: Loss: 0.9367\n",
            "Epoch 3, Sample 14879: Loss: 0.0626\n",
            "Epoch 3, Sample 14880: Loss: 0.7453\n",
            "Epoch 3, Sample 14881: Loss: 0.1248\n",
            "Epoch 3, Sample 14882: Loss: 0.3126\n",
            "Epoch 3, Sample 14883: Loss: 0.5000\n",
            "Epoch 3, Sample 14884: Loss: 0.2036\n",
            "Epoch 3, Sample 14885: Loss: 1.0530\n",
            "Epoch 3, Sample 14886: Loss: 0.1170\n",
            "Epoch 3, Sample 14887: Loss: 0.2044\n",
            "Epoch 3, Sample 14888: Loss: 0.4032\n",
            "Epoch 3, Sample 14889: Loss: 0.3441\n",
            "Epoch 3, Sample 14890: Loss: 0.3399\n",
            "Epoch 3, Sample 14891: Loss: 0.0938\n",
            "Epoch 3, Sample 14892: Loss: 0.7036\n",
            "Epoch 3, Sample 14893: Loss: 3.2472\n",
            "Epoch 3, Sample 14894: Loss: 0.0077\n",
            "Epoch 3, Sample 14895: Loss: 0.0286\n",
            "Epoch 3, Sample 14896: Loss: 0.0034\n",
            "Epoch 3, Sample 14897: Loss: 0.6092\n",
            "Epoch 3, Sample 14898: Loss: 1.0524\n",
            "Epoch 3, Sample 14899: Loss: 1.4187\n",
            "Epoch 3, Sample 14900: Loss: 0.3949\n",
            "Epoch 3, Sample 14901: Loss: 0.6867\n",
            "Epoch 3, Sample 14902: Loss: 0.1056\n",
            "Epoch 3, Sample 14903: Loss: 0.0026\n",
            "Epoch 3, Sample 14904: Loss: 0.3758\n",
            "Epoch 3, Sample 14905: Loss: 1.0524\n",
            "Epoch 3, Sample 14906: Loss: 0.0704\n",
            "Epoch 3, Sample 14907: Loss: 0.2112\n",
            "Epoch 3, Sample 14908: Loss: 0.4644\n",
            "Epoch 3, Sample 14909: Loss: 1.0155\n",
            "Epoch 3, Sample 14910: Loss: 0.0018\n",
            "Epoch 3, Sample 14911: Loss: 0.2044\n",
            "Epoch 3, Sample 14912: Loss: 0.0026\n",
            "Epoch 3, Sample 14913: Loss: 0.0205\n",
            "Epoch 3, Sample 14914: Loss: 0.1260\n",
            "Epoch 3, Sample 14915: Loss: 0.5003\n",
            "Epoch 3, Sample 14916: Loss: 0.0363\n",
            "Epoch 3, Sample 14917: Loss: 0.6990\n",
            "Epoch 3, Sample 14918: Loss: 0.3441\n",
            "Epoch 3, Sample 14919: Loss: 1.8284\n",
            "Epoch 3, Sample 14920: Loss: 0.2032\n",
            "Epoch 3, Sample 14921: Loss: 0.0150\n",
            "Epoch 3, Sample 14922: Loss: 0.1170\n",
            "Epoch 3, Sample 14923: Loss: 0.0062\n",
            "Epoch 3, Sample 14924: Loss: 0.0200\n",
            "Epoch 3, Sample 14925: Loss: 0.0626\n",
            "Epoch 3, Sample 14926: Loss: 0.0001\n",
            "Epoch 3, Sample 14927: Loss: 0.6304\n",
            "Epoch 3, Sample 14928: Loss: 0.0025\n",
            "Epoch 3, Sample 14929: Loss: 1.4289\n",
            "Epoch 3, Sample 14930: Loss: 0.0018\n",
            "Epoch 3, Sample 14931: Loss: 0.0802\n",
            "Epoch 3, Sample 14932: Loss: 0.3399\n",
            "Epoch 3, Sample 14933: Loss: 0.0108\n",
            "Epoch 3, Sample 14934: Loss: 0.2962\n",
            "Epoch 3, Sample 14935: Loss: 0.0066\n",
            "Epoch 3, Sample 14936: Loss: 0.3441\n",
            "Epoch 3, Sample 14937: Loss: 0.2182\n",
            "Epoch 3, Sample 14938: Loss: 0.0013\n",
            "Epoch 3, Sample 14939: Loss: 0.3399\n",
            "Epoch 3, Sample 14940: Loss: 0.6304\n",
            "Epoch 3, Sample 14941: Loss: 0.8182\n",
            "Epoch 3, Sample 14942: Loss: 0.1170\n",
            "Epoch 3, Sample 14943: Loss: 1.0530\n",
            "Epoch 3, Sample 14944: Loss: 0.0022\n",
            "Epoch 3, Sample 14945: Loss: 0.3399\n",
            "Epoch 3, Sample 14946: Loss: 0.4607\n",
            "Epoch 3, Sample 14947: Loss: 0.0630\n",
            "Epoch 3, Sample 14948: Loss: 0.2639\n",
            "Epoch 3, Sample 14949: Loss: 0.0062\n",
            "Epoch 3, Sample 14950: Loss: 0.5858\n",
            "Epoch 3, Sample 14951: Loss: 0.0084\n",
            "Epoch 3, Sample 14952: Loss: 0.0258\n",
            "Epoch 3, Sample 14953: Loss: 0.1397\n",
            "Epoch 3, Sample 14954: Loss: 0.2559\n",
            "Epoch 3, Sample 14955: Loss: 0.1559\n",
            "Epoch 3, Sample 14956: Loss: 0.2032\n",
            "Epoch 3, Sample 14957: Loss: 0.6345\n",
            "Epoch 3, Sample 14958: Loss: 0.3399\n",
            "Epoch 3, Sample 14959: Loss: 0.0988\n",
            "Epoch 3, Sample 14960: Loss: 2.0829\n",
            "Epoch 3, Sample 14961: Loss: 0.2219\n",
            "Epoch 3, Sample 14962: Loss: 0.1186\n",
            "Epoch 3, Sample 14963: Loss: 0.2044\n",
            "Epoch 3, Sample 14964: Loss: 0.0030\n",
            "Epoch 3, Sample 14965: Loss: 0.7036\n",
            "Epoch 3, Sample 14966: Loss: 0.0712\n",
            "Epoch 3, Sample 14967: Loss: 0.1252\n",
            "Epoch 3, Sample 14968: Loss: 0.0026\n",
            "Epoch 3, Sample 14969: Loss: 2.0108\n",
            "Epoch 3, Sample 14970: Loss: 0.0080\n",
            "Epoch 3, Sample 14971: Loss: 0.5003\n",
            "Epoch 3, Sample 14972: Loss: 0.0466\n",
            "Epoch 3, Sample 14973: Loss: 0.1246\n",
            "Epoch 3, Sample 14974: Loss: 1.0524\n",
            "Epoch 3, Sample 14975: Loss: 0.5042\n",
            "Epoch 3, Sample 14976: Loss: 0.0466\n",
            "Epoch 3, Sample 14977: Loss: 1.0524\n",
            "Epoch 3, Sample 14978: Loss: 0.2931\n",
            "Epoch 3, Sample 14979: Loss: 0.0026\n",
            "Epoch 3, Sample 14980: Loss: 0.0026\n",
            "Epoch 3, Sample 14981: Loss: 0.4799\n",
            "Epoch 3, Sample 14982: Loss: 0.8484\n",
            "Epoch 3, Sample 14983: Loss: 0.4930\n",
            "Epoch 3, Sample 14984: Loss: 1.0155\n",
            "Epoch 3, Sample 14985: Loss: 0.0026\n",
            "Epoch 3, Sample 14986: Loss: 0.0026\n",
            "Epoch 3, Sample 14987: Loss: 0.7613\n",
            "Epoch 3, Sample 14988: Loss: 1.0688\n",
            "Epoch 3, Sample 14989: Loss: 0.0942\n",
            "Epoch 3, Sample 14990: Loss: 0.0181\n",
            "Epoch 3, Sample 14991: Loss: 0.1225\n",
            "Epoch 3, Sample 14992: Loss: 1.0524\n",
            "Epoch 3, Sample 14993: Loss: 0.9785\n",
            "Epoch 3, Sample 14994: Loss: 0.4611\n",
            "Epoch 3, Sample 14995: Loss: 0.6990\n",
            "Epoch 3, Sample 14996: Loss: 0.4641\n",
            "Epoch 3, Sample 14997: Loss: 0.6990\n",
            "Epoch 3, Sample 14998: Loss: 0.6867\n",
            "Epoch 3, Sample 14999: Loss: 0.0992\n",
            "Epoch 3, Sample 15000: Loss: 0.3949\n",
            "Epoch 3, Sample 15001: Loss: 0.0018\n",
            "Epoch 3, Sample 15002: Loss: 0.2832\n",
            "Epoch 3, Sample 15003: Loss: 0.1364\n",
            "Epoch 3, Sample 15004: Loss: 0.2182\n",
            "Epoch 3, Sample 15005: Loss: 0.0024\n",
            "Epoch 3, Sample 15006: Loss: 0.1964\n",
            "Epoch 3, Sample 15007: Loss: 0.2032\n",
            "Epoch 3, Sample 15008: Loss: 0.2044\n",
            "Epoch 3, Sample 15009: Loss: 0.2219\n",
            "Epoch 3, Sample 15010: Loss: 0.3949\n",
            "Epoch 3, Sample 15011: Loss: 0.4930\n",
            "Epoch 3, Sample 15012: Loss: 0.2044\n",
            "Epoch 3, Sample 15013: Loss: 0.0006\n",
            "Epoch 3, Sample 15014: Loss: 1.0524\n",
            "Epoch 3, Sample 15015: Loss: 0.3399\n",
            "Epoch 3, Sample 15016: Loss: 0.0018\n",
            "Epoch 3, Sample 15017: Loss: 1.0524\n",
            "Epoch 3, Sample 15018: Loss: 0.7702\n",
            "Epoch 3, Sample 15019: Loss: 0.0101\n",
            "Epoch 3, Sample 15020: Loss: 2.6113\n",
            "Epoch 3, Sample 15021: Loss: 0.3402\n",
            "Epoch 3, Sample 15022: Loss: 0.7702\n",
            "Epoch 3, Sample 15023: Loss: 0.2044\n",
            "Epoch 3, Sample 15024: Loss: 0.1622\n",
            "Epoch 3, Sample 15025: Loss: 1.0155\n",
            "Epoch 3, Sample 15026: Loss: 0.0303\n",
            "Epoch 3, Sample 15027: Loss: 0.0001\n",
            "Epoch 3, Sample 15028: Loss: 0.0088\n",
            "Epoch 3, Sample 15029: Loss: 0.1039\n",
            "Epoch 3, Sample 15030: Loss: 1.0155\n",
            "Epoch 3, Sample 15031: Loss: 2.9673\n",
            "Epoch 3, Sample 15032: Loss: 0.0536\n",
            "Epoch 3, Sample 15033: Loss: 0.3332\n",
            "Epoch 3, Sample 15034: Loss: 0.0026\n",
            "Epoch 3, Sample 15035: Loss: 0.6990\n",
            "Epoch 3, Sample 15036: Loss: 0.1225\n",
            "Epoch 3, Sample 15037: Loss: 0.0679\n",
            "Epoch 3, Sample 15038: Loss: 0.0076\n",
            "Epoch 3, Sample 15039: Loss: 0.2034\n",
            "Epoch 3, Sample 15040: Loss: 0.5858\n",
            "Epoch 3, Sample 15041: Loss: 0.8951\n",
            "Epoch 3, Sample 15042: Loss: 1.0524\n",
            "Epoch 3, Sample 15043: Loss: 0.1581\n",
            "Epoch 3, Sample 15044: Loss: 0.0034\n",
            "Epoch 3, Sample 15045: Loss: 8.9184\n",
            "Epoch 3, Sample 15046: Loss: 1.0524\n",
            "Epoch 3, Sample 15047: Loss: 0.0026\n",
            "Epoch 3, Sample 15048: Loss: 1.5113\n",
            "Epoch 3, Sample 15049: Loss: 0.2558\n",
            "Epoch 3, Sample 15050: Loss: 0.7036\n",
            "Epoch 3, Sample 15051: Loss: 1.0524\n",
            "Epoch 3, Sample 15052: Loss: 0.1040\n",
            "Epoch 3, Sample 15053: Loss: 0.0439\n",
            "Epoch 3, Sample 15054: Loss: 0.2034\n",
            "Epoch 3, Sample 15055: Loss: 0.3399\n",
            "Epoch 3, Sample 15056: Loss: 0.4111\n",
            "Epoch 3, Sample 15057: Loss: 0.3984\n",
            "Epoch 3, Sample 15058: Loss: 9.8818\n",
            "Epoch 3, Sample 15059: Loss: 0.2044\n",
            "Epoch 3, Sample 15060: Loss: 0.4311\n",
            "Epoch 3, Sample 15061: Loss: 1.0898\n",
            "Epoch 3, Sample 15062: Loss: 0.3399\n",
            "Epoch 3, Sample 15063: Loss: 0.2865\n",
            "Epoch 3, Sample 15064: Loss: 0.1364\n",
            "Epoch 3, Sample 15065: Loss: 0.0254\n",
            "Epoch 3, Sample 15066: Loss: 0.3441\n",
            "Epoch 3, Sample 15067: Loss: 0.2032\n",
            "Epoch 3, Sample 15068: Loss: 0.2036\n",
            "Epoch 3, Sample 15069: Loss: 0.1250\n",
            "Epoch 3, Sample 15070: Loss: 1.0530\n",
            "Epoch 3, Sample 15071: Loss: 0.0026\n",
            "Epoch 3, Sample 15072: Loss: 1.6506\n",
            "Epoch 3, Sample 15073: Loss: 0.0642\n",
            "Epoch 3, Sample 15074: Loss: 0.4032\n",
            "Epoch 3, Sample 15075: Loss: 2.1313\n",
            "Epoch 3, Sample 15076: Loss: 0.4799\n",
            "Epoch 3, Sample 15077: Loss: 0.7036\n",
            "Epoch 3, Sample 15078: Loss: 0.1408\n",
            "Epoch 3, Sample 15079: Loss: 0.0912\n",
            "Epoch 3, Sample 15080: Loss: 0.2832\n",
            "Epoch 3, Sample 15081: Loss: 0.1170\n",
            "Epoch 3, Sample 15082: Loss: 0.2935\n",
            "Epoch 3, Sample 15083: Loss: 0.0000\n",
            "Epoch 3, Sample 15084: Loss: 0.0025\n",
            "Epoch 3, Sample 15085: Loss: 0.1055\n",
            "Epoch 3, Sample 15086: Loss: 0.3332\n",
            "Epoch 3, Sample 15087: Loss: 0.0157\n",
            "Epoch 3, Sample 15088: Loss: 0.3441\n",
            "Epoch 3, Sample 15089: Loss: 0.2032\n",
            "Epoch 3, Sample 15090: Loss: 0.0001\n",
            "Epoch 3, Sample 15091: Loss: 0.0637\n",
            "Epoch 3, Sample 15092: Loss: 0.0361\n",
            "Epoch 3, Sample 15093: Loss: 0.6990\n",
            "Epoch 3, Sample 15094: Loss: 0.0026\n",
            "Epoch 3, Sample 15095: Loss: 0.5000\n",
            "Epoch 3, Sample 15096: Loss: 0.0604\n",
            "Epoch 3, Sample 15097: Loss: 0.0026\n",
            "Epoch 3, Sample 15098: Loss: 0.8803\n",
            "Epoch 3, Sample 15099: Loss: 0.0306\n",
            "Epoch 3, Sample 15100: Loss: 0.0026\n",
            "Epoch 3, Sample 15101: Loss: 0.1899\n",
            "Epoch 3, Sample 15102: Loss: 0.7702\n",
            "Epoch 3, Sample 15103: Loss: 0.3949\n",
            "Epoch 3, Sample 15104: Loss: 1.0524\n",
            "Epoch 3, Sample 15105: Loss: 0.5003\n",
            "Epoch 3, Sample 15106: Loss: 0.2044\n",
            "Epoch 3, Sample 15107: Loss: 1.0155\n",
            "Epoch 3, Sample 15108: Loss: 0.0843\n",
            "Epoch 3, Sample 15109: Loss: 0.1248\n",
            "Epoch 3, Sample 15110: Loss: 1.0524\n",
            "Epoch 3, Sample 15111: Loss: 1.0953\n",
            "Epoch 3, Sample 15112: Loss: 0.0005\n",
            "Epoch 3, Sample 15113: Loss: 0.4107\n",
            "Epoch 3, Sample 15114: Loss: 1.8616\n",
            "Epoch 3, Sample 15115: Loss: 3.4549\n",
            "Epoch 3, Sample 15116: Loss: 0.0714\n",
            "Epoch 3, Sample 15117: Loss: 0.3441\n",
            "Epoch 3, Sample 15118: Loss: 1.0688\n",
            "Epoch 3, Sample 15119: Loss: 0.1170\n",
            "Epoch 3, Sample 15120: Loss: 1.0524\n",
            "Epoch 3, Sample 15121: Loss: 1.0524\n",
            "Epoch 3, Sample 15122: Loss: 0.0018\n",
            "Epoch 3, Sample 15123: Loss: 0.1627\n",
            "Epoch 3, Sample 15124: Loss: 0.4898\n",
            "Epoch 3, Sample 15125: Loss: 0.0630\n",
            "Epoch 3, Sample 15126: Loss: 0.0466\n",
            "Epoch 3, Sample 15127: Loss: 1.0539\n",
            "Epoch 3, Sample 15128: Loss: 0.2044\n",
            "Epoch 3, Sample 15129: Loss: 0.2034\n",
            "Epoch 3, Sample 15130: Loss: 0.4799\n",
            "Epoch 3, Sample 15131: Loss: 0.2759\n",
            "Epoch 3, Sample 15132: Loss: 0.1225\n",
            "Epoch 3, Sample 15133: Loss: 0.8145\n",
            "Epoch 3, Sample 15134: Loss: 0.0001\n",
            "Epoch 3, Sample 15135: Loss: 0.2086\n",
            "Epoch 3, Sample 15136: Loss: 0.2962\n",
            "Epoch 3, Sample 15137: Loss: 0.3872\n",
            "Epoch 3, Sample 15138: Loss: 0.4339\n",
            "Epoch 3, Sample 15139: Loss: 1.0524\n",
            "Epoch 3, Sample 15140: Loss: 0.3568\n",
            "Epoch 3, Sample 15141: Loss: 0.2044\n",
            "Epoch 3, Sample 15142: Loss: 1.0524\n",
            "Epoch 3, Sample 15143: Loss: 0.0023\n",
            "Epoch 3, Sample 15144: Loss: 0.0001\n",
            "Epoch 3, Sample 15145: Loss: 1.2671\n",
            "Epoch 3, Sample 15146: Loss: 1.0524\n",
            "Epoch 3, Sample 15147: Loss: 0.0026\n",
            "Epoch 3, Sample 15148: Loss: 0.6092\n",
            "Epoch 3, Sample 15149: Loss: 3.9353\n",
            "Epoch 3, Sample 15150: Loss: 0.2862\n",
            "Epoch 3, Sample 15151: Loss: 0.7036\n",
            "Epoch 3, Sample 15152: Loss: 0.5078\n",
            "Epoch 3, Sample 15153: Loss: 0.0625\n",
            "Epoch 3, Sample 15154: Loss: 0.1114\n",
            "Epoch 3, Sample 15155: Loss: 0.7036\n",
            "Epoch 3, Sample 15156: Loss: 0.0062\n",
            "Epoch 3, Sample 15157: Loss: 0.1252\n",
            "Epoch 3, Sample 15158: Loss: 0.0150\n",
            "Epoch 3, Sample 15159: Loss: 0.0476\n",
            "Epoch 3, Sample 15160: Loss: 1.2009\n",
            "Epoch 3, Sample 15161: Loss: 0.0258\n",
            "Epoch 3, Sample 15162: Loss: 0.4930\n",
            "Epoch 3, Sample 15163: Loss: 1.0524\n",
            "Epoch 3, Sample 15164: Loss: 0.0401\n",
            "Epoch 3, Sample 15165: Loss: 0.4588\n",
            "Epoch 3, Sample 15166: Loss: 0.1246\n",
            "Epoch 3, Sample 15167: Loss: 0.2759\n",
            "Epoch 3, Sample 15168: Loss: 0.2941\n",
            "Epoch 3, Sample 15169: Loss: 0.1924\n",
            "Epoch 3, Sample 15170: Loss: 0.5858\n",
            "Epoch 3, Sample 15171: Loss: 0.0000\n",
            "Epoch 3, Sample 15172: Loss: 1.3325\n",
            "Epoch 3, Sample 15173: Loss: 0.6058\n",
            "Epoch 3, Sample 15174: Loss: 0.0001\n",
            "Epoch 3, Sample 15175: Loss: 0.1523\n",
            "Epoch 3, Sample 15176: Loss: 0.3367\n",
            "Epoch 3, Sample 15177: Loss: 1.0524\n",
            "Epoch 3, Sample 15178: Loss: 0.3399\n",
            "Epoch 3, Sample 15179: Loss: 0.4032\n",
            "Epoch 3, Sample 15180: Loss: 0.0743\n",
            "Epoch 3, Sample 15181: Loss: 0.2034\n",
            "Epoch 3, Sample 15182: Loss: 0.1170\n",
            "Epoch 3, Sample 15183: Loss: 0.0018\n",
            "Epoch 3, Sample 15184: Loss: 0.6990\n",
            "Epoch 3, Sample 15185: Loss: 0.0212\n",
            "Epoch 3, Sample 15186: Loss: 0.4799\n",
            "Epoch 3, Sample 15187: Loss: 0.2494\n",
            "Epoch 3, Sample 15188: Loss: 0.1185\n",
            "Epoch 3, Sample 15189: Loss: 0.2301\n",
            "Epoch 3, Sample 15190: Loss: 1.0530\n",
            "Epoch 3, Sample 15191: Loss: 0.2044\n",
            "Epoch 3, Sample 15192: Loss: 0.2032\n",
            "Epoch 3, Sample 15193: Loss: 0.2032\n",
            "Epoch 3, Sample 15194: Loss: 0.2219\n",
            "Epoch 3, Sample 15195: Loss: 14.1743\n",
            "Epoch 3, Sample 15196: Loss: 0.4996\n",
            "Epoch 3, Sample 15197: Loss: 0.6304\n",
            "Epoch 3, Sample 15198: Loss: 0.0915\n",
            "Epoch 3, Sample 15199: Loss: 0.1170\n",
            "Epoch 3, Sample 15200: Loss: 1.0530\n",
            "Epoch 3, Sample 15201: Loss: 0.0049\n",
            "Epoch 3, Sample 15202: Loss: 0.1248\n",
            "Epoch 3, Sample 15203: Loss: 0.2132\n",
            "Epoch 3, Sample 15204: Loss: 0.2034\n",
            "Epoch 3, Sample 15205: Loss: 1.2892\n",
            "Epoch 3, Sample 15206: Loss: 0.0915\n",
            "Epoch 3, Sample 15207: Loss: 0.2219\n",
            "Epoch 3, Sample 15208: Loss: 0.7279\n",
            "Epoch 3, Sample 15209: Loss: 0.6743\n",
            "Epoch 3, Sample 15210: Loss: 0.0084\n",
            "Epoch 3, Sample 15211: Loss: 0.3949\n",
            "Epoch 3, Sample 15212: Loss: 0.1875\n",
            "Epoch 3, Sample 15213: Loss: 0.2112\n",
            "Epoch 3, Sample 15214: Loss: 0.3399\n",
            "Epoch 3, Sample 15215: Loss: 1.0524\n",
            "Epoch 3, Sample 15216: Loss: 0.3477\n",
            "Epoch 3, Sample 15217: Loss: 0.0415\n",
            "Epoch 3, Sample 15218: Loss: 0.0815\n",
            "Epoch 3, Sample 15219: Loss: 1.7054\n",
            "Epoch 3, Sample 15220: Loss: 0.1146\n",
            "Epoch 3, Sample 15221: Loss: 0.2759\n",
            "Epoch 3, Sample 15222: Loss: 0.3399\n",
            "Epoch 3, Sample 15223: Loss: 0.4240\n",
            "Epoch 3, Sample 15224: Loss: 0.2034\n",
            "Epoch 3, Sample 15225: Loss: 0.0630\n",
            "Epoch 3, Sample 15226: Loss: 0.0212\n",
            "Epoch 3, Sample 15227: Loss: 0.0005\n",
            "Epoch 3, Sample 15228: Loss: 1.0524\n",
            "Epoch 3, Sample 15229: Loss: 0.8387\n",
            "Epoch 3, Sample 15230: Loss: 0.2034\n",
            "Epoch 3, Sample 15231: Loss: 0.1559\n",
            "Epoch 3, Sample 15232: Loss: 0.0802\n",
            "Epoch 3, Sample 15233: Loss: 0.0938\n",
            "Epoch 3, Sample 15234: Loss: 0.1817\n",
            "Epoch 3, Sample 15235: Loss: 1.0524\n",
            "Epoch 3, Sample 15236: Loss: 0.2452\n",
            "Epoch 3, Sample 15237: Loss: 0.0517\n",
            "Epoch 3, Sample 15238: Loss: 1.0524\n",
            "Epoch 3, Sample 15239: Loss: 0.3949\n",
            "Epoch 3, Sample 15240: Loss: 0.0751\n",
            "Epoch 3, Sample 15241: Loss: 0.4607\n",
            "Epoch 3, Sample 15242: Loss: 0.3441\n",
            "Epoch 3, Sample 15243: Loss: 1.0524\n",
            "Epoch 3, Sample 15244: Loss: 0.1472\n",
            "Epoch 3, Sample 15245: Loss: 0.1170\n",
            "Epoch 3, Sample 15246: Loss: 0.7036\n",
            "Epoch 3, Sample 15247: Loss: 1.0642\n",
            "Epoch 3, Sample 15248: Loss: 0.2032\n",
            "Epoch 3, Sample 15249: Loss: 0.8951\n",
            "Epoch 3, Sample 15250: Loss: 1.0524\n",
            "Epoch 3, Sample 15251: Loss: 0.2034\n",
            "Epoch 3, Sample 15252: Loss: 0.1276\n",
            "Epoch 3, Sample 15253: Loss: 0.0026\n",
            "Epoch 3, Sample 15254: Loss: 0.6139\n",
            "Epoch 3, Sample 15255: Loss: 1.9820\n",
            "Epoch 3, Sample 15256: Loss: 1.0155\n",
            "Epoch 3, Sample 15257: Loss: 0.0067\n",
            "Epoch 3, Sample 15258: Loss: 0.1039\n",
            "Epoch 3, Sample 15259: Loss: 0.2759\n",
            "Epoch 3, Sample 15260: Loss: 0.5858\n",
            "Epoch 3, Sample 15261: Loss: 0.3441\n",
            "Epoch 3, Sample 15262: Loss: 1.0524\n",
            "Epoch 3, Sample 15263: Loss: 1.0530\n",
            "Epoch 3, Sample 15264: Loss: 0.4611\n",
            "Epoch 3, Sample 15265: Loss: 0.2759\n",
            "Epoch 3, Sample 15266: Loss: 0.0337\n",
            "Epoch 3, Sample 15267: Loss: 0.5636\n",
            "Epoch 3, Sample 15268: Loss: 0.2032\n",
            "Epoch 3, Sample 15269: Loss: 0.0682\n",
            "Epoch 3, Sample 15270: Loss: 0.0416\n",
            "Epoch 3, Sample 15271: Loss: 0.0026\n",
            "Epoch 3, Sample 15272: Loss: 1.0524\n",
            "Epoch 3, Sample 15273: Loss: 0.0000\n",
            "Epoch 3, Sample 15274: Loss: 0.2032\n",
            "Epoch 3, Sample 15275: Loss: 0.3034\n",
            "Epoch 3, Sample 15276: Loss: 0.1170\n",
            "Epoch 3, Sample 15277: Loss: 0.1661\n",
            "Epoch 3, Sample 15278: Loss: 0.1968\n",
            "Epoch 3, Sample 15279: Loss: 0.1264\n",
            "Epoch 3, Sample 15280: Loss: 0.2878\n",
            "Epoch 3, Sample 15281: Loss: 1.1569\n",
            "Epoch 3, Sample 15282: Loss: 0.0945\n",
            "Epoch 3, Sample 15283: Loss: 0.3418\n",
            "Epoch 3, Sample 15284: Loss: 0.1084\n",
            "Epoch 3, Sample 15285: Loss: 0.5048\n",
            "Epoch 3, Sample 15286: Loss: 0.0270\n",
            "Epoch 3, Sample 15287: Loss: 0.2996\n",
            "Epoch 3, Sample 15288: Loss: 0.3441\n",
            "Epoch 3, Sample 15289: Loss: 0.2044\n",
            "Epoch 3, Sample 15290: Loss: 0.0376\n",
            "Epoch 3, Sample 15291: Loss: 0.2034\n",
            "Epoch 3, Sample 15292: Loss: 0.2034\n",
            "Epoch 3, Sample 15293: Loss: 0.4799\n",
            "Epoch 3, Sample 15294: Loss: 0.1036\n",
            "Epoch 3, Sample 15295: Loss: 0.0025\n",
            "Epoch 3, Sample 15296: Loss: 0.2036\n",
            "Epoch 3, Sample 15297: Loss: 0.1397\n",
            "Epoch 3, Sample 15298: Loss: 0.1170\n",
            "Epoch 3, Sample 15299: Loss: 0.9785\n",
            "Epoch 3, Sample 15300: Loss: 0.0732\n",
            "Epoch 3, Sample 15301: Loss: 0.0015\n",
            "Epoch 3, Sample 15302: Loss: 0.0170\n",
            "Epoch 3, Sample 15303: Loss: 0.0001\n",
            "Epoch 3, Sample 15304: Loss: 0.7512\n",
            "Epoch 3, Sample 15305: Loss: 0.3238\n",
            "Epoch 3, Sample 15306: Loss: 0.3399\n",
            "Epoch 3, Sample 15307: Loss: 0.0626\n",
            "Epoch 3, Sample 15308: Loss: 0.1465\n",
            "Epoch 3, Sample 15309: Loss: 0.0819\n",
            "Epoch 3, Sample 15310: Loss: 10.3220\n",
            "Epoch 3, Sample 15311: Loss: 0.0466\n",
            "Epoch 3, Sample 15312: Loss: 1.0524\n",
            "Epoch 3, Sample 15313: Loss: 0.2639\n",
            "Epoch 3, Sample 15314: Loss: 0.3288\n",
            "Epoch 3, Sample 15315: Loss: 0.3477\n",
            "Epoch 3, Sample 15316: Loss: 0.6990\n",
            "Epoch 3, Sample 15317: Loss: 0.2044\n",
            "Epoch 3, Sample 15318: Loss: 0.4193\n",
            "Epoch 3, Sample 15319: Loss: 0.0079\n",
            "Epoch 3, Sample 15320: Loss: 1.0524\n",
            "Epoch 3, Sample 15321: Loss: 0.5799\n",
            "Epoch 3, Sample 15322: Loss: 0.4996\n",
            "Epoch 3, Sample 15323: Loss: 1.0155\n",
            "Epoch 3, Sample 15324: Loss: 0.0802\n",
            "Epoch 3, Sample 15325: Loss: 1.0524\n",
            "Epoch 3, Sample 15326: Loss: 0.0082\n",
            "Epoch 3, Sample 15327: Loss: 0.2032\n",
            "Epoch 3, Sample 15328: Loss: 0.3399\n",
            "Epoch 3, Sample 15329: Loss: 1.0524\n",
            "Epoch 3, Sample 15330: Loss: 1.0524\n",
            "Epoch 3, Sample 15331: Loss: 0.2034\n",
            "Epoch 3, Sample 15332: Loss: 0.0189\n",
            "Epoch 3, Sample 15333: Loss: 0.1546\n",
            "Epoch 3, Sample 15334: Loss: 0.1005\n",
            "Epoch 3, Sample 15335: Loss: 0.0018\n",
            "Epoch 3, Sample 15336: Loss: 0.0001\n",
            "Epoch 3, Sample 15337: Loss: 7.2439\n",
            "Epoch 3, Sample 15338: Loss: 0.0630\n",
            "Epoch 3, Sample 15339: Loss: 0.1039\n",
            "Epoch 3, Sample 15340: Loss: 0.0460\n",
            "Epoch 3, Sample 15341: Loss: 0.0270\n",
            "Epoch 3, Sample 15342: Loss: 0.7203\n",
            "Epoch 3, Sample 15343: Loss: 0.0640\n",
            "Epoch 3, Sample 15344: Loss: 0.7036\n",
            "Epoch 3, Sample 15345: Loss: 1.0524\n",
            "Epoch 3, Sample 15346: Loss: 0.3115\n",
            "Epoch 3, Sample 15347: Loss: 0.0426\n",
            "Epoch 3, Sample 15348: Loss: 0.0003\n",
            "Epoch 3, Sample 15349: Loss: 0.1246\n",
            "Epoch 3, Sample 15350: Loss: 0.2219\n",
            "Epoch 3, Sample 15351: Loss: 0.2036\n",
            "Epoch 3, Sample 15352: Loss: 0.0796\n",
            "Epoch 3, Sample 15353: Loss: 0.1559\n",
            "Epoch 3, Sample 15354: Loss: 1.0524\n",
            "Epoch 3, Sample 15355: Loss: 0.3949\n",
            "Epoch 3, Sample 15356: Loss: 0.1170\n",
            "Epoch 3, Sample 15357: Loss: 0.2488\n",
            "Epoch 3, Sample 15358: Loss: 0.0286\n",
            "Epoch 3, Sample 15359: Loss: 0.3399\n",
            "Epoch 3, Sample 15360: Loss: 1.7082\n",
            "Epoch 3, Sample 15361: Loss: 0.0001\n",
            "Epoch 3, Sample 15362: Loss: 0.3399\n",
            "Epoch 3, Sample 15363: Loss: 4.2335\n",
            "Epoch 3, Sample 15364: Loss: 1.5542\n",
            "Epoch 3, Sample 15365: Loss: 0.6990\n",
            "Epoch 3, Sample 15366: Loss: 0.1027\n",
            "Epoch 3, Sample 15367: Loss: 0.2759\n",
            "Epoch 3, Sample 15368: Loss: 0.3598\n",
            "Epoch 3, Sample 15369: Loss: 0.0915\n",
            "Epoch 3, Sample 15370: Loss: 0.7036\n",
            "Epoch 3, Sample 15371: Loss: 0.1246\n",
            "Epoch 3, Sample 15372: Loss: 0.5481\n",
            "Epoch 3, Sample 15373: Loss: 1.0530\n",
            "Epoch 3, Sample 15374: Loss: 0.2044\n",
            "Epoch 3, Sample 15375: Loss: 0.2044\n",
            "Epoch 3, Sample 15376: Loss: 0.0532\n",
            "Epoch 3, Sample 15377: Loss: 9.7806\n",
            "Epoch 3, Sample 15378: Loss: 0.6990\n",
            "Epoch 3, Sample 15379: Loss: 0.2044\n",
            "Epoch 3, Sample 15380: Loss: 0.1989\n",
            "Epoch 3, Sample 15381: Loss: 1.0524\n",
            "Epoch 3, Sample 15382: Loss: 0.5058\n",
            "Epoch 3, Sample 15383: Loss: 0.0005\n",
            "Epoch 3, Sample 15384: Loss: 0.3367\n",
            "Epoch 3, Sample 15385: Loss: 0.5000\n",
            "Epoch 3, Sample 15386: Loss: 0.9367\n",
            "Epoch 3, Sample 15387: Loss: 1.1015\n",
            "Epoch 3, Sample 15388: Loss: 4.4048\n",
            "Epoch 3, Sample 15389: Loss: 0.0063\n",
            "Epoch 3, Sample 15390: Loss: 1.0524\n",
            "Epoch 3, Sample 15391: Loss: 0.0008\n",
            "Epoch 3, Sample 15392: Loss: 0.4799\n",
            "Epoch 3, Sample 15393: Loss: 0.2778\n",
            "Epoch 3, Sample 15394: Loss: 0.0630\n",
            "Epoch 3, Sample 15395: Loss: 0.0063\n",
            "Epoch 3, Sample 15396: Loss: 0.0230\n",
            "Epoch 3, Sample 15397: Loss: 0.6092\n",
            "Epoch 3, Sample 15398: Loss: 0.9011\n",
            "Epoch 3, Sample 15399: Loss: 0.4996\n",
            "Epoch 3, Sample 15400: Loss: 0.0103\n",
            "Epoch 3, Sample 15401: Loss: 0.4717\n",
            "Epoch 3, Sample 15402: Loss: 1.0530\n",
            "Epoch 3, Sample 15403: Loss: 0.0001\n",
            "Epoch 3, Sample 15404: Loss: 0.0026\n",
            "Epoch 3, Sample 15405: Loss: 0.3617\n",
            "Epoch 3, Sample 15406: Loss: 0.5000\n",
            "Epoch 3, Sample 15407: Loss: 0.0838\n",
            "Epoch 3, Sample 15408: Loss: 0.0460\n",
            "Epoch 3, Sample 15409: Loss: 0.0001\n",
            "Epoch 3, Sample 15410: Loss: 0.1171\n",
            "Epoch 3, Sample 15411: Loss: 0.0572\n",
            "Epoch 3, Sample 15412: Loss: 0.7036\n",
            "Epoch 3, Sample 15413: Loss: 0.7453\n",
            "Epoch 3, Sample 15414: Loss: 0.2032\n",
            "Epoch 3, Sample 15415: Loss: 1.0524\n",
            "Epoch 3, Sample 15416: Loss: 0.7486\n",
            "Epoch 3, Sample 15417: Loss: 0.1170\n",
            "Epoch 3, Sample 15418: Loss: 0.5799\n",
            "Epoch 3, Sample 15419: Loss: 0.0120\n",
            "Epoch 3, Sample 15420: Loss: 0.5078\n",
            "Epoch 3, Sample 15421: Loss: 0.0261\n",
            "Epoch 3, Sample 15422: Loss: 1.0524\n",
            "Epoch 3, Sample 15423: Loss: 0.3062\n",
            "Epoch 3, Sample 15424: Loss: 0.1284\n",
            "Epoch 3, Sample 15425: Loss: 0.2032\n",
            "Epoch 3, Sample 15426: Loss: 0.0018\n",
            "Epoch 3, Sample 15427: Loss: 0.5422\n",
            "Epoch 3, Sample 15428: Loss: 0.0088\n",
            "Epoch 3, Sample 15429: Loss: 0.2329\n",
            "Epoch 3, Sample 15430: Loss: 0.2953\n",
            "Epoch 3, Sample 15431: Loss: 0.0013\n",
            "Epoch 3, Sample 15432: Loss: 0.4032\n",
            "Epoch 3, Sample 15433: Loss: 0.0915\n",
            "Epoch 3, Sample 15434: Loss: 0.2639\n",
            "Epoch 3, Sample 15435: Loss: 0.4258\n",
            "Epoch 3, Sample 15436: Loss: 0.0286\n",
            "Epoch 3, Sample 15437: Loss: 0.2809\n",
            "Epoch 3, Sample 15438: Loss: 0.8951\n",
            "Epoch 3, Sample 15439: Loss: 0.1588\n",
            "Epoch 3, Sample 15440: Loss: 0.1326\n",
            "Epoch 3, Sample 15441: Loss: 1.0524\n",
            "Epoch 3, Sample 15442: Loss: 0.5858\n",
            "Epoch 3, Sample 15443: Loss: 0.1309\n",
            "Epoch 3, Sample 15444: Loss: 0.2639\n",
            "Epoch 3, Sample 15445: Loss: 0.0149\n",
            "Epoch 3, Sample 15446: Loss: 1.0530\n",
            "Epoch 3, Sample 15447: Loss: 6.9441\n",
            "Epoch 3, Sample 15448: Loss: 0.2044\n",
            "Epoch 3, Sample 15449: Loss: 0.1170\n",
            "Epoch 3, Sample 15450: Loss: 0.1482\n",
            "Epoch 3, Sample 15451: Loss: 0.3399\n",
            "Epoch 3, Sample 15452: Loss: 0.3332\n",
            "Epoch 3, Sample 15453: Loss: 0.0625\n",
            "Epoch 3, Sample 15454: Loss: 0.7036\n",
            "Epoch 3, Sample 15455: Loss: 0.6775\n",
            "Epoch 3, Sample 15456: Loss: 0.0834\n",
            "Epoch 3, Sample 15457: Loss: 0.0213\n",
            "Epoch 3, Sample 15458: Loss: 0.0044\n",
            "Epoch 3, Sample 15459: Loss: 0.7036\n",
            "Epoch 3, Sample 15460: Loss: 1.3612\n",
            "Epoch 3, Sample 15461: Loss: 0.0630\n",
            "Epoch 3, Sample 15462: Loss: 0.0062\n",
            "Epoch 3, Sample 15463: Loss: 0.0483\n",
            "Epoch 3, Sample 15464: Loss: 0.3450\n",
            "Epoch 3, Sample 15465: Loss: 1.1052\n",
            "Epoch 3, Sample 15466: Loss: 0.0630\n",
            "Epoch 3, Sample 15467: Loss: 0.2044\n",
            "Epoch 3, Sample 15468: Loss: 0.5058\n",
            "Epoch 3, Sample 15469: Loss: 0.1472\n",
            "Epoch 3, Sample 15470: Loss: 0.2034\n",
            "Epoch 3, Sample 15471: Loss: 0.1417\n",
            "Epoch 3, Sample 15472: Loss: 0.4930\n",
            "Epoch 3, Sample 15473: Loss: 0.1559\n",
            "Epoch 3, Sample 15474: Loss: 0.0082\n",
            "Epoch 3, Sample 15475: Loss: 0.8951\n",
            "Epoch 3, Sample 15476: Loss: 0.9786\n",
            "Epoch 3, Sample 15477: Loss: 0.3584\n",
            "Epoch 3, Sample 15478: Loss: 1.0155\n",
            "Epoch 3, Sample 15479: Loss: 0.0220\n",
            "Epoch 3, Sample 15480: Loss: 0.5003\n",
            "Epoch 3, Sample 15481: Loss: 1.0155\n",
            "Epoch 3, Sample 15482: Loss: 0.7036\n",
            "Epoch 3, Sample 15483: Loss: 0.0313\n",
            "Epoch 3, Sample 15484: Loss: 0.6867\n",
            "Epoch 3, Sample 15485: Loss: 0.1399\n",
            "Epoch 3, Sample 15486: Loss: 0.3332\n",
            "Epoch 3, Sample 15487: Loss: 0.0640\n",
            "Epoch 3, Sample 15488: Loss: 0.2608\n",
            "Epoch 3, Sample 15489: Loss: 0.3418\n",
            "Epoch 3, Sample 15490: Loss: 0.0005\n",
            "Epoch 3, Sample 15491: Loss: 1.0524\n",
            "Epoch 3, Sample 15492: Loss: 1.0227\n",
            "Epoch 3, Sample 15493: Loss: 0.5000\n",
            "Epoch 3, Sample 15494: Loss: 0.5871\n",
            "Epoch 3, Sample 15495: Loss: 0.1225\n",
            "Epoch 3, Sample 15496: Loss: 0.0022\n",
            "Epoch 3, Sample 15497: Loss: 0.2355\n",
            "Epoch 3, Sample 15498: Loss: 0.1401\n",
            "Epoch 3, Sample 15499: Loss: 0.0018\n",
            "Epoch 3, Sample 15500: Loss: 1.0524\n",
            "Epoch 3, Sample 15501: Loss: 0.0001\n",
            "Epoch 3, Sample 15502: Loss: 0.7453\n",
            "Epoch 3, Sample 15503: Loss: 0.3718\n",
            "Epoch 3, Sample 15504: Loss: 0.2759\n",
            "Epoch 3, Sample 15505: Loss: 0.1738\n",
            "Epoch 3, Sample 15506: Loss: 2.4061\n",
            "Epoch 3, Sample 15507: Loss: 0.0270\n",
            "Epoch 3, Sample 15508: Loss: 0.4882\n",
            "Epoch 3, Sample 15509: Loss: 0.9367\n",
            "Epoch 3, Sample 15510: Loss: 1.0524\n",
            "Epoch 3, Sample 15511: Loss: 0.0018\n",
            "Epoch 3, Sample 15512: Loss: 0.2832\n",
            "Epoch 3, Sample 15513: Loss: 0.7036\n",
            "Epoch 3, Sample 15514: Loss: 2.7833\n",
            "Epoch 3, Sample 15515: Loss: 0.0364\n",
            "Epoch 3, Sample 15516: Loss: 0.0018\n",
            "Epoch 3, Sample 15517: Loss: 0.3441\n",
            "Epoch 3, Sample 15518: Loss: 0.2832\n",
            "Epoch 3, Sample 15519: Loss: 0.2175\n",
            "Epoch 3, Sample 15520: Loss: 0.2032\n",
            "Epoch 3, Sample 15521: Loss: 0.0240\n",
            "Epoch 3, Sample 15522: Loss: 0.0005\n",
            "Epoch 3, Sample 15523: Loss: 0.7036\n",
            "Epoch 3, Sample 15524: Loss: 0.3441\n",
            "Epoch 3, Sample 15525: Loss: 0.0212\n",
            "Epoch 3, Sample 15526: Loss: 1.0530\n",
            "Epoch 3, Sample 15527: Loss: 0.0212\n",
            "Epoch 3, Sample 15528: Loss: 0.2373\n",
            "Epoch 3, Sample 15529: Loss: 0.7036\n",
            "Epoch 3, Sample 15530: Loss: 2.2981\n",
            "Epoch 3, Sample 15531: Loss: 0.2704\n",
            "Epoch 3, Sample 15532: Loss: 0.1010\n",
            "Epoch 3, Sample 15533: Loss: 0.1588\n",
            "Epoch 3, Sample 15534: Loss: 0.3949\n",
            "Epoch 3, Sample 15535: Loss: 2.1901\n",
            "Epoch 3, Sample 15536: Loss: 0.1397\n",
            "Epoch 3, Sample 15537: Loss: 2.2545\n",
            "Epoch 3, Sample 15538: Loss: 1.0524\n",
            "Epoch 3, Sample 15539: Loss: 0.1546\n",
            "Epoch 3, Sample 15540: Loss: 0.0501\n",
            "Epoch 3, Sample 15541: Loss: 0.2851\n",
            "Epoch 3, Sample 15542: Loss: 0.3402\n",
            "Epoch 3, Sample 15543: Loss: 0.2759\n",
            "Epoch 3, Sample 15544: Loss: 0.2044\n",
            "Epoch 3, Sample 15545: Loss: 0.9367\n",
            "Epoch 3, Sample 15546: Loss: 0.2639\n",
            "Epoch 3, Sample 15547: Loss: 1.0524\n",
            "Epoch 3, Sample 15548: Loss: 0.1250\n",
            "Epoch 3, Sample 15549: Loss: 3.5704\n",
            "Epoch 3, Sample 15550: Loss: 0.0270\n",
            "Epoch 3, Sample 15551: Loss: 0.2962\n",
            "Epoch 3, Sample 15552: Loss: 1.0406\n",
            "Epoch 3, Sample 15553: Loss: 0.1244\n",
            "Epoch 3, Sample 15554: Loss: 0.8951\n",
            "Epoch 3, Sample 15555: Loss: 0.2759\n",
            "Epoch 3, Sample 15556: Loss: 0.2218\n",
            "Epoch 3, Sample 15557: Loss: 1.0266\n",
            "Epoch 3, Sample 15558: Loss: 0.0026\n",
            "Epoch 3, Sample 15559: Loss: 0.2157\n",
            "Epoch 3, Sample 15560: Loss: 1.0524\n",
            "Epoch 3, Sample 15561: Loss: 0.0145\n",
            "Epoch 3, Sample 15562: Loss: 0.3441\n",
            "Epoch 3, Sample 15563: Loss: 0.0026\n",
            "Epoch 3, Sample 15564: Loss: 0.1250\n",
            "Epoch 3, Sample 15565: Loss: 1.0524\n",
            "Epoch 3, Sample 15566: Loss: 0.1559\n",
            "Epoch 3, Sample 15567: Loss: 0.5163\n",
            "Epoch 3, Sample 15568: Loss: 0.2032\n",
            "Epoch 3, Sample 15569: Loss: 0.0915\n",
            "Epoch 3, Sample 15570: Loss: 0.2759\n",
            "Epoch 3, Sample 15571: Loss: 1.0524\n",
            "Epoch 3, Sample 15572: Loss: 0.3758\n",
            "Epoch 3, Sample 15573: Loss: 0.6139\n",
            "Epoch 3, Sample 15574: Loss: 1.0524\n",
            "Epoch 3, Sample 15575: Loss: 0.0018\n",
            "Epoch 3, Sample 15576: Loss: 1.1789\n",
            "Epoch 3, Sample 15577: Loss: 0.0543\n",
            "Epoch 3, Sample 15578: Loss: 0.0437\n",
            "Epoch 3, Sample 15579: Loss: 1.0524\n",
            "Epoch 3, Sample 15580: Loss: 0.2044\n",
            "Epoch 3, Sample 15581: Loss: 0.0122\n",
            "Epoch 3, Sample 15582: Loss: 0.2759\n",
            "Epoch 3, Sample 15583: Loss: 0.0630\n",
            "Epoch 3, Sample 15584: Loss: 0.1170\n",
            "Epoch 3, Sample 15585: Loss: 0.0001\n",
            "Epoch 3, Sample 15586: Loss: 0.2036\n",
            "Epoch 3, Sample 15587: Loss: 0.0018\n",
            "Epoch 3, Sample 15588: Loss: 1.0530\n",
            "Epoch 3, Sample 15589: Loss: 1.0524\n",
            "Epoch 3, Sample 15590: Loss: 1.5379\n",
            "Epoch 3, Sample 15591: Loss: 0.0568\n",
            "Epoch 3, Sample 15592: Loss: 0.0505\n",
            "Epoch 3, Sample 15593: Loss: 0.5165\n",
            "Epoch 3, Sample 15594: Loss: 0.4611\n",
            "Epoch 3, Sample 15595: Loss: 0.0630\n",
            "Epoch 3, Sample 15596: Loss: 1.0524\n",
            "Epoch 3, Sample 15597: Loss: 0.5320\n",
            "Epoch 3, Sample 15598: Loss: 0.8673\n",
            "Epoch 3, Sample 15599: Loss: 0.1248\n",
            "Epoch 3, Sample 15600: Loss: 0.2879\n",
            "Epoch 3, Sample 15601: Loss: 0.2832\n",
            "Epoch 3, Sample 15602: Loss: 0.1482\n",
            "Epoch 3, Sample 15603: Loss: 0.1250\n",
            "Epoch 3, Sample 15604: Loss: 0.9651\n",
            "Epoch 3, Sample 15605: Loss: 0.3247\n",
            "Epoch 3, Sample 15606: Loss: 1.0524\n",
            "Epoch 3, Sample 15607: Loss: 0.1924\n",
            "Epoch 3, Sample 15608: Loss: 3.0038\n",
            "Epoch 3, Sample 15609: Loss: 0.0026\n",
            "Epoch 3, Sample 15610: Loss: 0.4466\n",
            "Epoch 3, Sample 15611: Loss: 1.0524\n",
            "Epoch 3, Sample 15612: Loss: 0.7036\n",
            "Epoch 3, Sample 15613: Loss: 0.2044\n",
            "Epoch 3, Sample 15614: Loss: 0.4996\n",
            "Epoch 3, Sample 15615: Loss: 0.2034\n",
            "Epoch 3, Sample 15616: Loss: 0.1461\n",
            "Epoch 3, Sample 15617: Loss: 0.2639\n",
            "Epoch 3, Sample 15618: Loss: 0.6092\n",
            "Epoch 3, Sample 15619: Loss: 1.6190\n",
            "Epoch 3, Sample 15620: Loss: 0.2032\n",
            "Epoch 3, Sample 15621: Loss: 0.0838\n",
            "Epoch 3, Sample 15622: Loss: 0.1627\n",
            "Epoch 3, Sample 15623: Loss: 0.2639\n",
            "Epoch 3, Sample 15624: Loss: 0.5871\n",
            "Epoch 3, Sample 15625: Loss: 0.0521\n",
            "Epoch 3, Sample 15626: Loss: 0.3399\n",
            "Epoch 3, Sample 15627: Loss: 1.0524\n",
            "Epoch 3, Sample 15628: Loss: 1.8272\n",
            "Epoch 3, Sample 15629: Loss: 0.0026\n",
            "Epoch 3, Sample 15630: Loss: 0.1170\n",
            "Epoch 3, Sample 15631: Loss: 0.1989\n",
            "Epoch 3, Sample 15632: Loss: 0.1559\n",
            "Epoch 3, Sample 15633: Loss: 0.4611\n",
            "Epoch 3, Sample 15634: Loss: 0.4663\n",
            "Epoch 3, Sample 15635: Loss: 0.2032\n",
            "Epoch 3, Sample 15636: Loss: 0.2759\n",
            "Epoch 3, Sample 15637: Loss: 0.1337\n",
            "Epoch 3, Sample 15638: Loss: 0.5989\n",
            "Epoch 3, Sample 15639: Loss: 0.4930\n",
            "Epoch 3, Sample 15640: Loss: 0.2034\n",
            "Epoch 3, Sample 15641: Loss: 1.0524\n",
            "Epoch 3, Sample 15642: Loss: 0.1559\n",
            "Epoch 3, Sample 15643: Loss: 0.5019\n",
            "Epoch 3, Sample 15644: Loss: 1.0155\n",
            "Epoch 3, Sample 15645: Loss: 0.0145\n",
            "Epoch 3, Sample 15646: Loss: 0.3399\n",
            "Epoch 3, Sample 15647: Loss: 0.0938\n",
            "Epoch 3, Sample 15648: Loss: 0.0315\n",
            "Epoch 3, Sample 15649: Loss: 0.1170\n",
            "Epoch 3, Sample 15650: Loss: 0.7036\n",
            "Epoch 3, Sample 15651: Loss: 0.0178\n",
            "Epoch 3, Sample 15652: Loss: 0.7036\n",
            "Epoch 3, Sample 15653: Loss: 0.1170\n",
            "Epoch 3, Sample 15654: Loss: 0.5858\n",
            "Epoch 3, Sample 15655: Loss: 0.6793\n",
            "Epoch 3, Sample 15656: Loss: 0.7036\n",
            "Epoch 3, Sample 15657: Loss: 0.1336\n",
            "Epoch 3, Sample 15658: Loss: 0.0915\n",
            "Epoch 3, Sample 15659: Loss: 0.5000\n",
            "Epoch 3, Sample 15660: Loss: 0.2044\n",
            "Epoch 3, Sample 15661: Loss: 0.0866\n",
            "Epoch 3, Sample 15662: Loss: 0.8621\n",
            "Epoch 3, Sample 15663: Loss: 1.1871\n",
            "Epoch 3, Sample 15664: Loss: 0.4611\n",
            "Epoch 3, Sample 15665: Loss: 0.3491\n",
            "Epoch 3, Sample 15666: Loss: 0.7203\n",
            "Epoch 3, Sample 15667: Loss: 1.0155\n",
            "Epoch 3, Sample 15668: Loss: 1.0266\n",
            "Epoch 3, Sample 15669: Loss: 1.3581\n",
            "Epoch 3, Sample 15670: Loss: 0.1570\n",
            "Epoch 3, Sample 15671: Loss: 0.0972\n",
            "Epoch 3, Sample 15672: Loss: 0.1250\n",
            "Epoch 3, Sample 15673: Loss: 0.2989\n",
            "Epoch 3, Sample 15674: Loss: 0.0025\n",
            "Epoch 3, Sample 15675: Loss: 0.3132\n",
            "Epoch 3, Sample 15676: Loss: 0.4930\n",
            "Epoch 3, Sample 15677: Loss: 1.0524\n",
            "Epoch 3, Sample 15678: Loss: 0.3402\n",
            "Epoch 3, Sample 15679: Loss: 0.2112\n",
            "Epoch 3, Sample 15680: Loss: 1.0524\n",
            "Epoch 3, Sample 15681: Loss: 0.0025\n",
            "Epoch 3, Sample 15682: Loss: 0.3568\n",
            "Epoch 3, Sample 15683: Loss: 2.9992\n",
            "Epoch 3, Sample 15684: Loss: 0.1817\n",
            "Epoch 3, Sample 15685: Loss: 0.1036\n",
            "Epoch 3, Sample 15686: Loss: 1.9145\n",
            "Epoch 3, Sample 15687: Loss: 0.8285\n",
            "Epoch 3, Sample 15688: Loss: 0.1264\n",
            "Epoch 3, Sample 15689: Loss: 1.2660\n",
            "Epoch 3, Sample 15690: Loss: 0.2044\n",
            "Epoch 3, Sample 15691: Loss: 1.5159\n",
            "Epoch 3, Sample 15692: Loss: 0.2044\n",
            "Epoch 3, Sample 15693: Loss: 4.1611\n",
            "Epoch 3, Sample 15694: Loss: 1.0524\n",
            "Epoch 3, Sample 15695: Loss: 0.4550\n",
            "Epoch 3, Sample 15696: Loss: 0.7036\n",
            "Epoch 3, Sample 15697: Loss: 0.7453\n",
            "Epoch 3, Sample 15698: Loss: 0.3399\n",
            "Epoch 3, Sample 15699: Loss: 0.0026\n",
            "Epoch 3, Sample 15700: Loss: 0.0630\n",
            "Epoch 3, Sample 15701: Loss: 0.0026\n",
            "Epoch 3, Sample 15702: Loss: 0.0458\n",
            "Epoch 3, Sample 15703: Loss: 0.3247\n",
            "Epoch 3, Sample 15704: Loss: 0.0625\n",
            "Epoch 3, Sample 15705: Loss: 0.6990\n",
            "Epoch 3, Sample 15706: Loss: 0.3402\n",
            "Epoch 3, Sample 15707: Loss: 1.6326\n",
            "Epoch 3, Sample 15708: Loss: 0.0001\n",
            "Epoch 3, Sample 15709: Loss: 0.0035\n",
            "Epoch 3, Sample 15710: Loss: 0.3441\n",
            "Epoch 3, Sample 15711: Loss: 0.2759\n",
            "Epoch 3, Sample 15712: Loss: 1.8616\n",
            "Epoch 3, Sample 15713: Loss: 0.0653\n",
            "Epoch 3, Sample 15714: Loss: 0.6990\n",
            "Epoch 3, Sample 15715: Loss: 0.3399\n",
            "Epoch 3, Sample 15716: Loss: 0.1999\n",
            "Epoch 3, Sample 15717: Loss: 2.7331\n",
            "Epoch 3, Sample 15718: Loss: 0.1250\n",
            "Epoch 3, Sample 15719: Loss: 0.3805\n",
            "Epoch 3, Sample 15720: Loss: 0.1941\n",
            "Epoch 3, Sample 15721: Loss: 0.0005\n",
            "Epoch 3, Sample 15722: Loss: 0.0306\n",
            "Epoch 3, Sample 15723: Loss: 0.3949\n",
            "Epoch 3, Sample 15724: Loss: 2.9718\n",
            "Epoch 3, Sample 15725: Loss: 0.4349\n",
            "Epoch 3, Sample 15726: Loss: 0.2755\n",
            "Epoch 3, Sample 15727: Loss: 5.3472\n",
            "Epoch 3, Sample 15728: Loss: 1.0155\n",
            "Epoch 3, Sample 15729: Loss: 0.3949\n",
            "Epoch 3, Sample 15730: Loss: 0.6139\n",
            "Epoch 3, Sample 15731: Loss: 0.1559\n",
            "Epoch 3, Sample 15732: Loss: 2.2434\n",
            "Epoch 3, Sample 15733: Loss: 0.3332\n",
            "Epoch 3, Sample 15734: Loss: 0.1170\n",
            "Epoch 3, Sample 15735: Loss: 0.0505\n",
            "Epoch 3, Sample 15736: Loss: 0.5283\n",
            "Epoch 3, Sample 15737: Loss: 0.8951\n",
            "Epoch 3, Sample 15738: Loss: 0.4996\n",
            "Epoch 3, Sample 15739: Loss: 0.2219\n",
            "Epoch 3, Sample 15740: Loss: 0.2032\n",
            "Epoch 3, Sample 15741: Loss: 0.2044\n",
            "Epoch 3, Sample 15742: Loss: 0.4996\n",
            "Epoch 3, Sample 15743: Loss: 0.2219\n",
            "Epoch 3, Sample 15744: Loss: 0.3399\n",
            "Epoch 3, Sample 15745: Loss: 0.0460\n",
            "Epoch 3, Sample 15746: Loss: 0.1559\n",
            "Epoch 3, Sample 15747: Loss: 0.0630\n",
            "Epoch 3, Sample 15748: Loss: 0.1250\n",
            "Epoch 3, Sample 15749: Loss: 0.7486\n",
            "Epoch 3, Sample 15750: Loss: 0.0023\n",
            "Epoch 3, Sample 15751: Loss: 0.2044\n",
            "Epoch 3, Sample 15752: Loss: 0.1559\n",
            "Epoch 3, Sample 15753: Loss: 0.0018\n",
            "Epoch 3, Sample 15754: Loss: 0.0590\n",
            "Epoch 3, Sample 15755: Loss: 0.5000\n",
            "Epoch 3, Sample 15756: Loss: 0.0026\n",
            "Epoch 3, Sample 15757: Loss: 0.0085\n",
            "Epoch 3, Sample 15758: Loss: 0.1246\n",
            "Epoch 3, Sample 15759: Loss: 0.9367\n",
            "Epoch 3, Sample 15760: Loss: 0.1170\n",
            "Epoch 3, Sample 15761: Loss: 0.1077\n",
            "Epoch 3, Sample 15762: Loss: 0.4799\n",
            "Epoch 3, Sample 15763: Loss: 0.7453\n",
            "Epoch 3, Sample 15764: Loss: 0.6990\n",
            "Epoch 3, Sample 15765: Loss: 0.5003\n",
            "Epoch 3, Sample 15766: Loss: 1.0155\n",
            "Epoch 3, Sample 15767: Loss: 1.0524\n",
            "Epoch 3, Sample 15768: Loss: 0.3441\n",
            "Epoch 3, Sample 15769: Loss: 0.2186\n",
            "Epoch 3, Sample 15770: Loss: 0.7857\n",
            "Epoch 3, Sample 15771: Loss: 0.3539\n",
            "Epoch 3, Sample 15772: Loss: 0.6990\n",
            "Epoch 3, Sample 15773: Loss: 0.0042\n",
            "Epoch 3, Sample 15774: Loss: 0.7036\n",
            "Epoch 3, Sample 15775: Loss: 0.5871\n",
            "Epoch 3, Sample 15776: Loss: 0.3949\n",
            "Epoch 3, Sample 15777: Loss: 0.3441\n",
            "Epoch 3, Sample 15778: Loss: 0.0144\n",
            "Epoch 3, Sample 15779: Loss: 1.1569\n",
            "Epoch 3, Sample 15780: Loss: 0.1399\n",
            "Epoch 3, Sample 15781: Loss: 0.7036\n",
            "Epoch 3, Sample 15782: Loss: 0.1968\n",
            "Epoch 3, Sample 15783: Loss: 0.1397\n",
            "Epoch 3, Sample 15784: Loss: 0.7593\n",
            "Epoch 3, Sample 15785: Loss: 0.5003\n",
            "Epoch 3, Sample 15786: Loss: 0.2683\n",
            "Epoch 3, Sample 15787: Loss: 0.2034\n",
            "Epoch 3, Sample 15788: Loss: 1.0530\n",
            "Epoch 3, Sample 15789: Loss: 0.3441\n",
            "Epoch 3, Sample 15790: Loss: 0.1654\n",
            "Epoch 3, Sample 15791: Loss: 0.3399\n",
            "Epoch 3, Sample 15792: Loss: 0.4611\n",
            "Epoch 3, Sample 15793: Loss: 1.0524\n",
            "Epoch 3, Sample 15794: Loss: 1.0524\n",
            "Epoch 3, Sample 15795: Loss: 1.0524\n",
            "Epoch 3, Sample 15796: Loss: 0.0090\n",
            "Epoch 3, Sample 15797: Loss: 0.7486\n",
            "Epoch 3, Sample 15798: Loss: 0.1250\n",
            "Epoch 3, Sample 15799: Loss: 0.0130\n",
            "Epoch 3, Sample 15800: Loss: 1.0524\n",
            "Epoch 3, Sample 15801: Loss: 0.2034\n",
            "Epoch 3, Sample 15802: Loss: 0.3441\n",
            "Epoch 3, Sample 15803: Loss: 0.0838\n",
            "Epoch 3, Sample 15804: Loss: 0.4930\n",
            "Epoch 3, Sample 15805: Loss: 0.4655\n",
            "Epoch 3, Sample 15806: Loss: 0.1227\n",
            "Epoch 3, Sample 15807: Loss: 2.3808\n",
            "Epoch 3, Sample 15808: Loss: 1.0524\n",
            "Epoch 3, Sample 15809: Loss: 0.1288\n",
            "Epoch 3, Sample 15810: Loss: 0.0554\n",
            "Epoch 3, Sample 15811: Loss: 0.7036\n",
            "Epoch 3, Sample 15812: Loss: 0.1625\n",
            "Epoch 3, Sample 15813: Loss: 0.0145\n",
            "Epoch 3, Sample 15814: Loss: 0.2034\n",
            "Epoch 3, Sample 15815: Loss: 0.3441\n",
            "Epoch 3, Sample 15816: Loss: 0.0544\n",
            "Epoch 3, Sample 15817: Loss: 0.0018\n",
            "Epoch 3, Sample 15818: Loss: 0.0212\n",
            "Epoch 3, Sample 15819: Loss: 0.5469\n",
            "Epoch 3, Sample 15820: Loss: 0.0943\n",
            "Epoch 3, Sample 15821: Loss: 0.0130\n",
            "Epoch 3, Sample 15822: Loss: 0.4032\n",
            "Epoch 3, Sample 15823: Loss: 0.2989\n",
            "Epoch 3, Sample 15824: Loss: 0.2340\n",
            "Epoch 3, Sample 15825: Loss: 0.0026\n",
            "Epoch 3, Sample 15826: Loss: 0.0026\n",
            "Epoch 3, Sample 15827: Loss: 0.9785\n",
            "Epoch 3, Sample 15828: Loss: 2.7994\n",
            "Epoch 3, Sample 15829: Loss: 0.0510\n",
            "Epoch 3, Sample 15830: Loss: 0.9367\n",
            "Epoch 3, Sample 15831: Loss: 1.0524\n",
            "Epoch 3, Sample 15832: Loss: 0.2044\n",
            "Epoch 3, Sample 15833: Loss: 0.1170\n",
            "Epoch 3, Sample 15834: Loss: 0.0460\n",
            "Epoch 3, Sample 15835: Loss: 0.2935\n",
            "Epoch 3, Sample 15836: Loss: 0.1376\n",
            "Epoch 3, Sample 15837: Loss: 0.2044\n",
            "Epoch 3, Sample 15838: Loss: 0.2704\n",
            "Epoch 3, Sample 15839: Loss: 0.6139\n",
            "Epoch 3, Sample 15840: Loss: 2.6860\n",
            "Epoch 3, Sample 15841: Loss: 6.7937\n",
            "Epoch 3, Sample 15842: Loss: 0.1250\n",
            "Epoch 3, Sample 15843: Loss: 0.1170\n",
            "Epoch 3, Sample 15844: Loss: 0.0608\n",
            "Epoch 3, Sample 15845: Loss: 0.7036\n",
            "Epoch 3, Sample 15846: Loss: 0.4799\n",
            "Epoch 3, Sample 15847: Loss: 0.0026\n",
            "Epoch 3, Sample 15848: Loss: 0.2759\n",
            "Epoch 3, Sample 15849: Loss: 0.3949\n",
            "Epoch 3, Sample 15850: Loss: 0.2537\n",
            "Epoch 3, Sample 15851: Loss: 0.6931\n",
            "Epoch 3, Sample 15852: Loss: 0.0013\n",
            "Epoch 3, Sample 15853: Loss: 0.0018\n",
            "Epoch 3, Sample 15854: Loss: 0.8951\n",
            "Epoch 3, Sample 15855: Loss: 0.4382\n",
            "Epoch 3, Sample 15856: Loss: 0.3758\n",
            "Epoch 3, Sample 15857: Loss: 0.0018\n",
            "Epoch 3, Sample 15858: Loss: 0.0026\n",
            "Epoch 3, Sample 15859: Loss: 0.4902\n",
            "Epoch 3, Sample 15860: Loss: 0.2034\n",
            "Epoch 3, Sample 15861: Loss: 0.1250\n",
            "Epoch 3, Sample 15862: Loss: 0.3399\n",
            "Epoch 3, Sample 15863: Loss: 0.6199\n",
            "Epoch 3, Sample 15864: Loss: 0.2032\n",
            "Epoch 3, Sample 15865: Loss: 0.9367\n",
            "Epoch 3, Sample 15866: Loss: 0.2036\n",
            "Epoch 3, Sample 15867: Loss: 0.3131\n",
            "Epoch 3, Sample 15868: Loss: 2.1901\n",
            "Epoch 3, Sample 15869: Loss: 0.2032\n",
            "Epoch 3, Sample 15870: Loss: 0.8951\n",
            "Epoch 3, Sample 15871: Loss: 0.1250\n",
            "Epoch 3, Sample 15872: Loss: 0.2385\n",
            "Epoch 3, Sample 15873: Loss: 0.3441\n",
            "Epoch 3, Sample 15874: Loss: 0.1399\n",
            "Epoch 3, Sample 15875: Loss: 0.1807\n",
            "Epoch 3, Sample 15876: Loss: 0.0414\n",
            "Epoch 3, Sample 15877: Loss: 0.2759\n",
            "Epoch 3, Sample 15878: Loss: 0.0026\n",
            "Epoch 3, Sample 15879: Loss: 0.1559\n",
            "Epoch 3, Sample 15880: Loss: 0.1233\n",
            "Epoch 3, Sample 15881: Loss: 0.2034\n",
            "Epoch 3, Sample 15882: Loss: 0.1170\n",
            "Epoch 3, Sample 15883: Loss: 0.2485\n",
            "Epoch 3, Sample 15884: Loss: 0.8951\n",
            "Epoch 3, Sample 15885: Loss: 0.2759\n",
            "Epoch 3, Sample 15886: Loss: 0.1170\n",
            "Epoch 3, Sample 15887: Loss: 0.1170\n",
            "Epoch 3, Sample 15888: Loss: 0.2832\n",
            "Epoch 3, Sample 15889: Loss: 0.0161\n",
            "Epoch 3, Sample 15890: Loss: 0.0126\n",
            "Epoch 3, Sample 15891: Loss: 0.2340\n",
            "Epoch 3, Sample 15892: Loss: 0.2113\n",
            "Epoch 3, Sample 15893: Loss: 0.2044\n",
            "Epoch 3, Sample 15894: Loss: 0.2778\n",
            "Epoch 3, Sample 15895: Loss: 1.0155\n",
            "Epoch 3, Sample 15896: Loss: 0.4799\n",
            "Epoch 3, Sample 15897: Loss: 0.0026\n",
            "Epoch 3, Sample 15898: Loss: 0.0001\n",
            "Epoch 3, Sample 15899: Loss: 0.5498\n",
            "Epoch 3, Sample 15900: Loss: 0.3399\n",
            "Epoch 3, Sample 15901: Loss: 0.6304\n",
            "Epoch 3, Sample 15902: Loss: 0.2876\n",
            "Epoch 3, Sample 15903: Loss: 0.4651\n",
            "Epoch 3, Sample 15904: Loss: 0.5858\n",
            "Epoch 3, Sample 15905: Loss: 0.2034\n",
            "Epoch 3, Sample 15906: Loss: 0.0205\n",
            "Epoch 3, Sample 15907: Loss: 0.6990\n",
            "Epoch 3, Sample 15908: Loss: 0.5858\n",
            "Epoch 3, Sample 15909: Loss: 0.8951\n",
            "Epoch 3, Sample 15910: Loss: 0.2121\n",
            "Epoch 3, Sample 15911: Loss: 0.0625\n",
            "Epoch 3, Sample 15912: Loss: 0.3805\n",
            "Epoch 3, Sample 15913: Loss: 0.0001\n",
            "Epoch 3, Sample 15914: Loss: 11.2618\n",
            "Epoch 3, Sample 15915: Loss: 0.0630\n",
            "Epoch 3, Sample 15916: Loss: 0.0108\n",
            "Epoch 3, Sample 15917: Loss: 0.2032\n",
            "Epoch 3, Sample 15918: Loss: 0.2034\n",
            "Epoch 3, Sample 15919: Loss: 0.8301\n",
            "Epoch 3, Sample 15920: Loss: 0.5196\n",
            "Epoch 3, Sample 15921: Loss: 0.3126\n",
            "Epoch 3, Sample 15922: Loss: 0.7036\n",
            "Epoch 3, Sample 15923: Loss: 0.7036\n",
            "Epoch 3, Sample 15924: Loss: 0.4799\n",
            "Epoch 3, Sample 15925: Loss: 0.0026\n",
            "Epoch 3, Sample 15926: Loss: 0.0014\n",
            "Epoch 3, Sample 15927: Loss: 1.0530\n",
            "Epoch 3, Sample 15928: Loss: 0.0838\n",
            "Epoch 3, Sample 15929: Loss: 0.0000\n",
            "Epoch 3, Sample 15930: Loss: 0.3758\n",
            "Epoch 3, Sample 15931: Loss: 0.0306\n",
            "Epoch 3, Sample 15932: Loss: 0.3450\n",
            "Epoch 3, Sample 15933: Loss: 0.6960\n",
            "Epoch 3, Sample 15934: Loss: 0.0001\n",
            "Epoch 3, Sample 15935: Loss: 0.2743\n",
            "Epoch 3, Sample 15936: Loss: 1.6834\n",
            "Epoch 3, Sample 15937: Loss: 0.5089\n",
            "Epoch 3, Sample 15938: Loss: 1.8330\n",
            "Epoch 3, Sample 15939: Loss: 0.0626\n",
            "Epoch 3, Sample 15940: Loss: 0.6990\n",
            "Epoch 3, Sample 15941: Loss: 1.9855\n",
            "Epoch 3, Sample 15942: Loss: 0.1588\n",
            "Epoch 3, Sample 15943: Loss: 0.2935\n",
            "Epoch 3, Sample 15944: Loss: 0.3399\n",
            "Epoch 3, Sample 15945: Loss: 0.1217\n",
            "Epoch 3, Sample 15946: Loss: 0.1252\n",
            "Epoch 3, Sample 15947: Loss: 0.6458\n",
            "Epoch 3, Sample 15948: Loss: 0.0062\n",
            "Epoch 3, Sample 15949: Loss: 0.0303\n",
            "Epoch 3, Sample 15950: Loss: 0.4030\n",
            "Epoch 3, Sample 15951: Loss: 1.0524\n",
            "Epoch 3, Sample 15952: Loss: 0.2759\n",
            "Epoch 3, Sample 15953: Loss: 0.1627\n",
            "Epoch 3, Sample 15954: Loss: 0.1083\n",
            "Epoch 3, Sample 15955: Loss: 0.3399\n",
            "Epoch 3, Sample 15956: Loss: 0.6867\n",
            "Epoch 3, Sample 15957: Loss: 1.5481\n",
            "Epoch 3, Sample 15958: Loss: 0.0111\n",
            "Epoch 3, Sample 15959: Loss: 0.1250\n",
            "Epoch 3, Sample 15960: Loss: 0.2340\n",
            "Epoch 3, Sample 15961: Loss: 0.1621\n",
            "Epoch 3, Sample 15962: Loss: 0.9507\n",
            "Epoch 3, Sample 15963: Loss: 1.0530\n",
            "Epoch 3, Sample 15964: Loss: 0.1933\n",
            "Epoch 3, Sample 15965: Loss: 0.3332\n",
            "Epoch 3, Sample 15966: Loss: 0.6139\n",
            "Epoch 3, Sample 15967: Loss: 0.2962\n",
            "Epoch 3, Sample 15968: Loss: 0.2755\n",
            "Epoch 3, Sample 15969: Loss: 0.0244\n",
            "Epoch 3, Sample 15970: Loss: 0.1999\n",
            "Epoch 3, Sample 15971: Loss: 0.8325\n",
            "Epoch 3, Sample 15972: Loss: 0.0026\n",
            "Epoch 3, Sample 15973: Loss: 1.7535\n",
            "Epoch 3, Sample 15974: Loss: 0.3399\n",
            "Epoch 3, Sample 15975: Loss: 0.0807\n",
            "Epoch 3, Sample 15976: Loss: 1.0524\n",
            "Epoch 3, Sample 15977: Loss: 0.6867\n",
            "Epoch 3, Sample 15978: Loss: 0.2044\n",
            "Epoch 3, Sample 15979: Loss: 0.0630\n",
            "Epoch 3, Sample 15980: Loss: 0.8951\n",
            "Epoch 3, Sample 15981: Loss: 0.3441\n",
            "Epoch 3, Sample 15982: Loss: 0.3399\n",
            "Epoch 3, Sample 15983: Loss: 1.0524\n",
            "Epoch 3, Sample 15984: Loss: 0.0018\n",
            "Epoch 3, Sample 15985: Loss: 0.8951\n",
            "Epoch 3, Sample 15986: Loss: 0.1157\n",
            "Epoch 3, Sample 15987: Loss: 0.0026\n",
            "Epoch 3, Sample 15988: Loss: 0.0026\n",
            "Epoch 3, Sample 15989: Loss: 1.0155\n",
            "Epoch 3, Sample 15990: Loss: 0.4641\n",
            "Epoch 3, Sample 15991: Loss: 0.1460\n",
            "Epoch 3, Sample 15992: Loss: 0.1219\n",
            "Epoch 3, Sample 15993: Loss: 0.0650\n",
            "Epoch 3, Sample 15994: Loss: 0.1246\n",
            "Epoch 3, Sample 15995: Loss: 0.6139\n",
            "Epoch 3, Sample 15996: Loss: 7.6726\n",
            "Epoch 3, Sample 15997: Loss: 0.1369\n",
            "Epoch 3, Sample 15998: Loss: 0.5972\n",
            "Epoch 3, Sample 15999: Loss: 0.0261\n",
            "Epoch 3, Sample 16000: Loss: 0.6867\n",
            "\n",
            "Epoch 3 Average Loss: 0.5556\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For third trial we chose these settings\n",
        "epochs = 3\n",
        "learning_rate = .1\n",
        "input_size = 20\n",
        "Neurons = 50\n",
        "activation_input = 50\n",
        "activation function = relu\n",
        "output = 1"
      ],
      "metadata": {
        "id": "mIs2fJ4lHx5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "learning_rate = .1\n",
        "\n",
        "\n",
        "# Initializing Parameters\n",
        "w = 50\n",
        "\n",
        "loss_set = {}\n",
        "\n",
        "# 1. Creating a FeedForwardNetwork\n",
        "# 1.1 Structure (Architecture) of NN\n",
        "model_net3 = torch.nn.Sequential(torch.nn.Linear(20,50),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(0.33),\n",
        "\n",
        "                                 torch.nn.Linear(50,1),\n",
        "                                 torch.nn.ReLU(),\n",
        "\n",
        "                                 );\n",
        "\n",
        "# 1.2 Loss Function\n",
        "loss_mse = torch.nn.MSELoss()\n",
        "\n",
        "# 1.3 Optmization Approch\n",
        "optimizer = torch.optim.SGD(model_net3.parameters(), lr=learning_rate)\n",
        "\n",
        "w_his = []\n",
        "w_his.append(w)\n",
        "# Loop over the number of epochs\n",
        "for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over each sample in the dataset\n",
        "    for i in range(tensor_data_X.size(0)):\n",
        "\n",
        "      # 2. Forward Pass\n",
        "      output = model_net3.forward(tensor_data_X[i].reshape(-1))\n",
        "\n",
        "      # 3. FeedForward Evaluation\n",
        "      loss = loss_mse(output, tensor_data_Y[i].reshape(-1))\n",
        "      optimizer.zero_grad();\n",
        "\n",
        "      # 4. Backward Pass / Gradient Calculation\n",
        "      loss.backward()\n",
        "\n",
        "      # Store the loss for each epoch\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # 5. Back Propagation / Update Weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store the weight value for each sample of data\n",
        "      w_his.append(float(model_net3[0].weight.data[0][0]))\n",
        "\n",
        "      # Display the loss for the current sample\n",
        "      print(f\"Epoch {epoch+1}, Sample {i+1}: Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # Calculate and display average loss for the epoch\n",
        "    epoch_loss /= tensor_data_X.size(0)\n",
        "\n",
        "    # Store the loss for each sample of data\n",
        "    loss_set[epoch] = epoch_loss\n",
        "    print(f\"\\nEpoch {epoch+1} Average Loss: {epoch_loss:.4f}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f58c171f2b74c7abe6ec6f5fc26bbaa",
            "ec17beb0135d4c58a790bda28af0bdef",
            "39127a2bc1294c9b8e5c2226a5d291f5",
            "651f8a5f97824cbb92233c3cb46202a0",
            "c99e36cffcfc4e228f7f54852f53d370",
            "1981c0b578364c629073b9e80764918f",
            "30e9d82498944be6b0461e1b9ff21fee",
            "948d0eff5d414561a0f4e17dcd24cbae",
            "8149a6229d504a8dbb45ff7139f4ed3f",
            "78cd6a929a6a4dffbce223eeb311d950",
            "092c0d7ec74544d7a3f02931c2f5493a"
          ]
        },
        "id": "X6Ut42iAHVXO",
        "outputId": "3eaad567-8a4f-4200-b3be-fe8a51b1c669"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-279-c633475578be>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f58c171f2b74c7abe6ec6f5fc26bbaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 11005: Loss: 0.2832\n",
            "Epoch 3, Sample 11006: Loss: 1.5597\n",
            "Epoch 3, Sample 11007: Loss: 2.6384\n",
            "Epoch 3, Sample 11008: Loss: 0.7036\n",
            "Epoch 3, Sample 11009: Loss: 0.0864\n",
            "Epoch 3, Sample 11010: Loss: 0.0008\n",
            "Epoch 3, Sample 11011: Loss: 0.0026\n",
            "Epoch 3, Sample 11012: Loss: 0.7453\n",
            "Epoch 3, Sample 11013: Loss: 0.1246\n",
            "Epoch 3, Sample 11014: Loss: 0.2032\n",
            "Epoch 3, Sample 11015: Loss: 1.4884\n",
            "Epoch 3, Sample 11016: Loss: 0.3399\n",
            "Epoch 3, Sample 11017: Loss: 0.2339\n",
            "Epoch 3, Sample 11018: Loss: 2.7925\n",
            "Epoch 3, Sample 11019: Loss: 0.0505\n",
            "Epoch 3, Sample 11020: Loss: 0.1170\n",
            "Epoch 3, Sample 11021: Loss: 0.4663\n",
            "Epoch 3, Sample 11022: Loss: 1.6418\n",
            "Epoch 3, Sample 11023: Loss: 0.2750\n",
            "Epoch 3, Sample 11024: Loss: 0.9367\n",
            "Epoch 3, Sample 11025: Loss: 0.0025\n",
            "Epoch 3, Sample 11026: Loss: 1.1265\n",
            "Epoch 3, Sample 11027: Loss: 1.0155\n",
            "Epoch 3, Sample 11028: Loss: 0.7036\n",
            "Epoch 3, Sample 11029: Loss: 0.5871\n",
            "Epoch 3, Sample 11030: Loss: 0.0212\n",
            "Epoch 3, Sample 11031: Loss: 0.0505\n",
            "Epoch 3, Sample 11032: Loss: 1.0524\n",
            "Epoch 3, Sample 11033: Loss: 1.5597\n",
            "Epoch 3, Sample 11034: Loss: 0.1838\n",
            "Epoch 3, Sample 11035: Loss: 0.0189\n",
            "Epoch 3, Sample 11036: Loss: 0.0117\n",
            "Epoch 3, Sample 11037: Loss: 0.2098\n",
            "Epoch 3, Sample 11038: Loss: 0.3399\n",
            "Epoch 3, Sample 11039: Loss: 1.0155\n",
            "Epoch 3, Sample 11040: Loss: 1.0524\n",
            "Epoch 3, Sample 11041: Loss: 0.0391\n",
            "Epoch 3, Sample 11042: Loss: 0.6304\n",
            "Epoch 3, Sample 11043: Loss: 0.0287\n",
            "Epoch 3, Sample 11044: Loss: 0.2639\n",
            "Epoch 3, Sample 11045: Loss: 0.0630\n",
            "Epoch 3, Sample 11046: Loss: 0.3441\n",
            "Epoch 3, Sample 11047: Loss: 2.7331\n",
            "Epoch 3, Sample 11048: Loss: 0.9367\n",
            "Epoch 3, Sample 11049: Loss: 0.2759\n",
            "Epoch 3, Sample 11050: Loss: 0.0084\n",
            "Epoch 3, Sample 11051: Loss: 0.0001\n",
            "Epoch 3, Sample 11052: Loss: 0.0026\n",
            "Epoch 3, Sample 11053: Loss: 0.2032\n",
            "Epoch 3, Sample 11054: Loss: 0.0554\n",
            "Epoch 3, Sample 11055: Loss: 0.1248\n",
            "Epoch 3, Sample 11056: Loss: 0.0018\n",
            "Epoch 3, Sample 11057: Loss: 0.1248\n",
            "Epoch 3, Sample 11058: Loss: 13.5048\n",
            "Epoch 3, Sample 11059: Loss: 0.5972\n",
            "Epoch 3, Sample 11060: Loss: 0.0625\n",
            "Epoch 3, Sample 11061: Loss: 0.0207\n",
            "Epoch 3, Sample 11062: Loss: 0.0234\n",
            "Epoch 3, Sample 11063: Loss: 0.2044\n",
            "Epoch 3, Sample 11064: Loss: 0.9017\n",
            "Epoch 3, Sample 11065: Loss: 0.7036\n",
            "Epoch 3, Sample 11066: Loss: 1.5597\n",
            "Epoch 3, Sample 11067: Loss: 3.5504\n",
            "Epoch 3, Sample 11068: Loss: 1.0530\n",
            "Epoch 3, Sample 11069: Loss: 0.7036\n",
            "Epoch 3, Sample 11070: Loss: 0.2639\n",
            "Epoch 3, Sample 11071: Loss: 0.7036\n",
            "Epoch 3, Sample 11072: Loss: 0.5858\n",
            "Epoch 3, Sample 11073: Loss: 1.5597\n",
            "Epoch 3, Sample 11074: Loss: 2.7331\n",
            "Epoch 3, Sample 11075: Loss: 0.0026\n",
            "Epoch 3, Sample 11076: Loss: 3.9991\n",
            "Epoch 3, Sample 11077: Loss: 0.4367\n",
            "Epoch 3, Sample 11078: Loss: 0.2412\n",
            "Epoch 3, Sample 11079: Loss: 0.3399\n",
            "Epoch 3, Sample 11080: Loss: 1.5597\n",
            "Epoch 3, Sample 11081: Loss: 0.0145\n",
            "Epoch 3, Sample 11082: Loss: 0.0026\n",
            "Epoch 3, Sample 11083: Loss: 0.2639\n",
            "Epoch 3, Sample 11084: Loss: 0.0205\n",
            "Epoch 3, Sample 11085: Loss: 1.0524\n",
            "Epoch 3, Sample 11086: Loss: 0.3399\n",
            "Epoch 3, Sample 11087: Loss: 0.1559\n",
            "Epoch 3, Sample 11088: Loss: 1.0155\n",
            "Epoch 3, Sample 11089: Loss: 0.0022\n",
            "Epoch 3, Sample 11090: Loss: 0.0630\n",
            "Epoch 3, Sample 11091: Loss: 0.2044\n",
            "Epoch 3, Sample 11092: Loss: 0.0018\n",
            "Epoch 3, Sample 11093: Loss: 6.2039\n",
            "Epoch 3, Sample 11094: Loss: 0.0026\n",
            "Epoch 3, Sample 11095: Loss: 1.0524\n",
            "Epoch 3, Sample 11096: Loss: 0.2340\n",
            "Epoch 3, Sample 11097: Loss: 0.5078\n",
            "Epoch 3, Sample 11098: Loss: 0.0108\n",
            "Epoch 3, Sample 11099: Loss: 0.2295\n",
            "Epoch 3, Sample 11100: Loss: 0.2044\n",
            "Epoch 3, Sample 11101: Loss: 0.1170\n",
            "Epoch 3, Sample 11102: Loss: 0.2036\n",
            "Epoch 3, Sample 11103: Loss: 0.5858\n",
            "Epoch 3, Sample 11104: Loss: 0.2034\n",
            "Epoch 3, Sample 11105: Loss: 1.1263\n",
            "Epoch 3, Sample 11106: Loss: 0.2032\n",
            "Epoch 3, Sample 11107: Loss: 2.0225\n",
            "Epoch 3, Sample 11108: Loss: 0.0630\n",
            "Epoch 3, Sample 11109: Loss: 0.2340\n",
            "Epoch 3, Sample 11110: Loss: 1.0524\n",
            "Epoch 3, Sample 11111: Loss: 0.2032\n",
            "Epoch 3, Sample 11112: Loss: 2.6384\n",
            "Epoch 3, Sample 11113: Loss: 1.0524\n",
            "Epoch 3, Sample 11114: Loss: 1.0155\n",
            "Epoch 3, Sample 11115: Loss: 0.1250\n",
            "Epoch 3, Sample 11116: Loss: 0.4607\n",
            "Epoch 3, Sample 11117: Loss: 1.0524\n",
            "Epoch 3, Sample 11118: Loss: 0.0034\n",
            "Epoch 3, Sample 11119: Loss: 1.0524\n",
            "Epoch 3, Sample 11120: Loss: 0.7036\n",
            "Epoch 3, Sample 11121: Loss: 0.2044\n",
            "Epoch 3, Sample 11122: Loss: 0.1170\n",
            "Epoch 3, Sample 11123: Loss: 0.5278\n",
            "Epoch 3, Sample 11124: Loss: 0.2759\n",
            "Epoch 3, Sample 11125: Loss: 0.0630\n",
            "Epoch 3, Sample 11126: Loss: 0.7036\n",
            "Epoch 3, Sample 11127: Loss: 8.0504\n",
            "Epoch 3, Sample 11128: Loss: 0.4930\n",
            "Epoch 3, Sample 11129: Loss: 0.9367\n",
            "Epoch 3, Sample 11130: Loss: 5.3707\n",
            "Epoch 3, Sample 11131: Loss: 0.1250\n",
            "Epoch 3, Sample 11132: Loss: 1.0524\n",
            "Epoch 3, Sample 11133: Loss: 1.8616\n",
            "Epoch 3, Sample 11134: Loss: 0.0460\n",
            "Epoch 3, Sample 11135: Loss: 0.2036\n",
            "Epoch 3, Sample 11136: Loss: 0.0018\n",
            "Epoch 3, Sample 11137: Loss: 2.5104\n",
            "Epoch 3, Sample 11138: Loss: 1.8616\n",
            "Epoch 3, Sample 11139: Loss: 0.0001\n",
            "Epoch 3, Sample 11140: Loss: 0.0006\n",
            "Epoch 3, Sample 11141: Loss: 0.2759\n",
            "Epoch 3, Sample 11142: Loss: 0.4611\n",
            "Epoch 3, Sample 11143: Loss: 0.2032\n",
            "Epoch 3, Sample 11144: Loss: 0.2219\n",
            "Epoch 3, Sample 11145: Loss: 0.7036\n",
            "Epoch 3, Sample 11146: Loss: 0.0062\n",
            "Epoch 3, Sample 11147: Loss: 6.2547\n",
            "Epoch 3, Sample 11148: Loss: 0.0501\n",
            "Epoch 3, Sample 11149: Loss: 0.7036\n",
            "Epoch 3, Sample 11150: Loss: 0.4535\n",
            "Epoch 3, Sample 11151: Loss: 0.2036\n",
            "Epoch 3, Sample 11152: Loss: 2.7331\n",
            "Epoch 3, Sample 11153: Loss: 0.6990\n",
            "Epoch 3, Sample 11154: Loss: 0.0802\n",
            "Epoch 3, Sample 11155: Loss: 0.1250\n",
            "Epoch 3, Sample 11156: Loss: 0.6304\n",
            "Epoch 3, Sample 11157: Loss: 0.9785\n",
            "Epoch 3, Sample 11158: Loss: 0.8951\n",
            "Epoch 3, Sample 11159: Loss: 0.2044\n",
            "Epoch 3, Sample 11160: Loss: 0.0915\n",
            "Epoch 3, Sample 11161: Loss: 0.0026\n",
            "Epoch 3, Sample 11162: Loss: 0.0026\n",
            "Epoch 3, Sample 11163: Loss: 0.2112\n",
            "Epoch 3, Sample 11164: Loss: 2.9274\n",
            "Epoch 3, Sample 11165: Loss: 0.0144\n",
            "Epoch 3, Sample 11166: Loss: 0.2032\n",
            "Epoch 3, Sample 11167: Loss: 0.7036\n",
            "Epoch 3, Sample 11168: Loss: 0.3873\n",
            "Epoch 3, Sample 11169: Loss: 6.2547\n",
            "Epoch 3, Sample 11170: Loss: 1.5542\n",
            "Epoch 3, Sample 11171: Loss: 1.0530\n",
            "Epoch 3, Sample 11172: Loss: 0.0026\n",
            "Epoch 3, Sample 11173: Loss: 0.2036\n",
            "Epoch 3, Sample 11174: Loss: 0.1523\n",
            "Epoch 3, Sample 11175: Loss: 0.2759\n",
            "Epoch 3, Sample 11176: Loss: 0.0637\n",
            "Epoch 3, Sample 11177: Loss: 0.0026\n",
            "Epoch 3, Sample 11178: Loss: 0.8951\n",
            "Epoch 3, Sample 11179: Loss: 0.1616\n",
            "Epoch 3, Sample 11180: Loss: 0.5000\n",
            "Epoch 3, Sample 11181: Loss: 0.6190\n",
            "Epoch 3, Sample 11182: Loss: 1.0155\n",
            "Epoch 3, Sample 11183: Loss: 2.7331\n",
            "Epoch 3, Sample 11184: Loss: 1.0524\n",
            "Epoch 3, Sample 11185: Loss: 2.1055\n",
            "Epoch 3, Sample 11186: Loss: 0.4611\n",
            "Epoch 3, Sample 11187: Loss: 6.7927\n",
            "Epoch 3, Sample 11188: Loss: 0.2032\n",
            "Epoch 3, Sample 11189: Loss: 1.0155\n",
            "Epoch 3, Sample 11190: Loss: 0.0475\n",
            "Epoch 3, Sample 11191: Loss: 0.3399\n",
            "Epoch 3, Sample 11192: Loss: 0.7036\n",
            "Epoch 3, Sample 11193: Loss: 0.2639\n",
            "Epoch 3, Sample 11194: Loss: 0.2034\n",
            "Epoch 3, Sample 11195: Loss: 0.7036\n",
            "Epoch 3, Sample 11196: Loss: 0.2036\n",
            "Epoch 3, Sample 11197: Loss: 1.0524\n",
            "Epoch 3, Sample 11198: Loss: 0.0626\n",
            "Epoch 3, Sample 11199: Loss: 1.0530\n",
            "Epoch 3, Sample 11200: Loss: 2.6384\n",
            "Epoch 3, Sample 11201: Loss: 0.2639\n",
            "Epoch 3, Sample 11202: Loss: 0.0027\n",
            "Epoch 3, Sample 11203: Loss: 0.2034\n",
            "Epoch 3, Sample 11204: Loss: 0.0083\n",
            "Epoch 3, Sample 11205: Loss: 0.4611\n",
            "Epoch 3, Sample 11206: Loss: 1.0524\n",
            "Epoch 3, Sample 11207: Loss: 1.0524\n",
            "Epoch 3, Sample 11208: Loss: 1.0956\n",
            "Epoch 3, Sample 11209: Loss: 0.0630\n",
            "Epoch 3, Sample 11210: Loss: 0.0026\n",
            "Epoch 3, Sample 11211: Loss: 0.2044\n",
            "Epoch 3, Sample 11212: Loss: 0.2832\n",
            "Epoch 3, Sample 11213: Loss: 0.3441\n",
            "Epoch 3, Sample 11214: Loss: 0.4996\n",
            "Epoch 3, Sample 11215: Loss: 0.5375\n",
            "Epoch 3, Sample 11216: Loss: 0.0460\n",
            "Epoch 3, Sample 11217: Loss: 3.5504\n",
            "Epoch 3, Sample 11218: Loss: 0.1250\n",
            "Epoch 3, Sample 11219: Loss: 1.0524\n",
            "Epoch 3, Sample 11220: Loss: 0.0027\n",
            "Epoch 3, Sample 11221: Loss: 0.0108\n",
            "Epoch 3, Sample 11222: Loss: 1.0155\n",
            "Epoch 3, Sample 11223: Loss: 0.0026\n",
            "Epoch 3, Sample 11224: Loss: 0.1170\n",
            "Epoch 3, Sample 11225: Loss: 0.0018\n",
            "Epoch 3, Sample 11226: Loss: 0.2034\n",
            "Epoch 3, Sample 11227: Loss: 0.2340\n",
            "Epoch 3, Sample 11228: Loss: 2.0108\n",
            "Epoch 3, Sample 11229: Loss: 0.1225\n",
            "Epoch 3, Sample 11230: Loss: 0.1674\n",
            "Epoch 3, Sample 11231: Loss: 1.0155\n",
            "Epoch 3, Sample 11232: Loss: 0.3402\n",
            "Epoch 3, Sample 11233: Loss: 0.2340\n",
            "Epoch 3, Sample 11234: Loss: 0.0026\n",
            "Epoch 3, Sample 11235: Loss: 0.1463\n",
            "Epoch 3, Sample 11236: Loss: 0.8951\n",
            "Epoch 3, Sample 11237: Loss: 0.2044\n",
            "Epoch 3, Sample 11238: Loss: 0.4032\n",
            "Epoch 3, Sample 11239: Loss: 0.8584\n",
            "Epoch 3, Sample 11240: Loss: 0.4032\n",
            "Epoch 3, Sample 11241: Loss: 0.0234\n",
            "Epoch 3, Sample 11242: Loss: 0.6990\n",
            "Epoch 3, Sample 11243: Loss: 0.0363\n",
            "Epoch 3, Sample 11244: Loss: 2.4095\n",
            "Epoch 3, Sample 11245: Loss: 0.0625\n",
            "Epoch 3, Sample 11246: Loss: 1.0359\n",
            "Epoch 3, Sample 11247: Loss: 0.1546\n",
            "Epoch 3, Sample 11248: Loss: 0.3907\n",
            "Epoch 3, Sample 11249: Loss: 0.2098\n",
            "Epoch 3, Sample 11250: Loss: 1.0155\n",
            "Epoch 3, Sample 11251: Loss: 0.0915\n",
            "Epoch 3, Sample 11252: Loss: 0.9367\n",
            "Epoch 3, Sample 11253: Loss: 0.0026\n",
            "Epoch 3, Sample 11254: Loss: 0.1559\n",
            "Epoch 3, Sample 11255: Loss: 0.3399\n",
            "Epoch 3, Sample 11256: Loss: 0.3402\n",
            "Epoch 3, Sample 11257: Loss: 0.1250\n",
            "Epoch 3, Sample 11258: Loss: 1.4884\n",
            "Epoch 3, Sample 11259: Loss: 0.6990\n",
            "Epoch 3, Sample 11260: Loss: 1.0524\n",
            "Epoch 3, Sample 11261: Loss: 1.2192\n",
            "Epoch 3, Sample 11262: Loss: 0.0026\n",
            "Epoch 3, Sample 11263: Loss: 0.0391\n",
            "Epoch 3, Sample 11264: Loss: 0.3441\n",
            "Epoch 3, Sample 11265: Loss: 0.8951\n",
            "Epoch 3, Sample 11266: Loss: 5.1063\n",
            "Epoch 3, Sample 11267: Loss: 0.0001\n",
            "Epoch 3, Sample 11268: Loss: 0.2759\n",
            "Epoch 3, Sample 11269: Loss: 0.6304\n",
            "Epoch 3, Sample 11270: Loss: 0.2759\n",
            "Epoch 3, Sample 11271: Loss: 0.2034\n",
            "Epoch 3, Sample 11272: Loss: 0.5858\n",
            "Epoch 3, Sample 11273: Loss: 0.0018\n",
            "Epoch 3, Sample 11274: Loss: 0.3399\n",
            "Epoch 3, Sample 11275: Loss: 1.0266\n",
            "Epoch 3, Sample 11276: Loss: 0.0475\n",
            "Epoch 3, Sample 11277: Loss: 0.0915\n",
            "Epoch 3, Sample 11278: Loss: 0.2044\n",
            "Epoch 3, Sample 11279: Loss: 0.7036\n",
            "Epoch 3, Sample 11280: Loss: 0.3399\n",
            "Epoch 3, Sample 11281: Loss: 2.2434\n",
            "Epoch 3, Sample 11282: Loss: 0.0070\n",
            "Epoch 3, Sample 11283: Loss: 1.0359\n",
            "Epoch 3, Sample 11284: Loss: 0.0018\n",
            "Epoch 3, Sample 11285: Loss: 0.4930\n",
            "Epoch 3, Sample 11286: Loss: 1.4884\n",
            "Epoch 3, Sample 11287: Loss: 2.7331\n",
            "Epoch 3, Sample 11288: Loss: 0.4032\n",
            "Epoch 3, Sample 11289: Loss: 0.2759\n",
            "Epoch 3, Sample 11290: Loss: 0.1335\n",
            "Epoch 3, Sample 11291: Loss: 0.4032\n",
            "Epoch 3, Sample 11292: Loss: 4.4745\n",
            "Epoch 3, Sample 11293: Loss: 0.5871\n",
            "Epoch 3, Sample 11294: Loss: 0.3399\n",
            "Epoch 3, Sample 11295: Loss: 1.5597\n",
            "Epoch 3, Sample 11296: Loss: 0.0630\n",
            "Epoch 3, Sample 11297: Loss: 0.4032\n",
            "Epoch 3, Sample 11298: Loss: 0.2044\n",
            "Epoch 3, Sample 11299: Loss: 0.4867\n",
            "Epoch 3, Sample 11300: Loss: 1.8616\n",
            "Epoch 3, Sample 11301: Loss: 0.4607\n",
            "Epoch 3, Sample 11302: Loss: 0.2044\n",
            "Epoch 3, Sample 11303: Loss: 0.1559\n",
            "Epoch 3, Sample 11304: Loss: 0.2659\n",
            "Epoch 3, Sample 11305: Loss: 13.7179\n",
            "Epoch 3, Sample 11306: Loss: 0.0212\n",
            "Epoch 3, Sample 11307: Loss: 1.0359\n",
            "Epoch 3, Sample 11308: Loss: 2.7331\n",
            "Epoch 3, Sample 11309: Loss: 0.6990\n",
            "Epoch 3, Sample 11310: Loss: 1.5597\n",
            "Epoch 3, Sample 11311: Loss: 1.0359\n",
            "Epoch 3, Sample 11312: Loss: 0.0212\n",
            "Epoch 3, Sample 11313: Loss: 0.2182\n",
            "Epoch 3, Sample 11314: Loss: 0.3399\n",
            "Epoch 3, Sample 11315: Loss: 0.3399\n",
            "Epoch 3, Sample 11316: Loss: 0.0915\n",
            "Epoch 3, Sample 11317: Loss: 0.7036\n",
            "Epoch 3, Sample 11318: Loss: 0.0576\n",
            "Epoch 3, Sample 11319: Loss: 0.4611\n",
            "Epoch 3, Sample 11320: Loss: 0.6092\n",
            "Epoch 3, Sample 11321: Loss: 0.1523\n",
            "Epoch 3, Sample 11322: Loss: 0.3949\n",
            "Epoch 3, Sample 11323: Loss: 0.2738\n",
            "Epoch 3, Sample 11324: Loss: 0.9367\n",
            "Epoch 3, Sample 11325: Loss: 0.1040\n",
            "Epoch 3, Sample 11326: Loss: 1.0524\n",
            "Epoch 3, Sample 11327: Loss: 0.3949\n",
            "Epoch 3, Sample 11328: Loss: 0.1264\n",
            "Epoch 3, Sample 11329: Loss: 0.0013\n",
            "Epoch 3, Sample 11330: Loss: 0.2044\n",
            "Epoch 3, Sample 11331: Loss: 0.0455\n",
            "Epoch 3, Sample 11332: Loss: 0.3399\n",
            "Epoch 3, Sample 11333: Loss: 1.5597\n",
            "Epoch 3, Sample 11334: Loss: 0.0501\n",
            "Epoch 3, Sample 11335: Loss: 3.8747\n",
            "Epoch 3, Sample 11336: Loss: 0.5799\n",
            "Epoch 3, Sample 11337: Loss: 0.2729\n",
            "Epoch 3, Sample 11338: Loss: 0.4761\n",
            "Epoch 3, Sample 11339: Loss: 0.0466\n",
            "Epoch 3, Sample 11340: Loss: 0.3332\n",
            "Epoch 3, Sample 11341: Loss: 0.2044\n",
            "Epoch 3, Sample 11342: Loss: 0.7036\n",
            "Epoch 3, Sample 11343: Loss: 0.2079\n",
            "Epoch 3, Sample 11344: Loss: 0.1250\n",
            "Epoch 3, Sample 11345: Loss: 0.2014\n",
            "Epoch 3, Sample 11346: Loss: 17.3544\n",
            "Epoch 3, Sample 11347: Loss: 0.2832\n",
            "Epoch 3, Sample 11348: Loss: 0.5019\n",
            "Epoch 3, Sample 11349: Loss: 2.0225\n",
            "Epoch 3, Sample 11350: Loss: 0.3399\n",
            "Epoch 3, Sample 11351: Loss: 0.0026\n",
            "Epoch 3, Sample 11352: Loss: 0.9651\n",
            "Epoch 3, Sample 11353: Loss: 0.8951\n",
            "Epoch 3, Sample 11354: Loss: 0.3367\n",
            "Epoch 3, Sample 11355: Loss: 0.1248\n",
            "Epoch 3, Sample 11356: Loss: 4.9766\n",
            "Epoch 3, Sample 11357: Loss: 0.5972\n",
            "Epoch 3, Sample 11358: Loss: 0.2044\n",
            "Epoch 3, Sample 11359: Loss: 0.1627\n",
            "Epoch 3, Sample 11360: Loss: 1.5597\n",
            "Epoch 3, Sample 11361: Loss: 0.1225\n",
            "Epoch 3, Sample 11362: Loss: 0.3805\n",
            "Epoch 3, Sample 11363: Loss: 0.0026\n",
            "Epoch 3, Sample 11364: Loss: 0.0068\n",
            "Epoch 3, Sample 11365: Loss: 0.5858\n",
            "Epoch 3, Sample 11366: Loss: 0.2034\n",
            "Epoch 3, Sample 11367: Loss: 0.4032\n",
            "Epoch 3, Sample 11368: Loss: 0.5858\n",
            "Epoch 3, Sample 11369: Loss: 1.5597\n",
            "Epoch 3, Sample 11370: Loss: 0.1250\n",
            "Epoch 3, Sample 11371: Loss: 0.0161\n",
            "Epoch 3, Sample 11372: Loss: 0.0144\n",
            "Epoch 3, Sample 11373: Loss: 0.0001\n",
            "Epoch 3, Sample 11374: Loss: 1.0524\n",
            "Epoch 3, Sample 11375: Loss: 0.2759\n",
            "Epoch 3, Sample 11376: Loss: 0.2084\n",
            "Epoch 3, Sample 11377: Loss: 2.4541\n",
            "Epoch 3, Sample 11378: Loss: 1.5597\n",
            "Epoch 3, Sample 11379: Loss: 0.2962\n",
            "Epoch 3, Sample 11380: Loss: 0.0460\n",
            "Epoch 3, Sample 11381: Loss: 1.0524\n",
            "Epoch 3, Sample 11382: Loss: 0.0838\n",
            "Epoch 3, Sample 11383: Loss: 0.7036\n",
            "Epoch 3, Sample 11384: Loss: 10.8862\n",
            "Epoch 3, Sample 11385: Loss: 0.2079\n",
            "Epoch 3, Sample 11386: Loss: 0.1250\n",
            "Epoch 3, Sample 11387: Loss: 0.0834\n",
            "Epoch 3, Sample 11388: Loss: 0.0972\n",
            "Epoch 3, Sample 11389: Loss: 0.9007\n",
            "Epoch 3, Sample 11390: Loss: 0.5871\n",
            "Epoch 3, Sample 11391: Loss: 1.0266\n",
            "Epoch 3, Sample 11392: Loss: 0.6099\n",
            "Epoch 3, Sample 11393: Loss: 0.0700\n",
            "Epoch 3, Sample 11394: Loss: 0.3441\n",
            "Epoch 3, Sample 11395: Loss: 4.9766\n",
            "Epoch 3, Sample 11396: Loss: 1.0524\n",
            "Epoch 3, Sample 11397: Loss: 0.0567\n",
            "Epoch 3, Sample 11398: Loss: 4.1748\n",
            "Epoch 3, Sample 11399: Loss: 0.4792\n",
            "Epoch 3, Sample 11400: Loss: 0.1219\n",
            "Epoch 3, Sample 11401: Loss: 0.2044\n",
            "Epoch 3, Sample 11402: Loss: 0.0026\n",
            "Epoch 3, Sample 11403: Loss: 0.0626\n",
            "Epoch 3, Sample 11404: Loss: 0.2759\n",
            "Epoch 3, Sample 11405: Loss: 1.0524\n",
            "Epoch 3, Sample 11406: Loss: 1.0524\n",
            "Epoch 3, Sample 11407: Loss: 1.0155\n",
            "Epoch 3, Sample 11408: Loss: 1.8616\n",
            "Epoch 3, Sample 11409: Loss: 0.0018\n",
            "Epoch 3, Sample 11410: Loss: 0.0018\n",
            "Epoch 3, Sample 11411: Loss: 0.2044\n",
            "Epoch 3, Sample 11412: Loss: 0.8951\n",
            "Epoch 3, Sample 11413: Loss: 0.0101\n",
            "Epoch 3, Sample 11414: Loss: 0.2832\n",
            "Epoch 3, Sample 11415: Loss: 0.0777\n",
            "Epoch 3, Sample 11416: Loss: 0.3402\n",
            "Epoch 3, Sample 11417: Loss: 3.9991\n",
            "Epoch 3, Sample 11418: Loss: 0.0001\n",
            "Epoch 3, Sample 11419: Loss: 0.2044\n",
            "Epoch 3, Sample 11420: Loss: 0.9024\n",
            "Epoch 3, Sample 11421: Loss: 0.7453\n",
            "Epoch 3, Sample 11422: Loss: 0.2759\n",
            "Epoch 3, Sample 11423: Loss: 0.7036\n",
            "Epoch 3, Sample 11424: Loss: 0.0286\n",
            "Epoch 3, Sample 11425: Loss: 0.2034\n",
            "Epoch 3, Sample 11426: Loss: 0.2044\n",
            "Epoch 3, Sample 11427: Loss: 0.5858\n",
            "Epoch 3, Sample 11428: Loss: 1.0524\n",
            "Epoch 3, Sample 11429: Loss: 0.0018\n",
            "Epoch 3, Sample 11430: Loss: 0.5871\n",
            "Epoch 3, Sample 11431: Loss: 0.9780\n",
            "Epoch 3, Sample 11432: Loss: 0.2044\n",
            "Epoch 3, Sample 11433: Loss: 0.0026\n",
            "Epoch 3, Sample 11434: Loss: 0.1463\n",
            "Epoch 3, Sample 11435: Loss: 0.0838\n",
            "Epoch 3, Sample 11436: Loss: 0.6304\n",
            "Epoch 3, Sample 11437: Loss: 5.3707\n",
            "Epoch 3, Sample 11438: Loss: 0.2044\n",
            "Epoch 3, Sample 11439: Loss: 0.0640\n",
            "Epoch 3, Sample 11440: Loss: 0.8625\n",
            "Epoch 3, Sample 11441: Loss: 2.5922\n",
            "Epoch 3, Sample 11442: Loss: 0.0026\n",
            "Epoch 3, Sample 11443: Loss: 1.0956\n",
            "Epoch 3, Sample 11444: Loss: 1.0524\n",
            "Epoch 3, Sample 11445: Loss: 3.5504\n",
            "Epoch 3, Sample 11446: Loss: 0.3441\n",
            "Epoch 3, Sample 11447: Loss: 0.8951\n",
            "Epoch 3, Sample 11448: Loss: 0.5078\n",
            "Epoch 3, Sample 11449: Loss: 1.0524\n",
            "Epoch 3, Sample 11450: Loss: 0.9780\n",
            "Epoch 3, Sample 11451: Loss: 1.0658\n",
            "Epoch 3, Sample 11452: Loss: 0.2340\n",
            "Epoch 3, Sample 11453: Loss: 0.2832\n",
            "Epoch 3, Sample 11454: Loss: 15.4828\n",
            "Epoch 3, Sample 11455: Loss: 0.0018\n",
            "Epoch 3, Sample 11456: Loss: 1.5597\n",
            "Epoch 3, Sample 11457: Loss: 0.1210\n",
            "Epoch 3, Sample 11458: Loss: 1.0155\n",
            "Epoch 3, Sample 11459: Loss: 0.3949\n",
            "Epoch 3, Sample 11460: Loss: 0.4644\n",
            "Epoch 3, Sample 11461: Loss: 0.8484\n",
            "Epoch 3, Sample 11462: Loss: 0.1170\n",
            "Epoch 3, Sample 11463: Loss: 0.9367\n",
            "Epoch 3, Sample 11464: Loss: 0.2032\n",
            "Epoch 3, Sample 11465: Loss: 0.0022\n",
            "Epoch 3, Sample 11466: Loss: 9.5046\n",
            "Epoch 3, Sample 11467: Loss: 1.0956\n",
            "Epoch 3, Sample 11468: Loss: 0.0001\n",
            "Epoch 3, Sample 11469: Loss: 0.2639\n",
            "Epoch 3, Sample 11470: Loss: 0.5858\n",
            "Epoch 3, Sample 11471: Loss: 1.0530\n",
            "Epoch 3, Sample 11472: Loss: 0.5972\n",
            "Epoch 3, Sample 11473: Loss: 0.0142\n",
            "Epoch 3, Sample 11474: Loss: 3.1802\n",
            "Epoch 3, Sample 11475: Loss: 0.1246\n",
            "Epoch 3, Sample 11476: Loss: 0.0630\n",
            "Epoch 3, Sample 11477: Loss: 0.8951\n",
            "Epoch 3, Sample 11478: Loss: 0.7036\n",
            "Epoch 3, Sample 11479: Loss: 0.0108\n",
            "Epoch 3, Sample 11480: Loss: 0.0625\n",
            "Epoch 3, Sample 11481: Loss: 0.3441\n",
            "Epoch 3, Sample 11482: Loss: 0.0063\n",
            "Epoch 3, Sample 11483: Loss: 16.4053\n",
            "Epoch 3, Sample 11484: Loss: 0.2759\n",
            "Epoch 3, Sample 11485: Loss: 0.5972\n",
            "Epoch 3, Sample 11486: Loss: 2.7687\n",
            "Epoch 3, Sample 11487: Loss: 0.0466\n",
            "Epoch 3, Sample 11488: Loss: 0.0026\n",
            "Epoch 3, Sample 11489: Loss: 0.2034\n",
            "Epoch 3, Sample 11490: Loss: 1.0359\n",
            "Epoch 3, Sample 11491: Loss: 0.1822\n",
            "Epoch 3, Sample 11492: Loss: 0.1559\n",
            "Epoch 3, Sample 11493: Loss: 1.7711\n",
            "Epoch 3, Sample 11494: Loss: 0.4930\n",
            "Epoch 3, Sample 11495: Loss: 0.0116\n",
            "Epoch 3, Sample 11496: Loss: 0.7036\n",
            "Epoch 3, Sample 11497: Loss: 0.7036\n",
            "Epoch 3, Sample 11498: Loss: 0.2036\n",
            "Epoch 3, Sample 11499: Loss: 1.5597\n",
            "Epoch 3, Sample 11500: Loss: 0.2699\n",
            "Epoch 3, Sample 11501: Loss: 0.0110\n",
            "Epoch 3, Sample 11502: Loss: 0.3007\n",
            "Epoch 3, Sample 11503: Loss: 1.0524\n",
            "Epoch 3, Sample 11504: Loss: 0.3598\n",
            "Epoch 3, Sample 11505: Loss: 0.7036\n",
            "Epoch 3, Sample 11506: Loss: 0.0026\n",
            "Epoch 3, Sample 11507: Loss: 0.0013\n",
            "Epoch 3, Sample 11508: Loss: 0.3399\n",
            "Epoch 3, Sample 11509: Loss: 0.3441\n",
            "Epoch 3, Sample 11510: Loss: 0.0026\n",
            "Epoch 3, Sample 11511: Loss: 0.9367\n",
            "Epoch 3, Sample 11512: Loss: 2.7331\n",
            "Epoch 3, Sample 11513: Loss: 1.5597\n",
            "Epoch 3, Sample 11514: Loss: 0.0258\n",
            "Epoch 3, Sample 11515: Loss: 0.2044\n",
            "Epoch 3, Sample 11516: Loss: 0.0180\n",
            "Epoch 3, Sample 11517: Loss: 0.1588\n",
            "Epoch 3, Sample 11518: Loss: 0.0212\n",
            "Epoch 3, Sample 11519: Loss: 0.2832\n",
            "Epoch 3, Sample 11520: Loss: 0.2329\n",
            "Epoch 3, Sample 11521: Loss: 0.3399\n",
            "Epoch 3, Sample 11522: Loss: 1.0359\n",
            "Epoch 3, Sample 11523: Loss: 0.0026\n",
            "Epoch 3, Sample 11524: Loss: 0.2112\n",
            "Epoch 3, Sample 11525: Loss: 1.5597\n",
            "Epoch 3, Sample 11526: Loss: 3.3895\n",
            "Epoch 3, Sample 11527: Loss: 4.0002\n",
            "Epoch 3, Sample 11528: Loss: 0.8951\n",
            "Epoch 3, Sample 11529: Loss: 1.0155\n",
            "Epoch 3, Sample 11530: Loss: 1.0524\n",
            "Epoch 3, Sample 11531: Loss: 0.3399\n",
            "Epoch 3, Sample 11532: Loss: 4.6602\n",
            "Epoch 3, Sample 11533: Loss: 0.0084\n",
            "Epoch 3, Sample 11534: Loss: 0.0630\n",
            "Epoch 3, Sample 11535: Loss: 12.2612\n",
            "Epoch 3, Sample 11536: Loss: 1.5597\n",
            "Epoch 3, Sample 11537: Loss: 0.2558\n",
            "Epoch 3, Sample 11538: Loss: 1.0524\n",
            "Epoch 3, Sample 11539: Loss: 0.1463\n",
            "Epoch 3, Sample 11540: Loss: 8.0504\n",
            "Epoch 3, Sample 11541: Loss: 0.0018\n",
            "Epoch 3, Sample 11542: Loss: 0.7036\n",
            "Epoch 3, Sample 11543: Loss: 0.2034\n",
            "Epoch 3, Sample 11544: Loss: 0.0258\n",
            "Epoch 3, Sample 11545: Loss: 0.9780\n",
            "Epoch 3, Sample 11546: Loss: 0.1559\n",
            "Epoch 3, Sample 11547: Loss: 1.0524\n",
            "Epoch 3, Sample 11548: Loss: 1.0524\n",
            "Epoch 3, Sample 11549: Loss: 1.0155\n",
            "Epoch 3, Sample 11550: Loss: 0.6990\n",
            "Epoch 3, Sample 11551: Loss: 2.8787\n",
            "Epoch 3, Sample 11552: Loss: 0.3441\n",
            "Epoch 3, Sample 11553: Loss: 0.0306\n",
            "Epoch 3, Sample 11554: Loss: 0.7036\n",
            "Epoch 3, Sample 11555: Loss: 0.0018\n",
            "Epoch 3, Sample 11556: Loss: 0.5003\n",
            "Epoch 3, Sample 11557: Loss: 1.0155\n",
            "Epoch 3, Sample 11558: Loss: 0.2044\n",
            "Epoch 3, Sample 11559: Loss: 0.1838\n",
            "Epoch 3, Sample 11560: Loss: 0.0626\n",
            "Epoch 3, Sample 11561: Loss: 0.2759\n",
            "Epoch 3, Sample 11562: Loss: 0.5310\n",
            "Epoch 3, Sample 11563: Loss: 1.5597\n",
            "Epoch 3, Sample 11564: Loss: 1.5597\n",
            "Epoch 3, Sample 11565: Loss: 0.2112\n",
            "Epoch 3, Sample 11566: Loss: 0.2989\n",
            "Epoch 3, Sample 11567: Loss: 0.1151\n",
            "Epoch 3, Sample 11568: Loss: 0.2699\n",
            "Epoch 3, Sample 11569: Loss: 1.0524\n",
            "Epoch 3, Sample 11570: Loss: 0.2044\n",
            "Epoch 3, Sample 11571: Loss: 0.5858\n",
            "Epoch 3, Sample 11572: Loss: 0.0466\n",
            "Epoch 3, Sample 11573: Loss: 0.1817\n",
            "Epoch 3, Sample 11574: Loss: 0.1559\n",
            "Epoch 3, Sample 11575: Loss: 0.2032\n",
            "Epoch 3, Sample 11576: Loss: 0.6893\n",
            "Epoch 3, Sample 11577: Loss: 1.0524\n",
            "Epoch 3, Sample 11578: Loss: 0.2044\n",
            "Epoch 3, Sample 11579: Loss: 0.1252\n",
            "Epoch 3, Sample 11580: Loss: 0.7036\n",
            "Epoch 3, Sample 11581: Loss: 3.5504\n",
            "Epoch 3, Sample 11582: Loss: 1.0530\n",
            "Epoch 3, Sample 11583: Loss: 0.1523\n",
            "Epoch 3, Sample 11584: Loss: 1.0155\n",
            "Epoch 3, Sample 11585: Loss: 0.1654\n",
            "Epoch 3, Sample 11586: Loss: 0.5858\n",
            "Epoch 3, Sample 11587: Loss: 0.5858\n",
            "Epoch 3, Sample 11588: Loss: 0.0212\n",
            "Epoch 3, Sample 11589: Loss: 0.0501\n",
            "Epoch 3, Sample 11590: Loss: 0.0630\n",
            "Epoch 3, Sample 11591: Loss: 0.1248\n",
            "Epoch 3, Sample 11592: Loss: 0.2032\n",
            "Epoch 3, Sample 11593: Loss: 0.0018\n",
            "Epoch 3, Sample 11594: Loss: 0.2340\n",
            "Epoch 3, Sample 11595: Loss: 0.2044\n",
            "Epoch 3, Sample 11596: Loss: 0.3399\n",
            "Epoch 3, Sample 11597: Loss: 0.2034\n",
            "Epoch 3, Sample 11598: Loss: 1.4537\n",
            "Epoch 3, Sample 11599: Loss: 2.7331\n",
            "Epoch 3, Sample 11600: Loss: 2.9566\n",
            "Epoch 3, Sample 11601: Loss: 0.2044\n",
            "Epoch 3, Sample 11602: Loss: 3.1802\n",
            "Epoch 3, Sample 11603: Loss: 1.0155\n",
            "Epoch 3, Sample 11604: Loss: 0.0466\n",
            "Epoch 3, Sample 11605: Loss: 0.1246\n",
            "Epoch 3, Sample 11606: Loss: 0.3568\n",
            "Epoch 3, Sample 11607: Loss: 0.2361\n",
            "Epoch 3, Sample 11608: Loss: 0.0026\n",
            "Epoch 3, Sample 11609: Loss: 0.6092\n",
            "Epoch 3, Sample 11610: Loss: 0.3062\n",
            "Epoch 3, Sample 11611: Loss: 0.4996\n",
            "Epoch 3, Sample 11612: Loss: 1.0530\n",
            "Epoch 3, Sample 11613: Loss: 3.3270\n",
            "Epoch 3, Sample 11614: Loss: 1.0155\n",
            "Epoch 3, Sample 11615: Loss: 0.0477\n",
            "Epoch 3, Sample 11616: Loss: 17.1169\n",
            "Epoch 3, Sample 11617: Loss: 0.2044\n",
            "Epoch 3, Sample 11618: Loss: 0.2459\n",
            "Epoch 3, Sample 11619: Loss: 0.7036\n",
            "Epoch 3, Sample 11620: Loss: 0.7702\n",
            "Epoch 3, Sample 11621: Loss: 0.4996\n",
            "Epoch 3, Sample 11622: Loss: 0.2032\n",
            "Epoch 3, Sample 11623: Loss: 0.5000\n",
            "Epoch 3, Sample 11624: Loss: 0.1170\n",
            "Epoch 3, Sample 11625: Loss: 0.0460\n",
            "Epoch 3, Sample 11626: Loss: 0.2363\n",
            "Epoch 3, Sample 11627: Loss: 7.6726\n",
            "Epoch 3, Sample 11628: Loss: 0.2044\n",
            "Epoch 3, Sample 11629: Loss: 0.1924\n",
            "Epoch 3, Sample 11630: Loss: 1.0155\n",
            "Epoch 3, Sample 11631: Loss: 1.0155\n",
            "Epoch 3, Sample 11632: Loss: 0.1250\n",
            "Epoch 3, Sample 11633: Loss: 0.6139\n",
            "Epoch 3, Sample 11634: Loss: 0.0630\n",
            "Epoch 3, Sample 11635: Loss: 0.0034\n",
            "Epoch 3, Sample 11636: Loss: 0.7036\n",
            "Epoch 3, Sample 11637: Loss: 0.2032\n",
            "Epoch 3, Sample 11638: Loss: 0.2339\n",
            "Epoch 3, Sample 11639: Loss: 0.2044\n",
            "Epoch 3, Sample 11640: Loss: 0.3399\n",
            "Epoch 3, Sample 11641: Loss: 0.3399\n",
            "Epoch 3, Sample 11642: Loss: 0.0018\n",
            "Epoch 3, Sample 11643: Loss: 1.5597\n",
            "Epoch 3, Sample 11644: Loss: 1.5597\n",
            "Epoch 3, Sample 11645: Loss: 0.7036\n",
            "Epoch 3, Sample 11646: Loss: 0.2913\n",
            "Epoch 3, Sample 11647: Loss: 0.0026\n",
            "Epoch 3, Sample 11648: Loss: 0.7036\n",
            "Epoch 3, Sample 11649: Loss: 0.0018\n",
            "Epoch 3, Sample 11650: Loss: 0.5858\n",
            "Epoch 3, Sample 11651: Loss: 0.5858\n",
            "Epoch 3, Sample 11652: Loss: 0.0026\n",
            "Epoch 3, Sample 11653: Loss: 0.7036\n",
            "Epoch 3, Sample 11654: Loss: 0.1248\n",
            "Epoch 3, Sample 11655: Loss: 0.0018\n",
            "Epoch 3, Sample 11656: Loss: 0.3399\n",
            "Epoch 3, Sample 11657: Loss: 0.4032\n",
            "Epoch 3, Sample 11658: Loss: 0.0026\n",
            "Epoch 3, Sample 11659: Loss: 0.0150\n",
            "Epoch 3, Sample 11660: Loss: 0.2639\n",
            "Epoch 3, Sample 11661: Loss: 2.7331\n",
            "Epoch 3, Sample 11662: Loss: 0.5196\n",
            "Epoch 3, Sample 11663: Loss: 0.3441\n",
            "Epoch 3, Sample 11664: Loss: 1.0155\n",
            "Epoch 3, Sample 11665: Loss: 0.1170\n",
            "Epoch 3, Sample 11666: Loss: 0.2036\n",
            "Epoch 3, Sample 11667: Loss: 0.5078\n",
            "Epoch 3, Sample 11668: Loss: 0.4032\n",
            "Epoch 3, Sample 11669: Loss: 0.2832\n",
            "Epoch 3, Sample 11670: Loss: 0.2044\n",
            "Epoch 3, Sample 11671: Loss: 0.0026\n",
            "Epoch 3, Sample 11672: Loss: 0.2709\n",
            "Epoch 3, Sample 11673: Loss: 0.0001\n",
            "Epoch 3, Sample 11674: Loss: 6.2039\n",
            "Epoch 3, Sample 11675: Loss: 0.5078\n",
            "Epoch 3, Sample 11676: Loss: 0.0460\n",
            "Epoch 3, Sample 11677: Loss: 2.6384\n",
            "Epoch 3, Sample 11678: Loss: 1.0359\n",
            "Epoch 3, Sample 11679: Loss: 0.2044\n",
            "Epoch 3, Sample 11680: Loss: 0.0212\n",
            "Epoch 3, Sample 11681: Loss: 1.0524\n",
            "Epoch 3, Sample 11682: Loss: 0.5078\n",
            "Epoch 3, Sample 11683: Loss: 0.4799\n",
            "Epoch 3, Sample 11684: Loss: 1.2926\n",
            "Epoch 3, Sample 11685: Loss: 0.1170\n",
            "Epoch 3, Sample 11686: Loss: 0.0026\n",
            "Epoch 3, Sample 11687: Loss: 0.0018\n",
            "Epoch 3, Sample 11688: Loss: 0.2219\n",
            "Epoch 3, Sample 11689: Loss: 0.9780\n",
            "Epoch 3, Sample 11690: Loss: 0.0006\n",
            "Epoch 3, Sample 11691: Loss: 0.2044\n",
            "Epoch 3, Sample 11692: Loss: 0.0026\n",
            "Epoch 3, Sample 11693: Loss: 0.0498\n",
            "Epoch 3, Sample 11694: Loss: 0.5000\n",
            "Epoch 3, Sample 11695: Loss: 0.3399\n",
            "Epoch 3, Sample 11696: Loss: 0.2759\n",
            "Epoch 3, Sample 11697: Loss: 0.1791\n",
            "Epoch 3, Sample 11698: Loss: 3.8844\n",
            "Epoch 3, Sample 11699: Loss: 0.0026\n",
            "Epoch 3, Sample 11700: Loss: 0.2036\n",
            "Epoch 3, Sample 11701: Loss: 1.0956\n",
            "Epoch 3, Sample 11702: Loss: 2.2632\n",
            "Epoch 3, Sample 11703: Loss: 0.0554\n",
            "Epoch 3, Sample 11704: Loss: 0.1250\n",
            "Epoch 3, Sample 11705: Loss: 2.7331\n",
            "Epoch 3, Sample 11706: Loss: 7.4307\n",
            "Epoch 3, Sample 11707: Loss: 0.0133\n",
            "Epoch 3, Sample 11708: Loss: 2.9652\n",
            "Epoch 3, Sample 11709: Loss: 5.5054\n",
            "Epoch 3, Sample 11710: Loss: 1.0956\n",
            "Epoch 3, Sample 11711: Loss: 3.3270\n",
            "Epoch 3, Sample 11712: Loss: 3.7714\n",
            "Epoch 3, Sample 11713: Loss: 0.2759\n",
            "Epoch 3, Sample 11714: Loss: 0.2759\n",
            "Epoch 3, Sample 11715: Loss: 0.5858\n",
            "Epoch 3, Sample 11716: Loss: 1.0524\n",
            "Epoch 3, Sample 11717: Loss: 0.0630\n",
            "Epoch 3, Sample 11718: Loss: 0.5000\n",
            "Epoch 3, Sample 11719: Loss: 0.3450\n",
            "Epoch 3, Sample 11720: Loss: 1.0155\n",
            "Epoch 3, Sample 11721: Loss: 0.1250\n",
            "Epoch 3, Sample 11722: Loss: 0.2112\n",
            "Epoch 3, Sample 11723: Loss: 1.0070\n",
            "Epoch 3, Sample 11724: Loss: 2.7331\n",
            "Epoch 3, Sample 11725: Loss: 0.2112\n",
            "Epoch 3, Sample 11726: Loss: 0.2044\n",
            "Epoch 3, Sample 11727: Loss: 0.2759\n",
            "Epoch 3, Sample 11728: Loss: 0.4841\n",
            "Epoch 3, Sample 11729: Loss: 0.1559\n",
            "Epoch 3, Sample 11730: Loss: 0.3007\n",
            "Epoch 3, Sample 11731: Loss: 0.0018\n",
            "Epoch 3, Sample 11732: Loss: 0.0507\n",
            "Epoch 3, Sample 11733: Loss: 2.2765\n",
            "Epoch 3, Sample 11734: Loss: 0.3399\n",
            "Epoch 3, Sample 11735: Loss: 1.4884\n",
            "Epoch 3, Sample 11736: Loss: 10.5084\n",
            "Epoch 3, Sample 11737: Loss: 0.0026\n",
            "Epoch 3, Sample 11738: Loss: 0.0013\n",
            "Epoch 3, Sample 11739: Loss: 0.7453\n",
            "Epoch 3, Sample 11740: Loss: 3.0780\n",
            "Epoch 3, Sample 11741: Loss: 4.7222\n",
            "Epoch 3, Sample 11742: Loss: 0.1248\n",
            "Epoch 3, Sample 11743: Loss: 0.9367\n",
            "Epoch 3, Sample 11744: Loss: 0.1170\n",
            "Epoch 3, Sample 11745: Loss: 0.3441\n",
            "Epoch 3, Sample 11746: Loss: 0.5196\n",
            "Epoch 3, Sample 11747: Loss: 2.0531\n",
            "Epoch 3, Sample 11748: Loss: 0.0072\n",
            "Epoch 3, Sample 11749: Loss: 0.0630\n",
            "Epoch 3, Sample 11750: Loss: 0.1250\n",
            "Epoch 3, Sample 11751: Loss: 0.1326\n",
            "Epoch 3, Sample 11752: Loss: 0.2970\n",
            "Epoch 3, Sample 11753: Loss: 0.2832\n",
            "Epoch 3, Sample 11754: Loss: 1.2522\n",
            "Epoch 3, Sample 11755: Loss: 0.0084\n",
            "Epoch 3, Sample 11756: Loss: 0.0640\n",
            "Epoch 3, Sample 11757: Loss: 0.2036\n",
            "Epoch 3, Sample 11758: Loss: 0.4644\n",
            "Epoch 3, Sample 11759: Loss: 0.2032\n",
            "Epoch 3, Sample 11760: Loss: 0.6990\n",
            "Epoch 3, Sample 11761: Loss: 2.4360\n",
            "Epoch 3, Sample 11762: Loss: 0.0775\n",
            "Epoch 3, Sample 11763: Loss: 0.1250\n",
            "Epoch 3, Sample 11764: Loss: 0.0306\n",
            "Epoch 3, Sample 11765: Loss: 5.6013\n",
            "Epoch 3, Sample 11766: Loss: 0.0018\n",
            "Epoch 3, Sample 11767: Loss: 0.0744\n",
            "Epoch 3, Sample 11768: Loss: 0.1523\n",
            "Epoch 3, Sample 11769: Loss: 1.0155\n",
            "Epoch 3, Sample 11770: Loss: 0.5989\n",
            "Epoch 3, Sample 11771: Loss: 0.3399\n",
            "Epoch 3, Sample 11772: Loss: 1.0155\n",
            "Epoch 3, Sample 11773: Loss: 0.1248\n",
            "Epoch 3, Sample 11774: Loss: 0.1250\n",
            "Epoch 3, Sample 11775: Loss: 0.0007\n",
            "Epoch 3, Sample 11776: Loss: 1.0524\n",
            "Epoch 3, Sample 11777: Loss: 0.7638\n",
            "Epoch 3, Sample 11778: Loss: 0.2044\n",
            "Epoch 3, Sample 11779: Loss: 0.2759\n",
            "Epoch 3, Sample 11780: Loss: 0.0626\n",
            "Epoch 3, Sample 11781: Loss: 0.5000\n",
            "Epoch 3, Sample 11782: Loss: 1.0227\n",
            "Epoch 3, Sample 11783: Loss: 0.2032\n",
            "Epoch 3, Sample 11784: Loss: 0.6304\n",
            "Epoch 3, Sample 11785: Loss: 0.4841\n",
            "Epoch 3, Sample 11786: Loss: 1.0155\n",
            "Epoch 3, Sample 11787: Loss: 0.2941\n",
            "Epoch 3, Sample 11788: Loss: 0.5089\n",
            "Epoch 3, Sample 11789: Loss: 0.3949\n",
            "Epoch 3, Sample 11790: Loss: 0.0039\n",
            "Epoch 3, Sample 11791: Loss: 0.0026\n",
            "Epoch 3, Sample 11792: Loss: 0.0630\n",
            "Epoch 3, Sample 11793: Loss: 1.0155\n",
            "Epoch 3, Sample 11794: Loss: 0.0018\n",
            "Epoch 3, Sample 11795: Loss: 3.5504\n",
            "Epoch 3, Sample 11796: Loss: 0.2044\n",
            "Epoch 3, Sample 11797: Loss: 0.7453\n",
            "Epoch 3, Sample 11798: Loss: 10.4159\n",
            "Epoch 3, Sample 11799: Loss: 0.2832\n",
            "Epoch 3, Sample 11800: Loss: 0.2034\n",
            "Epoch 3, Sample 11801: Loss: 0.0630\n",
            "Epoch 3, Sample 11802: Loss: 0.0027\n",
            "Epoch 3, Sample 11803: Loss: 5.5067\n",
            "Epoch 3, Sample 11804: Loss: 0.5003\n",
            "Epoch 3, Sample 11805: Loss: 2.8294\n",
            "Epoch 3, Sample 11806: Loss: 0.0212\n",
            "Epoch 3, Sample 11807: Loss: 2.4541\n",
            "Epoch 3, Sample 11808: Loss: 0.0168\n",
            "Epoch 3, Sample 11809: Loss: 11.5233\n",
            "Epoch 3, Sample 11810: Loss: 0.0026\n",
            "Epoch 3, Sample 11811: Loss: 0.0026\n",
            "Epoch 3, Sample 11812: Loss: 0.2044\n",
            "Epoch 3, Sample 11813: Loss: 0.0640\n",
            "Epoch 3, Sample 11814: Loss: 0.2941\n",
            "Epoch 3, Sample 11815: Loss: 0.1546\n",
            "Epoch 3, Sample 11816: Loss: 0.1559\n",
            "Epoch 3, Sample 11817: Loss: 0.5858\n",
            "Epoch 3, Sample 11818: Loss: 0.3399\n",
            "Epoch 3, Sample 11819: Loss: 0.4032\n",
            "Epoch 3, Sample 11820: Loss: 0.2036\n",
            "Epoch 3, Sample 11821: Loss: 0.2639\n",
            "Epoch 3, Sample 11822: Loss: 1.0530\n",
            "Epoch 3, Sample 11823: Loss: 2.9661\n",
            "Epoch 3, Sample 11824: Loss: 0.2639\n",
            "Epoch 3, Sample 11825: Loss: 0.7036\n",
            "Epoch 3, Sample 11826: Loss: 3.1802\n",
            "Epoch 3, Sample 11827: Loss: 0.9780\n",
            "Epoch 3, Sample 11828: Loss: 2.0225\n",
            "Epoch 3, Sample 11829: Loss: 1.0530\n",
            "Epoch 3, Sample 11830: Loss: 0.2044\n",
            "Epoch 3, Sample 11831: Loss: 0.0240\n",
            "Epoch 3, Sample 11832: Loss: 0.0895\n",
            "Epoch 3, Sample 11833: Loss: 0.2044\n",
            "Epoch 3, Sample 11834: Loss: 0.2044\n",
            "Epoch 3, Sample 11835: Loss: 0.3399\n",
            "Epoch 3, Sample 11836: Loss: 0.0875\n",
            "Epoch 3, Sample 11837: Loss: 2.7331\n",
            "Epoch 3, Sample 11838: Loss: 0.2041\n",
            "Epoch 3, Sample 11839: Loss: 0.3441\n",
            "Epoch 3, Sample 11840: Loss: 0.1465\n",
            "Epoch 3, Sample 11841: Loss: 0.0026\n",
            "Epoch 3, Sample 11842: Loss: 0.7036\n",
            "Epoch 3, Sample 11843: Loss: 0.7036\n",
            "Epoch 3, Sample 11844: Loss: 1.9999\n",
            "Epoch 3, Sample 11845: Loss: 0.3584\n",
            "Epoch 3, Sample 11846: Loss: 0.3949\n",
            "Epoch 3, Sample 11847: Loss: 1.5597\n",
            "Epoch 3, Sample 11848: Loss: 0.2759\n",
            "Epoch 3, Sample 11849: Loss: 0.2759\n",
            "Epoch 3, Sample 11850: Loss: 0.2759\n",
            "Epoch 3, Sample 11851: Loss: 0.9894\n",
            "Epoch 3, Sample 11852: Loss: 0.0588\n",
            "Epoch 3, Sample 11853: Loss: 7.6726\n",
            "Epoch 3, Sample 11854: Loss: 0.8951\n",
            "Epoch 3, Sample 11855: Loss: 0.2375\n",
            "Epoch 3, Sample 11856: Loss: 0.0938\n",
            "Epoch 3, Sample 11857: Loss: 0.0018\n",
            "Epoch 3, Sample 11858: Loss: 0.0455\n",
            "Epoch 3, Sample 11859: Loss: 0.1627\n",
            "Epoch 3, Sample 11860: Loss: 0.0026\n",
            "Epoch 3, Sample 11861: Loss: 0.5375\n",
            "Epoch 3, Sample 11862: Loss: 1.0511\n",
            "Epoch 3, Sample 11863: Loss: 0.2044\n",
            "Epoch 3, Sample 11864: Loss: 0.0030\n",
            "Epoch 3, Sample 11865: Loss: 8.0426\n",
            "Epoch 3, Sample 11866: Loss: 0.7036\n",
            "Epoch 3, Sample 11867: Loss: 2.7331\n",
            "Epoch 3, Sample 11868: Loss: 0.3092\n",
            "Epoch 3, Sample 11869: Loss: 1.4537\n",
            "Epoch 3, Sample 11870: Loss: 0.0026\n",
            "Epoch 3, Sample 11871: Loss: 0.4588\n",
            "Epoch 3, Sample 11872: Loss: 0.0938\n",
            "Epoch 3, Sample 11873: Loss: 0.0466\n",
            "Epoch 3, Sample 11874: Loss: 6.3986\n",
            "Epoch 3, Sample 11875: Loss: 0.0205\n",
            "Epoch 3, Sample 11876: Loss: 1.0227\n",
            "Epoch 3, Sample 11877: Loss: 0.3399\n",
            "Epoch 3, Sample 11878: Loss: 1.0688\n",
            "Epoch 3, Sample 11879: Loss: 0.5972\n",
            "Epoch 3, Sample 11880: Loss: 0.0030\n",
            "Epoch 3, Sample 11881: Loss: 11.5326\n",
            "Epoch 3, Sample 11882: Loss: 0.5858\n",
            "Epoch 3, Sample 11883: Loss: 0.0505\n",
            "Epoch 3, Sample 11884: Loss: 0.0013\n",
            "Epoch 3, Sample 11885: Loss: 0.7036\n",
            "Epoch 3, Sample 11886: Loss: 1.0155\n",
            "Epoch 3, Sample 11887: Loss: 0.2034\n",
            "Epoch 3, Sample 11888: Loss: 0.5141\n",
            "Epoch 3, Sample 11889: Loss: 0.7036\n",
            "Epoch 3, Sample 11890: Loss: 0.2686\n",
            "Epoch 3, Sample 11891: Loss: 0.6990\n",
            "Epoch 3, Sample 11892: Loss: 0.1170\n",
            "Epoch 3, Sample 11893: Loss: 0.0026\n",
            "Epoch 3, Sample 11894: Loss: 0.2032\n",
            "Epoch 3, Sample 11895: Loss: 0.5858\n",
            "Epoch 3, Sample 11896: Loss: 1.4537\n",
            "Epoch 3, Sample 11897: Loss: 0.2639\n",
            "Epoch 3, Sample 11898: Loss: 4.9130\n",
            "Epoch 3, Sample 11899: Loss: 0.3399\n",
            "Epoch 3, Sample 11900: Loss: 8.7194\n",
            "Epoch 3, Sample 11901: Loss: 0.5003\n",
            "Epoch 3, Sample 11902: Loss: 0.3092\n",
            "Epoch 3, Sample 11903: Loss: 0.1250\n",
            "Epoch 3, Sample 11904: Loss: 0.1246\n",
            "Epoch 3, Sample 11905: Loss: 0.2832\n",
            "Epoch 3, Sample 11906: Loss: 0.3441\n",
            "Epoch 3, Sample 11907: Loss: 0.0205\n",
            "Epoch 3, Sample 11908: Loss: 0.1250\n",
            "Epoch 3, Sample 11909: Loss: 0.0026\n",
            "Epoch 3, Sample 11910: Loss: 0.3399\n",
            "Epoch 3, Sample 11911: Loss: 1.3501\n",
            "Epoch 3, Sample 11912: Loss: 0.1399\n",
            "Epoch 3, Sample 11913: Loss: 0.0625\n",
            "Epoch 3, Sample 11914: Loss: 0.2639\n",
            "Epoch 3, Sample 11915: Loss: 0.2034\n",
            "Epoch 3, Sample 11916: Loss: 1.2845\n",
            "Epoch 3, Sample 11917: Loss: 2.9661\n",
            "Epoch 3, Sample 11918: Loss: 0.0026\n",
            "Epoch 3, Sample 11919: Loss: 0.0630\n",
            "Epoch 3, Sample 11920: Loss: 2.7331\n",
            "Epoch 3, Sample 11921: Loss: 0.6990\n",
            "Epoch 3, Sample 11922: Loss: 0.3441\n",
            "Epoch 3, Sample 11923: Loss: 0.3399\n",
            "Epoch 3, Sample 11924: Loss: 0.5000\n",
            "Epoch 3, Sample 11925: Loss: 0.0630\n",
            "Epoch 3, Sample 11926: Loss: 1.0359\n",
            "Epoch 3, Sample 11927: Loss: 0.2340\n",
            "Epoch 3, Sample 11928: Loss: 0.3624\n",
            "Epoch 3, Sample 11929: Loss: 2.7331\n",
            "Epoch 3, Sample 11930: Loss: 0.4367\n",
            "Epoch 3, Sample 11931: Loss: 0.0060\n",
            "Epoch 3, Sample 11932: Loss: 3.0271\n",
            "Epoch 3, Sample 11933: Loss: 0.0554\n",
            "Epoch 3, Sample 11934: Loss: 0.9651\n",
            "Epoch 3, Sample 11935: Loss: 0.4930\n",
            "Epoch 3, Sample 11936: Loss: 0.0026\n",
            "Epoch 3, Sample 11937: Loss: 1.8819\n",
            "Epoch 3, Sample 11938: Loss: 0.1372\n",
            "Epoch 3, Sample 11939: Loss: 0.2044\n",
            "Epoch 3, Sample 11940: Loss: 1.0524\n",
            "Epoch 3, Sample 11941: Loss: 0.2044\n",
            "Epoch 3, Sample 11942: Loss: 0.1250\n",
            "Epoch 3, Sample 11943: Loss: 0.7702\n",
            "Epoch 3, Sample 11944: Loss: 0.0025\n",
            "Epoch 3, Sample 11945: Loss: 0.5858\n",
            "Epoch 3, Sample 11946: Loss: 1.0524\n",
            "Epoch 3, Sample 11947: Loss: 0.1170\n",
            "Epoch 3, Sample 11948: Loss: 0.0212\n",
            "Epoch 3, Sample 11949: Loss: 0.2036\n",
            "Epoch 3, Sample 11950: Loss: 0.3402\n",
            "Epoch 3, Sample 11951: Loss: 0.8217\n",
            "Epoch 3, Sample 11952: Loss: 0.5000\n",
            "Epoch 3, Sample 11953: Loss: 0.0838\n",
            "Epoch 3, Sample 11954: Loss: 1.5963\n",
            "Epoch 3, Sample 11955: Loss: 0.1337\n",
            "Epoch 3, Sample 11956: Loss: 0.4799\n",
            "Epoch 3, Sample 11957: Loss: 0.0625\n",
            "Epoch 3, Sample 11958: Loss: 0.4155\n",
            "Epoch 3, Sample 11959: Loss: 7.6467\n",
            "Epoch 3, Sample 11960: Loss: 0.3007\n",
            "Epoch 3, Sample 11961: Loss: 0.2759\n",
            "Epoch 3, Sample 11962: Loss: 1.5597\n",
            "Epoch 3, Sample 11963: Loss: 0.0083\n",
            "Epoch 3, Sample 11964: Loss: 0.7702\n",
            "Epoch 3, Sample 11965: Loss: 0.0018\n",
            "Epoch 3, Sample 11966: Loss: 0.2034\n",
            "Epoch 3, Sample 11967: Loss: 0.0640\n",
            "Epoch 3, Sample 11968: Loss: 7.2518\n",
            "Epoch 3, Sample 11969: Loss: 0.6990\n",
            "Epoch 3, Sample 11970: Loss: 0.2044\n",
            "Epoch 3, Sample 11971: Loss: 0.3399\n",
            "Epoch 3, Sample 11972: Loss: 0.0062\n",
            "Epoch 3, Sample 11973: Loss: 0.4799\n",
            "Epoch 3, Sample 11974: Loss: 0.4611\n",
            "Epoch 3, Sample 11975: Loss: 1.0524\n",
            "Epoch 3, Sample 11976: Loss: 0.5871\n",
            "Epoch 3, Sample 11977: Loss: 1.0524\n",
            "Epoch 3, Sample 11978: Loss: 0.2044\n",
            "Epoch 3, Sample 11979: Loss: 1.5597\n",
            "Epoch 3, Sample 11980: Loss: 0.6867\n",
            "Epoch 3, Sample 11981: Loss: 0.0000\n",
            "Epoch 3, Sample 11982: Loss: 0.5000\n",
            "Epoch 3, Sample 11983: Loss: 0.0018\n",
            "Epoch 3, Sample 11984: Loss: 0.1508\n",
            "Epoch 3, Sample 11985: Loss: 0.3506\n",
            "Epoch 3, Sample 11986: Loss: 0.5314\n",
            "Epoch 3, Sample 11987: Loss: 4.3234\n",
            "Epoch 3, Sample 11988: Loss: 1.7073\n",
            "Epoch 3, Sample 11989: Loss: 3.5504\n",
            "Epoch 3, Sample 11990: Loss: 0.2034\n",
            "Epoch 3, Sample 11991: Loss: 0.2034\n",
            "Epoch 3, Sample 11992: Loss: 0.5003\n",
            "Epoch 3, Sample 11993: Loss: 0.3598\n",
            "Epoch 3, Sample 11994: Loss: 0.0536\n",
            "Epoch 3, Sample 11995: Loss: 1.0524\n",
            "Epoch 3, Sample 11996: Loss: 0.1091\n",
            "Epoch 3, Sample 11997: Loss: 0.2036\n",
            "Epoch 3, Sample 11998: Loss: 0.1250\n",
            "Epoch 3, Sample 11999: Loss: 8.7405\n",
            "Epoch 3, Sample 12000: Loss: 0.0018\n",
            "Epoch 3, Sample 12001: Loss: 5.9195\n",
            "Epoch 3, Sample 12002: Loss: 0.0306\n",
            "Epoch 3, Sample 12003: Loss: 0.0001\n",
            "Epoch 3, Sample 12004: Loss: 0.0005\n",
            "Epoch 3, Sample 12005: Loss: 0.7344\n",
            "Epoch 3, Sample 12006: Loss: 0.1890\n",
            "Epoch 3, Sample 12007: Loss: 1.5542\n",
            "Epoch 3, Sample 12008: Loss: 0.0001\n",
            "Epoch 3, Sample 12009: Loss: 0.2044\n",
            "Epoch 3, Sample 12010: Loss: 0.0476\n",
            "Epoch 3, Sample 12011: Loss: 0.4607\n",
            "Epoch 3, Sample 12012: Loss: 0.0000\n",
            "Epoch 3, Sample 12013: Loss: 0.4930\n",
            "Epoch 3, Sample 12014: Loss: 0.1114\n",
            "Epoch 3, Sample 12015: Loss: 0.3598\n",
            "Epoch 3, Sample 12016: Loss: 0.2044\n",
            "Epoch 3, Sample 12017: Loss: 1.1263\n",
            "Epoch 3, Sample 12018: Loss: 0.0626\n",
            "Epoch 3, Sample 12019: Loss: 0.2044\n",
            "Epoch 3, Sample 12020: Loss: 3.7586\n",
            "Epoch 3, Sample 12021: Loss: 0.3949\n",
            "Epoch 3, Sample 12022: Loss: 0.3949\n",
            "Epoch 3, Sample 12023: Loss: 0.1250\n",
            "Epoch 3, Sample 12024: Loss: 1.0524\n",
            "Epoch 3, Sample 12025: Loss: 1.0524\n",
            "Epoch 3, Sample 12026: Loss: 0.2759\n",
            "Epoch 3, Sample 12027: Loss: 0.0060\n",
            "Epoch 3, Sample 12028: Loss: 0.5019\n",
            "Epoch 3, Sample 12029: Loss: 0.2219\n",
            "Epoch 3, Sample 12030: Loss: 0.4382\n",
            "Epoch 3, Sample 12031: Loss: 0.0006\n",
            "Epoch 3, Sample 12032: Loss: 0.3441\n",
            "Epoch 3, Sample 12033: Loss: 17.3544\n",
            "Epoch 3, Sample 12034: Loss: 0.3441\n",
            "Epoch 3, Sample 12035: Loss: 0.2459\n",
            "Epoch 3, Sample 12036: Loss: 0.1039\n",
            "Epoch 3, Sample 12037: Loss: 0.0018\n",
            "Epoch 3, Sample 12038: Loss: 0.0630\n",
            "Epoch 3, Sample 12039: Loss: 0.4663\n",
            "Epoch 3, Sample 12040: Loss: 0.1660\n",
            "Epoch 3, Sample 12041: Loss: 0.3367\n",
            "Epoch 3, Sample 12042: Loss: 0.0558\n",
            "Epoch 3, Sample 12043: Loss: 0.0247\n",
            "Epoch 3, Sample 12044: Loss: 0.7036\n",
            "Epoch 3, Sample 12045: Loss: 0.0026\n",
            "Epoch 3, Sample 12046: Loss: 0.2034\n",
            "Epoch 3, Sample 12047: Loss: 0.0009\n",
            "Epoch 3, Sample 12048: Loss: 0.6139\n",
            "Epoch 3, Sample 12049: Loss: 0.1559\n",
            "Epoch 3, Sample 12050: Loss: 0.5003\n",
            "Epoch 3, Sample 12051: Loss: 1.0359\n",
            "Epoch 3, Sample 12052: Loss: 0.0026\n",
            "Epoch 3, Sample 12053: Loss: 0.3584\n",
            "Epoch 3, Sample 12054: Loss: 0.1250\n",
            "Epoch 3, Sample 12055: Loss: 0.0625\n",
            "Epoch 3, Sample 12056: Loss: 0.5019\n",
            "Epoch 3, Sample 12057: Loss: 1.5597\n",
            "Epoch 3, Sample 12058: Loss: 0.1863\n",
            "Epoch 3, Sample 12059: Loss: 0.2034\n",
            "Epoch 3, Sample 12060: Loss: 0.6990\n",
            "Epoch 3, Sample 12061: Loss: 1.4537\n",
            "Epoch 3, Sample 12062: Loss: 0.0018\n",
            "Epoch 3, Sample 12063: Loss: 0.3441\n",
            "Epoch 3, Sample 12064: Loss: 0.3399\n",
            "Epoch 3, Sample 12065: Loss: 0.0201\n",
            "Epoch 3, Sample 12066: Loss: 0.0505\n",
            "Epoch 3, Sample 12067: Loss: 0.0002\n",
            "Epoch 3, Sample 12068: Loss: 0.0025\n",
            "Epoch 3, Sample 12069: Loss: 0.2032\n",
            "Epoch 3, Sample 12070: Loss: 1.8616\n",
            "Epoch 3, Sample 12071: Loss: 9.7728\n",
            "Epoch 3, Sample 12072: Loss: 20.8867\n",
            "Epoch 3, Sample 12073: Loss: 1.0155\n",
            "Epoch 3, Sample 12074: Loss: 0.7036\n",
            "Epoch 3, Sample 12075: Loss: 0.1170\n",
            "Epoch 3, Sample 12076: Loss: 0.3319\n",
            "Epoch 3, Sample 12077: Loss: 0.2044\n",
            "Epoch 3, Sample 12078: Loss: 0.0026\n",
            "Epoch 3, Sample 12079: Loss: 10.8862\n",
            "Epoch 3, Sample 12080: Loss: 0.7453\n",
            "Epoch 3, Sample 12081: Loss: 0.6867\n",
            "Epoch 3, Sample 12082: Loss: 0.7036\n",
            "Epoch 3, Sample 12083: Loss: 0.6304\n",
            "Epoch 3, Sample 12084: Loss: 0.1399\n",
            "Epoch 3, Sample 12085: Loss: 0.2759\n",
            "Epoch 3, Sample 12086: Loss: 0.8951\n",
            "Epoch 3, Sample 12087: Loss: 0.7036\n",
            "Epoch 3, Sample 12088: Loss: 1.0524\n",
            "Epoch 3, Sample 12089: Loss: 0.2044\n",
            "Epoch 3, Sample 12090: Loss: 0.2962\n",
            "Epoch 3, Sample 12091: Loss: 0.2639\n",
            "Epoch 3, Sample 12092: Loss: 0.2044\n",
            "Epoch 3, Sample 12093: Loss: 0.5314\n",
            "Epoch 3, Sample 12094: Loss: 0.0018\n",
            "Epoch 3, Sample 12095: Loss: 0.7036\n",
            "Epoch 3, Sample 12096: Loss: 0.6990\n",
            "Epoch 3, Sample 12097: Loss: 0.7036\n",
            "Epoch 3, Sample 12098: Loss: 0.0108\n",
            "Epoch 3, Sample 12099: Loss: 0.0161\n",
            "Epoch 3, Sample 12100: Loss: 1.7296\n",
            "Epoch 3, Sample 12101: Loss: 0.2036\n",
            "Epoch 3, Sample 12102: Loss: 0.2044\n",
            "Epoch 3, Sample 12103: Loss: 0.3441\n",
            "Epoch 3, Sample 12104: Loss: 0.2032\n",
            "Epoch 3, Sample 12105: Loss: 0.0630\n",
            "Epoch 3, Sample 12106: Loss: 1.0530\n",
            "Epoch 3, Sample 12107: Loss: 0.0063\n",
            "Epoch 3, Sample 12108: Loss: 0.1397\n",
            "Epoch 3, Sample 12109: Loss: 0.0116\n",
            "Epoch 3, Sample 12110: Loss: 0.0630\n",
            "Epoch 3, Sample 12111: Loss: 0.1559\n",
            "Epoch 3, Sample 12112: Loss: 0.2375\n",
            "Epoch 3, Sample 12113: Loss: 1.0524\n",
            "Epoch 3, Sample 12114: Loss: 0.7036\n",
            "Epoch 3, Sample 12115: Loss: 2.0233\n",
            "Epoch 3, Sample 12116: Loss: 1.0359\n",
            "Epoch 3, Sample 12117: Loss: 0.5972\n",
            "Epoch 3, Sample 12118: Loss: 15.5912\n",
            "Epoch 3, Sample 12119: Loss: 3.5504\n",
            "Epoch 3, Sample 12120: Loss: 0.3399\n",
            "Epoch 3, Sample 12121: Loss: 0.5196\n",
            "Epoch 3, Sample 12122: Loss: 0.2832\n",
            "Epoch 3, Sample 12123: Loss: 0.6990\n",
            "Epoch 3, Sample 12124: Loss: 0.1056\n",
            "Epoch 3, Sample 12125: Loss: 0.0145\n",
            "Epoch 3, Sample 12126: Loss: 0.0018\n",
            "Epoch 3, Sample 12127: Loss: 0.1250\n",
            "Epoch 3, Sample 12128: Loss: 0.2044\n",
            "Epoch 3, Sample 12129: Loss: 1.0530\n",
            "Epoch 3, Sample 12130: Loss: 0.0630\n",
            "Epoch 3, Sample 12131: Loss: 0.8951\n",
            "Epoch 3, Sample 12132: Loss: 4.4015\n",
            "Epoch 3, Sample 12133: Loss: 0.1248\n",
            "Epoch 3, Sample 12134: Loss: 0.2034\n",
            "Epoch 3, Sample 12135: Loss: 0.2044\n",
            "Epoch 3, Sample 12136: Loss: 2.0092\n",
            "Epoch 3, Sample 12137: Loss: 0.2759\n",
            "Epoch 3, Sample 12138: Loss: 0.1822\n",
            "Epoch 3, Sample 12139: Loss: 0.2759\n",
            "Epoch 3, Sample 12140: Loss: 0.2044\n",
            "Epoch 3, Sample 12141: Loss: 0.0144\n",
            "Epoch 3, Sample 12142: Loss: 4.4745\n",
            "Epoch 3, Sample 12143: Loss: 1.0155\n",
            "Epoch 3, Sample 12144: Loss: 0.2759\n",
            "Epoch 3, Sample 12145: Loss: 0.3402\n",
            "Epoch 3, Sample 12146: Loss: 0.5062\n",
            "Epoch 3, Sample 12147: Loss: 0.1170\n",
            "Epoch 3, Sample 12148: Loss: 0.6653\n",
            "Epoch 3, Sample 12149: Loss: 0.0626\n",
            "Epoch 3, Sample 12150: Loss: 0.1559\n",
            "Epoch 3, Sample 12151: Loss: 0.0026\n",
            "Epoch 3, Sample 12152: Loss: 1.5597\n",
            "Epoch 3, Sample 12153: Loss: 0.1250\n",
            "Epoch 3, Sample 12154: Loss: 1.4823\n",
            "Epoch 3, Sample 12155: Loss: 0.2044\n",
            "Epoch 3, Sample 12156: Loss: 0.1170\n",
            "Epoch 3, Sample 12157: Loss: 1.0530\n",
            "Epoch 3, Sample 12158: Loss: 0.0819\n",
            "Epoch 3, Sample 12159: Loss: 0.2044\n",
            "Epoch 3, Sample 12160: Loss: 0.2044\n",
            "Epoch 3, Sample 12161: Loss: 0.3399\n",
            "Epoch 3, Sample 12162: Loss: 0.0206\n",
            "Epoch 3, Sample 12163: Loss: 0.0018\n",
            "Epoch 3, Sample 12164: Loss: 0.3399\n",
            "Epoch 3, Sample 12165: Loss: 0.9780\n",
            "Epoch 3, Sample 12166: Loss: 1.5597\n",
            "Epoch 3, Sample 12167: Loss: 0.1044\n",
            "Epoch 3, Sample 12168: Loss: 0.0207\n",
            "Epoch 3, Sample 12169: Loss: 0.0212\n",
            "Epoch 3, Sample 12170: Loss: 0.7036\n",
            "Epoch 3, Sample 12171: Loss: 0.3399\n",
            "Epoch 3, Sample 12172: Loss: 0.2044\n",
            "Epoch 3, Sample 12173: Loss: 0.0013\n",
            "Epoch 3, Sample 12174: Loss: 0.1170\n",
            "Epoch 3, Sample 12175: Loss: 0.7036\n",
            "Epoch 3, Sample 12176: Loss: 0.0830\n",
            "Epoch 3, Sample 12177: Loss: 1.0524\n",
            "Epoch 3, Sample 12178: Loss: 0.0026\n",
            "Epoch 3, Sample 12179: Loss: 1.5597\n",
            "Epoch 3, Sample 12180: Loss: 0.7036\n",
            "Epoch 3, Sample 12181: Loss: 1.0524\n",
            "Epoch 3, Sample 12182: Loss: 0.0838\n",
            "Epoch 3, Sample 12183: Loss: 0.7036\n",
            "Epoch 3, Sample 12184: Loss: 0.7036\n",
            "Epoch 3, Sample 12185: Loss: 0.0034\n",
            "Epoch 3, Sample 12186: Loss: 0.4514\n",
            "Epoch 3, Sample 12187: Loss: 1.5597\n",
            "Epoch 3, Sample 12188: Loss: 0.2036\n",
            "Epoch 3, Sample 12189: Loss: 1.0524\n",
            "Epoch 3, Sample 12190: Loss: 0.0838\n",
            "Epoch 3, Sample 12191: Loss: 1.5597\n",
            "Epoch 3, Sample 12192: Loss: 0.2962\n",
            "Epoch 3, Sample 12193: Loss: 1.9213\n",
            "Epoch 3, Sample 12194: Loss: 0.0026\n",
            "Epoch 3, Sample 12195: Loss: 0.3399\n",
            "Epoch 3, Sample 12196: Loss: 0.3402\n",
            "Epoch 3, Sample 12197: Loss: 0.3441\n",
            "Epoch 3, Sample 12198: Loss: 0.4607\n",
            "Epoch 3, Sample 12199: Loss: 0.0018\n",
            "Epoch 3, Sample 12200: Loss: 0.1863\n",
            "Epoch 3, Sample 12201: Loss: 0.3399\n",
            "Epoch 3, Sample 12202: Loss: 0.1559\n",
            "Epoch 3, Sample 12203: Loss: 0.2219\n",
            "Epoch 3, Sample 12204: Loss: 0.2044\n",
            "Epoch 3, Sample 12205: Loss: 0.2759\n",
            "Epoch 3, Sample 12206: Loss: 0.5858\n",
            "Epoch 3, Sample 12207: Loss: 8.4662\n",
            "Epoch 3, Sample 12208: Loss: 0.0026\n",
            "Epoch 3, Sample 12209: Loss: 0.0415\n",
            "Epoch 3, Sample 12210: Loss: 0.1248\n",
            "Epoch 3, Sample 12211: Loss: 0.0030\n",
            "Epoch 3, Sample 12212: Loss: 2.7331\n",
            "Epoch 3, Sample 12213: Loss: 4.4745\n",
            "Epoch 3, Sample 12214: Loss: 0.5858\n",
            "Epoch 3, Sample 12215: Loss: 0.3399\n",
            "Epoch 3, Sample 12216: Loss: 0.0108\n",
            "Epoch 3, Sample 12217: Loss: 0.0026\n",
            "Epoch 3, Sample 12218: Loss: 0.3441\n",
            "Epoch 3, Sample 12219: Loss: 1.0524\n",
            "Epoch 3, Sample 12220: Loss: 0.6990\n",
            "Epoch 3, Sample 12221: Loss: 0.2044\n",
            "Epoch 3, Sample 12222: Loss: 8.0504\n",
            "Epoch 3, Sample 12223: Loss: 0.0306\n",
            "Epoch 3, Sample 12224: Loss: 0.2340\n",
            "Epoch 3, Sample 12225: Loss: 0.2034\n",
            "Epoch 3, Sample 12226: Loss: 1.0551\n",
            "Epoch 3, Sample 12227: Loss: 0.1248\n",
            "Epoch 3, Sample 12228: Loss: 0.2219\n",
            "Epoch 3, Sample 12229: Loss: 0.5636\n",
            "Epoch 3, Sample 12230: Loss: 4.4745\n",
            "Epoch 3, Sample 12231: Loss: 0.4761\n",
            "Epoch 3, Sample 12232: Loss: 0.0505\n",
            "Epoch 3, Sample 12233: Loss: 0.0000\n",
            "Epoch 3, Sample 12234: Loss: 0.2832\n",
            "Epoch 3, Sample 12235: Loss: 0.9367\n",
            "Epoch 3, Sample 12236: Loss: 0.1250\n",
            "Epoch 3, Sample 12237: Loss: 0.1687\n",
            "Epoch 3, Sample 12238: Loss: 0.0238\n",
            "Epoch 3, Sample 12239: Loss: 0.3441\n",
            "Epoch 3, Sample 12240: Loss: 2.7331\n",
            "Epoch 3, Sample 12241: Loss: 3.9629\n",
            "Epoch 3, Sample 12242: Loss: 0.6867\n",
            "Epoch 3, Sample 12243: Loss: 0.0060\n",
            "Epoch 3, Sample 12244: Loss: 0.2044\n",
            "Epoch 3, Sample 12245: Loss: 1.0155\n",
            "Epoch 3, Sample 12246: Loss: 0.1248\n",
            "Epoch 3, Sample 12247: Loss: 2.3207\n",
            "Epoch 3, Sample 12248: Loss: 0.3441\n",
            "Epoch 3, Sample 12249: Loss: 0.2112\n",
            "Epoch 3, Sample 12250: Loss: 0.7036\n",
            "Epoch 3, Sample 12251: Loss: 0.0145\n",
            "Epoch 3, Sample 12252: Loss: 0.0067\n",
            "Epoch 3, Sample 12253: Loss: 1.0524\n",
            "Epoch 3, Sample 12254: Loss: 0.0303\n",
            "Epoch 3, Sample 12255: Loss: 0.2832\n",
            "Epoch 3, Sample 12256: Loss: 2.4541\n",
            "Epoch 3, Sample 12257: Loss: 0.2032\n",
            "Epoch 3, Sample 12258: Loss: 1.0524\n",
            "Epoch 3, Sample 12259: Loss: 0.2036\n",
            "Epoch 3, Sample 12260: Loss: 1.4537\n",
            "Epoch 3, Sample 12261: Loss: 0.8951\n",
            "Epoch 3, Sample 12262: Loss: 0.5972\n",
            "Epoch 3, Sample 12263: Loss: 0.0630\n",
            "Epoch 3, Sample 12264: Loss: 0.1252\n",
            "Epoch 3, Sample 12265: Loss: 3.7299\n",
            "Epoch 3, Sample 12266: Loss: 0.4930\n",
            "Epoch 3, Sample 12267: Loss: 17.3544\n",
            "Epoch 3, Sample 12268: Loss: 0.2044\n",
            "Epoch 3, Sample 12269: Loss: 0.1170\n",
            "Epoch 3, Sample 12270: Loss: 1.0524\n",
            "Epoch 3, Sample 12271: Loss: 0.3332\n",
            "Epoch 3, Sample 12272: Loss: 1.0524\n",
            "Epoch 3, Sample 12273: Loss: 2.7331\n",
            "Epoch 3, Sample 12274: Loss: 9.5046\n",
            "Epoch 3, Sample 12275: Loss: 0.0626\n",
            "Epoch 3, Sample 12276: Loss: 9.3274\n",
            "Epoch 3, Sample 12277: Loss: 0.8484\n",
            "Epoch 3, Sample 12278: Loss: 1.0524\n",
            "Epoch 3, Sample 12279: Loss: 1.2522\n",
            "Epoch 3, Sample 12280: Loss: 0.0270\n",
            "Epoch 3, Sample 12281: Loss: 0.2032\n",
            "Epoch 3, Sample 12282: Loss: 0.1248\n",
            "Epoch 3, Sample 12283: Loss: 2.8908\n",
            "Epoch 3, Sample 12284: Loss: 0.5972\n",
            "Epoch 3, Sample 12285: Loss: 1.0155\n",
            "Epoch 3, Sample 12286: Loss: 0.1938\n",
            "Epoch 3, Sample 12287: Loss: 0.2759\n",
            "Epoch 3, Sample 12288: Loss: 1.0956\n",
            "Epoch 3, Sample 12289: Loss: 0.0026\n",
            "Epoch 3, Sample 12290: Loss: 0.0082\n",
            "Epoch 3, Sample 12291: Loss: 0.3441\n",
            "Epoch 3, Sample 12292: Loss: 0.1273\n",
            "Epoch 3, Sample 12293: Loss: 0.7036\n",
            "Epoch 3, Sample 12294: Loss: 0.0026\n",
            "Epoch 3, Sample 12295: Loss: 1.5597\n",
            "Epoch 3, Sample 12296: Loss: 0.3294\n",
            "Epoch 3, Sample 12297: Loss: 3.6506\n",
            "Epoch 3, Sample 12298: Loss: 1.0524\n",
            "Epoch 3, Sample 12299: Loss: 0.2970\n",
            "Epoch 3, Sample 12300: Loss: 0.0063\n",
            "Epoch 3, Sample 12301: Loss: 0.1113\n",
            "Epoch 3, Sample 12302: Loss: 0.4799\n",
            "Epoch 3, Sample 12303: Loss: 0.5000\n",
            "Epoch 3, Sample 12304: Loss: 0.5858\n",
            "Epoch 3, Sample 12305: Loss: 0.2938\n",
            "Epoch 3, Sample 12306: Loss: 0.0630\n",
            "Epoch 3, Sample 12307: Loss: 1.0956\n",
            "Epoch 3, Sample 12308: Loss: 1.4537\n",
            "Epoch 3, Sample 12309: Loss: 1.0530\n",
            "Epoch 3, Sample 12310: Loss: 0.7036\n",
            "Epoch 3, Sample 12311: Loss: 0.1170\n",
            "Epoch 3, Sample 12312: Loss: 2.8693\n",
            "Epoch 3, Sample 12313: Loss: 0.3399\n",
            "Epoch 3, Sample 12314: Loss: 0.6653\n",
            "Epoch 3, Sample 12315: Loss: 0.1170\n",
            "Epoch 3, Sample 12316: Loss: 0.1248\n",
            "Epoch 3, Sample 12317: Loss: 0.2044\n",
            "Epoch 3, Sample 12318: Loss: 0.1248\n",
            "Epoch 3, Sample 12319: Loss: 0.6990\n",
            "Epoch 3, Sample 12320: Loss: 0.2032\n",
            "Epoch 3, Sample 12321: Loss: 0.5062\n",
            "Epoch 3, Sample 12322: Loss: 1.0524\n",
            "Epoch 3, Sample 12323: Loss: 0.2962\n",
            "Epoch 3, Sample 12324: Loss: 1.0524\n",
            "Epoch 3, Sample 12325: Loss: 1.0524\n",
            "Epoch 3, Sample 12326: Loss: 0.0623\n",
            "Epoch 3, Sample 12327: Loss: 1.0530\n",
            "Epoch 3, Sample 12328: Loss: 0.1372\n",
            "Epoch 3, Sample 12329: Loss: 0.1559\n",
            "Epoch 3, Sample 12330: Loss: 0.0005\n",
            "Epoch 3, Sample 12331: Loss: 0.0031\n",
            "Epoch 3, Sample 12332: Loss: 5.1063\n",
            "Epoch 3, Sample 12333: Loss: 0.9024\n",
            "Epoch 3, Sample 12334: Loss: 0.9780\n",
            "Epoch 3, Sample 12335: Loss: 2.7331\n",
            "Epoch 3, Sample 12336: Loss: 0.1039\n",
            "Epoch 3, Sample 12337: Loss: 0.0063\n",
            "Epoch 3, Sample 12338: Loss: 7.4082\n",
            "Epoch 3, Sample 12339: Loss: 0.6867\n",
            "Epoch 3, Sample 12340: Loss: 0.3949\n",
            "Epoch 3, Sample 12341: Loss: 0.0026\n",
            "Epoch 3, Sample 12342: Loss: 1.0155\n",
            "Epoch 3, Sample 12343: Loss: 40.0936\n",
            "Epoch 3, Sample 12344: Loss: 0.7036\n",
            "Epoch 3, Sample 12345: Loss: 0.0001\n",
            "Epoch 3, Sample 12346: Loss: 0.4930\n",
            "Epoch 3, Sample 12347: Loss: 0.7036\n",
            "Epoch 3, Sample 12348: Loss: 0.5196\n",
            "Epoch 3, Sample 12349: Loss: 0.2036\n",
            "Epoch 3, Sample 12350: Loss: 0.9785\n",
            "Epoch 3, Sample 12351: Loss: 1.0155\n",
            "Epoch 3, Sample 12352: Loss: 0.1463\n",
            "Epoch 3, Sample 12353: Loss: 0.6092\n",
            "Epoch 3, Sample 12354: Loss: 1.5597\n",
            "Epoch 3, Sample 12355: Loss: 0.0062\n",
            "Epoch 3, Sample 12356: Loss: 0.2832\n",
            "Epoch 3, Sample 12357: Loss: 0.5858\n",
            "Epoch 3, Sample 12358: Loss: 0.3949\n",
            "Epoch 3, Sample 12359: Loss: 0.0415\n",
            "Epoch 3, Sample 12360: Loss: 4.9827\n",
            "Epoch 3, Sample 12361: Loss: 0.0026\n",
            "Epoch 3, Sample 12362: Loss: 0.7036\n",
            "Epoch 3, Sample 12363: Loss: 0.0630\n",
            "Epoch 3, Sample 12364: Loss: 1.0266\n",
            "Epoch 3, Sample 12365: Loss: 1.4128\n",
            "Epoch 3, Sample 12366: Loss: 0.3402\n",
            "Epoch 3, Sample 12367: Loss: 1.7066\n",
            "Epoch 3, Sample 12368: Loss: 0.0953\n",
            "Epoch 3, Sample 12369: Loss: 1.0524\n",
            "Epoch 3, Sample 12370: Loss: 1.0155\n",
            "Epoch 3, Sample 12371: Loss: 0.1478\n",
            "Epoch 3, Sample 12372: Loss: 0.3399\n",
            "Epoch 3, Sample 12373: Loss: 0.9780\n",
            "Epoch 3, Sample 12374: Loss: 0.1508\n",
            "Epoch 3, Sample 12375: Loss: 0.0306\n",
            "Epoch 3, Sample 12376: Loss: 0.2034\n",
            "Epoch 3, Sample 12377: Loss: 0.2044\n",
            "Epoch 3, Sample 12378: Loss: 0.8484\n",
            "Epoch 3, Sample 12379: Loss: 7.6710\n",
            "Epoch 3, Sample 12380: Loss: 0.0026\n",
            "Epoch 3, Sample 12381: Loss: 0.2034\n",
            "Epoch 3, Sample 12382: Loss: 10.1372\n",
            "Epoch 3, Sample 12383: Loss: 1.5597\n",
            "Epoch 3, Sample 12384: Loss: 0.0013\n",
            "Epoch 3, Sample 12385: Loss: 0.3852\n",
            "Epoch 3, Sample 12386: Loss: 0.7036\n",
            "Epoch 3, Sample 12387: Loss: 0.7036\n",
            "Epoch 3, Sample 12388: Loss: 0.5972\n",
            "Epoch 3, Sample 12389: Loss: 0.4799\n",
            "Epoch 3, Sample 12390: Loss: 0.0018\n",
            "Epoch 3, Sample 12391: Loss: 0.3441\n",
            "Epoch 3, Sample 12392: Loss: 0.7036\n",
            "Epoch 3, Sample 12393: Loss: 3.1294\n",
            "Epoch 3, Sample 12394: Loss: 2.7989\n",
            "Epoch 3, Sample 12395: Loss: 1.0524\n",
            "Epoch 3, Sample 12396: Loss: 0.4841\n",
            "Epoch 3, Sample 12397: Loss: 0.2204\n",
            "Epoch 3, Sample 12398: Loss: 0.2759\n",
            "Epoch 3, Sample 12399: Loss: 1.5597\n",
            "Epoch 3, Sample 12400: Loss: 1.0155\n",
            "Epoch 3, Sample 12401: Loss: 1.5597\n",
            "Epoch 3, Sample 12402: Loss: 0.7702\n",
            "Epoch 3, Sample 12403: Loss: 0.0026\n",
            "Epoch 3, Sample 12404: Loss: 0.2989\n",
            "Epoch 3, Sample 12405: Loss: 0.1170\n",
            "Epoch 3, Sample 12406: Loss: 0.0860\n",
            "Epoch 3, Sample 12407: Loss: 1.0524\n",
            "Epoch 3, Sample 12408: Loss: 0.1588\n",
            "Epoch 3, Sample 12409: Loss: 0.0026\n",
            "Epoch 3, Sample 12410: Loss: 1.7195\n",
            "Epoch 3, Sample 12411: Loss: 0.1250\n",
            "Epoch 3, Sample 12412: Loss: 4.7115\n",
            "Epoch 3, Sample 12413: Loss: 1.0524\n",
            "Epoch 3, Sample 12414: Loss: 0.0018\n",
            "Epoch 3, Sample 12415: Loss: 1.0359\n",
            "Epoch 3, Sample 12416: Loss: 0.1250\n",
            "Epoch 3, Sample 12417: Loss: 0.5858\n",
            "Epoch 3, Sample 12418: Loss: 1.0530\n",
            "Epoch 3, Sample 12419: Loss: 0.4466\n",
            "Epoch 3, Sample 12420: Loss: 0.0915\n",
            "Epoch 3, Sample 12421: Loss: 1.2198\n",
            "Epoch 3, Sample 12422: Loss: 0.2699\n",
            "Epoch 3, Sample 12423: Loss: 0.1559\n",
            "Epoch 3, Sample 12424: Loss: 0.7036\n",
            "Epoch 3, Sample 12425: Loss: 1.5597\n",
            "Epoch 3, Sample 12426: Loss: 0.0915\n",
            "Epoch 3, Sample 12427: Loss: 0.0630\n",
            "Epoch 3, Sample 12428: Loss: 0.1372\n",
            "Epoch 3, Sample 12429: Loss: 0.2034\n",
            "Epoch 3, Sample 12430: Loss: 0.5972\n",
            "Epoch 3, Sample 12431: Loss: 3.5504\n",
            "Epoch 3, Sample 12432: Loss: 0.3399\n",
            "Epoch 3, Sample 12433: Loss: 0.6190\n",
            "Epoch 3, Sample 12434: Loss: 0.7036\n",
            "Epoch 3, Sample 12435: Loss: 0.4841\n",
            "Epoch 3, Sample 12436: Loss: 0.1559\n",
            "Epoch 3, Sample 12437: Loss: 0.2032\n",
            "Epoch 3, Sample 12438: Loss: 0.0026\n",
            "Epoch 3, Sample 12439: Loss: 1.0359\n",
            "Epoch 3, Sample 12440: Loss: 1.0155\n",
            "Epoch 3, Sample 12441: Loss: 1.0524\n",
            "Epoch 3, Sample 12442: Loss: 0.2200\n",
            "Epoch 3, Sample 12443: Loss: 0.0513\n",
            "Epoch 3, Sample 12444: Loss: 13.1892\n",
            "Epoch 3, Sample 12445: Loss: 1.5597\n",
            "Epoch 3, Sample 12446: Loss: 0.5003\n",
            "Epoch 3, Sample 12447: Loss: 1.0956\n",
            "Epoch 3, Sample 12448: Loss: 0.0147\n",
            "Epoch 3, Sample 12449: Loss: 1.0524\n",
            "Epoch 3, Sample 12450: Loss: 0.4032\n",
            "Epoch 3, Sample 12451: Loss: 0.0063\n",
            "Epoch 3, Sample 12452: Loss: 0.3949\n",
            "Epoch 3, Sample 12453: Loss: 0.8951\n",
            "Epoch 3, Sample 12454: Loss: 4.0002\n",
            "Epoch 3, Sample 12455: Loss: 2.4541\n",
            "Epoch 3, Sample 12456: Loss: 0.0005\n",
            "Epoch 3, Sample 12457: Loss: 0.2182\n",
            "Epoch 3, Sample 12458: Loss: 0.7036\n",
            "Epoch 3, Sample 12459: Loss: 0.8951\n",
            "Epoch 3, Sample 12460: Loss: 0.3949\n",
            "Epoch 3, Sample 12461: Loss: 0.1248\n",
            "Epoch 3, Sample 12462: Loss: 0.5972\n",
            "Epoch 3, Sample 12463: Loss: 0.5000\n",
            "Epoch 3, Sample 12464: Loss: 1.0359\n",
            "Epoch 3, Sample 12465: Loss: 0.6304\n",
            "Epoch 3, Sample 12466: Loss: 0.0205\n",
            "Epoch 3, Sample 12467: Loss: 0.2219\n",
            "Epoch 3, Sample 12468: Loss: 0.0537\n",
            "Epoch 3, Sample 12469: Loss: 1.6326\n",
            "Epoch 3, Sample 12470: Loss: 0.2034\n",
            "Epoch 3, Sample 12471: Loss: 0.6867\n",
            "Epoch 3, Sample 12472: Loss: 0.2044\n",
            "Epoch 3, Sample 12473: Loss: 0.2036\n",
            "Epoch 3, Sample 12474: Loss: 0.0041\n",
            "Epoch 3, Sample 12475: Loss: 0.9367\n",
            "Epoch 3, Sample 12476: Loss: 0.7453\n",
            "Epoch 3, Sample 12477: Loss: 0.0364\n",
            "Epoch 3, Sample 12478: Loss: 0.1044\n",
            "Epoch 3, Sample 12479: Loss: 0.0744\n",
            "Epoch 3, Sample 12480: Loss: 0.2112\n",
            "Epoch 3, Sample 12481: Loss: 7.6726\n",
            "Epoch 3, Sample 12482: Loss: 0.4367\n",
            "Epoch 3, Sample 12483: Loss: 0.2036\n",
            "Epoch 3, Sample 12484: Loss: 0.3402\n",
            "Epoch 3, Sample 12485: Loss: 1.0359\n",
            "Epoch 3, Sample 12486: Loss: 0.4906\n",
            "Epoch 3, Sample 12487: Loss: 1.5597\n",
            "Epoch 3, Sample 12488: Loss: 0.5496\n",
            "Epoch 3, Sample 12489: Loss: 0.0027\n",
            "Epoch 3, Sample 12490: Loss: 0.7036\n",
            "Epoch 3, Sample 12491: Loss: 0.0108\n",
            "Epoch 3, Sample 12492: Loss: 0.7036\n",
            "Epoch 3, Sample 12493: Loss: 0.2044\n",
            "Epoch 3, Sample 12494: Loss: 1.0530\n",
            "Epoch 3, Sample 12495: Loss: 0.2759\n",
            "Epoch 3, Sample 12496: Loss: 8.0504\n",
            "Epoch 3, Sample 12497: Loss: 0.1170\n",
            "Epoch 3, Sample 12498: Loss: 0.2034\n",
            "Epoch 3, Sample 12499: Loss: 0.7036\n",
            "Epoch 3, Sample 12500: Loss: 0.0026\n",
            "Epoch 3, Sample 12501: Loss: 0.0018\n",
            "Epoch 3, Sample 12502: Loss: 7.6726\n",
            "Epoch 3, Sample 12503: Loss: 0.1594\n",
            "Epoch 3, Sample 12504: Loss: 1.2845\n",
            "Epoch 3, Sample 12505: Loss: 0.0108\n",
            "Epoch 3, Sample 12506: Loss: 0.1219\n",
            "Epoch 3, Sample 12507: Loss: 0.1248\n",
            "Epoch 3, Sample 12508: Loss: 0.2941\n",
            "Epoch 3, Sample 12509: Loss: 0.2044\n",
            "Epoch 3, Sample 12510: Loss: 0.4611\n",
            "Epoch 3, Sample 12511: Loss: 0.2340\n",
            "Epoch 3, Sample 12512: Loss: 0.1114\n",
            "Epoch 3, Sample 12513: Loss: 0.1056\n",
            "Epoch 3, Sample 12514: Loss: 0.7036\n",
            "Epoch 3, Sample 12515: Loss: 1.0524\n",
            "Epoch 3, Sample 12516: Loss: 0.0026\n",
            "Epoch 3, Sample 12517: Loss: 0.1248\n",
            "Epoch 3, Sample 12518: Loss: 0.3088\n",
            "Epoch 3, Sample 12519: Loss: 3.5504\n",
            "Epoch 3, Sample 12520: Loss: 0.1248\n",
            "Epoch 3, Sample 12521: Loss: 0.0013\n",
            "Epoch 3, Sample 12522: Loss: 0.0031\n",
            "Epoch 3, Sample 12523: Loss: 0.0001\n",
            "Epoch 3, Sample 12524: Loss: 0.3399\n",
            "Epoch 3, Sample 12525: Loss: 0.9367\n",
            "Epoch 3, Sample 12526: Loss: 2.7331\n",
            "Epoch 3, Sample 12527: Loss: 1.0524\n",
            "Epoch 3, Sample 12528: Loss: 0.3399\n",
            "Epoch 3, Sample 12529: Loss: 17.5959\n",
            "Epoch 3, Sample 12530: Loss: 0.2363\n",
            "Epoch 3, Sample 12531: Loss: 0.9780\n",
            "Epoch 3, Sample 12532: Loss: 0.0212\n",
            "Epoch 3, Sample 12533: Loss: 0.0027\n",
            "Epoch 3, Sample 12534: Loss: 1.0155\n",
            "Epoch 3, Sample 12535: Loss: 0.0625\n",
            "Epoch 3, Sample 12536: Loss: 0.3539\n",
            "Epoch 3, Sample 12537: Loss: 0.3402\n",
            "Epoch 3, Sample 12538: Loss: 0.8951\n",
            "Epoch 3, Sample 12539: Loss: 0.1170\n",
            "Epoch 3, Sample 12540: Loss: 0.2855\n",
            "Epoch 3, Sample 12541: Loss: 0.2044\n",
            "Epoch 3, Sample 12542: Loss: 0.1250\n",
            "Epoch 3, Sample 12543: Loss: 0.0938\n",
            "Epoch 3, Sample 12544: Loss: 0.7036\n",
            "Epoch 3, Sample 12545: Loss: 1.0524\n",
            "Epoch 3, Sample 12546: Loss: 1.2926\n",
            "Epoch 3, Sample 12547: Loss: 0.0938\n",
            "Epoch 3, Sample 12548: Loss: 0.1355\n",
            "Epoch 3, Sample 12549: Loss: 1.5597\n",
            "Epoch 3, Sample 12550: Loss: 0.0000\n",
            "Epoch 3, Sample 12551: Loss: 2.0233\n",
            "Epoch 3, Sample 12552: Loss: 0.0013\n",
            "Epoch 3, Sample 12553: Loss: 0.2044\n",
            "Epoch 3, Sample 12554: Loss: 0.0189\n",
            "Epoch 3, Sample 12555: Loss: 1.5542\n",
            "Epoch 3, Sample 12556: Loss: 0.0026\n",
            "Epoch 3, Sample 12557: Loss: 0.1233\n",
            "Epoch 3, Sample 12558: Loss: 0.1250\n",
            "Epoch 3, Sample 12559: Loss: 2.5104\n",
            "Epoch 3, Sample 12560: Loss: 1.5597\n",
            "Epoch 3, Sample 12561: Loss: 0.1250\n",
            "Epoch 3, Sample 12562: Loss: 1.0727\n",
            "Epoch 3, Sample 12563: Loss: 2.7331\n",
            "Epoch 3, Sample 12564: Loss: 1.0956\n",
            "Epoch 3, Sample 12565: Loss: 1.0956\n",
            "Epoch 3, Sample 12566: Loss: 0.1463\n",
            "Epoch 3, Sample 12567: Loss: 0.1508\n",
            "Epoch 3, Sample 12568: Loss: 0.7036\n",
            "Epoch 3, Sample 12569: Loss: 7.7260\n",
            "Epoch 3, Sample 12570: Loss: 0.0108\n",
            "Epoch 3, Sample 12571: Loss: 0.0007\n",
            "Epoch 3, Sample 12572: Loss: 0.0106\n",
            "Epoch 3, Sample 12573: Loss: 1.2845\n",
            "Epoch 3, Sample 12574: Loss: 10.8862\n",
            "Epoch 3, Sample 12575: Loss: 0.2034\n",
            "Epoch 3, Sample 12576: Loss: 2.0225\n",
            "Epoch 3, Sample 12577: Loss: 0.0466\n",
            "Epoch 3, Sample 12578: Loss: 0.1250\n",
            "Epoch 3, Sample 12579: Loss: 0.0205\n",
            "Epoch 3, Sample 12580: Loss: 0.0108\n",
            "Epoch 3, Sample 12581: Loss: 0.2989\n",
            "Epoch 3, Sample 12582: Loss: 0.0063\n",
            "Epoch 3, Sample 12583: Loss: 1.0524\n",
            "Epoch 3, Sample 12584: Loss: 0.0026\n",
            "Epoch 3, Sample 12585: Loss: 1.0956\n",
            "Epoch 3, Sample 12586: Loss: 1.5597\n",
            "Epoch 3, Sample 12587: Loss: 0.9780\n",
            "Epoch 3, Sample 12588: Loss: 1.0524\n",
            "Epoch 3, Sample 12589: Loss: 0.1250\n",
            "Epoch 3, Sample 12590: Loss: 0.7183\n",
            "Epoch 3, Sample 12591: Loss: 0.0630\n",
            "Epoch 3, Sample 12592: Loss: 2.1901\n",
            "Epoch 3, Sample 12593: Loss: 2.7331\n",
            "Epoch 3, Sample 12594: Loss: 0.9367\n",
            "Epoch 3, Sample 12595: Loss: 0.7628\n",
            "Epoch 3, Sample 12596: Loss: 0.2034\n",
            "Epoch 3, Sample 12597: Loss: 2.4326\n",
            "Epoch 3, Sample 12598: Loss: 0.2759\n",
            "Epoch 3, Sample 12599: Loss: 0.7453\n",
            "Epoch 3, Sample 12600: Loss: 2.5454\n",
            "Epoch 3, Sample 12601: Loss: 0.0022\n",
            "Epoch 3, Sample 12602: Loss: 1.0524\n",
            "Epoch 3, Sample 12603: Loss: 12.6690\n",
            "Epoch 3, Sample 12604: Loss: 0.0026\n",
            "Epoch 3, Sample 12605: Loss: 0.7036\n",
            "Epoch 3, Sample 12606: Loss: 1.0359\n",
            "Epoch 3, Sample 12607: Loss: 0.1246\n",
            "Epoch 3, Sample 12608: Loss: 0.1225\n",
            "Epoch 3, Sample 12609: Loss: 0.0026\n",
            "Epoch 3, Sample 12610: Loss: 7.7260\n",
            "Epoch 3, Sample 12611: Loss: 0.0205\n",
            "Epoch 3, Sample 12612: Loss: 0.2034\n",
            "Epoch 3, Sample 12613: Loss: 0.0025\n",
            "Epoch 3, Sample 12614: Loss: 0.0604\n",
            "Epoch 3, Sample 12615: Loss: 2.8693\n",
            "Epoch 3, Sample 12616: Loss: 7.4082\n",
            "Epoch 3, Sample 12617: Loss: 0.2044\n",
            "Epoch 3, Sample 12618: Loss: 0.2811\n",
            "Epoch 3, Sample 12619: Loss: 0.1170\n",
            "Epoch 3, Sample 12620: Loss: 0.2759\n",
            "Epoch 3, Sample 12621: Loss: 0.2044\n",
            "Epoch 3, Sample 12622: Loss: 0.5858\n",
            "Epoch 3, Sample 12623: Loss: 0.0306\n",
            "Epoch 3, Sample 12624: Loss: 0.0033\n",
            "Epoch 3, Sample 12625: Loss: 0.2962\n",
            "Epoch 3, Sample 12626: Loss: 0.3441\n",
            "Epoch 3, Sample 12627: Loss: 0.0258\n",
            "Epoch 3, Sample 12628: Loss: 0.1549\n",
            "Epoch 3, Sample 12629: Loss: 0.2032\n",
            "Epoch 3, Sample 12630: Loss: 0.1248\n",
            "Epoch 3, Sample 12631: Loss: 0.9367\n",
            "Epoch 3, Sample 12632: Loss: 0.2034\n",
            "Epoch 3, Sample 12633: Loss: 0.0099\n",
            "Epoch 3, Sample 12634: Loss: 0.0363\n",
            "Epoch 3, Sample 12635: Loss: 0.1523\n",
            "Epoch 3, Sample 12636: Loss: 0.0513\n",
            "Epoch 3, Sample 12637: Loss: 0.1417\n",
            "Epoch 3, Sample 12638: Loss: 0.2044\n",
            "Epoch 3, Sample 12639: Loss: 0.0630\n",
            "Epoch 3, Sample 12640: Loss: 0.0063\n",
            "Epoch 3, Sample 12641: Loss: 0.7910\n",
            "Epoch 3, Sample 12642: Loss: 0.1777\n",
            "Epoch 3, Sample 12643: Loss: 1.1263\n",
            "Epoch 3, Sample 12644: Loss: 1.0524\n",
            "Epoch 3, Sample 12645: Loss: 0.3568\n",
            "Epoch 3, Sample 12646: Loss: 0.7453\n",
            "Epoch 3, Sample 12647: Loss: 0.0062\n",
            "Epoch 3, Sample 12648: Loss: 0.0205\n",
            "Epoch 3, Sample 12649: Loss: 0.0630\n",
            "Epoch 3, Sample 12650: Loss: 0.4611\n",
            "Epoch 3, Sample 12651: Loss: 0.1692\n",
            "Epoch 3, Sample 12652: Loss: 0.2044\n",
            "Epoch 3, Sample 12653: Loss: 1.0956\n",
            "Epoch 3, Sample 12654: Loss: 1.0155\n",
            "Epoch 3, Sample 12655: Loss: 9.0738\n",
            "Epoch 3, Sample 12656: Loss: 3.9018\n",
            "Epoch 3, Sample 12657: Loss: 0.3441\n",
            "Epoch 3, Sample 12658: Loss: 0.4841\n",
            "Epoch 3, Sample 12659: Loss: 0.1546\n",
            "Epoch 3, Sample 12660: Loss: 0.4930\n",
            "Epoch 3, Sample 12661: Loss: 0.0018\n",
            "Epoch 3, Sample 12662: Loss: 0.7036\n",
            "Epoch 3, Sample 12663: Loss: 0.0212\n",
            "Epoch 3, Sample 12664: Loss: 0.1546\n",
            "Epoch 3, Sample 12665: Loss: 0.3399\n",
            "Epoch 3, Sample 12666: Loss: 0.2044\n",
            "Epoch 3, Sample 12667: Loss: 1.0530\n",
            "Epoch 3, Sample 12668: Loss: 0.0084\n",
            "Epoch 3, Sample 12669: Loss: 2.7989\n",
            "Epoch 3, Sample 12670: Loss: 0.0028\n",
            "Epoch 3, Sample 12671: Loss: 0.5858\n",
            "Epoch 3, Sample 12672: Loss: 3.5504\n",
            "Epoch 3, Sample 12673: Loss: 0.7453\n",
            "Epoch 3, Sample 12674: Loss: 0.0001\n",
            "Epoch 3, Sample 12675: Loss: 0.5799\n",
            "Epoch 3, Sample 12676: Loss: 0.9780\n",
            "Epoch 3, Sample 12677: Loss: 7.2518\n",
            "Epoch 3, Sample 12678: Loss: 0.3399\n",
            "Epoch 3, Sample 12679: Loss: 0.2032\n",
            "Epoch 3, Sample 12680: Loss: 16.9580\n",
            "Epoch 3, Sample 12681: Loss: 1.0524\n",
            "Epoch 3, Sample 12682: Loss: 0.3441\n",
            "Epoch 3, Sample 12683: Loss: 0.1863\n",
            "Epoch 3, Sample 12684: Loss: 0.0840\n",
            "Epoch 3, Sample 12685: Loss: 0.1555\n",
            "Epoch 3, Sample 12686: Loss: 10.6983\n",
            "Epoch 3, Sample 12687: Loss: 2.1901\n",
            "Epoch 3, Sample 12688: Loss: 0.2032\n",
            "Epoch 3, Sample 12689: Loss: 1.0524\n",
            "Epoch 3, Sample 12690: Loss: 0.2032\n",
            "Epoch 3, Sample 12691: Loss: 0.1250\n",
            "Epoch 3, Sample 12692: Loss: 0.0234\n",
            "Epoch 3, Sample 12693: Loss: 0.2219\n",
            "Epoch 3, Sample 12694: Loss: 0.2962\n",
            "Epoch 3, Sample 12695: Loss: 0.9367\n",
            "Epoch 3, Sample 12696: Loss: 0.5858\n",
            "Epoch 3, Sample 12697: Loss: 0.2044\n",
            "Epoch 3, Sample 12698: Loss: 15.4828\n",
            "Epoch 3, Sample 12699: Loss: 0.4799\n",
            "Epoch 3, Sample 12700: Loss: 0.2036\n",
            "Epoch 3, Sample 12701: Loss: 0.7910\n",
            "Epoch 3, Sample 12702: Loss: 22.7781\n",
            "Epoch 3, Sample 12703: Loss: 3.7714\n",
            "Epoch 3, Sample 12704: Loss: 1.0530\n",
            "Epoch 3, Sample 12705: Loss: 0.1248\n",
            "Epoch 3, Sample 12706: Loss: 0.2832\n",
            "Epoch 3, Sample 12707: Loss: 0.8951\n",
            "Epoch 3, Sample 12708: Loss: 0.1890\n",
            "Epoch 3, Sample 12709: Loss: 0.1394\n",
            "Epoch 3, Sample 12710: Loss: 0.2034\n",
            "Epoch 3, Sample 12711: Loss: 0.0630\n",
            "Epoch 3, Sample 12712: Loss: 0.2935\n",
            "Epoch 3, Sample 12713: Loss: 2.6384\n",
            "Epoch 3, Sample 12714: Loss: 0.0018\n",
            "Epoch 3, Sample 12715: Loss: 0.2044\n",
            "Epoch 3, Sample 12716: Loss: 0.0026\n",
            "Epoch 3, Sample 12717: Loss: 0.6990\n",
            "Epoch 3, Sample 12718: Loss: 1.0524\n",
            "Epoch 3, Sample 12719: Loss: 0.7702\n",
            "Epoch 3, Sample 12720: Loss: 0.0002\n",
            "Epoch 3, Sample 12721: Loss: 0.0026\n",
            "Epoch 3, Sample 12722: Loss: 0.4220\n",
            "Epoch 3, Sample 12723: Loss: 0.2750\n",
            "Epoch 3, Sample 12724: Loss: 0.5019\n",
            "Epoch 3, Sample 12725: Loss: 0.7036\n",
            "Epoch 3, Sample 12726: Loss: 0.7453\n",
            "Epoch 3, Sample 12727: Loss: 2.7331\n",
            "Epoch 3, Sample 12728: Loss: 2.0351\n",
            "Epoch 3, Sample 12729: Loss: 1.0155\n",
            "Epoch 3, Sample 12730: Loss: 1.0155\n",
            "Epoch 3, Sample 12731: Loss: 1.4884\n",
            "Epoch 3, Sample 12732: Loss: 0.0981\n",
            "Epoch 3, Sample 12733: Loss: 0.0460\n",
            "Epoch 3, Sample 12734: Loss: 1.3508\n",
            "Epoch 3, Sample 12735: Loss: 0.0558\n",
            "Epoch 3, Sample 12736: Loss: 2.7331\n",
            "Epoch 3, Sample 12737: Loss: 0.0640\n",
            "Epoch 3, Sample 12738: Loss: 0.4032\n",
            "Epoch 3, Sample 12739: Loss: 2.7331\n",
            "Epoch 3, Sample 12740: Loss: 1.3114\n",
            "Epoch 3, Sample 12741: Loss: 0.2832\n",
            "Epoch 3, Sample 12742: Loss: 0.2639\n",
            "Epoch 3, Sample 12743: Loss: 0.0027\n",
            "Epoch 3, Sample 12744: Loss: 1.0524\n",
            "Epoch 3, Sample 12745: Loss: 3.0780\n",
            "Epoch 3, Sample 12746: Loss: 0.0026\n",
            "Epoch 3, Sample 12747: Loss: 3.0780\n",
            "Epoch 3, Sample 12748: Loss: 0.0731\n",
            "Epoch 3, Sample 12749: Loss: 0.0018\n",
            "Epoch 3, Sample 12750: Loss: 1.0155\n",
            "Epoch 3, Sample 12751: Loss: 0.5858\n",
            "Epoch 3, Sample 12752: Loss: 0.1250\n",
            "Epoch 3, Sample 12753: Loss: 0.1250\n",
            "Epoch 3, Sample 12754: Loss: 0.0026\n",
            "Epoch 3, Sample 12755: Loss: 0.3399\n",
            "Epoch 3, Sample 12756: Loss: 0.1040\n",
            "Epoch 3, Sample 12757: Loss: 0.0590\n",
            "Epoch 3, Sample 12758: Loss: 1.0511\n",
            "Epoch 3, Sample 12759: Loss: 0.1337\n",
            "Epoch 3, Sample 12760: Loss: 0.1170\n",
            "Epoch 3, Sample 12761: Loss: 0.2112\n",
            "Epoch 3, Sample 12762: Loss: 0.3477\n",
            "Epoch 3, Sample 12763: Loss: 0.2132\n",
            "Epoch 3, Sample 12764: Loss: 0.2034\n",
            "Epoch 3, Sample 12765: Loss: 1.9658\n",
            "Epoch 3, Sample 12766: Loss: 1.6326\n",
            "Epoch 3, Sample 12767: Loss: 7.5663\n",
            "Epoch 3, Sample 12768: Loss: 0.2044\n",
            "Epoch 3, Sample 12769: Loss: 0.0205\n",
            "Epoch 3, Sample 12770: Loss: 0.0274\n",
            "Epoch 3, Sample 12771: Loss: 1.0155\n",
            "Epoch 3, Sample 12772: Loss: 1.5597\n",
            "Epoch 3, Sample 12773: Loss: 0.3399\n",
            "Epoch 3, Sample 12774: Loss: 0.3092\n",
            "Epoch 3, Sample 12775: Loss: 0.2036\n",
            "Epoch 3, Sample 12776: Loss: 0.6304\n",
            "Epoch 3, Sample 12777: Loss: 1.0530\n",
            "Epoch 3, Sample 12778: Loss: 0.5858\n",
            "Epoch 3, Sample 12779: Loss: 0.5858\n",
            "Epoch 3, Sample 12780: Loss: 2.7989\n",
            "Epoch 3, Sample 12781: Loss: 6.9441\n",
            "Epoch 3, Sample 12782: Loss: 1.0155\n",
            "Epoch 3, Sample 12783: Loss: 0.3568\n",
            "Epoch 3, Sample 12784: Loss: 2.8294\n",
            "Epoch 3, Sample 12785: Loss: 0.2175\n",
            "Epoch 3, Sample 12786: Loss: 0.2832\n",
            "Epoch 3, Sample 12787: Loss: 2.0983\n",
            "Epoch 3, Sample 12788: Loss: 0.7036\n",
            "Epoch 3, Sample 12789: Loss: 0.7036\n",
            "Epoch 3, Sample 12790: Loss: 1.0530\n",
            "Epoch 3, Sample 12791: Loss: 0.2204\n",
            "Epoch 3, Sample 12792: Loss: 0.9367\n",
            "Epoch 3, Sample 12793: Loss: 0.5196\n",
            "Epoch 3, Sample 12794: Loss: 0.2759\n",
            "Epoch 3, Sample 12795: Loss: 0.7036\n",
            "Epoch 3, Sample 12796: Loss: 0.0018\n",
            "Epoch 3, Sample 12797: Loss: 0.1252\n",
            "Epoch 3, Sample 12798: Loss: 0.2044\n",
            "Epoch 3, Sample 12799: Loss: 0.7036\n",
            "Epoch 3, Sample 12800: Loss: 0.2036\n",
            "Epoch 3, Sample 12801: Loss: 0.3402\n",
            "Epoch 3, Sample 12802: Loss: 0.3367\n",
            "Epoch 3, Sample 12803: Loss: 0.0067\n",
            "Epoch 3, Sample 12804: Loss: 0.2639\n",
            "Epoch 3, Sample 12805: Loss: 0.1246\n",
            "Epoch 3, Sample 12806: Loss: 1.6207\n",
            "Epoch 3, Sample 12807: Loss: 0.2032\n",
            "Epoch 3, Sample 12808: Loss: 0.2219\n",
            "Epoch 3, Sample 12809: Loss: 0.1246\n",
            "Epoch 3, Sample 12810: Loss: 2.7331\n",
            "Epoch 3, Sample 12811: Loss: 0.2034\n",
            "Epoch 3, Sample 12812: Loss: 0.5858\n",
            "Epoch 3, Sample 12813: Loss: 0.9780\n",
            "Epoch 3, Sample 12814: Loss: 0.2032\n",
            "Epoch 3, Sample 12815: Loss: 0.8951\n",
            "Epoch 3, Sample 12816: Loss: 0.4032\n",
            "Epoch 3, Sample 12817: Loss: 1.0155\n",
            "Epoch 3, Sample 12818: Loss: 0.0205\n",
            "Epoch 3, Sample 12819: Loss: 0.0108\n",
            "Epoch 3, Sample 12820: Loss: 0.2074\n",
            "Epoch 3, Sample 12821: Loss: 1.4537\n",
            "Epoch 3, Sample 12822: Loss: 0.2032\n",
            "Epoch 3, Sample 12823: Loss: 0.1199\n",
            "Epoch 3, Sample 12824: Loss: 0.1508\n",
            "Epoch 3, Sample 12825: Loss: 0.0714\n",
            "Epoch 3, Sample 12826: Loss: 0.2340\n",
            "Epoch 3, Sample 12827: Loss: 0.2032\n",
            "Epoch 3, Sample 12828: Loss: 0.2832\n",
            "Epoch 3, Sample 12829: Loss: 0.5858\n",
            "Epoch 3, Sample 12830: Loss: 0.0026\n",
            "Epoch 3, Sample 12831: Loss: 1.0956\n",
            "Epoch 3, Sample 12832: Loss: 1.8819\n",
            "Epoch 3, Sample 12833: Loss: 0.0031\n",
            "Epoch 3, Sample 12834: Loss: 0.0026\n",
            "Epoch 3, Sample 12835: Loss: 0.2290\n",
            "Epoch 3, Sample 12836: Loss: 1.5597\n",
            "Epoch 3, Sample 12837: Loss: 0.1246\n",
            "Epoch 3, Sample 12838: Loss: 0.0027\n",
            "Epoch 3, Sample 12839: Loss: 0.3945\n",
            "Epoch 3, Sample 12840: Loss: 0.2935\n",
            "Epoch 3, Sample 12841: Loss: 0.2704\n",
            "Epoch 3, Sample 12842: Loss: 0.0306\n",
            "Epoch 3, Sample 12843: Loss: 0.2032\n",
            "Epoch 3, Sample 12844: Loss: 0.0026\n",
            "Epoch 3, Sample 12845: Loss: 0.7036\n",
            "Epoch 3, Sample 12846: Loss: 0.5972\n",
            "Epoch 3, Sample 12847: Loss: 0.1559\n",
            "Epoch 3, Sample 12848: Loss: 0.0391\n",
            "Epoch 3, Sample 12849: Loss: 0.0915\n",
            "Epoch 3, Sample 12850: Loss: 0.4032\n",
            "Epoch 3, Sample 12851: Loss: 0.0306\n",
            "Epoch 3, Sample 12852: Loss: 0.0501\n",
            "Epoch 3, Sample 12853: Loss: 1.4676\n",
            "Epoch 3, Sample 12854: Loss: 0.2044\n",
            "Epoch 3, Sample 12855: Loss: 0.3441\n",
            "Epoch 3, Sample 12856: Loss: 0.0380\n",
            "Epoch 3, Sample 12857: Loss: 0.2032\n",
            "Epoch 3, Sample 12858: Loss: 0.4996\n",
            "Epoch 3, Sample 12859: Loss: 0.1252\n",
            "Epoch 3, Sample 12860: Loss: 1.0477\n",
            "Epoch 3, Sample 12861: Loss: 0.0002\n",
            "Epoch 3, Sample 12862: Loss: 0.8951\n",
            "Epoch 3, Sample 12863: Loss: 0.1250\n",
            "Epoch 3, Sample 12864: Loss: 0.0212\n",
            "Epoch 3, Sample 12865: Loss: 0.0680\n",
            "Epoch 3, Sample 12866: Loss: 0.0013\n",
            "Epoch 3, Sample 12867: Loss: 1.4537\n",
            "Epoch 3, Sample 12868: Loss: 0.2935\n",
            "Epoch 3, Sample 12869: Loss: 0.1250\n",
            "Epoch 3, Sample 12870: Loss: 0.8951\n",
            "Epoch 3, Sample 12871: Loss: 0.0205\n",
            "Epoch 3, Sample 12872: Loss: 0.8951\n",
            "Epoch 3, Sample 12873: Loss: 0.2032\n",
            "Epoch 3, Sample 12874: Loss: 1.2192\n",
            "Epoch 3, Sample 12875: Loss: 0.0108\n",
            "Epoch 3, Sample 12876: Loss: 0.3949\n",
            "Epoch 3, Sample 12877: Loss: 2.2765\n",
            "Epoch 3, Sample 12878: Loss: 0.2044\n",
            "Epoch 3, Sample 12879: Loss: 18.3303\n",
            "Epoch 3, Sample 12880: Loss: 0.7453\n",
            "Epoch 3, Sample 12881: Loss: 2.2690\n",
            "Epoch 3, Sample 12882: Loss: 0.4032\n",
            "Epoch 3, Sample 12883: Loss: 0.2034\n",
            "Epoch 3, Sample 12884: Loss: 0.9367\n",
            "Epoch 3, Sample 12885: Loss: 0.1622\n",
            "Epoch 3, Sample 12886: Loss: 0.2044\n",
            "Epoch 3, Sample 12887: Loss: 0.0026\n",
            "Epoch 3, Sample 12888: Loss: 0.7453\n",
            "Epoch 3, Sample 12889: Loss: 0.2832\n",
            "Epoch 3, Sample 12890: Loss: 0.0201\n",
            "Epoch 3, Sample 12891: Loss: 0.5858\n",
            "Epoch 3, Sample 12892: Loss: 0.5989\n",
            "Epoch 3, Sample 12893: Loss: 1.0524\n",
            "Epoch 3, Sample 12894: Loss: 0.0838\n",
            "Epoch 3, Sample 12895: Loss: 1.5597\n",
            "Epoch 3, Sample 12896: Loss: 0.2832\n",
            "Epoch 3, Sample 12897: Loss: 0.0011\n",
            "Epoch 3, Sample 12898: Loss: 0.0052\n",
            "Epoch 3, Sample 12899: Loss: 0.1786\n",
            "Epoch 3, Sample 12900: Loss: 1.0524\n",
            "Epoch 3, Sample 12901: Loss: 0.9780\n",
            "Epoch 3, Sample 12902: Loss: 0.0205\n",
            "Epoch 3, Sample 12903: Loss: 0.0049\n",
            "Epoch 3, Sample 12904: Loss: 0.1482\n",
            "Epoch 3, Sample 12905: Loss: 0.5972\n",
            "Epoch 3, Sample 12906: Loss: 1.0266\n",
            "Epoch 3, Sample 12907: Loss: 1.5597\n",
            "Epoch 3, Sample 12908: Loss: 0.1246\n",
            "Epoch 3, Sample 12909: Loss: 0.0001\n",
            "Epoch 3, Sample 12910: Loss: 0.0026\n",
            "Epoch 3, Sample 12911: Loss: 0.3288\n",
            "Epoch 3, Sample 12912: Loss: 0.1349\n",
            "Epoch 3, Sample 12913: Loss: 1.0956\n",
            "Epoch 3, Sample 12914: Loss: 0.1463\n",
            "Epoch 3, Sample 12915: Loss: 0.1508\n",
            "Epoch 3, Sample 12916: Loss: 0.7036\n",
            "Epoch 3, Sample 12917: Loss: 0.0018\n",
            "Epoch 3, Sample 12918: Loss: 0.0498\n",
            "Epoch 3, Sample 12919: Loss: 0.3247\n",
            "Epoch 3, Sample 12920: Loss: 0.5972\n",
            "Epoch 3, Sample 12921: Loss: 0.2219\n",
            "Epoch 3, Sample 12922: Loss: 1.5597\n",
            "Epoch 3, Sample 12923: Loss: 1.0359\n",
            "Epoch 3, Sample 12924: Loss: 0.0027\n",
            "Epoch 3, Sample 12925: Loss: 0.0079\n",
            "Epoch 3, Sample 12926: Loss: 0.2759\n",
            "Epoch 3, Sample 12927: Loss: 0.6304\n",
            "Epoch 3, Sample 12928: Loss: 0.0287\n",
            "Epoch 3, Sample 12929: Loss: 0.1170\n",
            "Epoch 3, Sample 12930: Loss: 0.1559\n",
            "Epoch 3, Sample 12931: Loss: 1.4537\n",
            "Epoch 3, Sample 12932: Loss: 0.0001\n",
            "Epoch 3, Sample 12933: Loss: 0.2034\n",
            "Epoch 3, Sample 12934: Loss: 1.0155\n",
            "Epoch 3, Sample 12935: Loss: 0.1356\n",
            "Epoch 3, Sample 12936: Loss: 5.8501\n",
            "Epoch 3, Sample 12937: Loss: 4.6602\n",
            "Epoch 3, Sample 12938: Loss: 0.0626\n",
            "Epoch 3, Sample 12939: Loss: 0.1559\n",
            "Epoch 3, Sample 12940: Loss: 0.4607\n",
            "Epoch 3, Sample 12941: Loss: 0.1588\n",
            "Epoch 3, Sample 12942: Loss: 0.1523\n",
            "Epoch 3, Sample 12943: Loss: 0.4799\n",
            "Epoch 3, Sample 12944: Loss: 0.0229\n",
            "Epoch 3, Sample 12945: Loss: 0.0972\n",
            "Epoch 3, Sample 12946: Loss: 0.1248\n",
            "Epoch 3, Sample 12947: Loss: 0.2182\n",
            "Epoch 3, Sample 12948: Loss: 0.4611\n",
            "Epoch 3, Sample 12949: Loss: 0.0108\n",
            "Epoch 3, Sample 12950: Loss: 0.0018\n",
            "Epoch 3, Sample 12951: Loss: 0.0915\n",
            "Epoch 3, Sample 12952: Loss: 0.5858\n",
            "Epoch 3, Sample 12953: Loss: 0.5633\n",
            "Epoch 3, Sample 12954: Loss: 1.0155\n",
            "Epoch 3, Sample 12955: Loss: 1.5597\n",
            "Epoch 3, Sample 12956: Loss: 0.1246\n",
            "Epoch 3, Sample 12957: Loss: 0.1240\n",
            "Epoch 3, Sample 12958: Loss: 0.3441\n",
            "Epoch 3, Sample 12959: Loss: 0.0018\n",
            "Epoch 3, Sample 12960: Loss: 0.2032\n",
            "Epoch 3, Sample 12961: Loss: 0.8951\n",
            "Epoch 3, Sample 12962: Loss: 0.0270\n",
            "Epoch 3, Sample 12963: Loss: 17.7184\n",
            "Epoch 3, Sample 12964: Loss: 1.0359\n",
            "Epoch 3, Sample 12965: Loss: 0.2044\n",
            "Epoch 3, Sample 12966: Loss: 7.6726\n",
            "Epoch 3, Sample 12967: Loss: 0.1248\n",
            "Epoch 3, Sample 12968: Loss: 0.1250\n",
            "Epoch 3, Sample 12969: Loss: 0.0363\n",
            "Epoch 3, Sample 12970: Loss: 0.2032\n",
            "Epoch 3, Sample 12971: Loss: 0.6839\n",
            "Epoch 3, Sample 12972: Loss: 0.2044\n",
            "Epoch 3, Sample 12973: Loss: 0.5858\n",
            "Epoch 3, Sample 12974: Loss: 5.7798\n",
            "Epoch 3, Sample 12975: Loss: 0.4611\n",
            "Epoch 3, Sample 12976: Loss: 0.0287\n",
            "Epoch 3, Sample 12977: Loss: 1.0524\n",
            "Epoch 3, Sample 12978: Loss: 0.2750\n",
            "Epoch 3, Sample 12979: Loss: 0.1170\n",
            "Epoch 3, Sample 12980: Loss: 0.2044\n",
            "Epoch 3, Sample 12981: Loss: 0.6990\n",
            "Epoch 3, Sample 12982: Loss: 0.2778\n",
            "Epoch 3, Sample 12983: Loss: 0.5972\n",
            "Epoch 3, Sample 12984: Loss: 1.0524\n",
            "Epoch 3, Sample 12985: Loss: 0.1250\n",
            "Epoch 3, Sample 12986: Loss: 6.3986\n",
            "Epoch 3, Sample 12987: Loss: 0.0005\n",
            "Epoch 3, Sample 12988: Loss: 0.1687\n",
            "Epoch 3, Sample 12989: Loss: 0.2759\n",
            "Epoch 3, Sample 12990: Loss: 0.6720\n",
            "Epoch 3, Sample 12991: Loss: 0.1250\n",
            "Epoch 3, Sample 12992: Loss: 0.3399\n",
            "Epoch 3, Sample 12993: Loss: 2.7331\n",
            "Epoch 3, Sample 12994: Loss: 0.1170\n",
            "Epoch 3, Sample 12995: Loss: 0.0640\n",
            "Epoch 3, Sample 12996: Loss: 0.7036\n",
            "Epoch 3, Sample 12997: Loss: 0.0026\n",
            "Epoch 3, Sample 12998: Loss: 1.0524\n",
            "Epoch 3, Sample 12999: Loss: 0.0062\n",
            "Epoch 3, Sample 13000: Loss: 0.1559\n",
            "Epoch 3, Sample 13001: Loss: 0.2044\n",
            "Epoch 3, Sample 13002: Loss: 10.0289\n",
            "Epoch 3, Sample 13003: Loss: 1.0155\n",
            "Epoch 3, Sample 13004: Loss: 3.8942\n",
            "Epoch 3, Sample 13005: Loss: 0.0026\n",
            "Epoch 3, Sample 13006: Loss: 0.0026\n",
            "Epoch 3, Sample 13007: Loss: 1.8623\n",
            "Epoch 3, Sample 13008: Loss: 0.2686\n",
            "Epoch 3, Sample 13009: Loss: 1.0524\n",
            "Epoch 3, Sample 13010: Loss: 0.1523\n",
            "Epoch 3, Sample 13011: Loss: 0.0067\n",
            "Epoch 3, Sample 13012: Loss: 1.5597\n",
            "Epoch 3, Sample 13013: Loss: 1.0524\n",
            "Epoch 3, Sample 13014: Loss: 0.2034\n",
            "Epoch 3, Sample 13015: Loss: 0.3399\n",
            "Epoch 3, Sample 13016: Loss: 0.2036\n",
            "Epoch 3, Sample 13017: Loss: 0.0947\n",
            "Epoch 3, Sample 13018: Loss: 1.0524\n",
            "Epoch 3, Sample 13019: Loss: 10.6965\n",
            "Epoch 3, Sample 13020: Loss: 1.4537\n",
            "Epoch 3, Sample 13021: Loss: 2.0233\n",
            "Epoch 3, Sample 13022: Loss: 0.2044\n",
            "Epoch 3, Sample 13023: Loss: 0.2044\n",
            "Epoch 3, Sample 13024: Loss: 0.3477\n",
            "Epoch 3, Sample 13025: Loss: 3.5504\n",
            "Epoch 3, Sample 13026: Loss: 0.5871\n",
            "Epoch 3, Sample 13027: Loss: 1.0155\n",
            "Epoch 3, Sample 13028: Loss: 0.0455\n",
            "Epoch 3, Sample 13029: Loss: 1.0155\n",
            "Epoch 3, Sample 13030: Loss: 0.0455\n",
            "Epoch 3, Sample 13031: Loss: 1.0530\n",
            "Epoch 3, Sample 13032: Loss: 0.7910\n",
            "Epoch 3, Sample 13033: Loss: 1.6701\n",
            "Epoch 3, Sample 13034: Loss: 0.3399\n",
            "Epoch 3, Sample 13035: Loss: 0.3399\n",
            "Epoch 3, Sample 13036: Loss: 0.5858\n",
            "Epoch 3, Sample 13037: Loss: 0.3805\n",
            "Epoch 3, Sample 13038: Loss: 0.3949\n",
            "Epoch 3, Sample 13039: Loss: 0.7036\n",
            "Epoch 3, Sample 13040: Loss: 0.2034\n",
            "Epoch 3, Sample 13041: Loss: 0.4845\n",
            "Epoch 3, Sample 13042: Loss: 1.0524\n",
            "Epoch 3, Sample 13043: Loss: 0.6304\n",
            "Epoch 3, Sample 13044: Loss: 2.8731\n",
            "Epoch 3, Sample 13045: Loss: 0.5871\n",
            "Epoch 3, Sample 13046: Loss: 9.5046\n",
            "Epoch 3, Sample 13047: Loss: 0.9780\n",
            "Epoch 3, Sample 13048: Loss: 0.0630\n",
            "Epoch 3, Sample 13049: Loss: 1.5597\n",
            "Epoch 3, Sample 13050: Loss: 0.2036\n",
            "Epoch 3, Sample 13051: Loss: 0.0000\n",
            "Epoch 3, Sample 13052: Loss: 0.0002\n",
            "Epoch 3, Sample 13053: Loss: 0.2034\n",
            "Epoch 3, Sample 13054: Loss: 0.2832\n",
            "Epoch 3, Sample 13055: Loss: 0.1246\n",
            "Epoch 3, Sample 13056: Loss: 0.1170\n",
            "Epoch 3, Sample 13057: Loss: 0.3441\n",
            "Epoch 3, Sample 13058: Loss: 2.1055\n",
            "Epoch 3, Sample 13059: Loss: 0.7036\n",
            "Epoch 3, Sample 13060: Loss: 0.2759\n",
            "Epoch 3, Sample 13061: Loss: 0.5858\n",
            "Epoch 3, Sample 13062: Loss: 1.0155\n",
            "Epoch 3, Sample 13063: Loss: 0.3949\n",
            "Epoch 3, Sample 13064: Loss: 1.0524\n",
            "Epoch 3, Sample 13065: Loss: 0.5310\n",
            "Epoch 3, Sample 13066: Loss: 0.6058\n",
            "Epoch 3, Sample 13067: Loss: 0.0630\n",
            "Epoch 3, Sample 13068: Loss: 0.3949\n",
            "Epoch 3, Sample 13069: Loss: 0.7036\n",
            "Epoch 3, Sample 13070: Loss: 0.2034\n",
            "Epoch 3, Sample 13071: Loss: 1.1669\n",
            "Epoch 3, Sample 13072: Loss: 0.3399\n",
            "Epoch 3, Sample 13073: Loss: 1.5597\n",
            "Epoch 3, Sample 13074: Loss: 1.0524\n",
            "Epoch 3, Sample 13075: Loss: 0.0205\n",
            "Epoch 3, Sample 13076: Loss: 0.2034\n",
            "Epoch 3, Sample 13077: Loss: 0.7036\n",
            "Epoch 3, Sample 13078: Loss: 0.3450\n",
            "Epoch 3, Sample 13079: Loss: 0.5000\n",
            "Epoch 3, Sample 13080: Loss: 0.6092\n",
            "Epoch 3, Sample 13081: Loss: 0.0947\n",
            "Epoch 3, Sample 13082: Loss: 0.0013\n",
            "Epoch 3, Sample 13083: Loss: 0.6990\n",
            "Epoch 3, Sample 13084: Loss: 0.2044\n",
            "Epoch 3, Sample 13085: Loss: 1.5597\n",
            "Epoch 3, Sample 13086: Loss: 0.5062\n",
            "Epoch 3, Sample 13087: Loss: 0.9651\n",
            "Epoch 3, Sample 13088: Loss: 0.6990\n",
            "Epoch 3, Sample 13089: Loss: 0.7453\n",
            "Epoch 3, Sample 13090: Loss: 2.7331\n",
            "Epoch 3, Sample 13091: Loss: 1.5542\n",
            "Epoch 3, Sample 13092: Loss: 0.1250\n",
            "Epoch 3, Sample 13093: Loss: 0.3399\n",
            "Epoch 3, Sample 13094: Loss: 0.0630\n",
            "Epoch 3, Sample 13095: Loss: 0.2114\n",
            "Epoch 3, Sample 13096: Loss: 0.6867\n",
            "Epoch 3, Sample 13097: Loss: 0.0108\n",
            "Epoch 3, Sample 13098: Loss: 0.5871\n",
            "Epoch 3, Sample 13099: Loss: 0.1248\n",
            "Epoch 3, Sample 13100: Loss: 0.3852\n",
            "Epoch 3, Sample 13101: Loss: 4.4745\n",
            "Epoch 3, Sample 13102: Loss: 0.5871\n",
            "Epoch 3, Sample 13103: Loss: 1.0530\n",
            "Epoch 3, Sample 13104: Loss: 0.0108\n",
            "Epoch 3, Sample 13105: Loss: 0.2044\n",
            "Epoch 3, Sample 13106: Loss: 0.1250\n",
            "Epoch 3, Sample 13107: Loss: 0.2034\n",
            "Epoch 3, Sample 13108: Loss: 0.7036\n",
            "Epoch 3, Sample 13109: Loss: 2.2756\n",
            "Epoch 3, Sample 13110: Loss: 0.0630\n",
            "Epoch 3, Sample 13111: Loss: 0.0026\n",
            "Epoch 3, Sample 13112: Loss: 0.4930\n",
            "Epoch 3, Sample 13113: Loss: 0.0707\n",
            "Epoch 3, Sample 13114: Loss: 0.6981\n",
            "Epoch 3, Sample 13115: Loss: 0.0915\n",
            "Epoch 3, Sample 13116: Loss: 0.0234\n",
            "Epoch 3, Sample 13117: Loss: 0.6990\n",
            "Epoch 3, Sample 13118: Loss: 1.0530\n",
            "Epoch 3, Sample 13119: Loss: 0.9367\n",
            "Epoch 3, Sample 13120: Loss: 6.8646\n",
            "Epoch 3, Sample 13121: Loss: 0.2044\n",
            "Epoch 3, Sample 13122: Loss: 0.2639\n",
            "Epoch 3, Sample 13123: Loss: 0.7453\n",
            "Epoch 3, Sample 13124: Loss: 0.1588\n",
            "Epoch 3, Sample 13125: Loss: 0.1170\n",
            "Epoch 3, Sample 13126: Loss: 0.1114\n",
            "Epoch 3, Sample 13127: Loss: 1.5597\n",
            "Epoch 3, Sample 13128: Loss: 0.2034\n",
            "Epoch 3, Sample 13129: Loss: 0.2034\n",
            "Epoch 3, Sample 13130: Loss: 0.4032\n",
            "Epoch 3, Sample 13131: Loss: 1.0524\n",
            "Epoch 3, Sample 13132: Loss: 0.0270\n",
            "Epoch 3, Sample 13133: Loss: 0.0026\n",
            "Epoch 3, Sample 13134: Loss: 14.3672\n",
            "Epoch 3, Sample 13135: Loss: 0.1250\n",
            "Epoch 3, Sample 13136: Loss: 3.1802\n",
            "Epoch 3, Sample 13137: Loss: 0.2639\n",
            "Epoch 3, Sample 13138: Loss: 0.3399\n",
            "Epoch 3, Sample 13139: Loss: 1.9016\n",
            "Epoch 3, Sample 13140: Loss: 0.0498\n",
            "Epoch 3, Sample 13141: Loss: 0.7453\n",
            "Epoch 3, Sample 13142: Loss: 0.0117\n",
            "Epoch 3, Sample 13143: Loss: 1.4537\n",
            "Epoch 3, Sample 13144: Loss: 0.2494\n",
            "Epoch 3, Sample 13145: Loss: 0.2044\n",
            "Epoch 3, Sample 13146: Loss: 0.1372\n",
            "Epoch 3, Sample 13147: Loss: 2.1480\n",
            "Epoch 3, Sample 13148: Loss: 0.5858\n",
            "Epoch 3, Sample 13149: Loss: 1.0155\n",
            "Epoch 3, Sample 13150: Loss: 0.0018\n",
            "Epoch 3, Sample 13151: Loss: 0.3399\n",
            "Epoch 3, Sample 13152: Loss: 0.0001\n",
            "Epoch 3, Sample 13153: Loss: 0.0001\n",
            "Epoch 3, Sample 13154: Loss: 0.0000\n",
            "Epoch 3, Sample 13155: Loss: 0.8951\n",
            "Epoch 3, Sample 13156: Loss: 6.2712\n",
            "Epoch 3, Sample 13157: Loss: 0.0052\n",
            "Epoch 3, Sample 13158: Loss: 2.7989\n",
            "Epoch 3, Sample 13159: Loss: 2.6860\n",
            "Epoch 3, Sample 13160: Loss: 0.2759\n",
            "Epoch 3, Sample 13161: Loss: 1.5542\n",
            "Epoch 3, Sample 13162: Loss: 0.1250\n",
            "Epoch 3, Sample 13163: Loss: 1.8616\n",
            "Epoch 3, Sample 13164: Loss: 0.2036\n",
            "Epoch 3, Sample 13165: Loss: 0.1250\n",
            "Epoch 3, Sample 13166: Loss: 0.0303\n",
            "Epoch 3, Sample 13167: Loss: 0.0229\n",
            "Epoch 3, Sample 13168: Loss: 0.9780\n",
            "Epoch 3, Sample 13169: Loss: 0.1625\n",
            "Epoch 3, Sample 13170: Loss: 0.3539\n",
            "Epoch 3, Sample 13171: Loss: 0.7036\n",
            "Epoch 3, Sample 13172: Loss: 0.0026\n",
            "Epoch 3, Sample 13173: Loss: 0.0000\n",
            "Epoch 3, Sample 13174: Loss: 3.9991\n",
            "Epoch 3, Sample 13175: Loss: 0.1170\n",
            "Epoch 3, Sample 13176: Loss: 1.0155\n",
            "Epoch 3, Sample 13177: Loss: 0.3402\n",
            "Epoch 3, Sample 13178: Loss: 10.4159\n",
            "Epoch 3, Sample 13179: Loss: 0.0625\n",
            "Epoch 3, Sample 13180: Loss: 0.1170\n",
            "Epoch 3, Sample 13181: Loss: 0.0026\n",
            "Epoch 3, Sample 13182: Loss: 0.1838\n",
            "Epoch 3, Sample 13183: Loss: 0.6990\n",
            "Epoch 3, Sample 13184: Loss: 0.3441\n",
            "Epoch 3, Sample 13185: Loss: 0.0026\n",
            "Epoch 3, Sample 13186: Loss: 0.2160\n",
            "Epoch 3, Sample 13187: Loss: 8.3816\n",
            "Epoch 3, Sample 13188: Loss: 0.0438\n",
            "Epoch 3, Sample 13189: Loss: 0.7036\n",
            "Epoch 3, Sample 13190: Loss: 1.0524\n",
            "Epoch 3, Sample 13191: Loss: 0.0117\n",
            "Epoch 3, Sample 13192: Loss: 0.0006\n",
            "Epoch 3, Sample 13193: Loss: 1.0530\n",
            "Epoch 3, Sample 13194: Loss: 1.0530\n",
            "Epoch 3, Sample 13195: Loss: 0.5000\n",
            "Epoch 3, Sample 13196: Loss: 0.2759\n",
            "Epoch 3, Sample 13197: Loss: 0.4607\n",
            "Epoch 3, Sample 13198: Loss: 0.0640\n",
            "Epoch 3, Sample 13199: Loss: 1.0524\n",
            "Epoch 3, Sample 13200: Loss: 0.0062\n",
            "Epoch 3, Sample 13201: Loss: 1.0530\n",
            "Epoch 3, Sample 13202: Loss: 0.2832\n",
            "Epoch 3, Sample 13203: Loss: 0.0630\n",
            "Epoch 3, Sample 13204: Loss: 0.0590\n",
            "Epoch 3, Sample 13205: Loss: 0.1838\n",
            "Epoch 3, Sample 13206: Loss: 0.3568\n",
            "Epoch 3, Sample 13207: Loss: 3.6601\n",
            "Epoch 3, Sample 13208: Loss: 0.2044\n",
            "Epoch 3, Sample 13209: Loss: 0.2032\n",
            "Epoch 3, Sample 13210: Loss: 14.5870\n",
            "Epoch 3, Sample 13211: Loss: 0.0475\n",
            "Epoch 3, Sample 13212: Loss: 0.0582\n",
            "Epoch 3, Sample 13213: Loss: 2.0225\n",
            "Epoch 3, Sample 13214: Loss: 1.0155\n",
            "Epoch 3, Sample 13215: Loss: 1.3842\n",
            "Epoch 3, Sample 13216: Loss: 1.5542\n",
            "Epoch 3, Sample 13217: Loss: 1.5597\n",
            "Epoch 3, Sample 13218: Loss: 0.7453\n",
            "Epoch 3, Sample 13219: Loss: 0.0026\n",
            "Epoch 3, Sample 13220: Loss: 0.0026\n",
            "Epoch 3, Sample 13221: Loss: 1.0524\n",
            "Epoch 3, Sample 13222: Loss: 5.9530\n",
            "Epoch 3, Sample 13223: Loss: 0.2219\n",
            "Epoch 3, Sample 13224: Loss: 0.0026\n",
            "Epoch 3, Sample 13225: Loss: 0.0212\n",
            "Epoch 3, Sample 13226: Loss: 0.0026\n",
            "Epoch 3, Sample 13227: Loss: 0.7036\n",
            "Epoch 3, Sample 13228: Loss: 1.5597\n",
            "Epoch 3, Sample 13229: Loss: 0.3598\n",
            "Epoch 3, Sample 13230: Loss: 0.1248\n",
            "Epoch 3, Sample 13231: Loss: 0.2639\n",
            "Epoch 3, Sample 13232: Loss: 1.0155\n",
            "Epoch 3, Sample 13233: Loss: 0.0026\n",
            "Epoch 3, Sample 13234: Loss: 0.0001\n",
            "Epoch 3, Sample 13235: Loss: 0.2032\n",
            "Epoch 3, Sample 13236: Loss: 0.0915\n",
            "Epoch 3, Sample 13237: Loss: 0.6092\n",
            "Epoch 3, Sample 13238: Loss: 10.3238\n",
            "Epoch 3, Sample 13239: Loss: 0.1114\n",
            "Epoch 3, Sample 13240: Loss: 6.9441\n",
            "Epoch 3, Sample 13241: Loss: 0.0026\n",
            "Epoch 3, Sample 13242: Loss: 0.0018\n",
            "Epoch 3, Sample 13243: Loss: 0.2044\n",
            "Epoch 3, Sample 13244: Loss: 1.0070\n",
            "Epoch 3, Sample 13245: Loss: 5.3707\n",
            "Epoch 3, Sample 13246: Loss: 0.1559\n",
            "Epoch 3, Sample 13247: Loss: 0.1559\n",
            "Epoch 3, Sample 13248: Loss: 0.3332\n",
            "Epoch 3, Sample 13249: Loss: 0.1250\n",
            "Epoch 3, Sample 13250: Loss: 0.0001\n",
            "Epoch 3, Sample 13251: Loss: 1.0524\n",
            "Epoch 3, Sample 13252: Loss: 17.3544\n",
            "Epoch 3, Sample 13253: Loss: 0.0026\n",
            "Epoch 3, Sample 13254: Loss: 0.0027\n",
            "Epoch 3, Sample 13255: Loss: 0.3399\n",
            "Epoch 3, Sample 13256: Loss: 0.2483\n",
            "Epoch 3, Sample 13257: Loss: 0.1248\n",
            "Epoch 3, Sample 13258: Loss: 0.0915\n",
            "Epoch 3, Sample 13259: Loss: 0.4841\n",
            "Epoch 3, Sample 13260: Loss: 1.0524\n",
            "Epoch 3, Sample 13261: Loss: 0.0026\n",
            "Epoch 3, Sample 13262: Loss: 0.4032\n",
            "Epoch 3, Sample 13263: Loss: 0.3399\n",
            "Epoch 3, Sample 13264: Loss: 0.4611\n",
            "Epoch 3, Sample 13265: Loss: 0.0000\n",
            "Epoch 3, Sample 13266: Loss: 0.0026\n",
            "Epoch 3, Sample 13267: Loss: 0.1114\n",
            "Epoch 3, Sample 13268: Loss: 0.3450\n",
            "Epoch 3, Sample 13269: Loss: 0.5858\n",
            "Epoch 3, Sample 13270: Loss: 0.0000\n",
            "Epoch 3, Sample 13271: Loss: 0.2759\n",
            "Epoch 3, Sample 13272: Loss: 1.6630\n",
            "Epoch 3, Sample 13273: Loss: 0.2759\n",
            "Epoch 3, Sample 13274: Loss: 0.1559\n",
            "Epoch 3, Sample 13275: Loss: 1.0524\n",
            "Epoch 3, Sample 13276: Loss: 0.2044\n",
            "Epoch 3, Sample 13277: Loss: 0.0364\n",
            "Epoch 3, Sample 13278: Loss: 0.3450\n",
            "Epoch 3, Sample 13279: Loss: 1.1569\n",
            "Epoch 3, Sample 13280: Loss: 0.0026\n",
            "Epoch 3, Sample 13281: Loss: 1.0524\n",
            "Epoch 3, Sample 13282: Loss: 0.2759\n",
            "Epoch 3, Sample 13283: Loss: 0.3399\n",
            "Epoch 3, Sample 13284: Loss: 0.6139\n",
            "Epoch 3, Sample 13285: Loss: 1.0155\n",
            "Epoch 3, Sample 13286: Loss: 0.0486\n",
            "Epoch 3, Sample 13287: Loss: 0.3399\n",
            "Epoch 3, Sample 13288: Loss: 0.1687\n",
            "Epoch 3, Sample 13289: Loss: 0.0026\n",
            "Epoch 3, Sample 13290: Loss: 0.2219\n",
            "Epoch 3, Sample 13291: Loss: 1.0524\n",
            "Epoch 3, Sample 13292: Loss: 0.1250\n",
            "Epoch 3, Sample 13293: Loss: 0.2558\n",
            "Epoch 3, Sample 13294: Loss: 0.4906\n",
            "Epoch 3, Sample 13295: Loss: 0.5858\n",
            "Epoch 3, Sample 13296: Loss: 0.3399\n",
            "Epoch 3, Sample 13297: Loss: 2.7331\n",
            "Epoch 3, Sample 13298: Loss: 0.5858\n",
            "Epoch 3, Sample 13299: Loss: 0.0108\n",
            "Epoch 3, Sample 13300: Loss: 0.2639\n",
            "Epoch 3, Sample 13301: Loss: 0.2941\n",
            "Epoch 3, Sample 13302: Loss: 0.2044\n",
            "Epoch 3, Sample 13303: Loss: 0.0018\n",
            "Epoch 3, Sample 13304: Loss: 0.4799\n",
            "Epoch 3, Sample 13305: Loss: 0.1791\n",
            "Epoch 3, Sample 13306: Loss: 0.9780\n",
            "Epoch 3, Sample 13307: Loss: 0.0505\n",
            "Epoch 3, Sample 13308: Loss: 0.8951\n",
            "Epoch 3, Sample 13309: Loss: 0.2044\n",
            "Epoch 3, Sample 13310: Loss: 1.5597\n",
            "Epoch 3, Sample 13311: Loss: 0.0026\n",
            "Epoch 3, Sample 13312: Loss: 1.0070\n",
            "Epoch 3, Sample 13313: Loss: 0.2044\n",
            "Epoch 3, Sample 13314: Loss: 0.2044\n",
            "Epoch 3, Sample 13315: Loss: 0.2044\n",
            "Epoch 3, Sample 13316: Loss: 0.3166\n",
            "Epoch 3, Sample 13317: Loss: 6.4222\n",
            "Epoch 3, Sample 13318: Loss: 0.0001\n",
            "Epoch 3, Sample 13319: Loss: 0.4930\n",
            "Epoch 3, Sample 13320: Loss: 3.5504\n",
            "Epoch 3, Sample 13321: Loss: 16.1876\n",
            "Epoch 3, Sample 13322: Loss: 0.0630\n",
            "Epoch 3, Sample 13323: Loss: 20.1048\n",
            "Epoch 3, Sample 13324: Loss: 1.0524\n",
            "Epoch 3, Sample 13325: Loss: 0.7036\n",
            "Epoch 3, Sample 13326: Loss: 0.0777\n",
            "Epoch 3, Sample 13327: Loss: 0.0026\n",
            "Epoch 3, Sample 13328: Loss: 0.0205\n",
            "Epoch 3, Sample 13329: Loss: 1.5963\n",
            "Epoch 3, Sample 13330: Loss: 3.5504\n",
            "Epoch 3, Sample 13331: Loss: 6.5695\n",
            "Epoch 3, Sample 13332: Loss: 0.3949\n",
            "Epoch 3, Sample 13333: Loss: 0.2759\n",
            "Epoch 3, Sample 13334: Loss: 1.0530\n",
            "Epoch 3, Sample 13335: Loss: 0.0018\n",
            "Epoch 3, Sample 13336: Loss: 0.1246\n",
            "Epoch 3, Sample 13337: Loss: 0.8951\n",
            "Epoch 3, Sample 13338: Loss: 1.0155\n",
            "Epoch 3, Sample 13339: Loss: 0.0018\n",
            "Epoch 3, Sample 13340: Loss: 0.2034\n",
            "Epoch 3, Sample 13341: Loss: 0.2832\n",
            "Epoch 3, Sample 13342: Loss: 15.4828\n",
            "Epoch 3, Sample 13343: Loss: 4.4745\n",
            "Epoch 3, Sample 13344: Loss: 0.4799\n",
            "Epoch 3, Sample 13345: Loss: 1.0524\n",
            "Epoch 3, Sample 13346: Loss: 0.6990\n",
            "Epoch 3, Sample 13347: Loss: 22.0929\n",
            "Epoch 3, Sample 13348: Loss: 10.8862\n",
            "Epoch 3, Sample 13349: Loss: 1.5597\n",
            "Epoch 3, Sample 13350: Loss: 0.3441\n",
            "Epoch 3, Sample 13351: Loss: 0.3399\n",
            "Epoch 3, Sample 13352: Loss: 1.0530\n",
            "Epoch 3, Sample 13353: Loss: 0.2713\n",
            "Epoch 3, Sample 13354: Loss: 1.5597\n",
            "Epoch 3, Sample 13355: Loss: 2.9652\n",
            "Epoch 3, Sample 13356: Loss: 0.5858\n",
            "Epoch 3, Sample 13357: Loss: 0.0060\n",
            "Epoch 3, Sample 13358: Loss: 9.5930\n",
            "Epoch 3, Sample 13359: Loss: 5.3707\n",
            "Epoch 3, Sample 13360: Loss: 0.2036\n",
            "Epoch 3, Sample 13361: Loss: 0.5972\n",
            "Epoch 3, Sample 13362: Loss: 0.0018\n",
            "Epoch 3, Sample 13363: Loss: 0.0838\n",
            "Epoch 3, Sample 13364: Loss: 0.1170\n",
            "Epoch 3, Sample 13365: Loss: 0.5858\n",
            "Epoch 3, Sample 13366: Loss: 0.3441\n",
            "Epoch 3, Sample 13367: Loss: 1.0524\n",
            "Epoch 3, Sample 13368: Loss: 0.2759\n",
            "Epoch 3, Sample 13369: Loss: 0.0026\n",
            "Epoch 3, Sample 13370: Loss: 1.2522\n",
            "Epoch 3, Sample 13371: Loss: 1.6701\n",
            "Epoch 3, Sample 13372: Loss: 0.3441\n",
            "Epoch 3, Sample 13373: Loss: 0.0018\n",
            "Epoch 3, Sample 13374: Loss: 0.0630\n",
            "Epoch 3, Sample 13375: Loss: 0.2044\n",
            "Epoch 3, Sample 13376: Loss: 0.0212\n",
            "Epoch 3, Sample 13377: Loss: 0.0026\n",
            "Epoch 3, Sample 13378: Loss: 0.0539\n",
            "Epoch 3, Sample 13379: Loss: 0.3399\n",
            "Epoch 3, Sample 13380: Loss: 0.0108\n",
            "Epoch 3, Sample 13381: Loss: 0.3367\n",
            "Epoch 3, Sample 13382: Loss: 0.7036\n",
            "Epoch 3, Sample 13383: Loss: 0.2044\n",
            "Epoch 3, Sample 13384: Loss: 0.0168\n",
            "Epoch 3, Sample 13385: Loss: 0.4799\n",
            "Epoch 3, Sample 13386: Loss: 0.0180\n",
            "Epoch 3, Sample 13387: Loss: 0.0005\n",
            "Epoch 3, Sample 13388: Loss: 0.0025\n",
            "Epoch 3, Sample 13389: Loss: 0.0640\n",
            "Epoch 3, Sample 13390: Loss: 0.0148\n",
            "Epoch 3, Sample 13391: Loss: 0.3441\n",
            "Epoch 3, Sample 13392: Loss: 0.3399\n",
            "Epoch 3, Sample 13393: Loss: 0.0418\n",
            "Epoch 3, Sample 13394: Loss: 2.9283\n",
            "Epoch 3, Sample 13395: Loss: 0.3949\n",
            "Epoch 3, Sample 13396: Loss: 5.7125\n",
            "Epoch 3, Sample 13397: Loss: 0.3506\n",
            "Epoch 3, Sample 13398: Loss: 0.7381\n",
            "Epoch 3, Sample 13399: Loss: 1.1884\n",
            "Epoch 3, Sample 13400: Loss: 0.9367\n",
            "Epoch 3, Sample 13401: Loss: 0.2796\n",
            "Epoch 3, Sample 13402: Loss: 0.2759\n",
            "Epoch 3, Sample 13403: Loss: 0.3399\n",
            "Epoch 3, Sample 13404: Loss: 2.1901\n",
            "Epoch 3, Sample 13405: Loss: 0.0018\n",
            "Epoch 3, Sample 13406: Loss: 2.7331\n",
            "Epoch 3, Sample 13407: Loss: 0.7036\n",
            "Epoch 3, Sample 13408: Loss: 1.0530\n",
            "Epoch 3, Sample 13409: Loss: 0.3399\n",
            "Epoch 3, Sample 13410: Loss: 0.0303\n",
            "Epoch 3, Sample 13411: Loss: 0.0018\n",
            "Epoch 3, Sample 13412: Loss: 0.1523\n",
            "Epoch 3, Sample 13413: Loss: 0.2044\n",
            "Epoch 3, Sample 13414: Loss: 1.0530\n",
            "Epoch 3, Sample 13415: Loss: 0.2832\n",
            "Epoch 3, Sample 13416: Loss: 1.0530\n",
            "Epoch 3, Sample 13417: Loss: 0.3399\n",
            "Epoch 3, Sample 13418: Loss: 0.2962\n",
            "Epoch 3, Sample 13419: Loss: 0.8211\n",
            "Epoch 3, Sample 13420: Loss: 1.8616\n",
            "Epoch 3, Sample 13421: Loss: 0.1559\n",
            "Epoch 3, Sample 13422: Loss: 1.0155\n",
            "Epoch 3, Sample 13423: Loss: 0.3598\n",
            "Epoch 3, Sample 13424: Loss: 1.0524\n",
            "Epoch 3, Sample 13425: Loss: 0.2483\n",
            "Epoch 3, Sample 13426: Loss: 1.0155\n",
            "Epoch 3, Sample 13427: Loss: 4.6602\n",
            "Epoch 3, Sample 13428: Loss: 0.4039\n",
            "Epoch 3, Sample 13429: Loss: 1.5542\n",
            "Epoch 3, Sample 13430: Loss: 0.1372\n",
            "Epoch 3, Sample 13431: Loss: 0.0018\n",
            "Epoch 3, Sample 13432: Loss: 0.0018\n",
            "Epoch 3, Sample 13433: Loss: 0.2340\n",
            "Epoch 3, Sample 13434: Loss: 3.4424\n",
            "Epoch 3, Sample 13435: Loss: 0.0000\n",
            "Epoch 3, Sample 13436: Loss: 0.1091\n",
            "Epoch 3, Sample 13437: Loss: 0.2034\n",
            "Epoch 3, Sample 13438: Loss: 1.0359\n",
            "Epoch 3, Sample 13439: Loss: 2.0563\n",
            "Epoch 3, Sample 13440: Loss: 3.2314\n",
            "Epoch 3, Sample 13441: Loss: 0.7036\n",
            "Epoch 3, Sample 13442: Loss: 0.3399\n",
            "Epoch 3, Sample 13443: Loss: 1.0524\n",
            "Epoch 3, Sample 13444: Loss: 0.3399\n",
            "Epoch 3, Sample 13445: Loss: 0.0026\n",
            "Epoch 3, Sample 13446: Loss: 0.1252\n",
            "Epoch 3, Sample 13447: Loss: 1.7843\n",
            "Epoch 3, Sample 13448: Loss: 0.0062\n",
            "Epoch 3, Sample 13449: Loss: 0.0117\n",
            "Epoch 3, Sample 13450: Loss: 0.1326\n",
            "Epoch 3, Sample 13451: Loss: 0.2219\n",
            "Epoch 3, Sample 13452: Loss: 0.7036\n",
            "Epoch 3, Sample 13453: Loss: 20.2332\n",
            "Epoch 3, Sample 13454: Loss: 0.2639\n",
            "Epoch 3, Sample 13455: Loss: 0.0630\n",
            "Epoch 3, Sample 13456: Loss: 3.5826\n",
            "Epoch 3, Sample 13457: Loss: 0.0429\n",
            "Epoch 3, Sample 13458: Loss: 10.6965\n",
            "Epoch 3, Sample 13459: Loss: 4.9582\n",
            "Epoch 3, Sample 13460: Loss: 0.0205\n",
            "Epoch 3, Sample 13461: Loss: 0.1248\n",
            "Epoch 3, Sample 13462: Loss: 0.7036\n",
            "Epoch 3, Sample 13463: Loss: 4.5516\n",
            "Epoch 3, Sample 13464: Loss: 0.7036\n",
            "Epoch 3, Sample 13465: Loss: 0.1252\n",
            "Epoch 3, Sample 13466: Loss: 3.5504\n",
            "Epoch 3, Sample 13467: Loss: 0.0915\n",
            "Epoch 3, Sample 13468: Loss: 0.3399\n",
            "Epoch 3, Sample 13469: Loss: 0.0018\n",
            "Epoch 3, Sample 13470: Loss: 5.8501\n",
            "Epoch 3, Sample 13471: Loss: 0.1248\n",
            "Epoch 3, Sample 13472: Loss: 0.4930\n",
            "Epoch 3, Sample 13473: Loss: 0.0103\n",
            "Epoch 3, Sample 13474: Loss: 0.0000\n",
            "Epoch 3, Sample 13475: Loss: 0.0026\n",
            "Epoch 3, Sample 13476: Loss: 0.3126\n",
            "Epoch 3, Sample 13477: Loss: 0.3260\n",
            "Epoch 3, Sample 13478: Loss: 1.0524\n",
            "Epoch 3, Sample 13479: Loss: 0.6990\n",
            "Epoch 3, Sample 13480: Loss: 0.3399\n",
            "Epoch 3, Sample 13481: Loss: 0.7036\n",
            "Epoch 3, Sample 13482: Loss: 0.0306\n",
            "Epoch 3, Sample 13483: Loss: 0.3399\n",
            "Epoch 3, Sample 13484: Loss: 0.0838\n",
            "Epoch 3, Sample 13485: Loss: 0.7036\n",
            "Epoch 3, Sample 13486: Loss: 2.7331\n",
            "Epoch 3, Sample 13487: Loss: 1.5597\n",
            "Epoch 3, Sample 13488: Loss: 0.0099\n",
            "Epoch 3, Sample 13489: Loss: 0.1989\n",
            "Epoch 3, Sample 13490: Loss: 13.5149\n",
            "Epoch 3, Sample 13491: Loss: 1.0155\n",
            "Epoch 3, Sample 13492: Loss: 0.2044\n",
            "Epoch 3, Sample 13493: Loss: 0.2759\n",
            "Epoch 3, Sample 13494: Loss: 1.5597\n",
            "Epoch 3, Sample 13495: Loss: 0.2759\n",
            "Epoch 3, Sample 13496: Loss: 23.2903\n",
            "Epoch 3, Sample 13497: Loss: 0.1170\n",
            "Epoch 3, Sample 13498: Loss: 0.9367\n",
            "Epoch 3, Sample 13499: Loss: 0.0013\n",
            "Epoch 3, Sample 13500: Loss: 0.2044\n",
            "Epoch 3, Sample 13501: Loss: 0.2032\n",
            "Epoch 3, Sample 13502: Loss: 1.5597\n",
            "Epoch 3, Sample 13503: Loss: 0.2044\n",
            "Epoch 3, Sample 13504: Loss: 0.1337\n",
            "Epoch 3, Sample 13505: Loss: 0.2219\n",
            "Epoch 3, Sample 13506: Loss: 0.1250\n",
            "Epoch 3, Sample 13507: Loss: 0.1559\n",
            "Epoch 3, Sample 13508: Loss: 0.6990\n",
            "Epoch 3, Sample 13509: Loss: 0.3441\n",
            "Epoch 3, Sample 13510: Loss: 0.4663\n",
            "Epoch 3, Sample 13511: Loss: 0.2568\n",
            "Epoch 3, Sample 13512: Loss: 0.4799\n",
            "Epoch 3, Sample 13513: Loss: 1.0524\n",
            "Epoch 3, Sample 13514: Loss: 0.2034\n",
            "Epoch 3, Sample 13515: Loss: 0.4930\n",
            "Epoch 3, Sample 13516: Loss: 0.1250\n",
            "Epoch 3, Sample 13517: Loss: 0.4930\n",
            "Epoch 3, Sample 13518: Loss: 0.1246\n",
            "Epoch 3, Sample 13519: Loss: 0.0001\n",
            "Epoch 3, Sample 13520: Loss: 0.0630\n",
            "Epoch 3, Sample 13521: Loss: 0.0212\n",
            "Epoch 3, Sample 13522: Loss: 0.2704\n",
            "Epoch 3, Sample 13523: Loss: 0.5062\n",
            "Epoch 3, Sample 13524: Loss: 0.0026\n",
            "Epoch 3, Sample 13525: Loss: 0.0026\n",
            "Epoch 3, Sample 13526: Loss: 0.0630\n",
            "Epoch 3, Sample 13527: Loss: 0.3949\n",
            "Epoch 3, Sample 13528: Loss: 0.2044\n",
            "Epoch 3, Sample 13529: Loss: 0.3626\n",
            "Epoch 3, Sample 13530: Loss: 0.0018\n",
            "Epoch 3, Sample 13531: Loss: 0.7036\n",
            "Epoch 3, Sample 13532: Loss: 0.9780\n",
            "Epoch 3, Sample 13533: Loss: 0.1248\n",
            "Epoch 3, Sample 13534: Loss: 0.5858\n",
            "Epoch 3, Sample 13535: Loss: 0.0460\n",
            "Epoch 3, Sample 13536: Loss: 0.4799\n",
            "Epoch 3, Sample 13537: Loss: 0.6990\n",
            "Epoch 3, Sample 13538: Loss: 1.8616\n",
            "Epoch 3, Sample 13539: Loss: 0.5871\n",
            "Epoch 3, Sample 13540: Loss: 0.0234\n",
            "Epoch 3, Sample 13541: Loss: 0.0875\n",
            "Epoch 3, Sample 13542: Loss: 0.0258\n",
            "Epoch 3, Sample 13543: Loss: 0.2558\n",
            "Epoch 3, Sample 13544: Loss: 0.0026\n",
            "Epoch 3, Sample 13545: Loss: 1.0524\n",
            "Epoch 3, Sample 13546: Loss: 0.3758\n",
            "Epoch 3, Sample 13547: Loss: 1.0530\n",
            "Epoch 3, Sample 13548: Loss: 0.5000\n",
            "Epoch 3, Sample 13549: Loss: 0.0108\n",
            "Epoch 3, Sample 13550: Loss: 0.3441\n",
            "Epoch 3, Sample 13551: Loss: 0.0475\n",
            "Epoch 3, Sample 13552: Loss: 0.1463\n",
            "Epoch 3, Sample 13553: Loss: 1.5597\n",
            "Epoch 3, Sample 13554: Loss: 0.2044\n",
            "Epoch 3, Sample 13555: Loss: 0.0060\n",
            "Epoch 3, Sample 13556: Loss: 6.3486\n",
            "Epoch 3, Sample 13557: Loss: 0.2044\n",
            "Epoch 3, Sample 13558: Loss: 0.0018\n",
            "Epoch 3, Sample 13559: Loss: 1.0266\n",
            "Epoch 3, Sample 13560: Loss: 0.1250\n",
            "Epoch 3, Sample 13561: Loss: 0.1170\n",
            "Epoch 3, Sample 13562: Loss: 1.0524\n",
            "Epoch 3, Sample 13563: Loss: 0.3506\n",
            "Epoch 3, Sample 13564: Loss: 0.0838\n",
            "Epoch 3, Sample 13565: Loss: 7.6726\n",
            "Epoch 3, Sample 13566: Loss: 0.6152\n",
            "Epoch 3, Sample 13567: Loss: 13.2933\n",
            "Epoch 3, Sample 13568: Loss: 0.0915\n",
            "Epoch 3, Sample 13569: Loss: 0.2044\n",
            "Epoch 3, Sample 13570: Loss: 1.0266\n",
            "Epoch 3, Sample 13571: Loss: 0.1246\n",
            "Epoch 3, Sample 13572: Loss: 0.1248\n",
            "Epoch 3, Sample 13573: Loss: 1.7195\n",
            "Epoch 3, Sample 13574: Loss: 0.5196\n",
            "Epoch 3, Sample 13575: Loss: 0.8951\n",
            "Epoch 3, Sample 13576: Loss: 0.3247\n",
            "Epoch 3, Sample 13577: Loss: 0.0026\n",
            "Epoch 3, Sample 13578: Loss: 0.0000\n",
            "Epoch 3, Sample 13579: Loss: 0.2036\n",
            "Epoch 3, Sample 13580: Loss: 0.0205\n",
            "Epoch 3, Sample 13581: Loss: 0.3399\n",
            "Epoch 3, Sample 13582: Loss: 0.1248\n",
            "Epoch 3, Sample 13583: Loss: 0.2044\n",
            "Epoch 3, Sample 13584: Loss: 0.3399\n",
            "Epoch 3, Sample 13585: Loss: 0.7910\n",
            "Epoch 3, Sample 13586: Loss: 0.9780\n",
            "Epoch 3, Sample 13587: Loss: 0.8951\n",
            "Epoch 3, Sample 13588: Loss: 0.2851\n",
            "Epoch 3, Sample 13589: Loss: 1.0359\n",
            "Epoch 3, Sample 13590: Loss: 0.2759\n",
            "Epoch 3, Sample 13591: Loss: 6.9441\n",
            "Epoch 3, Sample 13592: Loss: 0.7486\n",
            "Epoch 3, Sample 13593: Loss: 0.1246\n",
            "Epoch 3, Sample 13594: Loss: 0.3441\n",
            "Epoch 3, Sample 13595: Loss: 0.2832\n",
            "Epoch 3, Sample 13596: Loss: 0.2034\n",
            "Epoch 3, Sample 13597: Loss: 0.2855\n",
            "Epoch 3, Sample 13598: Loss: 1.0956\n",
            "Epoch 3, Sample 13599: Loss: 0.0148\n",
            "Epoch 3, Sample 13600: Loss: 0.0026\n",
            "Epoch 3, Sample 13601: Loss: 0.4930\n",
            "Epoch 3, Sample 13602: Loss: 0.0001\n",
            "Epoch 3, Sample 13603: Loss: 0.1250\n",
            "Epoch 3, Sample 13604: Loss: 0.0303\n",
            "Epoch 3, Sample 13605: Loss: 0.1248\n",
            "Epoch 3, Sample 13606: Loss: 0.2044\n",
            "Epoch 3, Sample 13607: Loss: 0.0915\n",
            "Epoch 3, Sample 13608: Loss: 0.0084\n",
            "Epoch 3, Sample 13609: Loss: 1.5597\n",
            "Epoch 3, Sample 13610: Loss: 0.2340\n",
            "Epoch 3, Sample 13611: Loss: 0.0026\n",
            "Epoch 3, Sample 13612: Loss: 0.3938\n",
            "Epoch 3, Sample 13613: Loss: 0.0042\n",
            "Epoch 3, Sample 13614: Loss: 0.0026\n",
            "Epoch 3, Sample 13615: Loss: 1.0359\n",
            "Epoch 3, Sample 13616: Loss: 1.0524\n",
            "Epoch 3, Sample 13617: Loss: 0.0630\n",
            "Epoch 3, Sample 13618: Loss: 0.0026\n",
            "Epoch 3, Sample 13619: Loss: 0.2034\n",
            "Epoch 3, Sample 13620: Loss: 0.1240\n",
            "Epoch 3, Sample 13621: Loss: 0.0026\n",
            "Epoch 3, Sample 13622: Loss: 0.1250\n",
            "Epoch 3, Sample 13623: Loss: 0.0102\n",
            "Epoch 3, Sample 13624: Loss: 0.6990\n",
            "Epoch 3, Sample 13625: Loss: 0.4367\n",
            "Epoch 3, Sample 13626: Loss: 1.7836\n",
            "Epoch 3, Sample 13627: Loss: 0.0018\n",
            "Epoch 3, Sample 13628: Loss: 2.7331\n",
            "Epoch 3, Sample 13629: Loss: 0.1508\n",
            "Epoch 3, Sample 13630: Loss: 0.1372\n",
            "Epoch 3, Sample 13631: Loss: 5.2376\n",
            "Epoch 3, Sample 13632: Loss: 0.0002\n",
            "Epoch 3, Sample 13633: Loss: 0.3758\n",
            "Epoch 3, Sample 13634: Loss: 0.3441\n",
            "Epoch 3, Sample 13635: Loss: 0.1250\n",
            "Epoch 3, Sample 13636: Loss: 1.0359\n",
            "Epoch 3, Sample 13637: Loss: 0.1508\n",
            "Epoch 3, Sample 13638: Loss: 1.0524\n",
            "Epoch 3, Sample 13639: Loss: 0.9367\n",
            "Epoch 3, Sample 13640: Loss: 1.0266\n",
            "Epoch 3, Sample 13641: Loss: 1.0524\n",
            "Epoch 3, Sample 13642: Loss: 0.1523\n",
            "Epoch 3, Sample 13643: Loss: 0.3399\n",
            "Epoch 3, Sample 13644: Loss: 1.0524\n",
            "Epoch 3, Sample 13645: Loss: 8.2989\n",
            "Epoch 3, Sample 13646: Loss: 0.7547\n",
            "Epoch 3, Sample 13647: Loss: 0.3441\n",
            "Epoch 3, Sample 13648: Loss: 0.5858\n",
            "Epoch 3, Sample 13649: Loss: 0.0108\n",
            "Epoch 3, Sample 13650: Loss: 0.8951\n",
            "Epoch 3, Sample 13651: Loss: 0.7036\n",
            "Epoch 3, Sample 13652: Loss: 0.0026\n",
            "Epoch 3, Sample 13653: Loss: 0.5000\n",
            "Epoch 3, Sample 13654: Loss: 0.9780\n",
            "Epoch 3, Sample 13655: Loss: 0.0915\n",
            "Epoch 3, Sample 13656: Loss: 1.0524\n",
            "Epoch 3, Sample 13657: Loss: 0.5000\n",
            "Epoch 3, Sample 13658: Loss: 0.1588\n",
            "Epoch 3, Sample 13659: Loss: 0.3450\n",
            "Epoch 3, Sample 13660: Loss: 0.2759\n",
            "Epoch 3, Sample 13661: Loss: 1.6326\n",
            "Epoch 3, Sample 13662: Loss: 0.0026\n",
            "Epoch 3, Sample 13663: Loss: 0.2778\n",
            "Epoch 3, Sample 13664: Loss: 0.0962\n",
            "Epoch 3, Sample 13665: Loss: 0.0000\n",
            "Epoch 3, Sample 13666: Loss: 0.2759\n",
            "Epoch 3, Sample 13667: Loss: 0.4841\n",
            "Epoch 3, Sample 13668: Loss: 0.8951\n",
            "Epoch 3, Sample 13669: Loss: 1.0155\n",
            "Epoch 3, Sample 13670: Loss: 0.0026\n",
            "Epoch 3, Sample 13671: Loss: 0.4611\n",
            "Epoch 3, Sample 13672: Loss: 0.3438\n",
            "Epoch 3, Sample 13673: Loss: 2.8535\n",
            "Epoch 3, Sample 13674: Loss: 10.0464\n",
            "Epoch 3, Sample 13675: Loss: 21.1263\n",
            "Epoch 3, Sample 13676: Loss: 0.7036\n",
            "Epoch 3, Sample 13677: Loss: 0.2112\n",
            "Epoch 3, Sample 13678: Loss: 0.7036\n",
            "Epoch 3, Sample 13679: Loss: 0.4611\n",
            "Epoch 3, Sample 13680: Loss: 0.5196\n",
            "Epoch 3, Sample 13681: Loss: 1.5597\n",
            "Epoch 3, Sample 13682: Loss: 0.2759\n",
            "Epoch 3, Sample 13683: Loss: 13.5068\n",
            "Epoch 3, Sample 13684: Loss: 1.7073\n",
            "Epoch 3, Sample 13685: Loss: 7.6726\n",
            "Epoch 3, Sample 13686: Loss: 0.4799\n",
            "Epoch 3, Sample 13687: Loss: 0.5744\n",
            "Epoch 3, Sample 13688: Loss: 0.5972\n",
            "Epoch 3, Sample 13689: Loss: 0.0026\n",
            "Epoch 3, Sample 13690: Loss: 0.3758\n",
            "Epoch 3, Sample 13691: Loss: 0.3441\n",
            "Epoch 3, Sample 13692: Loss: 0.0026\n",
            "Epoch 3, Sample 13693: Loss: 0.7036\n",
            "Epoch 3, Sample 13694: Loss: 0.3568\n",
            "Epoch 3, Sample 13695: Loss: 0.1627\n",
            "Epoch 3, Sample 13696: Loss: 0.1246\n",
            "Epoch 3, Sample 13697: Loss: 0.2034\n",
            "Epoch 3, Sample 13698: Loss: 0.2219\n",
            "Epoch 3, Sample 13699: Loss: 1.0658\n",
            "Epoch 3, Sample 13700: Loss: 0.0915\n",
            "Epoch 3, Sample 13701: Loss: 0.4032\n",
            "Epoch 3, Sample 13702: Loss: 0.3402\n",
            "Epoch 3, Sample 13703: Loss: 0.7036\n",
            "Epoch 3, Sample 13704: Loss: 0.1248\n",
            "Epoch 3, Sample 13705: Loss: 0.2034\n",
            "Epoch 3, Sample 13706: Loss: 0.0006\n",
            "Epoch 3, Sample 13707: Loss: 0.0005\n",
            "Epoch 3, Sample 13708: Loss: 0.4902\n",
            "Epoch 3, Sample 13709: Loss: 0.7036\n",
            "Epoch 3, Sample 13710: Loss: 1.0524\n",
            "Epoch 3, Sample 13711: Loss: 0.6092\n",
            "Epoch 3, Sample 13712: Loss: 0.2044\n",
            "Epoch 3, Sample 13713: Loss: 0.3399\n",
            "Epoch 3, Sample 13714: Loss: 0.3441\n",
            "Epoch 3, Sample 13715: Loss: 0.2044\n",
            "Epoch 3, Sample 13716: Loss: 0.2832\n",
            "Epoch 3, Sample 13717: Loss: 0.1326\n",
            "Epoch 3, Sample 13718: Loss: 0.0640\n",
            "Epoch 3, Sample 13719: Loss: 0.2989\n",
            "Epoch 3, Sample 13720: Loss: 0.0018\n",
            "Epoch 3, Sample 13721: Loss: 1.0530\n",
            "Epoch 3, Sample 13722: Loss: 0.4996\n",
            "Epoch 3, Sample 13723: Loss: 0.2044\n",
            "Epoch 3, Sample 13724: Loss: 4.7858\n",
            "Epoch 3, Sample 13725: Loss: 1.0155\n",
            "Epoch 3, Sample 13726: Loss: 1.0155\n",
            "Epoch 3, Sample 13727: Loss: 2.7331\n",
            "Epoch 3, Sample 13728: Loss: 0.2851\n",
            "Epoch 3, Sample 13729: Loss: 0.2034\n",
            "Epoch 3, Sample 13730: Loss: 0.1091\n",
            "Epoch 3, Sample 13731: Loss: 0.5636\n",
            "Epoch 3, Sample 13732: Loss: 1.0359\n",
            "Epoch 3, Sample 13733: Loss: 0.1817\n",
            "Epoch 3, Sample 13734: Loss: 0.7036\n",
            "Epoch 3, Sample 13735: Loss: 0.0001\n",
            "Epoch 3, Sample 13736: Loss: 1.0155\n",
            "Epoch 3, Sample 13737: Loss: 0.1770\n",
            "Epoch 3, Sample 13738: Loss: 7.0182\n",
            "Epoch 3, Sample 13739: Loss: 0.2036\n",
            "Epoch 3, Sample 13740: Loss: 0.1465\n",
            "Epoch 3, Sample 13741: Loss: 0.0205\n",
            "Epoch 3, Sample 13742: Loss: 0.2989\n",
            "Epoch 3, Sample 13743: Loss: 1.0524\n",
            "Epoch 3, Sample 13744: Loss: 1.0155\n",
            "Epoch 3, Sample 13745: Loss: 0.8484\n",
            "Epoch 3, Sample 13746: Loss: 0.4032\n",
            "Epoch 3, Sample 13747: Loss: 0.2759\n",
            "Epoch 3, Sample 13748: Loss: 0.2851\n",
            "Epoch 3, Sample 13749: Loss: 0.2036\n",
            "Epoch 3, Sample 13750: Loss: 8.7194\n",
            "Epoch 3, Sample 13751: Loss: 1.5597\n",
            "Epoch 3, Sample 13752: Loss: 1.0524\n",
            "Epoch 3, Sample 13753: Loss: 0.0794\n",
            "Epoch 3, Sample 13754: Loss: 0.2044\n",
            "Epoch 3, Sample 13755: Loss: 0.0391\n",
            "Epoch 3, Sample 13756: Loss: 0.0744\n",
            "Epoch 3, Sample 13757: Loss: 0.1246\n",
            "Epoch 3, Sample 13758: Loss: 0.2044\n",
            "Epoch 3, Sample 13759: Loss: 0.0026\n",
            "Epoch 3, Sample 13760: Loss: 9.9542\n",
            "Epoch 3, Sample 13761: Loss: 0.3949\n",
            "Epoch 3, Sample 13762: Loss: 0.5000\n",
            "Epoch 3, Sample 13763: Loss: 0.0630\n",
            "Epoch 3, Sample 13764: Loss: 1.0155\n",
            "Epoch 3, Sample 13765: Loss: 0.8951\n",
            "Epoch 3, Sample 13766: Loss: 13.5048\n",
            "Epoch 3, Sample 13767: Loss: 0.2036\n",
            "Epoch 3, Sample 13768: Loss: 0.3399\n",
            "Epoch 3, Sample 13769: Loss: 0.0026\n",
            "Epoch 3, Sample 13770: Loss: 0.8951\n",
            "Epoch 3, Sample 13771: Loss: 0.5078\n",
            "Epoch 3, Sample 13772: Loss: 0.0915\n",
            "Epoch 3, Sample 13773: Loss: 0.9785\n",
            "Epoch 3, Sample 13774: Loss: 0.4611\n",
            "Epoch 3, Sample 13775: Loss: 0.7036\n",
            "Epoch 3, Sample 13776: Loss: 0.0475\n",
            "Epoch 3, Sample 13777: Loss: 0.2044\n",
            "Epoch 3, Sample 13778: Loss: 16.1721\n",
            "Epoch 3, Sample 13779: Loss: 4.9876\n",
            "Epoch 3, Sample 13780: Loss: 1.5597\n",
            "Epoch 3, Sample 13781: Loss: 2.9283\n",
            "Epoch 3, Sample 13782: Loss: 1.3405\n",
            "Epoch 3, Sample 13783: Loss: 0.0062\n",
            "Epoch 3, Sample 13784: Loss: 0.3399\n",
            "Epoch 3, Sample 13785: Loss: 0.0625\n",
            "Epoch 3, Sample 13786: Loss: 0.7036\n",
            "Epoch 3, Sample 13787: Loss: 0.0026\n",
            "Epoch 3, Sample 13788: Loss: 0.8671\n",
            "Epoch 3, Sample 13789: Loss: 0.2931\n",
            "Epoch 3, Sample 13790: Loss: 2.3645\n",
            "Epoch 3, Sample 13791: Loss: 0.6058\n",
            "Epoch 3, Sample 13792: Loss: 0.0145\n",
            "Epoch 3, Sample 13793: Loss: 0.3441\n",
            "Epoch 3, Sample 13794: Loss: 1.0359\n",
            "Epoch 3, Sample 13795: Loss: 0.3399\n",
            "Epoch 3, Sample 13796: Loss: 0.1516\n",
            "Epoch 3, Sample 13797: Loss: 1.0359\n",
            "Epoch 3, Sample 13798: Loss: 0.0202\n",
            "Epoch 3, Sample 13799: Loss: 1.0155\n",
            "Epoch 3, Sample 13800: Loss: 5.3707\n",
            "Epoch 3, Sample 13801: Loss: 0.0084\n",
            "Epoch 3, Sample 13802: Loss: 0.0067\n",
            "Epoch 3, Sample 13803: Loss: 2.7331\n",
            "Epoch 3, Sample 13804: Loss: 0.3399\n",
            "Epoch 3, Sample 13805: Loss: 1.0524\n",
            "Epoch 3, Sample 13806: Loss: 0.1250\n",
            "Epoch 3, Sample 13807: Loss: 0.1248\n",
            "Epoch 3, Sample 13808: Loss: 0.5858\n",
            "Epoch 3, Sample 13809: Loss: 0.2879\n",
            "Epoch 3, Sample 13810: Loss: 0.3441\n",
            "Epoch 3, Sample 13811: Loss: 0.5000\n",
            "Epoch 3, Sample 13812: Loss: 0.1246\n",
            "Epoch 3, Sample 13813: Loss: 1.5597\n",
            "Epoch 3, Sample 13814: Loss: 0.0018\n",
            "Epoch 3, Sample 13815: Loss: 1.0530\n",
            "Epoch 3, Sample 13816: Loss: 0.2044\n",
            "Epoch 3, Sample 13817: Loss: 0.2044\n",
            "Epoch 3, Sample 13818: Loss: 1.0524\n",
            "Epoch 3, Sample 13819: Loss: 0.4799\n",
            "Epoch 3, Sample 13820: Loss: 0.6058\n",
            "Epoch 3, Sample 13821: Loss: 1.1205\n",
            "Epoch 3, Sample 13822: Loss: 0.2034\n",
            "Epoch 3, Sample 13823: Loss: 0.0286\n",
            "Epoch 3, Sample 13824: Loss: 5.1063\n",
            "Epoch 3, Sample 13825: Loss: 0.0626\n",
            "Epoch 3, Sample 13826: Loss: 0.2832\n",
            "Epoch 3, Sample 13827: Loss: 2.7331\n",
            "Epoch 3, Sample 13828: Loss: 0.9785\n",
            "Epoch 3, Sample 13829: Loss: 0.1170\n",
            "Epoch 3, Sample 13830: Loss: 1.0524\n",
            "Epoch 3, Sample 13831: Loss: 0.2044\n",
            "Epoch 3, Sample 13832: Loss: 0.1170\n",
            "Epoch 3, Sample 13833: Loss: 1.0477\n",
            "Epoch 3, Sample 13834: Loss: 0.0774\n",
            "Epoch 3, Sample 13835: Loss: 0.7702\n",
            "Epoch 3, Sample 13836: Loss: 0.0267\n",
            "Epoch 3, Sample 13837: Loss: 1.0524\n",
            "Epoch 3, Sample 13838: Loss: 0.0475\n",
            "Epoch 3, Sample 13839: Loss: 2.6851\n",
            "Epoch 3, Sample 13840: Loss: 0.3024\n",
            "Epoch 3, Sample 13841: Loss: 0.1252\n",
            "Epoch 3, Sample 13842: Loss: 1.0524\n",
            "Epoch 3, Sample 13843: Loss: 1.9016\n",
            "Epoch 3, Sample 13844: Loss: 0.1170\n",
            "Epoch 3, Sample 13845: Loss: 0.5000\n",
            "Epoch 3, Sample 13846: Loss: 0.0060\n",
            "Epoch 3, Sample 13847: Loss: 0.2034\n",
            "Epoch 3, Sample 13848: Loss: 0.2832\n",
            "Epoch 3, Sample 13849: Loss: 0.2219\n",
            "Epoch 3, Sample 13850: Loss: 0.4841\n",
            "Epoch 3, Sample 13851: Loss: 1.5597\n",
            "Epoch 3, Sample 13852: Loss: 0.5871\n",
            "Epoch 3, Sample 13853: Loss: 1.0530\n",
            "Epoch 3, Sample 13854: Loss: 0.0026\n",
            "Epoch 3, Sample 13855: Loss: 0.1250\n",
            "Epoch 3, Sample 13856: Loss: 0.6304\n",
            "Epoch 3, Sample 13857: Loss: 0.1326\n",
            "Epoch 3, Sample 13858: Loss: 1.0524\n",
            "Epoch 3, Sample 13859: Loss: 0.0026\n",
            "Epoch 3, Sample 13860: Loss: 6.9441\n",
            "Epoch 3, Sample 13861: Loss: 0.0010\n",
            "Epoch 3, Sample 13862: Loss: 1.0524\n",
            "Epoch 3, Sample 13863: Loss: 0.9780\n",
            "Epoch 3, Sample 13864: Loss: 7.4878\n",
            "Epoch 3, Sample 13865: Loss: 0.2759\n",
            "Epoch 3, Sample 13866: Loss: 1.0155\n",
            "Epoch 3, Sample 13867: Loss: 0.0306\n",
            "Epoch 3, Sample 13868: Loss: 0.5871\n",
            "Epoch 3, Sample 13869: Loss: 0.0303\n",
            "Epoch 3, Sample 13870: Loss: 1.0524\n",
            "Epoch 3, Sample 13871: Loss: 0.2044\n",
            "Epoch 3, Sample 13872: Loss: 0.0630\n",
            "Epoch 3, Sample 13873: Loss: 0.9367\n",
            "Epoch 3, Sample 13874: Loss: 0.0000\n",
            "Epoch 3, Sample 13875: Loss: 0.0001\n",
            "Epoch 3, Sample 13876: Loss: 0.1091\n",
            "Epoch 3, Sample 13877: Loss: 0.0018\n",
            "Epoch 3, Sample 13878: Loss: 1.6701\n",
            "Epoch 3, Sample 13879: Loss: 0.0000\n",
            "Epoch 3, Sample 13880: Loss: 0.0026\n",
            "Epoch 3, Sample 13881: Loss: 1.7073\n",
            "Epoch 3, Sample 13882: Loss: 1.2926\n",
            "Epoch 3, Sample 13883: Loss: 0.5089\n",
            "Epoch 3, Sample 13884: Loss: 0.1252\n",
            "Epoch 3, Sample 13885: Loss: 0.6092\n",
            "Epoch 3, Sample 13886: Loss: 0.7036\n",
            "Epoch 3, Sample 13887: Loss: 0.0433\n",
            "Epoch 3, Sample 13888: Loss: 0.2036\n",
            "Epoch 3, Sample 13889: Loss: 0.1246\n",
            "Epoch 3, Sample 13890: Loss: 0.0025\n",
            "Epoch 3, Sample 13891: Loss: 0.2112\n",
            "Epoch 3, Sample 13892: Loss: 0.1482\n",
            "Epoch 3, Sample 13893: Loss: 0.7036\n",
            "Epoch 3, Sample 13894: Loss: 1.2095\n",
            "Epoch 3, Sample 13895: Loss: 0.6092\n",
            "Epoch 3, Sample 13896: Loss: 0.0630\n",
            "Epoch 3, Sample 13897: Loss: 0.0744\n",
            "Epoch 3, Sample 13898: Loss: 1.0070\n",
            "Epoch 3, Sample 13899: Loss: 0.2032\n",
            "Epoch 3, Sample 13900: Loss: 1.0155\n",
            "Epoch 3, Sample 13901: Loss: 17.9111\n",
            "Epoch 3, Sample 13902: Loss: 0.0013\n",
            "Epoch 3, Sample 13903: Loss: 0.7036\n",
            "Epoch 3, Sample 13904: Loss: 2.5454\n",
            "Epoch 3, Sample 13905: Loss: 2.7331\n",
            "Epoch 3, Sample 13906: Loss: 7.7260\n",
            "Epoch 3, Sample 13907: Loss: 0.4799\n",
            "Epoch 3, Sample 13908: Loss: 0.3399\n",
            "Epoch 3, Sample 13909: Loss: 2.0225\n",
            "Epoch 3, Sample 13910: Loss: 4.0002\n",
            "Epoch 3, Sample 13911: Loss: 0.1250\n",
            "Epoch 3, Sample 13912: Loss: 0.3598\n",
            "Epoch 3, Sample 13913: Loss: 0.2034\n",
            "Epoch 3, Sample 13914: Loss: 0.1337\n",
            "Epoch 3, Sample 13915: Loss: 0.0234\n",
            "Epoch 3, Sample 13916: Loss: 1.5597\n",
            "Epoch 3, Sample 13917: Loss: 0.0093\n",
            "Epoch 3, Sample 13918: Loss: 0.4930\n",
            "Epoch 3, Sample 13919: Loss: 0.2044\n",
            "Epoch 3, Sample 13920: Loss: 0.0426\n",
            "Epoch 3, Sample 13921: Loss: 0.7036\n",
            "Epoch 3, Sample 13922: Loss: 0.1627\n",
            "Epoch 3, Sample 13923: Loss: 0.0915\n",
            "Epoch 3, Sample 13924: Loss: 0.0026\n",
            "Epoch 3, Sample 13925: Loss: 0.3399\n",
            "Epoch 3, Sample 13926: Loss: 1.0524\n",
            "Epoch 3, Sample 13927: Loss: 0.5636\n",
            "Epoch 3, Sample 13928: Loss: 0.3399\n",
            "Epoch 3, Sample 13929: Loss: 0.0102\n",
            "Epoch 3, Sample 13930: Loss: 0.2034\n",
            "Epoch 3, Sample 13931: Loss: 1.0155\n",
            "Epoch 3, Sample 13932: Loss: 0.0018\n",
            "Epoch 3, Sample 13933: Loss: 1.5597\n",
            "Epoch 3, Sample 13934: Loss: 0.0026\n",
            "Epoch 3, Sample 13935: Loss: 0.1555\n",
            "Epoch 3, Sample 13936: Loss: 0.1248\n",
            "Epoch 3, Sample 13937: Loss: 0.1336\n",
            "Epoch 3, Sample 13938: Loss: 0.2034\n",
            "Epoch 3, Sample 13939: Loss: 0.2759\n",
            "Epoch 3, Sample 13940: Loss: 0.4611\n",
            "Epoch 3, Sample 13941: Loss: 0.0630\n",
            "Epoch 3, Sample 13942: Loss: 0.1250\n",
            "Epoch 3, Sample 13943: Loss: 0.3949\n",
            "Epoch 3, Sample 13944: Loss: 1.0155\n",
            "Epoch 3, Sample 13945: Loss: 0.1559\n",
            "Epoch 3, Sample 13946: Loss: 1.0524\n",
            "Epoch 3, Sample 13947: Loss: 0.2044\n",
            "Epoch 3, Sample 13948: Loss: 0.3568\n",
            "Epoch 3, Sample 13949: Loss: 0.4588\n",
            "Epoch 3, Sample 13950: Loss: 0.5003\n",
            "Epoch 3, Sample 13951: Loss: 0.2032\n",
            "Epoch 3, Sample 13952: Loss: 1.5597\n",
            "Epoch 3, Sample 13953: Loss: 0.1250\n",
            "Epoch 3, Sample 13954: Loss: 0.2032\n",
            "Epoch 3, Sample 13955: Loss: 7.6726\n",
            "Epoch 3, Sample 13956: Loss: 0.6867\n",
            "Epoch 3, Sample 13957: Loss: 0.3949\n",
            "Epoch 3, Sample 13958: Loss: 0.2699\n",
            "Epoch 3, Sample 13959: Loss: 0.7453\n",
            "Epoch 3, Sample 13960: Loss: 1.0155\n",
            "Epoch 3, Sample 13961: Loss: 0.3399\n",
            "Epoch 3, Sample 13962: Loss: 0.7036\n",
            "Epoch 3, Sample 13963: Loss: 0.5972\n",
            "Epoch 3, Sample 13964: Loss: 0.0000\n",
            "Epoch 3, Sample 13965: Loss: 0.4607\n",
            "Epoch 3, Sample 13966: Loss: 0.3441\n",
            "Epoch 3, Sample 13967: Loss: 0.2639\n",
            "Epoch 3, Sample 13968: Loss: 0.0595\n",
            "Epoch 3, Sample 13969: Loss: 1.1569\n",
            "Epoch 3, Sample 13970: Loss: 0.7453\n",
            "Epoch 3, Sample 13971: Loss: 0.2044\n",
            "Epoch 3, Sample 13972: Loss: 0.5078\n",
            "Epoch 3, Sample 13973: Loss: 25.3240\n",
            "Epoch 3, Sample 13974: Loss: 0.9367\n",
            "Epoch 3, Sample 13975: Loss: 0.0026\n",
            "Epoch 3, Sample 13976: Loss: 0.3399\n",
            "Epoch 3, Sample 13977: Loss: 0.2044\n",
            "Epoch 3, Sample 13978: Loss: 0.0303\n",
            "Epoch 3, Sample 13979: Loss: 0.0026\n",
            "Epoch 3, Sample 13980: Loss: 0.9367\n",
            "Epoch 3, Sample 13981: Loss: 0.5972\n",
            "Epoch 3, Sample 13982: Loss: 0.1250\n",
            "Epoch 3, Sample 13983: Loss: 0.0630\n",
            "Epoch 3, Sample 13984: Loss: 0.9785\n",
            "Epoch 3, Sample 13985: Loss: 0.0630\n",
            "Epoch 3, Sample 13986: Loss: 1.5597\n",
            "Epoch 3, Sample 13987: Loss: 0.1838\n",
            "Epoch 3, Sample 13988: Loss: 1.0359\n",
            "Epoch 3, Sample 13989: Loss: 1.5597\n",
            "Epoch 3, Sample 13990: Loss: 0.3332\n",
            "Epoch 3, Sample 13991: Loss: 0.2032\n",
            "Epoch 3, Sample 13992: Loss: 0.3402\n",
            "Epoch 3, Sample 13993: Loss: 0.2034\n",
            "Epoch 3, Sample 13994: Loss: 1.0524\n",
            "Epoch 3, Sample 13995: Loss: 0.4032\n",
            "Epoch 3, Sample 13996: Loss: 3.0318\n",
            "Epoch 3, Sample 13997: Loss: 0.6990\n",
            "Epoch 3, Sample 13998: Loss: 0.0026\n",
            "Epoch 3, Sample 13999: Loss: 0.0364\n",
            "Epoch 3, Sample 14000: Loss: 1.0155\n",
            "Epoch 3, Sample 14001: Loss: 0.0838\n",
            "Epoch 3, Sample 14002: Loss: 1.5597\n",
            "Epoch 3, Sample 14003: Loss: 0.0000\n",
            "Epoch 3, Sample 14004: Loss: 0.0001\n",
            "Epoch 3, Sample 14005: Loss: 1.8220\n",
            "Epoch 3, Sample 14006: Loss: 0.2036\n",
            "Epoch 3, Sample 14007: Loss: 0.0026\n",
            "Epoch 3, Sample 14008: Loss: 0.0084\n",
            "Epoch 3, Sample 14009: Loss: 0.1399\n",
            "Epoch 3, Sample 14010: Loss: 0.7036\n",
            "Epoch 3, Sample 14011: Loss: 0.4849\n",
            "Epoch 3, Sample 14012: Loss: 0.9780\n",
            "Epoch 3, Sample 14013: Loss: 0.3441\n",
            "Epoch 3, Sample 14014: Loss: 0.4799\n",
            "Epoch 3, Sample 14015: Loss: 0.0034\n",
            "Epoch 3, Sample 14016: Loss: 1.0155\n",
            "Epoch 3, Sample 14017: Loss: 2.7331\n",
            "Epoch 3, Sample 14018: Loss: 1.9213\n",
            "Epoch 3, Sample 14019: Loss: 5.7798\n",
            "Epoch 3, Sample 14020: Loss: 20.9773\n",
            "Epoch 3, Sample 14021: Loss: 0.3399\n",
            "Epoch 3, Sample 14022: Loss: 1.0524\n",
            "Epoch 3, Sample 14023: Loss: 1.0524\n",
            "Epoch 3, Sample 14024: Loss: 0.0915\n",
            "Epoch 3, Sample 14025: Loss: 0.3399\n",
            "Epoch 3, Sample 14026: Loss: 0.0466\n",
            "Epoch 3, Sample 14027: Loss: 0.3418\n",
            "Epoch 3, Sample 14028: Loss: 0.1559\n",
            "Epoch 3, Sample 14029: Loss: 0.5278\n",
            "Epoch 3, Sample 14030: Loss: 0.9785\n",
            "Epoch 3, Sample 14031: Loss: 0.9367\n",
            "Epoch 3, Sample 14032: Loss: 0.4032\n",
            "Epoch 3, Sample 14033: Loss: 1.5597\n",
            "Epoch 3, Sample 14034: Loss: 0.5003\n",
            "Epoch 3, Sample 14035: Loss: 0.0915\n",
            "Epoch 3, Sample 14036: Loss: 1.0070\n",
            "Epoch 3, Sample 14037: Loss: 0.8951\n",
            "Epoch 3, Sample 14038: Loss: 0.4382\n",
            "Epoch 3, Sample 14039: Loss: 0.1246\n",
            "Epoch 3, Sample 14040: Loss: 0.2494\n",
            "Epoch 3, Sample 14041: Loss: 4.4745\n",
            "Epoch 3, Sample 14042: Loss: 2.0108\n",
            "Epoch 3, Sample 14043: Loss: 0.1559\n",
            "Epoch 3, Sample 14044: Loss: 0.1248\n",
            "Epoch 3, Sample 14045: Loss: 0.1250\n",
            "Epoch 3, Sample 14046: Loss: 0.9785\n",
            "Epoch 3, Sample 14047: Loss: 0.6990\n",
            "Epoch 3, Sample 14048: Loss: 0.3598\n",
            "Epoch 3, Sample 14049: Loss: 0.2044\n",
            "Epoch 3, Sample 14050: Loss: 0.0062\n",
            "Epoch 3, Sample 14051: Loss: 0.4841\n",
            "Epoch 3, Sample 14052: Loss: 0.3288\n",
            "Epoch 3, Sample 14053: Loss: 0.9367\n",
            "Epoch 3, Sample 14054: Loss: 0.1989\n",
            "Epoch 3, Sample 14055: Loss: 0.2036\n",
            "Epoch 3, Sample 14056: Loss: 1.0524\n",
            "Epoch 3, Sample 14057: Loss: 0.2036\n",
            "Epoch 3, Sample 14058: Loss: 1.0524\n",
            "Epoch 3, Sample 14059: Loss: 0.1246\n",
            "Epoch 3, Sample 14060: Loss: 0.2044\n",
            "Epoch 3, Sample 14061: Loss: 0.4611\n",
            "Epoch 3, Sample 14062: Loss: 0.3539\n",
            "Epoch 3, Sample 14063: Loss: 1.0530\n",
            "Epoch 3, Sample 14064: Loss: 0.0176\n",
            "Epoch 3, Sample 14065: Loss: 0.0018\n",
            "Epoch 3, Sample 14066: Loss: 0.1170\n",
            "Epoch 3, Sample 14067: Loss: 0.0915\n",
            "Epoch 3, Sample 14068: Loss: 0.2219\n",
            "Epoch 3, Sample 14069: Loss: 0.0063\n",
            "Epoch 3, Sample 14070: Loss: 0.0630\n",
            "Epoch 3, Sample 14071: Loss: 0.2271\n",
            "Epoch 3, Sample 14072: Loss: 0.7036\n",
            "Epoch 3, Sample 14073: Loss: 0.5574\n",
            "Epoch 3, Sample 14074: Loss: 0.0625\n",
            "Epoch 3, Sample 14075: Loss: 0.8951\n",
            "Epoch 3, Sample 14076: Loss: 0.8951\n",
            "Epoch 3, Sample 14077: Loss: 0.6092\n",
            "Epoch 3, Sample 14078: Loss: 3.4037\n",
            "Epoch 3, Sample 14079: Loss: 5.6313\n",
            "Epoch 3, Sample 14080: Loss: 3.5504\n",
            "Epoch 3, Sample 14081: Loss: 0.1246\n",
            "Epoch 3, Sample 14082: Loss: 17.1146\n",
            "Epoch 3, Sample 14083: Loss: 0.2750\n",
            "Epoch 3, Sample 14084: Loss: 0.0915\n",
            "Epoch 3, Sample 14085: Loss: 2.0108\n",
            "Epoch 3, Sample 14086: Loss: 25.6156\n",
            "Epoch 3, Sample 14087: Loss: 0.3399\n",
            "Epoch 3, Sample 14088: Loss: 0.0168\n",
            "Epoch 3, Sample 14089: Loss: 0.3441\n",
            "Epoch 3, Sample 14090: Loss: 0.2044\n",
            "Epoch 3, Sample 14091: Loss: 0.1225\n",
            "Epoch 3, Sample 14092: Loss: 0.0915\n",
            "Epoch 3, Sample 14093: Loss: 0.0000\n",
            "Epoch 3, Sample 14094: Loss: 0.0915\n",
            "Epoch 3, Sample 14095: Loss: 0.3402\n",
            "Epoch 3, Sample 14096: Loss: 1.0530\n",
            "Epoch 3, Sample 14097: Loss: 0.1170\n",
            "Epoch 3, Sample 14098: Loss: 0.1091\n",
            "Epoch 3, Sample 14099: Loss: 1.5597\n",
            "Epoch 3, Sample 14100: Loss: 0.2034\n",
            "Epoch 3, Sample 14101: Loss: 0.2044\n",
            "Epoch 3, Sample 14102: Loss: 1.0524\n",
            "Epoch 3, Sample 14103: Loss: 0.3399\n",
            "Epoch 3, Sample 14104: Loss: 0.0027\n",
            "Epoch 3, Sample 14105: Loss: 0.7036\n",
            "Epoch 3, Sample 14106: Loss: 1.0524\n",
            "Epoch 3, Sample 14107: Loss: 0.2759\n",
            "Epoch 3, Sample 14108: Loss: 0.8951\n",
            "Epoch 3, Sample 14109: Loss: 0.1092\n",
            "Epoch 3, Sample 14110: Loss: 10.8862\n",
            "Epoch 3, Sample 14111: Loss: 0.2219\n",
            "Epoch 3, Sample 14112: Loss: 0.2846\n",
            "Epoch 3, Sample 14113: Loss: 0.1248\n",
            "Epoch 3, Sample 14114: Loss: 0.3949\n",
            "Epoch 3, Sample 14115: Loss: 0.4902\n",
            "Epoch 3, Sample 14116: Loss: 0.1364\n",
            "Epoch 3, Sample 14117: Loss: 0.0229\n",
            "Epoch 3, Sample 14118: Loss: 0.1335\n",
            "Epoch 3, Sample 14119: Loss: 0.0016\n",
            "Epoch 3, Sample 14120: Loss: 0.3399\n",
            "Epoch 3, Sample 14121: Loss: 1.0511\n",
            "Epoch 3, Sample 14122: Loss: 2.4541\n",
            "Epoch 3, Sample 14123: Loss: 0.3402\n",
            "Epoch 3, Sample 14124: Loss: 9.5930\n",
            "Epoch 3, Sample 14125: Loss: 0.2832\n",
            "Epoch 3, Sample 14126: Loss: 5.1063\n",
            "Epoch 3, Sample 14127: Loss: 0.3441\n",
            "Epoch 3, Sample 14128: Loss: 0.2044\n",
            "Epoch 3, Sample 14129: Loss: 0.2938\n",
            "Epoch 3, Sample 14130: Loss: 0.0303\n",
            "Epoch 3, Sample 14131: Loss: 1.1789\n",
            "Epoch 3, Sample 14132: Loss: 0.0002\n",
            "Epoch 3, Sample 14133: Loss: 0.1248\n",
            "Epoch 3, Sample 14134: Loss: 0.0363\n",
            "Epoch 3, Sample 14135: Loss: 0.5972\n",
            "Epoch 3, Sample 14136: Loss: 0.0915\n",
            "Epoch 3, Sample 14137: Loss: 0.1240\n",
            "Epoch 3, Sample 14138: Loss: 0.3399\n",
            "Epoch 3, Sample 14139: Loss: 1.0530\n",
            "Epoch 3, Sample 14140: Loss: 0.4841\n",
            "Epoch 3, Sample 14141: Loss: 2.7331\n",
            "Epoch 3, Sample 14142: Loss: 0.1250\n",
            "Epoch 3, Sample 14143: Loss: 0.3247\n",
            "Epoch 3, Sample 14144: Loss: 0.0938\n",
            "Epoch 3, Sample 14145: Loss: 0.3949\n",
            "Epoch 3, Sample 14146: Loss: 0.5858\n",
            "Epoch 3, Sample 14147: Loss: 0.2759\n",
            "Epoch 3, Sample 14148: Loss: 0.4032\n",
            "Epoch 3, Sample 14149: Loss: 0.3399\n",
            "Epoch 3, Sample 14150: Loss: 0.6092\n",
            "Epoch 3, Sample 14151: Loss: 0.1250\n",
            "Epoch 3, Sample 14152: Loss: 0.0144\n",
            "Epoch 3, Sample 14153: Loss: 0.1773\n",
            "Epoch 3, Sample 14154: Loss: 0.4930\n",
            "Epoch 3, Sample 14155: Loss: 0.0947\n",
            "Epoch 3, Sample 14156: Loss: 0.0306\n",
            "Epoch 3, Sample 14157: Loss: 0.0108\n",
            "Epoch 3, Sample 14158: Loss: 0.1250\n",
            "Epoch 3, Sample 14159: Loss: 0.0026\n",
            "Epoch 3, Sample 14160: Loss: 0.2687\n",
            "Epoch 3, Sample 14161: Loss: 0.4799\n",
            "Epoch 3, Sample 14162: Loss: 1.6207\n",
            "Epoch 3, Sample 14163: Loss: 0.0558\n",
            "Epoch 3, Sample 14164: Loss: 0.2044\n",
            "Epoch 3, Sample 14165: Loss: 0.1031\n",
            "Epoch 3, Sample 14166: Loss: 0.2032\n",
            "Epoch 3, Sample 14167: Loss: 0.0018\n",
            "Epoch 3, Sample 14168: Loss: 1.0524\n",
            "Epoch 3, Sample 14169: Loss: 0.0103\n",
            "Epoch 3, Sample 14170: Loss: 0.5375\n",
            "Epoch 3, Sample 14171: Loss: 0.0001\n",
            "Epoch 3, Sample 14172: Loss: 0.1335\n",
            "Epoch 3, Sample 14173: Loss: 0.4799\n",
            "Epoch 3, Sample 14174: Loss: 0.0082\n",
            "Epoch 3, Sample 14175: Loss: 0.1246\n",
            "Epoch 3, Sample 14176: Loss: 0.4032\n",
            "Epoch 3, Sample 14177: Loss: 0.2832\n",
            "Epoch 3, Sample 14178: Loss: 0.2044\n",
            "Epoch 3, Sample 14179: Loss: 0.2034\n",
            "Epoch 3, Sample 14180: Loss: 0.2290\n",
            "Epoch 3, Sample 14181: Loss: 0.5858\n",
            "Epoch 3, Sample 14182: Loss: 0.5972\n",
            "Epoch 3, Sample 14183: Loss: 0.0088\n",
            "Epoch 3, Sample 14184: Loss: 0.3441\n",
            "Epoch 3, Sample 14185: Loss: 0.1372\n",
            "Epoch 3, Sample 14186: Loss: 0.2832\n",
            "Epoch 3, Sample 14187: Loss: 0.0829\n",
            "Epoch 3, Sample 14188: Loss: 0.1559\n",
            "Epoch 3, Sample 14189: Loss: 0.2699\n",
            "Epoch 3, Sample 14190: Loss: 0.3450\n",
            "Epoch 3, Sample 14191: Loss: 0.1246\n",
            "Epoch 3, Sample 14192: Loss: 0.0026\n",
            "Epoch 3, Sample 14193: Loss: 0.3584\n",
            "Epoch 3, Sample 14194: Loss: 0.1170\n",
            "Epoch 3, Sample 14195: Loss: 0.6092\n",
            "Epoch 3, Sample 14196: Loss: 0.6139\n",
            "Epoch 3, Sample 14197: Loss: 1.0524\n",
            "Epoch 3, Sample 14198: Loss: 0.1938\n",
            "Epoch 3, Sample 14199: Loss: 0.0808\n",
            "Epoch 3, Sample 14200: Loss: 0.0168\n",
            "Epoch 3, Sample 14201: Loss: 0.0590\n",
            "Epoch 3, Sample 14202: Loss: 0.0026\n",
            "Epoch 3, Sample 14203: Loss: 0.2044\n",
            "Epoch 3, Sample 14204: Loss: 0.7036\n",
            "Epoch 3, Sample 14205: Loss: 0.2044\n",
            "Epoch 3, Sample 14206: Loss: 0.1113\n",
            "Epoch 3, Sample 14207: Loss: 0.0025\n",
            "Epoch 3, Sample 14208: Loss: 1.0524\n",
            "Epoch 3, Sample 14209: Loss: 2.7331\n",
            "Epoch 3, Sample 14210: Loss: 0.1248\n",
            "Epoch 3, Sample 14211: Loss: 0.4474\n",
            "Epoch 3, Sample 14212: Loss: 1.0524\n",
            "Epoch 3, Sample 14213: Loss: 0.3949\n",
            "Epoch 3, Sample 14214: Loss: 0.4611\n",
            "Epoch 3, Sample 14215: Loss: 0.5089\n",
            "Epoch 3, Sample 14216: Loss: 1.0524\n",
            "Epoch 3, Sample 14217: Loss: 0.0306\n",
            "Epoch 3, Sample 14218: Loss: 1.4187\n",
            "Epoch 3, Sample 14219: Loss: 0.2034\n",
            "Epoch 3, Sample 14220: Loss: 0.0026\n",
            "Epoch 3, Sample 14221: Loss: 0.0026\n",
            "Epoch 3, Sample 14222: Loss: 1.1263\n",
            "Epoch 3, Sample 14223: Loss: 1.5597\n",
            "Epoch 3, Sample 14224: Loss: 0.0963\n",
            "Epoch 3, Sample 14225: Loss: 0.3949\n",
            "Epoch 3, Sample 14226: Loss: 0.2639\n",
            "Epoch 3, Sample 14227: Loss: 0.2879\n",
            "Epoch 3, Sample 14228: Loss: 0.4663\n",
            "Epoch 3, Sample 14229: Loss: 0.2340\n",
            "Epoch 3, Sample 14230: Loss: 1.0530\n",
            "Epoch 3, Sample 14231: Loss: 0.0915\n",
            "Epoch 3, Sample 14232: Loss: 0.4799\n",
            "Epoch 3, Sample 14233: Loss: 1.0524\n",
            "Epoch 3, Sample 14234: Loss: 0.3399\n",
            "Epoch 3, Sample 14235: Loss: 0.2044\n",
            "Epoch 3, Sample 14236: Loss: 0.8951\n",
            "Epoch 3, Sample 14237: Loss: 0.3399\n",
            "Epoch 3, Sample 14238: Loss: 0.0013\n",
            "Epoch 3, Sample 14239: Loss: 0.1364\n",
            "Epoch 3, Sample 14240: Loss: 2.1901\n",
            "Epoch 3, Sample 14241: Loss: 0.0838\n",
            "Epoch 3, Sample 14242: Loss: 0.0604\n",
            "Epoch 3, Sample 14243: Loss: 0.0604\n",
            "Epoch 3, Sample 14244: Loss: 0.8620\n",
            "Epoch 3, Sample 14245: Loss: 0.2112\n",
            "Epoch 3, Sample 14246: Loss: 0.0026\n",
            "Epoch 3, Sample 14247: Loss: 0.2034\n",
            "Epoch 3, Sample 14248: Loss: 0.4611\n",
            "Epoch 3, Sample 14249: Loss: 0.0318\n",
            "Epoch 3, Sample 14250: Loss: 0.0915\n",
            "Epoch 3, Sample 14251: Loss: 1.5597\n",
            "Epoch 3, Sample 14252: Loss: 0.4930\n",
            "Epoch 3, Sample 14253: Loss: 1.8616\n",
            "Epoch 3, Sample 14254: Loss: 2.1055\n",
            "Epoch 3, Sample 14255: Loss: 0.2759\n",
            "Epoch 3, Sample 14256: Loss: 0.0026\n",
            "Epoch 3, Sample 14257: Loss: 0.3568\n",
            "Epoch 3, Sample 14258: Loss: 0.5702\n",
            "Epoch 3, Sample 14259: Loss: 1.4537\n",
            "Epoch 3, Sample 14260: Loss: 0.0018\n",
            "Epoch 3, Sample 14261: Loss: 0.6990\n",
            "Epoch 3, Sample 14262: Loss: 1.0266\n",
            "Epoch 3, Sample 14263: Loss: 2.0225\n",
            "Epoch 3, Sample 14264: Loss: 0.4382\n",
            "Epoch 3, Sample 14265: Loss: 1.5597\n",
            "Epoch 3, Sample 14266: Loss: 0.1559\n",
            "Epoch 3, Sample 14267: Loss: 1.4884\n",
            "Epoch 3, Sample 14268: Loss: 12.0464\n",
            "Epoch 3, Sample 14269: Loss: 0.0018\n",
            "Epoch 3, Sample 14270: Loss: 0.2832\n",
            "Epoch 3, Sample 14271: Loss: 0.3399\n",
            "Epoch 3, Sample 14272: Loss: 0.2639\n",
            "Epoch 3, Sample 14273: Loss: 0.0076\n",
            "Epoch 3, Sample 14274: Loss: 0.9780\n",
            "Epoch 3, Sample 14275: Loss: 0.0084\n",
            "Epoch 3, Sample 14276: Loss: 0.6190\n",
            "Epoch 3, Sample 14277: Loss: 0.0001\n",
            "Epoch 3, Sample 14278: Loss: 0.0303\n",
            "Epoch 3, Sample 14279: Loss: 0.0114\n",
            "Epoch 3, Sample 14280: Loss: 0.6990\n",
            "Epoch 3, Sample 14281: Loss: 0.5799\n",
            "Epoch 3, Sample 14282: Loss: 1.4884\n",
            "Epoch 3, Sample 14283: Loss: 0.0938\n",
            "Epoch 3, Sample 14284: Loss: 0.0938\n",
            "Epoch 3, Sample 14285: Loss: 0.5003\n",
            "Epoch 3, Sample 14286: Loss: 0.2032\n",
            "Epoch 3, Sample 14287: Loss: 0.7910\n",
            "Epoch 3, Sample 14288: Loss: 0.7453\n",
            "Epoch 3, Sample 14289: Loss: 0.2182\n",
            "Epoch 3, Sample 14290: Loss: 0.2132\n",
            "Epoch 3, Sample 14291: Loss: 0.0026\n",
            "Epoch 3, Sample 14292: Loss: 1.0530\n",
            "Epoch 3, Sample 14293: Loss: 0.0001\n",
            "Epoch 3, Sample 14294: Loss: 0.2034\n",
            "Epoch 3, Sample 14295: Loss: 1.3405\n",
            "Epoch 3, Sample 14296: Loss: 0.4799\n",
            "Epoch 3, Sample 14297: Loss: 0.2044\n",
            "Epoch 3, Sample 14298: Loss: 0.0063\n",
            "Epoch 3, Sample 14299: Loss: 0.0018\n",
            "Epoch 3, Sample 14300: Loss: 0.1170\n",
            "Epoch 3, Sample 14301: Loss: 1.0524\n",
            "Epoch 3, Sample 14302: Loss: 0.5858\n",
            "Epoch 3, Sample 14303: Loss: 1.0524\n",
            "Epoch 3, Sample 14304: Loss: 0.3402\n",
            "Epoch 3, Sample 14305: Loss: 0.0063\n",
            "Epoch 3, Sample 14306: Loss: 1.0524\n",
            "Epoch 3, Sample 14307: Loss: 0.1250\n",
            "Epoch 3, Sample 14308: Loss: 0.5871\n",
            "Epoch 3, Sample 14309: Loss: 0.0469\n",
            "Epoch 3, Sample 14310: Loss: 0.0415\n",
            "Epoch 3, Sample 14311: Loss: 0.3399\n",
            "Epoch 3, Sample 14312: Loss: 0.7036\n",
            "Epoch 3, Sample 14313: Loss: 0.2098\n",
            "Epoch 3, Sample 14314: Loss: 0.8951\n",
            "Epoch 3, Sample 14315: Loss: 9.4268\n",
            "Epoch 3, Sample 14316: Loss: 0.3399\n",
            "Epoch 3, Sample 14317: Loss: 0.4930\n",
            "Epoch 3, Sample 14318: Loss: 0.7036\n",
            "Epoch 3, Sample 14319: Loss: 0.2034\n",
            "Epoch 3, Sample 14320: Loss: 0.0640\n",
            "Epoch 3, Sample 14321: Loss: 0.6304\n",
            "Epoch 3, Sample 14322: Loss: 0.0838\n",
            "Epoch 3, Sample 14323: Loss: 0.0039\n",
            "Epoch 3, Sample 14324: Loss: 0.5858\n",
            "Epoch 3, Sample 14325: Loss: 0.2032\n",
            "Epoch 3, Sample 14326: Loss: 0.1250\n",
            "Epoch 3, Sample 14327: Loss: 0.2639\n",
            "Epoch 3, Sample 14328: Loss: 0.2044\n",
            "Epoch 3, Sample 14329: Loss: 0.5972\n",
            "Epoch 3, Sample 14330: Loss: 0.1250\n",
            "Epoch 3, Sample 14331: Loss: 1.0530\n",
            "Epoch 3, Sample 14332: Loss: 0.0001\n",
            "Epoch 3, Sample 14333: Loss: 0.1250\n",
            "Epoch 3, Sample 14334: Loss: 1.0530\n",
            "Epoch 3, Sample 14335: Loss: 0.0001\n",
            "Epoch 3, Sample 14336: Loss: 0.9780\n",
            "Epoch 3, Sample 14337: Loss: 0.6653\n",
            "Epoch 3, Sample 14338: Loss: 0.2832\n",
            "Epoch 3, Sample 14339: Loss: 1.0524\n",
            "Epoch 3, Sample 14340: Loss: 0.3758\n",
            "Epoch 3, Sample 14341: Loss: 0.1246\n",
            "Epoch 3, Sample 14342: Loss: 0.6304\n",
            "Epoch 3, Sample 14343: Loss: 0.0101\n",
            "Epoch 3, Sample 14344: Loss: 0.0063\n",
            "Epoch 3, Sample 14345: Loss: 0.1399\n",
            "Epoch 3, Sample 14346: Loss: 0.0006\n",
            "Epoch 3, Sample 14347: Loss: 1.0530\n",
            "Epoch 3, Sample 14348: Loss: 0.2639\n",
            "Epoch 3, Sample 14349: Loss: 0.7036\n",
            "Epoch 3, Sample 14350: Loss: 0.0005\n",
            "Epoch 3, Sample 14351: Loss: 0.1508\n",
            "Epoch 3, Sample 14352: Loss: 0.6990\n",
            "Epoch 3, Sample 14353: Loss: 2.9274\n",
            "Epoch 3, Sample 14354: Loss: 7.2518\n",
            "Epoch 3, Sample 14355: Loss: 0.0838\n",
            "Epoch 3, Sample 14356: Loss: 2.7331\n",
            "Epoch 3, Sample 14357: Loss: 1.0524\n",
            "Epoch 3, Sample 14358: Loss: 0.0018\n",
            "Epoch 3, Sample 14359: Loss: 0.4474\n",
            "Epoch 3, Sample 14360: Loss: 2.5454\n",
            "Epoch 3, Sample 14361: Loss: 3.5504\n",
            "Epoch 3, Sample 14362: Loss: 0.7453\n",
            "Epoch 3, Sample 14363: Loss: 0.6304\n",
            "Epoch 3, Sample 14364: Loss: 0.0712\n",
            "Epoch 3, Sample 14365: Loss: 0.0744\n",
            "Epoch 3, Sample 14366: Loss: 0.0026\n",
            "Epoch 3, Sample 14367: Loss: 0.5003\n",
            "Epoch 3, Sample 14368: Loss: 0.0026\n",
            "Epoch 3, Sample 14369: Loss: 0.4466\n",
            "Epoch 3, Sample 14370: Loss: 0.2032\n",
            "Epoch 3, Sample 14371: Loss: 0.0026\n",
            "Epoch 3, Sample 14372: Loss: 0.2044\n",
            "Epoch 3, Sample 14373: Loss: 0.5636\n",
            "Epoch 3, Sample 14374: Loss: 0.5000\n",
            "Epoch 3, Sample 14375: Loss: 0.2759\n",
            "Epoch 3, Sample 14376: Loss: 0.8484\n",
            "Epoch 3, Sample 14377: Loss: 1.1569\n",
            "Epoch 3, Sample 14378: Loss: 0.7036\n",
            "Epoch 3, Sample 14379: Loss: 0.0060\n",
            "Epoch 3, Sample 14380: Loss: 1.0530\n",
            "Epoch 3, Sample 14381: Loss: 0.0630\n",
            "Epoch 3, Sample 14382: Loss: 0.0270\n",
            "Epoch 3, Sample 14383: Loss: 0.2044\n",
            "Epoch 3, Sample 14384: Loss: 5.2263\n",
            "Epoch 3, Sample 14385: Loss: 0.0363\n",
            "Epoch 3, Sample 14386: Loss: 1.0070\n",
            "Epoch 3, Sample 14387: Loss: 0.3332\n",
            "Epoch 3, Sample 14388: Loss: 0.4382\n",
            "Epoch 3, Sample 14389: Loss: 0.3805\n",
            "Epoch 3, Sample 14390: Loss: 0.7036\n",
            "Epoch 3, Sample 14391: Loss: 4.7822\n",
            "Epoch 3, Sample 14392: Loss: 0.1559\n",
            "Epoch 3, Sample 14393: Loss: 1.2522\n",
            "Epoch 3, Sample 14394: Loss: 0.5858\n",
            "Epoch 3, Sample 14395: Loss: 0.0792\n",
            "Epoch 3, Sample 14396: Loss: 0.9780\n",
            "Epoch 3, Sample 14397: Loss: 1.0530\n",
            "Epoch 3, Sample 14398: Loss: 1.0524\n",
            "Epoch 3, Sample 14399: Loss: 0.2044\n",
            "Epoch 3, Sample 14400: Loss: 0.0013\n",
            "Epoch 3, Sample 14401: Loss: 0.1250\n",
            "Epoch 3, Sample 14402: Loss: 0.0026\n",
            "Epoch 3, Sample 14403: Loss: 0.5078\n",
            "Epoch 3, Sample 14404: Loss: 2.5454\n",
            "Epoch 3, Sample 14405: Loss: 1.0524\n",
            "Epoch 3, Sample 14406: Loss: 1.6694\n",
            "Epoch 3, Sample 14407: Loss: 1.0524\n",
            "Epoch 3, Sample 14408: Loss: 0.3399\n",
            "Epoch 3, Sample 14409: Loss: 4.4745\n",
            "Epoch 3, Sample 14410: Loss: 0.0018\n",
            "Epoch 3, Sample 14411: Loss: 0.0026\n",
            "Epoch 3, Sample 14412: Loss: 0.0026\n",
            "Epoch 3, Sample 14413: Loss: 0.2032\n",
            "Epoch 3, Sample 14414: Loss: 0.0026\n",
            "Epoch 3, Sample 14415: Loss: 0.5310\n",
            "Epoch 3, Sample 14416: Loss: 1.2192\n",
            "Epoch 3, Sample 14417: Loss: 10.6965\n",
            "Epoch 3, Sample 14418: Loss: 0.2044\n",
            "Epoch 3, Sample 14419: Loss: 3.5504\n",
            "Epoch 3, Sample 14420: Loss: 0.0001\n",
            "Epoch 3, Sample 14421: Loss: 1.8616\n",
            "Epoch 3, Sample 14422: Loss: 0.2759\n",
            "Epoch 3, Sample 14423: Loss: 0.3332\n",
            "Epoch 3, Sample 14424: Loss: 3.5504\n",
            "Epoch 3, Sample 14425: Loss: 0.4799\n",
            "Epoch 3, Sample 14426: Loss: 0.4474\n",
            "Epoch 3, Sample 14427: Loss: 2.2715\n",
            "Epoch 3, Sample 14428: Loss: 0.4841\n",
            "Epoch 3, Sample 14429: Loss: 1.2845\n",
            "Epoch 3, Sample 14430: Loss: 0.2044\n",
            "Epoch 3, Sample 14431: Loss: 0.9780\n",
            "Epoch 3, Sample 14432: Loss: 0.0707\n",
            "Epoch 3, Sample 14433: Loss: 1.5597\n",
            "Epoch 3, Sample 14434: Loss: 0.0018\n",
            "Epoch 3, Sample 14435: Loss: 1.0530\n",
            "Epoch 3, Sample 14436: Loss: 0.1170\n",
            "Epoch 3, Sample 14437: Loss: 0.2832\n",
            "Epoch 3, Sample 14438: Loss: 0.2034\n",
            "Epoch 3, Sample 14439: Loss: 0.3441\n",
            "Epoch 3, Sample 14440: Loss: 0.0026\n",
            "Epoch 3, Sample 14441: Loss: 0.7453\n",
            "Epoch 3, Sample 14442: Loss: 0.2962\n",
            "Epoch 3, Sample 14443: Loss: 0.1523\n",
            "Epoch 3, Sample 14444: Loss: 0.6304\n",
            "Epoch 3, Sample 14445: Loss: 1.0155\n",
            "Epoch 3, Sample 14446: Loss: 5.7798\n",
            "Epoch 3, Sample 14447: Loss: 0.0026\n",
            "Epoch 3, Sample 14448: Loss: 0.2044\n",
            "Epoch 3, Sample 14449: Loss: 0.7036\n",
            "Epoch 3, Sample 14450: Loss: 0.1559\n",
            "Epoch 3, Sample 14451: Loss: 6.0608\n",
            "Epoch 3, Sample 14452: Loss: 0.1170\n",
            "Epoch 3, Sample 14453: Loss: 0.2032\n",
            "Epoch 3, Sample 14454: Loss: 1.0524\n",
            "Epoch 3, Sample 14455: Loss: 0.2639\n",
            "Epoch 3, Sample 14456: Loss: 0.1559\n",
            "Epoch 3, Sample 14457: Loss: 0.7036\n",
            "Epoch 3, Sample 14458: Loss: 0.2112\n",
            "Epoch 3, Sample 14459: Loss: 8.6383\n",
            "Epoch 3, Sample 14460: Loss: 0.2032\n",
            "Epoch 3, Sample 14461: Loss: 0.2970\n",
            "Epoch 3, Sample 14462: Loss: 1.4884\n",
            "Epoch 3, Sample 14463: Loss: 0.2032\n",
            "Epoch 3, Sample 14464: Loss: 1.0524\n",
            "Epoch 3, Sample 14465: Loss: 7.6726\n",
            "Epoch 3, Sample 14466: Loss: 0.5000\n",
            "Epoch 3, Sample 14467: Loss: 0.1465\n",
            "Epoch 3, Sample 14468: Loss: 0.0026\n",
            "Epoch 3, Sample 14469: Loss: 0.1246\n",
            "Epoch 3, Sample 14470: Loss: 0.2832\n",
            "Epoch 3, Sample 14471: Loss: 0.0707\n",
            "Epoch 3, Sample 14472: Loss: 0.2036\n",
            "Epoch 3, Sample 14473: Loss: 0.5000\n",
            "Epoch 3, Sample 14474: Loss: 2.7331\n",
            "Epoch 3, Sample 14475: Loss: 1.5597\n",
            "Epoch 3, Sample 14476: Loss: 4.5364\n",
            "Epoch 3, Sample 14477: Loss: 0.0554\n",
            "Epoch 3, Sample 14478: Loss: 0.7036\n",
            "Epoch 3, Sample 14479: Loss: 0.0919\n",
            "Epoch 3, Sample 14480: Loss: 0.2704\n",
            "Epoch 3, Sample 14481: Loss: 0.2459\n",
            "Epoch 3, Sample 14482: Loss: 2.7331\n",
            "Epoch 3, Sample 14483: Loss: 5.1063\n",
            "Epoch 3, Sample 14484: Loss: 1.0155\n",
            "Epoch 3, Sample 14485: Loss: 0.0062\n",
            "Epoch 3, Sample 14486: Loss: 0.4799\n",
            "Epoch 3, Sample 14487: Loss: 5.1063\n",
            "Epoch 3, Sample 14488: Loss: 4.4745\n",
            "Epoch 3, Sample 14489: Loss: 0.2014\n",
            "Epoch 3, Sample 14490: Loss: 0.1240\n",
            "Epoch 3, Sample 14491: Loss: 0.8696\n",
            "Epoch 3, Sample 14492: Loss: 0.4032\n",
            "Epoch 3, Sample 14493: Loss: 1.0524\n",
            "Epoch 3, Sample 14494: Loss: 0.0915\n",
            "Epoch 3, Sample 14495: Loss: 9.3274\n",
            "Epoch 3, Sample 14496: Loss: 0.2855\n",
            "Epoch 3, Sample 14497: Loss: 0.5003\n",
            "Epoch 3, Sample 14498: Loss: 0.0026\n",
            "Epoch 3, Sample 14499: Loss: 0.2034\n",
            "Epoch 3, Sample 14500: Loss: 0.1225\n",
            "Epoch 3, Sample 14501: Loss: 0.4799\n",
            "Epoch 3, Sample 14502: Loss: 0.3399\n",
            "Epoch 3, Sample 14503: Loss: 0.0067\n",
            "Epoch 3, Sample 14504: Loss: 12.9803\n",
            "Epoch 3, Sample 14505: Loss: 0.0060\n",
            "Epoch 3, Sample 14506: Loss: 0.2034\n",
            "Epoch 3, Sample 14507: Loss: 8.6351\n",
            "Epoch 3, Sample 14508: Loss: 0.2832\n",
            "Epoch 3, Sample 14509: Loss: 9.5046\n",
            "Epoch 3, Sample 14510: Loss: 0.0001\n",
            "Epoch 3, Sample 14511: Loss: 0.1248\n",
            "Epoch 3, Sample 14512: Loss: 0.5858\n",
            "Epoch 3, Sample 14513: Loss: 0.7036\n",
            "Epoch 3, Sample 14514: Loss: 0.2036\n",
            "Epoch 3, Sample 14515: Loss: 1.5597\n",
            "Epoch 3, Sample 14516: Loss: 0.4799\n",
            "Epoch 3, Sample 14517: Loss: 0.0429\n",
            "Epoch 3, Sample 14518: Loss: 0.1170\n",
            "Epoch 3, Sample 14519: Loss: 0.0000\n",
            "Epoch 3, Sample 14520: Loss: 0.0625\n",
            "Epoch 3, Sample 14521: Loss: 0.8951\n",
            "Epoch 3, Sample 14522: Loss: 0.3506\n",
            "Epoch 3, Sample 14523: Loss: 0.4611\n",
            "Epoch 3, Sample 14524: Loss: 1.0524\n",
            "Epoch 3, Sample 14525: Loss: 0.2639\n",
            "Epoch 3, Sample 14526: Loss: 0.2759\n",
            "Epoch 3, Sample 14527: Loss: 0.7036\n",
            "Epoch 3, Sample 14528: Loss: 1.0359\n",
            "Epoch 3, Sample 14529: Loss: 0.0030\n",
            "Epoch 3, Sample 14530: Loss: 0.4611\n",
            "Epoch 3, Sample 14531: Loss: 0.0258\n",
            "Epoch 3, Sample 14532: Loss: 5.2717\n",
            "Epoch 3, Sample 14533: Loss: 0.3399\n",
            "Epoch 3, Sample 14534: Loss: 0.7036\n",
            "Epoch 3, Sample 14535: Loss: 0.0018\n",
            "Epoch 3, Sample 14536: Loss: 0.0258\n",
            "Epoch 3, Sample 14537: Loss: 1.0530\n",
            "Epoch 3, Sample 14538: Loss: 0.5000\n",
            "Epoch 3, Sample 14539: Loss: 0.0034\n",
            "Epoch 3, Sample 14540: Loss: 0.2044\n",
            "Epoch 3, Sample 14541: Loss: 0.2032\n",
            "Epoch 3, Sample 14542: Loss: 0.3441\n",
            "Epoch 3, Sample 14543: Loss: 1.0524\n",
            "Epoch 3, Sample 14544: Loss: 0.3399\n",
            "Epoch 3, Sample 14545: Loss: 0.2036\n",
            "Epoch 3, Sample 14546: Loss: 0.0018\n",
            "Epoch 3, Sample 14547: Loss: 1.0727\n",
            "Epoch 3, Sample 14548: Loss: 0.3441\n",
            "Epoch 3, Sample 14549: Loss: 0.0000\n",
            "Epoch 3, Sample 14550: Loss: 1.5597\n",
            "Epoch 3, Sample 14551: Loss: 0.1170\n",
            "Epoch 3, Sample 14552: Loss: 0.3598\n",
            "Epoch 3, Sample 14553: Loss: 3.5504\n",
            "Epoch 3, Sample 14554: Loss: 0.2494\n",
            "Epoch 3, Sample 14555: Loss: 0.1250\n",
            "Epoch 3, Sample 14556: Loss: 0.0915\n",
            "Epoch 3, Sample 14557: Loss: 0.0630\n",
            "Epoch 3, Sample 14558: Loss: 0.3758\n",
            "Epoch 3, Sample 14559: Loss: 0.4841\n",
            "Epoch 3, Sample 14560: Loss: 0.0145\n",
            "Epoch 3, Sample 14561: Loss: 0.1989\n",
            "Epoch 3, Sample 14562: Loss: 0.2036\n",
            "Epoch 3, Sample 14563: Loss: 1.0524\n",
            "Epoch 3, Sample 14564: Loss: 0.0018\n",
            "Epoch 3, Sample 14565: Loss: 1.0524\n",
            "Epoch 3, Sample 14566: Loss: 0.3568\n",
            "Epoch 3, Sample 14567: Loss: 1.0530\n",
            "Epoch 3, Sample 14568: Loss: 0.7036\n",
            "Epoch 3, Sample 14569: Loss: 0.0001\n",
            "Epoch 3, Sample 14570: Loss: 6.2039\n",
            "Epoch 3, Sample 14571: Loss: 0.2044\n",
            "Epoch 3, Sample 14572: Loss: 0.2044\n",
            "Epoch 3, Sample 14573: Loss: 0.2044\n",
            "Epoch 3, Sample 14574: Loss: 1.0524\n",
            "Epoch 3, Sample 14575: Loss: 0.0067\n",
            "Epoch 3, Sample 14576: Loss: 1.0359\n",
            "Epoch 3, Sample 14577: Loss: 5.6994\n",
            "Epoch 3, Sample 14578: Loss: 0.7036\n",
            "Epoch 3, Sample 14579: Loss: 0.1248\n",
            "Epoch 3, Sample 14580: Loss: 0.0036\n",
            "Epoch 3, Sample 14581: Loss: 0.0025\n",
            "Epoch 3, Sample 14582: Loss: 0.3949\n",
            "Epoch 3, Sample 14583: Loss: 0.0026\n",
            "Epoch 3, Sample 14584: Loss: 0.2112\n",
            "Epoch 3, Sample 14585: Loss: 0.2044\n",
            "Epoch 3, Sample 14586: Loss: 1.0524\n",
            "Epoch 3, Sample 14587: Loss: 0.1335\n",
            "Epoch 3, Sample 14588: Loss: 0.0212\n",
            "Epoch 3, Sample 14589: Loss: 24.7460\n",
            "Epoch 3, Sample 14590: Loss: 0.1248\n",
            "Epoch 3, Sample 14591: Loss: 0.0258\n",
            "Epoch 3, Sample 14592: Loss: 0.1523\n",
            "Epoch 3, Sample 14593: Loss: 0.8944\n",
            "Epoch 3, Sample 14594: Loss: 0.7036\n",
            "Epoch 3, Sample 14595: Loss: 0.0145\n",
            "Epoch 3, Sample 14596: Loss: 0.1250\n",
            "Epoch 3, Sample 14597: Loss: 0.0625\n",
            "Epoch 3, Sample 14598: Loss: 0.0630\n",
            "Epoch 3, Sample 14599: Loss: 0.2664\n",
            "Epoch 3, Sample 14600: Loss: 0.2339\n",
            "Epoch 3, Sample 14601: Loss: 0.0625\n",
            "Epoch 3, Sample 14602: Loss: 0.3399\n",
            "Epoch 3, Sample 14603: Loss: 4.4385\n",
            "Epoch 3, Sample 14604: Loss: 0.1170\n",
            "Epoch 3, Sample 14605: Loss: 1.0956\n",
            "Epoch 3, Sample 14606: Loss: 1.5597\n",
            "Epoch 3, Sample 14607: Loss: 0.0001\n",
            "Epoch 3, Sample 14608: Loss: 0.1419\n",
            "Epoch 3, Sample 14609: Loss: 0.4930\n",
            "Epoch 3, Sample 14610: Loss: 0.8141\n",
            "Epoch 3, Sample 14611: Loss: 0.1248\n",
            "Epoch 3, Sample 14612: Loss: 0.3036\n",
            "Epoch 3, Sample 14613: Loss: 0.0630\n",
            "Epoch 3, Sample 14614: Loss: 0.0027\n",
            "Epoch 3, Sample 14615: Loss: 0.2034\n",
            "Epoch 3, Sample 14616: Loss: 1.8616\n",
            "Epoch 3, Sample 14617: Loss: 0.0630\n",
            "Epoch 3, Sample 14618: Loss: 0.0018\n",
            "Epoch 3, Sample 14619: Loss: 0.0205\n",
            "Epoch 3, Sample 14620: Loss: 0.2759\n",
            "Epoch 3, Sample 14621: Loss: 0.3441\n",
            "Epoch 3, Sample 14622: Loss: 1.0227\n",
            "Epoch 3, Sample 14623: Loss: 0.2036\n",
            "Epoch 3, Sample 14624: Loss: 0.2032\n",
            "Epoch 3, Sample 14625: Loss: 0.4930\n",
            "Epoch 3, Sample 14626: Loss: 1.0524\n",
            "Epoch 3, Sample 14627: Loss: 0.2032\n",
            "Epoch 3, Sample 14628: Loss: 0.7036\n",
            "Epoch 3, Sample 14629: Loss: 0.1337\n",
            "Epoch 3, Sample 14630: Loss: 0.0026\n",
            "Epoch 3, Sample 14631: Loss: 0.0026\n",
            "Epoch 3, Sample 14632: Loss: 8.8908\n",
            "Epoch 3, Sample 14633: Loss: 0.2034\n",
            "Epoch 3, Sample 14634: Loss: 0.6990\n",
            "Epoch 3, Sample 14635: Loss: 0.1248\n",
            "Epoch 3, Sample 14636: Loss: 0.3399\n",
            "Epoch 3, Sample 14637: Loss: 1.5597\n",
            "Epoch 3, Sample 14638: Loss: 0.0630\n",
            "Epoch 3, Sample 14639: Loss: 1.0658\n",
            "Epoch 3, Sample 14640: Loss: 0.0915\n",
            "Epoch 3, Sample 14641: Loss: 0.2759\n",
            "Epoch 3, Sample 14642: Loss: 0.1559\n",
            "Epoch 3, Sample 14643: Loss: 4.7222\n",
            "Epoch 3, Sample 14644: Loss: 0.0026\n",
            "Epoch 3, Sample 14645: Loss: 0.2340\n",
            "Epoch 3, Sample 14646: Loss: 5.7798\n",
            "Epoch 3, Sample 14647: Loss: 1.6144\n",
            "Epoch 3, Sample 14648: Loss: 0.2032\n",
            "Epoch 3, Sample 14649: Loss: 1.1569\n",
            "Epoch 3, Sample 14650: Loss: 0.0013\n",
            "Epoch 3, Sample 14651: Loss: 0.0018\n",
            "Epoch 3, Sample 14652: Loss: 0.1248\n",
            "Epoch 3, Sample 14653: Loss: 1.0155\n",
            "Epoch 3, Sample 14654: Loss: 0.0819\n",
            "Epoch 3, Sample 14655: Loss: 0.7036\n",
            "Epoch 3, Sample 14656: Loss: 0.1092\n",
            "Epoch 3, Sample 14657: Loss: 0.2034\n",
            "Epoch 3, Sample 14658: Loss: 0.1817\n",
            "Epoch 3, Sample 14659: Loss: 0.8484\n",
            "Epoch 3, Sample 14660: Loss: 0.2032\n",
            "Epoch 3, Sample 14661: Loss: 0.2044\n",
            "Epoch 3, Sample 14662: Loss: 2.7331\n",
            "Epoch 3, Sample 14663: Loss: 0.0034\n",
            "Epoch 3, Sample 14664: Loss: 0.2759\n",
            "Epoch 3, Sample 14665: Loss: 7.0971\n",
            "Epoch 3, Sample 14666: Loss: 0.1588\n",
            "Epoch 3, Sample 14667: Loss: 0.2044\n",
            "Epoch 3, Sample 14668: Loss: 0.7036\n",
            "Epoch 3, Sample 14669: Loss: 0.0026\n",
            "Epoch 3, Sample 14670: Loss: 0.4996\n",
            "Epoch 3, Sample 14671: Loss: 0.0026\n",
            "Epoch 3, Sample 14672: Loss: 0.8951\n",
            "Epoch 3, Sample 14673: Loss: 0.1250\n",
            "Epoch 3, Sample 14674: Loss: 4.2335\n",
            "Epoch 3, Sample 14675: Loss: 0.2112\n",
            "Epoch 3, Sample 14676: Loss: 0.0072\n",
            "Epoch 3, Sample 14677: Loss: 0.2639\n",
            "Epoch 3, Sample 14678: Loss: 0.1555\n",
            "Epoch 3, Sample 14679: Loss: 0.0838\n",
            "Epoch 3, Sample 14680: Loss: 0.0938\n",
            "Epoch 3, Sample 14681: Loss: 0.3399\n",
            "Epoch 3, Sample 14682: Loss: 1.0524\n",
            "Epoch 3, Sample 14683: Loss: 0.0838\n",
            "Epoch 3, Sample 14684: Loss: 0.0947\n",
            "Epoch 3, Sample 14685: Loss: 0.1588\n",
            "Epoch 3, Sample 14686: Loss: 0.0108\n",
            "Epoch 3, Sample 14687: Loss: 0.2494\n",
            "Epoch 3, Sample 14688: Loss: 0.1559\n",
            "Epoch 3, Sample 14689: Loss: 0.0001\n",
            "Epoch 3, Sample 14690: Loss: 2.7331\n",
            "Epoch 3, Sample 14691: Loss: 0.0630\n",
            "Epoch 3, Sample 14692: Loss: 0.0026\n",
            "Epoch 3, Sample 14693: Loss: 1.0155\n",
            "Epoch 3, Sample 14694: Loss: 0.5871\n",
            "Epoch 3, Sample 14695: Loss: 0.5000\n",
            "Epoch 3, Sample 14696: Loss: 0.0018\n",
            "Epoch 3, Sample 14697: Loss: 0.5278\n",
            "Epoch 3, Sample 14698: Loss: 0.0630\n",
            "Epoch 3, Sample 14699: Loss: 0.2044\n",
            "Epoch 3, Sample 14700: Loss: 1.5963\n",
            "Epoch 3, Sample 14701: Loss: 0.2044\n",
            "Epoch 3, Sample 14702: Loss: 0.2639\n",
            "Epoch 3, Sample 14703: Loss: 0.1170\n",
            "Epoch 3, Sample 14704: Loss: 0.1250\n",
            "Epoch 3, Sample 14705: Loss: 0.7036\n",
            "Epoch 3, Sample 14706: Loss: 0.0026\n",
            "Epoch 3, Sample 14707: Loss: 1.0524\n",
            "Epoch 3, Sample 14708: Loss: 0.1250\n",
            "Epoch 3, Sample 14709: Loss: 4.4745\n",
            "Epoch 3, Sample 14710: Loss: 1.0227\n",
            "Epoch 3, Sample 14711: Loss: 1.0524\n",
            "Epoch 3, Sample 14712: Loss: 0.2704\n",
            "Epoch 3, Sample 14713: Loss: 0.1337\n",
            "Epoch 3, Sample 14714: Loss: 0.1250\n",
            "Epoch 3, Sample 14715: Loss: 0.2044\n",
            "Epoch 3, Sample 14716: Loss: 1.5597\n",
            "Epoch 3, Sample 14717: Loss: 0.4930\n",
            "Epoch 3, Sample 14718: Loss: 6.9441\n",
            "Epoch 3, Sample 14719: Loss: 0.0022\n",
            "Epoch 3, Sample 14720: Loss: 0.0630\n",
            "Epoch 3, Sample 14721: Loss: 0.2851\n",
            "Epoch 3, Sample 14722: Loss: 0.2044\n",
            "Epoch 3, Sample 14723: Loss: 0.0000\n",
            "Epoch 3, Sample 14724: Loss: 0.1252\n",
            "Epoch 3, Sample 14725: Loss: 0.7036\n",
            "Epoch 3, Sample 14726: Loss: 0.6092\n",
            "Epoch 3, Sample 14727: Loss: 0.2759\n",
            "Epoch 3, Sample 14728: Loss: 1.0524\n",
            "Epoch 3, Sample 14729: Loss: 3.1284\n",
            "Epoch 3, Sample 14730: Loss: 2.7331\n",
            "Epoch 3, Sample 14731: Loss: 0.3633\n",
            "Epoch 3, Sample 14732: Loss: 0.1378\n",
            "Epoch 3, Sample 14733: Loss: 0.0915\n",
            "Epoch 3, Sample 14734: Loss: 0.0009\n",
            "Epoch 3, Sample 14735: Loss: 0.7036\n",
            "Epoch 3, Sample 14736: Loss: 0.5858\n",
            "Epoch 3, Sample 14737: Loss: 0.0212\n",
            "Epoch 3, Sample 14738: Loss: 0.1523\n",
            "Epoch 3, Sample 14739: Loss: 0.0026\n",
            "Epoch 3, Sample 14740: Loss: 0.4032\n",
            "Epoch 3, Sample 14741: Loss: 0.0188\n",
            "Epoch 3, Sample 14742: Loss: 0.0838\n",
            "Epoch 3, Sample 14743: Loss: 0.7036\n",
            "Epoch 3, Sample 14744: Loss: 2.8908\n",
            "Epoch 3, Sample 14745: Loss: 0.2759\n",
            "Epoch 3, Sample 14746: Loss: 0.3441\n",
            "Epoch 3, Sample 14747: Loss: 0.1246\n",
            "Epoch 3, Sample 14748: Loss: 0.1337\n",
            "Epoch 3, Sample 14749: Loss: 0.5871\n",
            "Epoch 3, Sample 14750: Loss: 0.7453\n",
            "Epoch 3, Sample 14751: Loss: 0.0207\n",
            "Epoch 3, Sample 14752: Loss: 0.3399\n",
            "Epoch 3, Sample 14753: Loss: 0.0270\n",
            "Epoch 3, Sample 14754: Loss: 0.2639\n",
            "Epoch 3, Sample 14755: Loss: 0.0026\n",
            "Epoch 3, Sample 14756: Loss: 2.7331\n",
            "Epoch 3, Sample 14757: Loss: 0.0475\n",
            "Epoch 3, Sample 14758: Loss: 0.1246\n",
            "Epoch 3, Sample 14759: Loss: 3.4424\n",
            "Epoch 3, Sample 14760: Loss: 0.9785\n",
            "Epoch 3, Sample 14761: Loss: 0.0363\n",
            "Epoch 3, Sample 14762: Loss: 0.5196\n",
            "Epoch 3, Sample 14763: Loss: 0.2034\n",
            "Epoch 3, Sample 14764: Loss: 1.0266\n",
            "Epoch 3, Sample 14765: Loss: 0.0303\n",
            "Epoch 3, Sample 14766: Loss: 0.1250\n",
            "Epoch 3, Sample 14767: Loss: 0.0306\n",
            "Epoch 3, Sample 14768: Loss: 0.0026\n",
            "Epoch 3, Sample 14769: Loss: 0.2759\n",
            "Epoch 3, Sample 14770: Loss: 0.2962\n",
            "Epoch 3, Sample 14771: Loss: 0.7036\n",
            "Epoch 3, Sample 14772: Loss: 0.1250\n",
            "Epoch 3, Sample 14773: Loss: 0.3399\n",
            "Epoch 3, Sample 14774: Loss: 1.0155\n",
            "Epoch 3, Sample 14775: Loss: 0.0031\n",
            "Epoch 3, Sample 14776: Loss: 1.0524\n",
            "Epoch 3, Sample 14777: Loss: 0.2219\n",
            "Epoch 3, Sample 14778: Loss: 0.7036\n",
            "Epoch 3, Sample 14779: Loss: 0.1250\n",
            "Epoch 3, Sample 14780: Loss: 0.1199\n",
            "Epoch 3, Sample 14781: Loss: 7.0971\n",
            "Epoch 3, Sample 14782: Loss: 0.0025\n",
            "Epoch 3, Sample 14783: Loss: 0.1248\n",
            "Epoch 3, Sample 14784: Loss: 0.2044\n",
            "Epoch 3, Sample 14785: Loss: 0.0084\n",
            "Epoch 3, Sample 14786: Loss: 0.1170\n",
            "Epoch 3, Sample 14787: Loss: 0.0205\n",
            "Epoch 3, Sample 14788: Loss: 0.0915\n",
            "Epoch 3, Sample 14789: Loss: 0.5858\n",
            "Epoch 3, Sample 14790: Loss: 0.1250\n",
            "Epoch 3, Sample 14791: Loss: 1.5597\n",
            "Epoch 3, Sample 14792: Loss: 1.0530\n",
            "Epoch 3, Sample 14793: Loss: 0.2086\n",
            "Epoch 3, Sample 14794: Loss: 0.0415\n",
            "Epoch 3, Sample 14795: Loss: 0.5972\n",
            "Epoch 3, Sample 14796: Loss: 0.3399\n",
            "Epoch 3, Sample 14797: Loss: 0.2558\n",
            "Epoch 3, Sample 14798: Loss: 0.0006\n",
            "Epoch 3, Sample 14799: Loss: 1.0155\n",
            "Epoch 3, Sample 14800: Loss: 0.0026\n",
            "Epoch 3, Sample 14801: Loss: 0.2044\n",
            "Epoch 3, Sample 14802: Loss: 0.6990\n",
            "Epoch 3, Sample 14803: Loss: 0.0018\n",
            "Epoch 3, Sample 14804: Loss: 0.0630\n",
            "Epoch 3, Sample 14805: Loss: 0.0088\n",
            "Epoch 3, Sample 14806: Loss: 0.8484\n",
            "Epoch 3, Sample 14807: Loss: 0.2034\n",
            "Epoch 3, Sample 14808: Loss: 0.2032\n",
            "Epoch 3, Sample 14809: Loss: 0.2759\n",
            "Epoch 3, Sample 14810: Loss: 0.1250\n",
            "Epoch 3, Sample 14811: Loss: 1.0524\n",
            "Epoch 3, Sample 14812: Loss: 1.0155\n",
            "Epoch 3, Sample 14813: Loss: 0.7561\n",
            "Epoch 3, Sample 14814: Loss: 2.1901\n",
            "Epoch 3, Sample 14815: Loss: 0.2989\n",
            "Epoch 3, Sample 14816: Loss: 0.9780\n",
            "Epoch 3, Sample 14817: Loss: 1.0266\n",
            "Epoch 3, Sample 14818: Loss: 0.0838\n",
            "Epoch 3, Sample 14819: Loss: 0.2219\n",
            "Epoch 3, Sample 14820: Loss: 0.3402\n",
            "Epoch 3, Sample 14821: Loss: 0.1248\n",
            "Epoch 3, Sample 14822: Loss: 0.2759\n",
            "Epoch 3, Sample 14823: Loss: 1.0524\n",
            "Epoch 3, Sample 14824: Loss: 0.3949\n",
            "Epoch 3, Sample 14825: Loss: 0.5636\n",
            "Epoch 3, Sample 14826: Loss: 1.0359\n",
            "Epoch 3, Sample 14827: Loss: 1.0359\n",
            "Epoch 3, Sample 14828: Loss: 2.7989\n",
            "Epoch 3, Sample 14829: Loss: 0.7036\n",
            "Epoch 3, Sample 14830: Loss: 5.3707\n",
            "Epoch 3, Sample 14831: Loss: 5.5067\n",
            "Epoch 3, Sample 14832: Loss: 0.0133\n",
            "Epoch 3, Sample 14833: Loss: 0.7453\n",
            "Epoch 3, Sample 14834: Loss: 0.3441\n",
            "Epoch 3, Sample 14835: Loss: 0.1674\n",
            "Epoch 3, Sample 14836: Loss: 0.0554\n",
            "Epoch 3, Sample 14837: Loss: 0.4382\n",
            "Epoch 3, Sample 14838: Loss: 0.2044\n",
            "Epoch 3, Sample 14839: Loss: 0.3399\n",
            "Epoch 3, Sample 14840: Loss: 0.6139\n",
            "Epoch 3, Sample 14841: Loss: 1.0524\n",
            "Epoch 3, Sample 14842: Loss: 0.3441\n",
            "Epoch 3, Sample 14843: Loss: 0.9785\n",
            "Epoch 3, Sample 14844: Loss: 19.9570\n",
            "Epoch 3, Sample 14845: Loss: 0.0313\n",
            "Epoch 3, Sample 14846: Loss: 0.2639\n",
            "Epoch 3, Sample 14847: Loss: 0.0001\n",
            "Epoch 3, Sample 14848: Loss: 3.9991\n",
            "Epoch 3, Sample 14849: Loss: 2.9274\n",
            "Epoch 3, Sample 14850: Loss: 1.0155\n",
            "Epoch 3, Sample 14851: Loss: 0.0026\n",
            "Epoch 3, Sample 14852: Loss: 0.2036\n",
            "Epoch 3, Sample 14853: Loss: 0.0026\n",
            "Epoch 3, Sample 14854: Loss: 1.0956\n",
            "Epoch 3, Sample 14855: Loss: 0.0018\n",
            "Epoch 3, Sample 14856: Loss: 0.0042\n",
            "Epoch 3, Sample 14857: Loss: 0.2832\n",
            "Epoch 3, Sample 14858: Loss: 1.1205\n",
            "Epoch 3, Sample 14859: Loss: 0.0108\n",
            "Epoch 3, Sample 14860: Loss: 0.0318\n",
            "Epoch 3, Sample 14861: Loss: 0.1246\n",
            "Epoch 3, Sample 14862: Loss: 0.3399\n",
            "Epoch 3, Sample 14863: Loss: 1.0359\n",
            "Epoch 3, Sample 14864: Loss: 0.3441\n",
            "Epoch 3, Sample 14865: Loss: 0.0391\n",
            "Epoch 3, Sample 14866: Loss: 0.0477\n",
            "Epoch 3, Sample 14867: Loss: 1.0530\n",
            "Epoch 3, Sample 14868: Loss: 0.0380\n",
            "Epoch 3, Sample 14869: Loss: 3.5504\n",
            "Epoch 3, Sample 14870: Loss: 0.0005\n",
            "Epoch 3, Sample 14871: Loss: 1.5597\n",
            "Epoch 3, Sample 14872: Loss: 0.8951\n",
            "Epoch 3, Sample 14873: Loss: 0.0013\n",
            "Epoch 3, Sample 14874: Loss: 2.1055\n",
            "Epoch 3, Sample 14875: Loss: 0.4607\n",
            "Epoch 3, Sample 14876: Loss: 0.1559\n",
            "Epoch 3, Sample 14877: Loss: 0.0018\n",
            "Epoch 3, Sample 14878: Loss: 0.9367\n",
            "Epoch 3, Sample 14879: Loss: 0.0626\n",
            "Epoch 3, Sample 14880: Loss: 0.7453\n",
            "Epoch 3, Sample 14881: Loss: 0.1248\n",
            "Epoch 3, Sample 14882: Loss: 0.3126\n",
            "Epoch 3, Sample 14883: Loss: 0.5000\n",
            "Epoch 3, Sample 14884: Loss: 0.2036\n",
            "Epoch 3, Sample 14885: Loss: 1.0530\n",
            "Epoch 3, Sample 14886: Loss: 0.1170\n",
            "Epoch 3, Sample 14887: Loss: 0.2044\n",
            "Epoch 3, Sample 14888: Loss: 0.4032\n",
            "Epoch 3, Sample 14889: Loss: 0.3441\n",
            "Epoch 3, Sample 14890: Loss: 0.3399\n",
            "Epoch 3, Sample 14891: Loss: 0.0938\n",
            "Epoch 3, Sample 14892: Loss: 0.7036\n",
            "Epoch 3, Sample 14893: Loss: 8.7194\n",
            "Epoch 3, Sample 14894: Loss: 0.1248\n",
            "Epoch 3, Sample 14895: Loss: 0.0286\n",
            "Epoch 3, Sample 14896: Loss: 0.0034\n",
            "Epoch 3, Sample 14897: Loss: 0.6092\n",
            "Epoch 3, Sample 14898: Loss: 1.0524\n",
            "Epoch 3, Sample 14899: Loss: 1.4187\n",
            "Epoch 3, Sample 14900: Loss: 0.3949\n",
            "Epoch 3, Sample 14901: Loss: 0.6867\n",
            "Epoch 3, Sample 14902: Loss: 0.1056\n",
            "Epoch 3, Sample 14903: Loss: 0.0026\n",
            "Epoch 3, Sample 14904: Loss: 0.3758\n",
            "Epoch 3, Sample 14905: Loss: 1.0524\n",
            "Epoch 3, Sample 14906: Loss: 0.0630\n",
            "Epoch 3, Sample 14907: Loss: 0.2112\n",
            "Epoch 3, Sample 14908: Loss: 0.4644\n",
            "Epoch 3, Sample 14909: Loss: 1.0155\n",
            "Epoch 3, Sample 14910: Loss: 0.0018\n",
            "Epoch 3, Sample 14911: Loss: 0.2044\n",
            "Epoch 3, Sample 14912: Loss: 0.0026\n",
            "Epoch 3, Sample 14913: Loss: 0.0205\n",
            "Epoch 3, Sample 14914: Loss: 0.1260\n",
            "Epoch 3, Sample 14915: Loss: 0.5003\n",
            "Epoch 3, Sample 14916: Loss: 0.0363\n",
            "Epoch 3, Sample 14917: Loss: 0.6990\n",
            "Epoch 3, Sample 14918: Loss: 0.3441\n",
            "Epoch 3, Sample 14919: Loss: 9.7728\n",
            "Epoch 3, Sample 14920: Loss: 0.2032\n",
            "Epoch 3, Sample 14921: Loss: 0.0150\n",
            "Epoch 3, Sample 14922: Loss: 0.1170\n",
            "Epoch 3, Sample 14923: Loss: 0.0062\n",
            "Epoch 3, Sample 14924: Loss: 1.5597\n",
            "Epoch 3, Sample 14925: Loss: 0.0626\n",
            "Epoch 3, Sample 14926: Loss: 0.0001\n",
            "Epoch 3, Sample 14927: Loss: 0.6304\n",
            "Epoch 3, Sample 14928: Loss: 0.0025\n",
            "Epoch 3, Sample 14929: Loss: 0.1246\n",
            "Epoch 3, Sample 14930: Loss: 0.0018\n",
            "Epoch 3, Sample 14931: Loss: 0.0802\n",
            "Epoch 3, Sample 14932: Loss: 0.3399\n",
            "Epoch 3, Sample 14933: Loss: 0.0108\n",
            "Epoch 3, Sample 14934: Loss: 0.2962\n",
            "Epoch 3, Sample 14935: Loss: 0.6190\n",
            "Epoch 3, Sample 14936: Loss: 0.3441\n",
            "Epoch 3, Sample 14937: Loss: 0.2182\n",
            "Epoch 3, Sample 14938: Loss: 0.0013\n",
            "Epoch 3, Sample 14939: Loss: 0.3399\n",
            "Epoch 3, Sample 14940: Loss: 0.6304\n",
            "Epoch 3, Sample 14941: Loss: 1.0359\n",
            "Epoch 3, Sample 14942: Loss: 0.1170\n",
            "Epoch 3, Sample 14943: Loss: 1.0530\n",
            "Epoch 3, Sample 14944: Loss: 1.0956\n",
            "Epoch 3, Sample 14945: Loss: 0.3399\n",
            "Epoch 3, Sample 14946: Loss: 0.4607\n",
            "Epoch 3, Sample 14947: Loss: 0.0630\n",
            "Epoch 3, Sample 14948: Loss: 0.2639\n",
            "Epoch 3, Sample 14949: Loss: 0.0062\n",
            "Epoch 3, Sample 14950: Loss: 0.5858\n",
            "Epoch 3, Sample 14951: Loss: 0.0084\n",
            "Epoch 3, Sample 14952: Loss: 0.0258\n",
            "Epoch 3, Sample 14953: Loss: 0.1397\n",
            "Epoch 3, Sample 14954: Loss: 0.0018\n",
            "Epoch 3, Sample 14955: Loss: 0.1559\n",
            "Epoch 3, Sample 14956: Loss: 0.2032\n",
            "Epoch 3, Sample 14957: Loss: 1.5597\n",
            "Epoch 3, Sample 14958: Loss: 0.3399\n",
            "Epoch 3, Sample 14959: Loss: 1.0956\n",
            "Epoch 3, Sample 14960: Loss: 0.2759\n",
            "Epoch 3, Sample 14961: Loss: 0.2219\n",
            "Epoch 3, Sample 14962: Loss: 4.3888\n",
            "Epoch 3, Sample 14963: Loss: 0.2044\n",
            "Epoch 3, Sample 14964: Loss: 0.0030\n",
            "Epoch 3, Sample 14965: Loss: 0.7036\n",
            "Epoch 3, Sample 14966: Loss: 0.0712\n",
            "Epoch 3, Sample 14967: Loss: 0.1252\n",
            "Epoch 3, Sample 14968: Loss: 0.0026\n",
            "Epoch 3, Sample 14969: Loss: 2.0108\n",
            "Epoch 3, Sample 14970: Loss: 0.0080\n",
            "Epoch 3, Sample 14971: Loss: 0.5003\n",
            "Epoch 3, Sample 14972: Loss: 0.0466\n",
            "Epoch 3, Sample 14973: Loss: 0.1246\n",
            "Epoch 3, Sample 14974: Loss: 1.0524\n",
            "Epoch 3, Sample 14975: Loss: 0.1463\n",
            "Epoch 3, Sample 14976: Loss: 0.0466\n",
            "Epoch 3, Sample 14977: Loss: 1.0524\n",
            "Epoch 3, Sample 14978: Loss: 0.2931\n",
            "Epoch 3, Sample 14979: Loss: 0.0026\n",
            "Epoch 3, Sample 14980: Loss: 0.0026\n",
            "Epoch 3, Sample 14981: Loss: 0.4799\n",
            "Epoch 3, Sample 14982: Loss: 0.8484\n",
            "Epoch 3, Sample 14983: Loss: 0.4930\n",
            "Epoch 3, Sample 14984: Loss: 1.0155\n",
            "Epoch 3, Sample 14985: Loss: 0.0026\n",
            "Epoch 3, Sample 14986: Loss: 0.0026\n",
            "Epoch 3, Sample 14987: Loss: 3.6601\n",
            "Epoch 3, Sample 14988: Loss: 1.0688\n",
            "Epoch 3, Sample 14989: Loss: 1.0359\n",
            "Epoch 3, Sample 14990: Loss: 0.1250\n",
            "Epoch 3, Sample 14991: Loss: 0.1225\n",
            "Epoch 3, Sample 14992: Loss: 1.0524\n",
            "Epoch 3, Sample 14993: Loss: 0.9785\n",
            "Epoch 3, Sample 14994: Loss: 0.4611\n",
            "Epoch 3, Sample 14995: Loss: 0.6990\n",
            "Epoch 3, Sample 14996: Loss: 0.4641\n",
            "Epoch 3, Sample 14997: Loss: 0.6990\n",
            "Epoch 3, Sample 14998: Loss: 0.6867\n",
            "Epoch 3, Sample 14999: Loss: 0.1250\n",
            "Epoch 3, Sample 15000: Loss: 0.3949\n",
            "Epoch 3, Sample 15001: Loss: 0.0018\n",
            "Epoch 3, Sample 15002: Loss: 0.2832\n",
            "Epoch 3, Sample 15003: Loss: 0.1364\n",
            "Epoch 3, Sample 15004: Loss: 0.2182\n",
            "Epoch 3, Sample 15005: Loss: 1.0956\n",
            "Epoch 3, Sample 15006: Loss: 0.1964\n",
            "Epoch 3, Sample 15007: Loss: 0.2032\n",
            "Epoch 3, Sample 15008: Loss: 0.2044\n",
            "Epoch 3, Sample 15009: Loss: 0.2219\n",
            "Epoch 3, Sample 15010: Loss: 0.3949\n",
            "Epoch 3, Sample 15011: Loss: 0.4930\n",
            "Epoch 3, Sample 15012: Loss: 0.2044\n",
            "Epoch 3, Sample 15013: Loss: 0.0006\n",
            "Epoch 3, Sample 15014: Loss: 1.0524\n",
            "Epoch 3, Sample 15015: Loss: 0.3399\n",
            "Epoch 3, Sample 15016: Loss: 0.0018\n",
            "Epoch 3, Sample 15017: Loss: 1.0524\n",
            "Epoch 3, Sample 15018: Loss: 0.7702\n",
            "Epoch 3, Sample 15019: Loss: 2.9775\n",
            "Epoch 3, Sample 15020: Loss: 10.1372\n",
            "Epoch 3, Sample 15021: Loss: 0.3402\n",
            "Epoch 3, Sample 15022: Loss: 0.7702\n",
            "Epoch 3, Sample 15023: Loss: 0.2044\n",
            "Epoch 3, Sample 15024: Loss: 0.1622\n",
            "Epoch 3, Sample 15025: Loss: 1.0155\n",
            "Epoch 3, Sample 15026: Loss: 0.0303\n",
            "Epoch 3, Sample 15027: Loss: 0.1246\n",
            "Epoch 3, Sample 15028: Loss: 1.0070\n",
            "Epoch 3, Sample 15029: Loss: 0.1039\n",
            "Epoch 3, Sample 15030: Loss: 1.0155\n",
            "Epoch 3, Sample 15031: Loss: 13.9327\n",
            "Epoch 3, Sample 15032: Loss: 0.0018\n",
            "Epoch 3, Sample 15033: Loss: 0.3332\n",
            "Epoch 3, Sample 15034: Loss: 0.0026\n",
            "Epoch 3, Sample 15035: Loss: 0.6990\n",
            "Epoch 3, Sample 15036: Loss: 0.1225\n",
            "Epoch 3, Sample 15037: Loss: 2.0225\n",
            "Epoch 3, Sample 15038: Loss: 2.7331\n",
            "Epoch 3, Sample 15039: Loss: 0.2034\n",
            "Epoch 3, Sample 15040: Loss: 0.5858\n",
            "Epoch 3, Sample 15041: Loss: 0.8951\n",
            "Epoch 3, Sample 15042: Loss: 1.0524\n",
            "Epoch 3, Sample 15043: Loss: 1.8616\n",
            "Epoch 3, Sample 15044: Loss: 0.0034\n",
            "Epoch 3, Sample 15045: Loss: 19.0797\n",
            "Epoch 3, Sample 15046: Loss: 1.0524\n",
            "Epoch 3, Sample 15047: Loss: 0.0026\n",
            "Epoch 3, Sample 15048: Loss: 1.5113\n",
            "Epoch 3, Sample 15049: Loss: 0.2558\n",
            "Epoch 3, Sample 15050: Loss: 0.7036\n",
            "Epoch 3, Sample 15051: Loss: 1.0524\n",
            "Epoch 3, Sample 15052: Loss: 0.1040\n",
            "Epoch 3, Sample 15053: Loss: 1.0359\n",
            "Epoch 3, Sample 15054: Loss: 0.2034\n",
            "Epoch 3, Sample 15055: Loss: 0.3399\n",
            "Epoch 3, Sample 15056: Loss: 0.1246\n",
            "Epoch 3, Sample 15057: Loss: 0.3984\n",
            "Epoch 3, Sample 15058: Loss: 21.6888\n",
            "Epoch 3, Sample 15059: Loss: 0.2044\n",
            "Epoch 3, Sample 15060: Loss: 1.0359\n",
            "Epoch 3, Sample 15061: Loss: 2.9274\n",
            "Epoch 3, Sample 15062: Loss: 0.3399\n",
            "Epoch 3, Sample 15063: Loss: 0.5636\n",
            "Epoch 3, Sample 15064: Loss: 0.1364\n",
            "Epoch 3, Sample 15065: Loss: 2.5000\n",
            "Epoch 3, Sample 15066: Loss: 0.3441\n",
            "Epoch 3, Sample 15067: Loss: 0.2032\n",
            "Epoch 3, Sample 15068: Loss: 0.2036\n",
            "Epoch 3, Sample 15069: Loss: 0.1250\n",
            "Epoch 3, Sample 15070: Loss: 1.0530\n",
            "Epoch 3, Sample 15071: Loss: 0.0026\n",
            "Epoch 3, Sample 15072: Loss: 0.0026\n",
            "Epoch 3, Sample 15073: Loss: 1.8616\n",
            "Epoch 3, Sample 15074: Loss: 0.4032\n",
            "Epoch 3, Sample 15075: Loss: 0.0161\n",
            "Epoch 3, Sample 15076: Loss: 0.4799\n",
            "Epoch 3, Sample 15077: Loss: 0.7036\n",
            "Epoch 3, Sample 15078: Loss: 0.0025\n",
            "Epoch 3, Sample 15079: Loss: 0.1240\n",
            "Epoch 3, Sample 15080: Loss: 0.2832\n",
            "Epoch 3, Sample 15081: Loss: 0.1170\n",
            "Epoch 3, Sample 15082: Loss: 0.2935\n",
            "Epoch 3, Sample 15083: Loss: 0.0000\n",
            "Epoch 3, Sample 15084: Loss: 0.0025\n",
            "Epoch 3, Sample 15085: Loss: 0.1055\n",
            "Epoch 3, Sample 15086: Loss: 0.3332\n",
            "Epoch 3, Sample 15087: Loss: 0.1252\n",
            "Epoch 3, Sample 15088: Loss: 0.3441\n",
            "Epoch 3, Sample 15089: Loss: 0.2032\n",
            "Epoch 3, Sample 15090: Loss: 0.0001\n",
            "Epoch 3, Sample 15091: Loss: 0.0637\n",
            "Epoch 3, Sample 15092: Loss: 2.4541\n",
            "Epoch 3, Sample 15093: Loss: 0.6990\n",
            "Epoch 3, Sample 15094: Loss: 0.0026\n",
            "Epoch 3, Sample 15095: Loss: 0.5000\n",
            "Epoch 3, Sample 15096: Loss: 2.7331\n",
            "Epoch 3, Sample 15097: Loss: 0.0026\n",
            "Epoch 3, Sample 15098: Loss: 0.1248\n",
            "Epoch 3, Sample 15099: Loss: 0.0306\n",
            "Epoch 3, Sample 15100: Loss: 0.0026\n",
            "Epoch 3, Sample 15101: Loss: 0.0026\n",
            "Epoch 3, Sample 15102: Loss: 0.7702\n",
            "Epoch 3, Sample 15103: Loss: 0.3949\n",
            "Epoch 3, Sample 15104: Loss: 1.0524\n",
            "Epoch 3, Sample 15105: Loss: 0.5003\n",
            "Epoch 3, Sample 15106: Loss: 0.2044\n",
            "Epoch 3, Sample 15107: Loss: 1.0155\n",
            "Epoch 3, Sample 15108: Loss: 0.6893\n",
            "Epoch 3, Sample 15109: Loss: 0.1248\n",
            "Epoch 3, Sample 15110: Loss: 1.0524\n",
            "Epoch 3, Sample 15111: Loss: 0.1397\n",
            "Epoch 3, Sample 15112: Loss: 0.0005\n",
            "Epoch 3, Sample 15113: Loss: 0.2044\n",
            "Epoch 3, Sample 15114: Loss: 1.8616\n",
            "Epoch 3, Sample 15115: Loss: 3.5504\n",
            "Epoch 3, Sample 15116: Loss: 0.5636\n",
            "Epoch 3, Sample 15117: Loss: 0.3441\n",
            "Epoch 3, Sample 15118: Loss: 1.0688\n",
            "Epoch 3, Sample 15119: Loss: 0.1170\n",
            "Epoch 3, Sample 15120: Loss: 1.0524\n",
            "Epoch 3, Sample 15121: Loss: 1.0524\n",
            "Epoch 3, Sample 15122: Loss: 0.0018\n",
            "Epoch 3, Sample 15123: Loss: 0.1627\n",
            "Epoch 3, Sample 15124: Loss: 0.2778\n",
            "Epoch 3, Sample 15125: Loss: 0.0630\n",
            "Epoch 3, Sample 15126: Loss: 0.0466\n",
            "Epoch 3, Sample 15127: Loss: 2.7989\n",
            "Epoch 3, Sample 15128: Loss: 0.2044\n",
            "Epoch 3, Sample 15129: Loss: 0.2034\n",
            "Epoch 3, Sample 15130: Loss: 0.4799\n",
            "Epoch 3, Sample 15131: Loss: 0.2759\n",
            "Epoch 3, Sample 15132: Loss: 0.1225\n",
            "Epoch 3, Sample 15133: Loss: 7.3306\n",
            "Epoch 3, Sample 15134: Loss: 0.0001\n",
            "Epoch 3, Sample 15135: Loss: 0.2086\n",
            "Epoch 3, Sample 15136: Loss: 0.2962\n",
            "Epoch 3, Sample 15137: Loss: 0.3872\n",
            "Epoch 3, Sample 15138: Loss: 0.1250\n",
            "Epoch 3, Sample 15139: Loss: 1.0524\n",
            "Epoch 3, Sample 15140: Loss: 0.3568\n",
            "Epoch 3, Sample 15141: Loss: 0.2044\n",
            "Epoch 3, Sample 15142: Loss: 1.0524\n",
            "Epoch 3, Sample 15143: Loss: 0.0023\n",
            "Epoch 3, Sample 15144: Loss: 0.0001\n",
            "Epoch 3, Sample 15145: Loss: 0.0026\n",
            "Epoch 3, Sample 15146: Loss: 1.0524\n",
            "Epoch 3, Sample 15147: Loss: 0.0026\n",
            "Epoch 3, Sample 15148: Loss: 0.6092\n",
            "Epoch 3, Sample 15149: Loss: 9.1485\n",
            "Epoch 3, Sample 15150: Loss: 1.5597\n",
            "Epoch 3, Sample 15151: Loss: 0.7036\n",
            "Epoch 3, Sample 15152: Loss: 0.5078\n",
            "Epoch 3, Sample 15153: Loss: 0.0625\n",
            "Epoch 3, Sample 15154: Loss: 0.1114\n",
            "Epoch 3, Sample 15155: Loss: 0.7036\n",
            "Epoch 3, Sample 15156: Loss: 0.0062\n",
            "Epoch 3, Sample 15157: Loss: 0.1252\n",
            "Epoch 3, Sample 15158: Loss: 0.0150\n",
            "Epoch 3, Sample 15159: Loss: 0.0476\n",
            "Epoch 3, Sample 15160: Loss: 6.9441\n",
            "Epoch 3, Sample 15161: Loss: 0.0258\n",
            "Epoch 3, Sample 15162: Loss: 0.4930\n",
            "Epoch 3, Sample 15163: Loss: 1.0524\n",
            "Epoch 3, Sample 15164: Loss: 1.9213\n",
            "Epoch 3, Sample 15165: Loss: 0.4588\n",
            "Epoch 3, Sample 15166: Loss: 0.1246\n",
            "Epoch 3, Sample 15167: Loss: 0.2759\n",
            "Epoch 3, Sample 15168: Loss: 0.2941\n",
            "Epoch 3, Sample 15169: Loss: 0.1924\n",
            "Epoch 3, Sample 15170: Loss: 0.5858\n",
            "Epoch 3, Sample 15171: Loss: 0.0000\n",
            "Epoch 3, Sample 15172: Loss: 0.0027\n",
            "Epoch 3, Sample 15173: Loss: 3.5504\n",
            "Epoch 3, Sample 15174: Loss: 0.0001\n",
            "Epoch 3, Sample 15175: Loss: 0.1523\n",
            "Epoch 3, Sample 15176: Loss: 0.3367\n",
            "Epoch 3, Sample 15177: Loss: 1.0524\n",
            "Epoch 3, Sample 15178: Loss: 0.3399\n",
            "Epoch 3, Sample 15179: Loss: 0.4032\n",
            "Epoch 3, Sample 15180: Loss: 0.1238\n",
            "Epoch 3, Sample 15181: Loss: 0.2034\n",
            "Epoch 3, Sample 15182: Loss: 0.1170\n",
            "Epoch 3, Sample 15183: Loss: 0.0018\n",
            "Epoch 3, Sample 15184: Loss: 0.6990\n",
            "Epoch 3, Sample 15185: Loss: 0.0212\n",
            "Epoch 3, Sample 15186: Loss: 0.4799\n",
            "Epoch 3, Sample 15187: Loss: 0.2494\n",
            "Epoch 3, Sample 15188: Loss: 0.1248\n",
            "Epoch 3, Sample 15189: Loss: 2.1901\n",
            "Epoch 3, Sample 15190: Loss: 1.0530\n",
            "Epoch 3, Sample 15191: Loss: 0.2044\n",
            "Epoch 3, Sample 15192: Loss: 0.2032\n",
            "Epoch 3, Sample 15193: Loss: 0.2032\n",
            "Epoch 3, Sample 15194: Loss: 0.2219\n",
            "Epoch 3, Sample 15195: Loss: 41.5700\n",
            "Epoch 3, Sample 15196: Loss: 0.4996\n",
            "Epoch 3, Sample 15197: Loss: 0.6304\n",
            "Epoch 3, Sample 15198: Loss: 0.0915\n",
            "Epoch 3, Sample 15199: Loss: 0.1170\n",
            "Epoch 3, Sample 15200: Loss: 1.0530\n",
            "Epoch 3, Sample 15201: Loss: 0.0049\n",
            "Epoch 3, Sample 15202: Loss: 0.1248\n",
            "Epoch 3, Sample 15203: Loss: 0.2132\n",
            "Epoch 3, Sample 15204: Loss: 0.2034\n",
            "Epoch 3, Sample 15205: Loss: 0.0915\n",
            "Epoch 3, Sample 15206: Loss: 0.0915\n",
            "Epoch 3, Sample 15207: Loss: 0.2219\n",
            "Epoch 3, Sample 15208: Loss: 0.1250\n",
            "Epoch 3, Sample 15209: Loss: 4.5881\n",
            "Epoch 3, Sample 15210: Loss: 0.0084\n",
            "Epoch 3, Sample 15211: Loss: 0.3949\n",
            "Epoch 3, Sample 15212: Loss: 6.2039\n",
            "Epoch 3, Sample 15213: Loss: 0.2112\n",
            "Epoch 3, Sample 15214: Loss: 0.3399\n",
            "Epoch 3, Sample 15215: Loss: 1.0524\n",
            "Epoch 3, Sample 15216: Loss: 0.3477\n",
            "Epoch 3, Sample 15217: Loss: 0.0415\n",
            "Epoch 3, Sample 15218: Loss: 5.8208\n",
            "Epoch 3, Sample 15219: Loss: 3.6056\n",
            "Epoch 3, Sample 15220: Loss: 1.0359\n",
            "Epoch 3, Sample 15221: Loss: 0.2759\n",
            "Epoch 3, Sample 15222: Loss: 0.3399\n",
            "Epoch 3, Sample 15223: Loss: 2.7331\n",
            "Epoch 3, Sample 15224: Loss: 0.2034\n",
            "Epoch 3, Sample 15225: Loss: 0.0630\n",
            "Epoch 3, Sample 15226: Loss: 0.0212\n",
            "Epoch 3, Sample 15227: Loss: 1.2192\n",
            "Epoch 3, Sample 15228: Loss: 1.0524\n",
            "Epoch 3, Sample 15229: Loss: 0.7036\n",
            "Epoch 3, Sample 15230: Loss: 0.2034\n",
            "Epoch 3, Sample 15231: Loss: 0.1559\n",
            "Epoch 3, Sample 15232: Loss: 0.0802\n",
            "Epoch 3, Sample 15233: Loss: 0.0938\n",
            "Epoch 3, Sample 15234: Loss: 0.1817\n",
            "Epoch 3, Sample 15235: Loss: 1.0524\n",
            "Epoch 3, Sample 15236: Loss: 0.2452\n",
            "Epoch 3, Sample 15237: Loss: 0.1248\n",
            "Epoch 3, Sample 15238: Loss: 1.0524\n",
            "Epoch 3, Sample 15239: Loss: 0.3949\n",
            "Epoch 3, Sample 15240: Loss: 0.0751\n",
            "Epoch 3, Sample 15241: Loss: 0.4607\n",
            "Epoch 3, Sample 15242: Loss: 0.3441\n",
            "Epoch 3, Sample 15243: Loss: 1.0524\n",
            "Epoch 3, Sample 15244: Loss: 0.1472\n",
            "Epoch 3, Sample 15245: Loss: 0.1170\n",
            "Epoch 3, Sample 15246: Loss: 0.7036\n",
            "Epoch 3, Sample 15247: Loss: 1.5597\n",
            "Epoch 3, Sample 15248: Loss: 0.2032\n",
            "Epoch 3, Sample 15249: Loss: 0.8951\n",
            "Epoch 3, Sample 15250: Loss: 1.0524\n",
            "Epoch 3, Sample 15251: Loss: 0.2034\n",
            "Epoch 3, Sample 15252: Loss: 0.0042\n",
            "Epoch 3, Sample 15253: Loss: 0.0026\n",
            "Epoch 3, Sample 15254: Loss: 0.6139\n",
            "Epoch 3, Sample 15255: Loss: 1.9820\n",
            "Epoch 3, Sample 15256: Loss: 1.0155\n",
            "Epoch 3, Sample 15257: Loss: 0.0067\n",
            "Epoch 3, Sample 15258: Loss: 0.1039\n",
            "Epoch 3, Sample 15259: Loss: 0.2759\n",
            "Epoch 3, Sample 15260: Loss: 0.5858\n",
            "Epoch 3, Sample 15261: Loss: 0.3441\n",
            "Epoch 3, Sample 15262: Loss: 1.0524\n",
            "Epoch 3, Sample 15263: Loss: 1.0530\n",
            "Epoch 3, Sample 15264: Loss: 0.4611\n",
            "Epoch 3, Sample 15265: Loss: 0.2759\n",
            "Epoch 3, Sample 15266: Loss: 0.0337\n",
            "Epoch 3, Sample 15267: Loss: 0.5636\n",
            "Epoch 3, Sample 15268: Loss: 0.2032\n",
            "Epoch 3, Sample 15269: Loss: 0.0682\n",
            "Epoch 3, Sample 15270: Loss: 0.1248\n",
            "Epoch 3, Sample 15271: Loss: 0.0026\n",
            "Epoch 3, Sample 15272: Loss: 1.0524\n",
            "Epoch 3, Sample 15273: Loss: 0.0000\n",
            "Epoch 3, Sample 15274: Loss: 0.2032\n",
            "Epoch 3, Sample 15275: Loss: 3.8563\n",
            "Epoch 3, Sample 15276: Loss: 0.1170\n",
            "Epoch 3, Sample 15277: Loss: 2.0351\n",
            "Epoch 3, Sample 15278: Loss: 0.1968\n",
            "Epoch 3, Sample 15279: Loss: 0.1264\n",
            "Epoch 3, Sample 15280: Loss: 0.9785\n",
            "Epoch 3, Sample 15281: Loss: 1.1569\n",
            "Epoch 3, Sample 15282: Loss: 0.0945\n",
            "Epoch 3, Sample 15283: Loss: 0.3418\n",
            "Epoch 3, Sample 15284: Loss: 1.5597\n",
            "Epoch 3, Sample 15285: Loss: 0.9780\n",
            "Epoch 3, Sample 15286: Loss: 0.0270\n",
            "Epoch 3, Sample 15287: Loss: 1.5597\n",
            "Epoch 3, Sample 15288: Loss: 0.3441\n",
            "Epoch 3, Sample 15289: Loss: 0.2044\n",
            "Epoch 3, Sample 15290: Loss: 3.1802\n",
            "Epoch 3, Sample 15291: Loss: 0.2034\n",
            "Epoch 3, Sample 15292: Loss: 0.2034\n",
            "Epoch 3, Sample 15293: Loss: 0.4799\n",
            "Epoch 3, Sample 15294: Loss: 0.1036\n",
            "Epoch 3, Sample 15295: Loss: 0.0025\n",
            "Epoch 3, Sample 15296: Loss: 0.2036\n",
            "Epoch 3, Sample 15297: Loss: 0.1397\n",
            "Epoch 3, Sample 15298: Loss: 0.1170\n",
            "Epoch 3, Sample 15299: Loss: 0.9785\n",
            "Epoch 3, Sample 15300: Loss: 0.1246\n",
            "Epoch 3, Sample 15301: Loss: 2.8489\n",
            "Epoch 3, Sample 15302: Loss: 0.0170\n",
            "Epoch 3, Sample 15303: Loss: 0.0001\n",
            "Epoch 3, Sample 15304: Loss: 1.2845\n",
            "Epoch 3, Sample 15305: Loss: 0.1040\n",
            "Epoch 3, Sample 15306: Loss: 0.3399\n",
            "Epoch 3, Sample 15307: Loss: 0.0626\n",
            "Epoch 3, Sample 15308: Loss: 0.1465\n",
            "Epoch 3, Sample 15309: Loss: 0.0819\n",
            "Epoch 3, Sample 15310: Loss: 10.3220\n",
            "Epoch 3, Sample 15311: Loss: 0.0466\n",
            "Epoch 3, Sample 15312: Loss: 1.0524\n",
            "Epoch 3, Sample 15313: Loss: 0.2639\n",
            "Epoch 3, Sample 15314: Loss: 0.3288\n",
            "Epoch 3, Sample 15315: Loss: 0.3477\n",
            "Epoch 3, Sample 15316: Loss: 0.6990\n",
            "Epoch 3, Sample 15317: Loss: 0.2044\n",
            "Epoch 3, Sample 15318: Loss: 1.5597\n",
            "Epoch 3, Sample 15319: Loss: 1.4537\n",
            "Epoch 3, Sample 15320: Loss: 1.0524\n",
            "Epoch 3, Sample 15321: Loss: 0.5799\n",
            "Epoch 3, Sample 15322: Loss: 0.4996\n",
            "Epoch 3, Sample 15323: Loss: 1.0155\n",
            "Epoch 3, Sample 15324: Loss: 0.0802\n",
            "Epoch 3, Sample 15325: Loss: 1.0524\n",
            "Epoch 3, Sample 15326: Loss: 0.0082\n",
            "Epoch 3, Sample 15327: Loss: 0.2032\n",
            "Epoch 3, Sample 15328: Loss: 0.3399\n",
            "Epoch 3, Sample 15329: Loss: 1.0524\n",
            "Epoch 3, Sample 15330: Loss: 1.0524\n",
            "Epoch 3, Sample 15331: Loss: 0.2034\n",
            "Epoch 3, Sample 15332: Loss: 3.2314\n",
            "Epoch 3, Sample 15333: Loss: 0.1546\n",
            "Epoch 3, Sample 15334: Loss: 0.1005\n",
            "Epoch 3, Sample 15335: Loss: 0.0018\n",
            "Epoch 3, Sample 15336: Loss: 0.0001\n",
            "Epoch 3, Sample 15337: Loss: 14.5870\n",
            "Epoch 3, Sample 15338: Loss: 0.0630\n",
            "Epoch 3, Sample 15339: Loss: 0.1039\n",
            "Epoch 3, Sample 15340: Loss: 0.0460\n",
            "Epoch 3, Sample 15341: Loss: 0.0270\n",
            "Epoch 3, Sample 15342: Loss: 0.7203\n",
            "Epoch 3, Sample 15343: Loss: 0.0640\n",
            "Epoch 3, Sample 15344: Loss: 0.7036\n",
            "Epoch 3, Sample 15345: Loss: 1.0524\n",
            "Epoch 3, Sample 15346: Loss: 1.0359\n",
            "Epoch 3, Sample 15347: Loss: 0.0426\n",
            "Epoch 3, Sample 15348: Loss: 3.7714\n",
            "Epoch 3, Sample 15349: Loss: 0.1246\n",
            "Epoch 3, Sample 15350: Loss: 0.2219\n",
            "Epoch 3, Sample 15351: Loss: 0.2036\n",
            "Epoch 3, Sample 15352: Loss: 5.8208\n",
            "Epoch 3, Sample 15353: Loss: 0.1559\n",
            "Epoch 3, Sample 15354: Loss: 1.0524\n",
            "Epoch 3, Sample 15355: Loss: 0.3949\n",
            "Epoch 3, Sample 15356: Loss: 0.1170\n",
            "Epoch 3, Sample 15357: Loss: 5.1724\n",
            "Epoch 3, Sample 15358: Loss: 0.0286\n",
            "Epoch 3, Sample 15359: Loss: 0.3399\n",
            "Epoch 3, Sample 15360: Loss: 7.8073\n",
            "Epoch 3, Sample 15361: Loss: 0.0001\n",
            "Epoch 3, Sample 15362: Loss: 0.3399\n",
            "Epoch 3, Sample 15363: Loss: 4.2335\n",
            "Epoch 3, Sample 15364: Loss: 1.5542\n",
            "Epoch 3, Sample 15365: Loss: 0.6990\n",
            "Epoch 3, Sample 15366: Loss: 1.6326\n",
            "Epoch 3, Sample 15367: Loss: 0.2759\n",
            "Epoch 3, Sample 15368: Loss: 0.3598\n",
            "Epoch 3, Sample 15369: Loss: 0.0915\n",
            "Epoch 3, Sample 15370: Loss: 0.7036\n",
            "Epoch 3, Sample 15371: Loss: 0.1246\n",
            "Epoch 3, Sample 15372: Loss: 3.6601\n",
            "Epoch 3, Sample 15373: Loss: 1.0530\n",
            "Epoch 3, Sample 15374: Loss: 0.2044\n",
            "Epoch 3, Sample 15375: Loss: 0.2044\n",
            "Epoch 3, Sample 15376: Loss: 0.0532\n",
            "Epoch 3, Sample 15377: Loss: 27.2501\n",
            "Epoch 3, Sample 15378: Loss: 0.6990\n",
            "Epoch 3, Sample 15379: Loss: 0.2044\n",
            "Epoch 3, Sample 15380: Loss: 0.1989\n",
            "Epoch 3, Sample 15381: Loss: 1.0524\n",
            "Epoch 3, Sample 15382: Loss: 0.5058\n",
            "Epoch 3, Sample 15383: Loss: 0.0005\n",
            "Epoch 3, Sample 15384: Loss: 0.3367\n",
            "Epoch 3, Sample 15385: Loss: 0.5000\n",
            "Epoch 3, Sample 15386: Loss: 0.9367\n",
            "Epoch 3, Sample 15387: Loss: 0.0026\n",
            "Epoch 3, Sample 15388: Loss: 18.7901\n",
            "Epoch 3, Sample 15389: Loss: 0.0063\n",
            "Epoch 3, Sample 15390: Loss: 1.0524\n",
            "Epoch 3, Sample 15391: Loss: 6.3986\n",
            "Epoch 3, Sample 15392: Loss: 0.4799\n",
            "Epoch 3, Sample 15393: Loss: 0.2778\n",
            "Epoch 3, Sample 15394: Loss: 0.0630\n",
            "Epoch 3, Sample 15395: Loss: 0.0063\n",
            "Epoch 3, Sample 15396: Loss: 0.0230\n",
            "Epoch 3, Sample 15397: Loss: 0.6092\n",
            "Epoch 3, Sample 15398: Loss: 0.0039\n",
            "Epoch 3, Sample 15399: Loss: 0.4996\n",
            "Epoch 3, Sample 15400: Loss: 0.5636\n",
            "Epoch 3, Sample 15401: Loss: 1.2845\n",
            "Epoch 3, Sample 15402: Loss: 1.0530\n",
            "Epoch 3, Sample 15403: Loss: 0.0001\n",
            "Epoch 3, Sample 15404: Loss: 0.0026\n",
            "Epoch 3, Sample 15405: Loss: 1.5597\n",
            "Epoch 3, Sample 15406: Loss: 0.5000\n",
            "Epoch 3, Sample 15407: Loss: 0.0838\n",
            "Epoch 3, Sample 15408: Loss: 0.0460\n",
            "Epoch 3, Sample 15409: Loss: 0.0001\n",
            "Epoch 3, Sample 15410: Loss: 0.1171\n",
            "Epoch 3, Sample 15411: Loss: 2.8294\n",
            "Epoch 3, Sample 15412: Loss: 0.7036\n",
            "Epoch 3, Sample 15413: Loss: 0.7453\n",
            "Epoch 3, Sample 15414: Loss: 0.2032\n",
            "Epoch 3, Sample 15415: Loss: 1.0524\n",
            "Epoch 3, Sample 15416: Loss: 0.7486\n",
            "Epoch 3, Sample 15417: Loss: 0.1170\n",
            "Epoch 3, Sample 15418: Loss: 0.5799\n",
            "Epoch 3, Sample 15419: Loss: 0.0026\n",
            "Epoch 3, Sample 15420: Loss: 0.5078\n",
            "Epoch 3, Sample 15421: Loss: 3.9991\n",
            "Epoch 3, Sample 15422: Loss: 1.0524\n",
            "Epoch 3, Sample 15423: Loss: 0.3062\n",
            "Epoch 3, Sample 15424: Loss: 0.0270\n",
            "Epoch 3, Sample 15425: Loss: 0.2032\n",
            "Epoch 3, Sample 15426: Loss: 0.0018\n",
            "Epoch 3, Sample 15427: Loss: 1.5893\n",
            "Epoch 3, Sample 15428: Loss: 1.5597\n",
            "Epoch 3, Sample 15429: Loss: 0.2329\n",
            "Epoch 3, Sample 15430: Loss: 1.0359\n",
            "Epoch 3, Sample 15431: Loss: 0.0013\n",
            "Epoch 3, Sample 15432: Loss: 0.4032\n",
            "Epoch 3, Sample 15433: Loss: 0.0915\n",
            "Epoch 3, Sample 15434: Loss: 0.2639\n",
            "Epoch 3, Sample 15435: Loss: 0.1559\n",
            "Epoch 3, Sample 15436: Loss: 0.0286\n",
            "Epoch 3, Sample 15437: Loss: 1.7843\n",
            "Epoch 3, Sample 15438: Loss: 0.8951\n",
            "Epoch 3, Sample 15439: Loss: 0.1588\n",
            "Epoch 3, Sample 15440: Loss: 0.1326\n",
            "Epoch 3, Sample 15441: Loss: 1.0524\n",
            "Epoch 3, Sample 15442: Loss: 0.5858\n",
            "Epoch 3, Sample 15443: Loss: 0.1248\n",
            "Epoch 3, Sample 15444: Loss: 0.2639\n",
            "Epoch 3, Sample 15445: Loss: 1.5597\n",
            "Epoch 3, Sample 15446: Loss: 1.0530\n",
            "Epoch 3, Sample 15447: Loss: 6.9441\n",
            "Epoch 3, Sample 15448: Loss: 0.2044\n",
            "Epoch 3, Sample 15449: Loss: 0.1170\n",
            "Epoch 3, Sample 15450: Loss: 0.0026\n",
            "Epoch 3, Sample 15451: Loss: 0.3399\n",
            "Epoch 3, Sample 15452: Loss: 0.3332\n",
            "Epoch 3, Sample 15453: Loss: 0.0625\n",
            "Epoch 3, Sample 15454: Loss: 0.7036\n",
            "Epoch 3, Sample 15455: Loss: 1.0359\n",
            "Epoch 3, Sample 15456: Loss: 1.4884\n",
            "Epoch 3, Sample 15457: Loss: 2.7331\n",
            "Epoch 3, Sample 15458: Loss: 2.7331\n",
            "Epoch 3, Sample 15459: Loss: 0.7036\n",
            "Epoch 3, Sample 15460: Loss: 9.6835\n",
            "Epoch 3, Sample 15461: Loss: 0.0630\n",
            "Epoch 3, Sample 15462: Loss: 0.0062\n",
            "Epoch 3, Sample 15463: Loss: 1.7843\n",
            "Epoch 3, Sample 15464: Loss: 0.3450\n",
            "Epoch 3, Sample 15465: Loss: 1.2553\n",
            "Epoch 3, Sample 15466: Loss: 0.0630\n",
            "Epoch 3, Sample 15467: Loss: 0.2044\n",
            "Epoch 3, Sample 15468: Loss: 0.5058\n",
            "Epoch 3, Sample 15469: Loss: 0.1248\n",
            "Epoch 3, Sample 15470: Loss: 0.2034\n",
            "Epoch 3, Sample 15471: Loss: 0.1417\n",
            "Epoch 3, Sample 15472: Loss: 0.4930\n",
            "Epoch 3, Sample 15473: Loss: 0.1559\n",
            "Epoch 3, Sample 15474: Loss: 2.8294\n",
            "Epoch 3, Sample 15475: Loss: 0.8951\n",
            "Epoch 3, Sample 15476: Loss: 0.0026\n",
            "Epoch 3, Sample 15477: Loss: 0.3584\n",
            "Epoch 3, Sample 15478: Loss: 1.0155\n",
            "Epoch 3, Sample 15479: Loss: 0.0220\n",
            "Epoch 3, Sample 15480: Loss: 0.5003\n",
            "Epoch 3, Sample 15481: Loss: 1.0155\n",
            "Epoch 3, Sample 15482: Loss: 0.7036\n",
            "Epoch 3, Sample 15483: Loss: 0.0313\n",
            "Epoch 3, Sample 15484: Loss: 0.6867\n",
            "Epoch 3, Sample 15485: Loss: 0.1399\n",
            "Epoch 3, Sample 15486: Loss: 0.3332\n",
            "Epoch 3, Sample 15487: Loss: 0.0640\n",
            "Epoch 3, Sample 15488: Loss: 1.3405\n",
            "Epoch 3, Sample 15489: Loss: 0.3418\n",
            "Epoch 3, Sample 15490: Loss: 1.5597\n",
            "Epoch 3, Sample 15491: Loss: 1.0524\n",
            "Epoch 3, Sample 15492: Loss: 1.0227\n",
            "Epoch 3, Sample 15493: Loss: 0.5000\n",
            "Epoch 3, Sample 15494: Loss: 0.5871\n",
            "Epoch 3, Sample 15495: Loss: 0.1225\n",
            "Epoch 3, Sample 15496: Loss: 0.0022\n",
            "Epoch 3, Sample 15497: Loss: 0.2355\n",
            "Epoch 3, Sample 15498: Loss: 0.1401\n",
            "Epoch 3, Sample 15499: Loss: 0.0018\n",
            "Epoch 3, Sample 15500: Loss: 1.0524\n",
            "Epoch 3, Sample 15501: Loss: 0.0001\n",
            "Epoch 3, Sample 15502: Loss: 0.7453\n",
            "Epoch 3, Sample 15503: Loss: 0.9780\n",
            "Epoch 3, Sample 15504: Loss: 0.2759\n",
            "Epoch 3, Sample 15505: Loss: 3.6601\n",
            "Epoch 3, Sample 15506: Loss: 0.1335\n",
            "Epoch 3, Sample 15507: Loss: 0.0270\n",
            "Epoch 3, Sample 15508: Loss: 0.1246\n",
            "Epoch 3, Sample 15509: Loss: 0.9367\n",
            "Epoch 3, Sample 15510: Loss: 1.0524\n",
            "Epoch 3, Sample 15511: Loss: 0.0018\n",
            "Epoch 3, Sample 15512: Loss: 0.2832\n",
            "Epoch 3, Sample 15513: Loss: 0.7036\n",
            "Epoch 3, Sample 15514: Loss: 10.5084\n",
            "Epoch 3, Sample 15515: Loss: 0.0364\n",
            "Epoch 3, Sample 15516: Loss: 0.0018\n",
            "Epoch 3, Sample 15517: Loss: 0.3441\n",
            "Epoch 3, Sample 15518: Loss: 0.2832\n",
            "Epoch 3, Sample 15519: Loss: 0.2175\n",
            "Epoch 3, Sample 15520: Loss: 0.2032\n",
            "Epoch 3, Sample 15521: Loss: 0.0240\n",
            "Epoch 3, Sample 15522: Loss: 3.5504\n",
            "Epoch 3, Sample 15523: Loss: 0.7036\n",
            "Epoch 3, Sample 15524: Loss: 0.3441\n",
            "Epoch 3, Sample 15525: Loss: 0.0212\n",
            "Epoch 3, Sample 15526: Loss: 1.0530\n",
            "Epoch 3, Sample 15527: Loss: 0.0212\n",
            "Epoch 3, Sample 15528: Loss: 0.1248\n",
            "Epoch 3, Sample 15529: Loss: 0.7036\n",
            "Epoch 3, Sample 15530: Loss: 2.2981\n",
            "Epoch 3, Sample 15531: Loss: 0.2704\n",
            "Epoch 3, Sample 15532: Loss: 2.0642\n",
            "Epoch 3, Sample 15533: Loss: 0.1588\n",
            "Epoch 3, Sample 15534: Loss: 0.3949\n",
            "Epoch 3, Sample 15535: Loss: 2.1901\n",
            "Epoch 3, Sample 15536: Loss: 0.1397\n",
            "Epoch 3, Sample 15537: Loss: 0.0026\n",
            "Epoch 3, Sample 15538: Loss: 1.0524\n",
            "Epoch 3, Sample 15539: Loss: 0.1546\n",
            "Epoch 3, Sample 15540: Loss: 0.0501\n",
            "Epoch 3, Sample 15541: Loss: 0.2851\n",
            "Epoch 3, Sample 15542: Loss: 0.3402\n",
            "Epoch 3, Sample 15543: Loss: 0.2759\n",
            "Epoch 3, Sample 15544: Loss: 0.2044\n",
            "Epoch 3, Sample 15545: Loss: 0.9367\n",
            "Epoch 3, Sample 15546: Loss: 0.2639\n",
            "Epoch 3, Sample 15547: Loss: 1.0524\n",
            "Epoch 3, Sample 15548: Loss: 0.1250\n",
            "Epoch 3, Sample 15549: Loss: 9.7728\n",
            "Epoch 3, Sample 15550: Loss: 0.0270\n",
            "Epoch 3, Sample 15551: Loss: 0.2962\n",
            "Epoch 3, Sample 15552: Loss: 0.0005\n",
            "Epoch 3, Sample 15553: Loss: 0.9780\n",
            "Epoch 3, Sample 15554: Loss: 0.8951\n",
            "Epoch 3, Sample 15555: Loss: 0.2759\n",
            "Epoch 3, Sample 15556: Loss: 0.0938\n",
            "Epoch 3, Sample 15557: Loss: 1.0266\n",
            "Epoch 3, Sample 15558: Loss: 0.0026\n",
            "Epoch 3, Sample 15559: Loss: 2.7331\n",
            "Epoch 3, Sample 15560: Loss: 1.0524\n",
            "Epoch 3, Sample 15561: Loss: 0.0145\n",
            "Epoch 3, Sample 15562: Loss: 0.3441\n",
            "Epoch 3, Sample 15563: Loss: 0.0026\n",
            "Epoch 3, Sample 15564: Loss: 0.1250\n",
            "Epoch 3, Sample 15565: Loss: 1.0524\n",
            "Epoch 3, Sample 15566: Loss: 0.1559\n",
            "Epoch 3, Sample 15567: Loss: 1.0359\n",
            "Epoch 3, Sample 15568: Loss: 0.2032\n",
            "Epoch 3, Sample 15569: Loss: 0.0915\n",
            "Epoch 3, Sample 15570: Loss: 0.2759\n",
            "Epoch 3, Sample 15571: Loss: 1.0524\n",
            "Epoch 3, Sample 15572: Loss: 0.3758\n",
            "Epoch 3, Sample 15573: Loss: 0.6139\n",
            "Epoch 3, Sample 15574: Loss: 1.0524\n",
            "Epoch 3, Sample 15575: Loss: 0.0018\n",
            "Epoch 3, Sample 15576: Loss: 1.1789\n",
            "Epoch 3, Sample 15577: Loss: 0.6190\n",
            "Epoch 3, Sample 15578: Loss: 0.1248\n",
            "Epoch 3, Sample 15579: Loss: 1.0524\n",
            "Epoch 3, Sample 15580: Loss: 0.2044\n",
            "Epoch 3, Sample 15581: Loss: 2.7331\n",
            "Epoch 3, Sample 15582: Loss: 0.2759\n",
            "Epoch 3, Sample 15583: Loss: 0.0630\n",
            "Epoch 3, Sample 15584: Loss: 0.1170\n",
            "Epoch 3, Sample 15585: Loss: 0.0001\n",
            "Epoch 3, Sample 15586: Loss: 0.2036\n",
            "Epoch 3, Sample 15587: Loss: 0.0018\n",
            "Epoch 3, Sample 15588: Loss: 1.0530\n",
            "Epoch 3, Sample 15589: Loss: 1.0524\n",
            "Epoch 3, Sample 15590: Loss: 4.3531\n",
            "Epoch 3, Sample 15591: Loss: 0.1248\n",
            "Epoch 3, Sample 15592: Loss: 0.0505\n",
            "Epoch 3, Sample 15593: Loss: 0.0207\n",
            "Epoch 3, Sample 15594: Loss: 0.4611\n",
            "Epoch 3, Sample 15595: Loss: 0.0630\n",
            "Epoch 3, Sample 15596: Loss: 1.0524\n",
            "Epoch 3, Sample 15597: Loss: 3.5504\n",
            "Epoch 3, Sample 15598: Loss: 0.9780\n",
            "Epoch 3, Sample 15599: Loss: 0.1248\n",
            "Epoch 3, Sample 15600: Loss: 0.2879\n",
            "Epoch 3, Sample 15601: Loss: 0.2832\n",
            "Epoch 3, Sample 15602: Loss: 0.1482\n",
            "Epoch 3, Sample 15603: Loss: 0.1250\n",
            "Epoch 3, Sample 15604: Loss: 0.9651\n",
            "Epoch 3, Sample 15605: Loss: 0.3247\n",
            "Epoch 3, Sample 15606: Loss: 1.0524\n",
            "Epoch 3, Sample 15607: Loss: 0.1924\n",
            "Epoch 3, Sample 15608: Loss: 0.0532\n",
            "Epoch 3, Sample 15609: Loss: 0.0026\n",
            "Epoch 3, Sample 15610: Loss: 0.4466\n",
            "Epoch 3, Sample 15611: Loss: 1.0524\n",
            "Epoch 3, Sample 15612: Loss: 0.7036\n",
            "Epoch 3, Sample 15613: Loss: 0.2044\n",
            "Epoch 3, Sample 15614: Loss: 0.4996\n",
            "Epoch 3, Sample 15615: Loss: 0.2034\n",
            "Epoch 3, Sample 15616: Loss: 0.4102\n",
            "Epoch 3, Sample 15617: Loss: 0.2639\n",
            "Epoch 3, Sample 15618: Loss: 0.6092\n",
            "Epoch 3, Sample 15619: Loss: 0.2044\n",
            "Epoch 3, Sample 15620: Loss: 0.2032\n",
            "Epoch 3, Sample 15621: Loss: 0.0838\n",
            "Epoch 3, Sample 15622: Loss: 0.1627\n",
            "Epoch 3, Sample 15623: Loss: 0.2639\n",
            "Epoch 3, Sample 15624: Loss: 0.5871\n",
            "Epoch 3, Sample 15625: Loss: 5.1063\n",
            "Epoch 3, Sample 15626: Loss: 0.3399\n",
            "Epoch 3, Sample 15627: Loss: 1.0524\n",
            "Epoch 3, Sample 15628: Loss: 0.0026\n",
            "Epoch 3, Sample 15629: Loss: 0.0026\n",
            "Epoch 3, Sample 15630: Loss: 0.1170\n",
            "Epoch 3, Sample 15631: Loss: 0.1989\n",
            "Epoch 3, Sample 15632: Loss: 0.1559\n",
            "Epoch 3, Sample 15633: Loss: 0.4611\n",
            "Epoch 3, Sample 15634: Loss: 0.4663\n",
            "Epoch 3, Sample 15635: Loss: 0.2032\n",
            "Epoch 3, Sample 15636: Loss: 0.2759\n",
            "Epoch 3, Sample 15637: Loss: 0.1337\n",
            "Epoch 3, Sample 15638: Loss: 0.5989\n",
            "Epoch 3, Sample 15639: Loss: 0.4930\n",
            "Epoch 3, Sample 15640: Loss: 0.2034\n",
            "Epoch 3, Sample 15641: Loss: 1.0524\n",
            "Epoch 3, Sample 15642: Loss: 0.1559\n",
            "Epoch 3, Sample 15643: Loss: 0.5019\n",
            "Epoch 3, Sample 15644: Loss: 1.0155\n",
            "Epoch 3, Sample 15645: Loss: 0.0145\n",
            "Epoch 3, Sample 15646: Loss: 0.3399\n",
            "Epoch 3, Sample 15647: Loss: 0.0938\n",
            "Epoch 3, Sample 15648: Loss: 2.8693\n",
            "Epoch 3, Sample 15649: Loss: 0.1170\n",
            "Epoch 3, Sample 15650: Loss: 0.7036\n",
            "Epoch 3, Sample 15651: Loss: 0.0145\n",
            "Epoch 3, Sample 15652: Loss: 0.7036\n",
            "Epoch 3, Sample 15653: Loss: 0.1170\n",
            "Epoch 3, Sample 15654: Loss: 0.5858\n",
            "Epoch 3, Sample 15655: Loss: 4.7222\n",
            "Epoch 3, Sample 15656: Loss: 0.7036\n",
            "Epoch 3, Sample 15657: Loss: 0.1336\n",
            "Epoch 3, Sample 15658: Loss: 0.0915\n",
            "Epoch 3, Sample 15659: Loss: 0.5000\n",
            "Epoch 3, Sample 15660: Loss: 0.2044\n",
            "Epoch 3, Sample 15661: Loss: 2.7331\n",
            "Epoch 3, Sample 15662: Loss: 0.1248\n",
            "Epoch 3, Sample 15663: Loss: 1.8616\n",
            "Epoch 3, Sample 15664: Loss: 0.4611\n",
            "Epoch 3, Sample 15665: Loss: 2.5454\n",
            "Epoch 3, Sample 15666: Loss: 0.7203\n",
            "Epoch 3, Sample 15667: Loss: 1.0155\n",
            "Epoch 3, Sample 15668: Loss: 1.0266\n",
            "Epoch 3, Sample 15669: Loss: 1.9743\n",
            "Epoch 3, Sample 15670: Loss: 0.0026\n",
            "Epoch 3, Sample 15671: Loss: 0.0972\n",
            "Epoch 3, Sample 15672: Loss: 0.1250\n",
            "Epoch 3, Sample 15673: Loss: 0.2989\n",
            "Epoch 3, Sample 15674: Loss: 0.0025\n",
            "Epoch 3, Sample 15675: Loss: 1.0956\n",
            "Epoch 3, Sample 15676: Loss: 0.4930\n",
            "Epoch 3, Sample 15677: Loss: 1.0524\n",
            "Epoch 3, Sample 15678: Loss: 0.3402\n",
            "Epoch 3, Sample 15679: Loss: 0.2112\n",
            "Epoch 3, Sample 15680: Loss: 1.0524\n",
            "Epoch 3, Sample 15681: Loss: 0.0025\n",
            "Epoch 3, Sample 15682: Loss: 0.3568\n",
            "Epoch 3, Sample 15683: Loss: 0.4611\n",
            "Epoch 3, Sample 15684: Loss: 0.1817\n",
            "Epoch 3, Sample 15685: Loss: 0.1036\n",
            "Epoch 3, Sample 15686: Loss: 0.0027\n",
            "Epoch 3, Sample 15687: Loss: 2.7331\n",
            "Epoch 3, Sample 15688: Loss: 3.2960\n",
            "Epoch 3, Sample 15689: Loss: 3.1294\n",
            "Epoch 3, Sample 15690: Loss: 0.2044\n",
            "Epoch 3, Sample 15691: Loss: 0.1625\n",
            "Epoch 3, Sample 15692: Loss: 0.2044\n",
            "Epoch 3, Sample 15693: Loss: 15.2563\n",
            "Epoch 3, Sample 15694: Loss: 1.0524\n",
            "Epoch 3, Sample 15695: Loss: 0.4550\n",
            "Epoch 3, Sample 15696: Loss: 0.7036\n",
            "Epoch 3, Sample 15697: Loss: 0.7453\n",
            "Epoch 3, Sample 15698: Loss: 0.3399\n",
            "Epoch 3, Sample 15699: Loss: 0.0026\n",
            "Epoch 3, Sample 15700: Loss: 0.0630\n",
            "Epoch 3, Sample 15701: Loss: 0.0026\n",
            "Epoch 3, Sample 15702: Loss: 2.9274\n",
            "Epoch 3, Sample 15703: Loss: 0.3247\n",
            "Epoch 3, Sample 15704: Loss: 0.0625\n",
            "Epoch 3, Sample 15705: Loss: 0.6990\n",
            "Epoch 3, Sample 15706: Loss: 0.3402\n",
            "Epoch 3, Sample 15707: Loss: 1.6326\n",
            "Epoch 3, Sample 15708: Loss: 2.8731\n",
            "Epoch 3, Sample 15709: Loss: 3.6601\n",
            "Epoch 3, Sample 15710: Loss: 0.3441\n",
            "Epoch 3, Sample 15711: Loss: 0.2759\n",
            "Epoch 3, Sample 15712: Loss: 1.8616\n",
            "Epoch 3, Sample 15713: Loss: 2.0351\n",
            "Epoch 3, Sample 15714: Loss: 0.6990\n",
            "Epoch 3, Sample 15715: Loss: 0.3399\n",
            "Epoch 3, Sample 15716: Loss: 3.5504\n",
            "Epoch 3, Sample 15717: Loss: 2.7331\n",
            "Epoch 3, Sample 15718: Loss: 0.1250\n",
            "Epoch 3, Sample 15719: Loss: 0.3805\n",
            "Epoch 3, Sample 15720: Loss: 0.1941\n",
            "Epoch 3, Sample 15721: Loss: 2.1901\n",
            "Epoch 3, Sample 15722: Loss: 0.0306\n",
            "Epoch 3, Sample 15723: Loss: 0.3949\n",
            "Epoch 3, Sample 15724: Loss: 2.9718\n",
            "Epoch 3, Sample 15725: Loss: 0.1246\n",
            "Epoch 3, Sample 15726: Loss: 0.2755\n",
            "Epoch 3, Sample 15727: Loss: 0.3332\n",
            "Epoch 3, Sample 15728: Loss: 1.0155\n",
            "Epoch 3, Sample 15729: Loss: 0.3949\n",
            "Epoch 3, Sample 15730: Loss: 0.6139\n",
            "Epoch 3, Sample 15731: Loss: 0.1559\n",
            "Epoch 3, Sample 15732: Loss: 2.2434\n",
            "Epoch 3, Sample 15733: Loss: 0.3332\n",
            "Epoch 3, Sample 15734: Loss: 0.1170\n",
            "Epoch 3, Sample 15735: Loss: 0.0505\n",
            "Epoch 3, Sample 15736: Loss: 1.5597\n",
            "Epoch 3, Sample 15737: Loss: 0.8951\n",
            "Epoch 3, Sample 15738: Loss: 0.4996\n",
            "Epoch 3, Sample 15739: Loss: 0.2219\n",
            "Epoch 3, Sample 15740: Loss: 0.2032\n",
            "Epoch 3, Sample 15741: Loss: 0.2044\n",
            "Epoch 3, Sample 15742: Loss: 0.4996\n",
            "Epoch 3, Sample 15743: Loss: 0.2219\n",
            "Epoch 3, Sample 15744: Loss: 0.3399\n",
            "Epoch 3, Sample 15745: Loss: 0.0460\n",
            "Epoch 3, Sample 15746: Loss: 0.1559\n",
            "Epoch 3, Sample 15747: Loss: 0.0630\n",
            "Epoch 3, Sample 15748: Loss: 0.1250\n",
            "Epoch 3, Sample 15749: Loss: 0.7486\n",
            "Epoch 3, Sample 15750: Loss: 2.7331\n",
            "Epoch 3, Sample 15751: Loss: 0.2044\n",
            "Epoch 3, Sample 15752: Loss: 0.1559\n",
            "Epoch 3, Sample 15753: Loss: 0.0018\n",
            "Epoch 3, Sample 15754: Loss: 0.0590\n",
            "Epoch 3, Sample 15755: Loss: 0.5000\n",
            "Epoch 3, Sample 15756: Loss: 0.0026\n",
            "Epoch 3, Sample 15757: Loss: 0.9780\n",
            "Epoch 3, Sample 15758: Loss: 0.1246\n",
            "Epoch 3, Sample 15759: Loss: 0.9367\n",
            "Epoch 3, Sample 15760: Loss: 0.1170\n",
            "Epoch 3, Sample 15761: Loss: 0.8141\n",
            "Epoch 3, Sample 15762: Loss: 0.4799\n",
            "Epoch 3, Sample 15763: Loss: 0.7453\n",
            "Epoch 3, Sample 15764: Loss: 0.6990\n",
            "Epoch 3, Sample 15765: Loss: 0.5003\n",
            "Epoch 3, Sample 15766: Loss: 1.0155\n",
            "Epoch 3, Sample 15767: Loss: 1.0524\n",
            "Epoch 3, Sample 15768: Loss: 0.3441\n",
            "Epoch 3, Sample 15769: Loss: 0.1219\n",
            "Epoch 3, Sample 15770: Loss: 0.9780\n",
            "Epoch 3, Sample 15771: Loss: 0.3539\n",
            "Epoch 3, Sample 15772: Loss: 0.6990\n",
            "Epoch 3, Sample 15773: Loss: 0.0042\n",
            "Epoch 3, Sample 15774: Loss: 0.7036\n",
            "Epoch 3, Sample 15775: Loss: 0.5871\n",
            "Epoch 3, Sample 15776: Loss: 0.3949\n",
            "Epoch 3, Sample 15777: Loss: 0.3441\n",
            "Epoch 3, Sample 15778: Loss: 0.0144\n",
            "Epoch 3, Sample 15779: Loss: 1.1569\n",
            "Epoch 3, Sample 15780: Loss: 0.1399\n",
            "Epoch 3, Sample 15781: Loss: 0.7036\n",
            "Epoch 3, Sample 15782: Loss: 0.1968\n",
            "Epoch 3, Sample 15783: Loss: 0.1397\n",
            "Epoch 3, Sample 15784: Loss: 3.6601\n",
            "Epoch 3, Sample 15785: Loss: 0.5003\n",
            "Epoch 3, Sample 15786: Loss: 2.1901\n",
            "Epoch 3, Sample 15787: Loss: 0.2034\n",
            "Epoch 3, Sample 15788: Loss: 1.0530\n",
            "Epoch 3, Sample 15789: Loss: 0.3441\n",
            "Epoch 3, Sample 15790: Loss: 0.1654\n",
            "Epoch 3, Sample 15791: Loss: 0.3399\n",
            "Epoch 3, Sample 15792: Loss: 0.4611\n",
            "Epoch 3, Sample 15793: Loss: 1.0524\n",
            "Epoch 3, Sample 15794: Loss: 1.0524\n",
            "Epoch 3, Sample 15795: Loss: 1.0524\n",
            "Epoch 3, Sample 15796: Loss: 2.7331\n",
            "Epoch 3, Sample 15797: Loss: 0.7486\n",
            "Epoch 3, Sample 15798: Loss: 0.1250\n",
            "Epoch 3, Sample 15799: Loss: 0.0026\n",
            "Epoch 3, Sample 15800: Loss: 1.0524\n",
            "Epoch 3, Sample 15801: Loss: 0.2034\n",
            "Epoch 3, Sample 15802: Loss: 0.3441\n",
            "Epoch 3, Sample 15803: Loss: 0.0838\n",
            "Epoch 3, Sample 15804: Loss: 0.4930\n",
            "Epoch 3, Sample 15805: Loss: 0.0475\n",
            "Epoch 3, Sample 15806: Loss: 1.7195\n",
            "Epoch 3, Sample 15807: Loss: 3.2314\n",
            "Epoch 3, Sample 15808: Loss: 1.0524\n",
            "Epoch 3, Sample 15809: Loss: 1.0956\n",
            "Epoch 3, Sample 15810: Loss: 0.0554\n",
            "Epoch 3, Sample 15811: Loss: 0.7036\n",
            "Epoch 3, Sample 15812: Loss: 0.1625\n",
            "Epoch 3, Sample 15813: Loss: 0.0145\n",
            "Epoch 3, Sample 15814: Loss: 0.2034\n",
            "Epoch 3, Sample 15815: Loss: 0.3441\n",
            "Epoch 3, Sample 15816: Loss: 2.6860\n",
            "Epoch 3, Sample 15817: Loss: 0.0018\n",
            "Epoch 3, Sample 15818: Loss: 0.0212\n",
            "Epoch 3, Sample 15819: Loss: 1.1205\n",
            "Epoch 3, Sample 15820: Loss: 0.0026\n",
            "Epoch 3, Sample 15821: Loss: 3.5504\n",
            "Epoch 3, Sample 15822: Loss: 0.4032\n",
            "Epoch 3, Sample 15823: Loss: 0.2989\n",
            "Epoch 3, Sample 15824: Loss: 0.2340\n",
            "Epoch 3, Sample 15825: Loss: 0.0026\n",
            "Epoch 3, Sample 15826: Loss: 0.0026\n",
            "Epoch 3, Sample 15827: Loss: 0.9785\n",
            "Epoch 3, Sample 15828: Loss: 15.2563\n",
            "Epoch 3, Sample 15829: Loss: 4.2937\n",
            "Epoch 3, Sample 15830: Loss: 0.9367\n",
            "Epoch 3, Sample 15831: Loss: 1.0524\n",
            "Epoch 3, Sample 15832: Loss: 0.2044\n",
            "Epoch 3, Sample 15833: Loss: 0.1170\n",
            "Epoch 3, Sample 15834: Loss: 0.0460\n",
            "Epoch 3, Sample 15835: Loss: 0.2935\n",
            "Epoch 3, Sample 15836: Loss: 2.7331\n",
            "Epoch 3, Sample 15837: Loss: 0.2044\n",
            "Epoch 3, Sample 15838: Loss: 0.2704\n",
            "Epoch 3, Sample 15839: Loss: 0.6139\n",
            "Epoch 3, Sample 15840: Loss: 2.6860\n",
            "Epoch 3, Sample 15841: Loss: 15.3704\n",
            "Epoch 3, Sample 15842: Loss: 0.1250\n",
            "Epoch 3, Sample 15843: Loss: 0.1170\n",
            "Epoch 3, Sample 15844: Loss: 0.0608\n",
            "Epoch 3, Sample 15845: Loss: 0.7036\n",
            "Epoch 3, Sample 15846: Loss: 0.4799\n",
            "Epoch 3, Sample 15847: Loss: 0.0026\n",
            "Epoch 3, Sample 15848: Loss: 0.2759\n",
            "Epoch 3, Sample 15849: Loss: 0.3949\n",
            "Epoch 3, Sample 15850: Loss: 1.5597\n",
            "Epoch 3, Sample 15851: Loss: 1.4884\n",
            "Epoch 3, Sample 15852: Loss: 0.0013\n",
            "Epoch 3, Sample 15853: Loss: 0.0018\n",
            "Epoch 3, Sample 15854: Loss: 0.8951\n",
            "Epoch 3, Sample 15855: Loss: 0.4382\n",
            "Epoch 3, Sample 15856: Loss: 0.3758\n",
            "Epoch 3, Sample 15857: Loss: 0.0018\n",
            "Epoch 3, Sample 15858: Loss: 0.0026\n",
            "Epoch 3, Sample 15859: Loss: 0.4902\n",
            "Epoch 3, Sample 15860: Loss: 0.2034\n",
            "Epoch 3, Sample 15861: Loss: 0.1250\n",
            "Epoch 3, Sample 15862: Loss: 0.3399\n",
            "Epoch 3, Sample 15863: Loss: 4.9130\n",
            "Epoch 3, Sample 15864: Loss: 0.2032\n",
            "Epoch 3, Sample 15865: Loss: 0.9367\n",
            "Epoch 3, Sample 15866: Loss: 0.2036\n",
            "Epoch 3, Sample 15867: Loss: 0.2970\n",
            "Epoch 3, Sample 15868: Loss: 2.1901\n",
            "Epoch 3, Sample 15869: Loss: 0.2032\n",
            "Epoch 3, Sample 15870: Loss: 0.8951\n",
            "Epoch 3, Sample 15871: Loss: 0.1250\n",
            "Epoch 3, Sample 15872: Loss: 1.0359\n",
            "Epoch 3, Sample 15873: Loss: 0.3441\n",
            "Epoch 3, Sample 15874: Loss: 0.1399\n",
            "Epoch 3, Sample 15875: Loss: 0.1807\n",
            "Epoch 3, Sample 15876: Loss: 3.5504\n",
            "Epoch 3, Sample 15877: Loss: 0.2759\n",
            "Epoch 3, Sample 15878: Loss: 0.0026\n",
            "Epoch 3, Sample 15879: Loss: 0.1559\n",
            "Epoch 3, Sample 15880: Loss: 0.1233\n",
            "Epoch 3, Sample 15881: Loss: 0.2034\n",
            "Epoch 3, Sample 15882: Loss: 0.1170\n",
            "Epoch 3, Sample 15883: Loss: 0.1863\n",
            "Epoch 3, Sample 15884: Loss: 0.8951\n",
            "Epoch 3, Sample 15885: Loss: 0.2759\n",
            "Epoch 3, Sample 15886: Loss: 0.1170\n",
            "Epoch 3, Sample 15887: Loss: 0.1170\n",
            "Epoch 3, Sample 15888: Loss: 0.2832\n",
            "Epoch 3, Sample 15889: Loss: 4.7858\n",
            "Epoch 3, Sample 15890: Loss: 0.3347\n",
            "Epoch 3, Sample 15891: Loss: 0.2340\n",
            "Epoch 3, Sample 15892: Loss: 2.7331\n",
            "Epoch 3, Sample 15893: Loss: 0.2044\n",
            "Epoch 3, Sample 15894: Loss: 0.2778\n",
            "Epoch 3, Sample 15895: Loss: 1.0155\n",
            "Epoch 3, Sample 15896: Loss: 0.4799\n",
            "Epoch 3, Sample 15897: Loss: 0.0026\n",
            "Epoch 3, Sample 15898: Loss: 0.0001\n",
            "Epoch 3, Sample 15899: Loss: 0.1248\n",
            "Epoch 3, Sample 15900: Loss: 0.3399\n",
            "Epoch 3, Sample 15901: Loss: 0.6304\n",
            "Epoch 3, Sample 15902: Loss: 2.4095\n",
            "Epoch 3, Sample 15903: Loss: 1.6256\n",
            "Epoch 3, Sample 15904: Loss: 0.5858\n",
            "Epoch 3, Sample 15905: Loss: 0.2034\n",
            "Epoch 3, Sample 15906: Loss: 0.0205\n",
            "Epoch 3, Sample 15907: Loss: 0.6990\n",
            "Epoch 3, Sample 15908: Loss: 0.5858\n",
            "Epoch 3, Sample 15909: Loss: 0.8951\n",
            "Epoch 3, Sample 15910: Loss: 0.2121\n",
            "Epoch 3, Sample 15911: Loss: 0.0625\n",
            "Epoch 3, Sample 15912: Loss: 0.0036\n",
            "Epoch 3, Sample 15913: Loss: 0.0001\n",
            "Epoch 3, Sample 15914: Loss: 24.7460\n",
            "Epoch 3, Sample 15915: Loss: 0.0630\n",
            "Epoch 3, Sample 15916: Loss: 0.0108\n",
            "Epoch 3, Sample 15917: Loss: 0.2032\n",
            "Epoch 3, Sample 15918: Loss: 0.2428\n",
            "Epoch 3, Sample 15919: Loss: 2.7331\n",
            "Epoch 3, Sample 15920: Loss: 0.5196\n",
            "Epoch 3, Sample 15921: Loss: 0.3126\n",
            "Epoch 3, Sample 15922: Loss: 0.7036\n",
            "Epoch 3, Sample 15923: Loss: 0.7036\n",
            "Epoch 3, Sample 15924: Loss: 0.4799\n",
            "Epoch 3, Sample 15925: Loss: 0.0026\n",
            "Epoch 3, Sample 15926: Loss: 0.0014\n",
            "Epoch 3, Sample 15927: Loss: 1.0530\n",
            "Epoch 3, Sample 15928: Loss: 0.0838\n",
            "Epoch 3, Sample 15929: Loss: 0.9780\n",
            "Epoch 3, Sample 15930: Loss: 0.3758\n",
            "Epoch 3, Sample 15931: Loss: 0.0306\n",
            "Epoch 3, Sample 15932: Loss: 0.3450\n",
            "Epoch 3, Sample 15933: Loss: 1.2845\n",
            "Epoch 3, Sample 15934: Loss: 0.0001\n",
            "Epoch 3, Sample 15935: Loss: 1.5597\n",
            "Epoch 3, Sample 15936: Loss: 0.6190\n",
            "Epoch 3, Sample 15937: Loss: 0.5089\n",
            "Epoch 3, Sample 15938: Loss: 0.7007\n",
            "Epoch 3, Sample 15939: Loss: 0.0626\n",
            "Epoch 3, Sample 15940: Loss: 0.6990\n",
            "Epoch 3, Sample 15941: Loss: 0.2759\n",
            "Epoch 3, Sample 15942: Loss: 0.1588\n",
            "Epoch 3, Sample 15943: Loss: 0.2935\n",
            "Epoch 3, Sample 15944: Loss: 0.3399\n",
            "Epoch 3, Sample 15945: Loss: 1.0956\n",
            "Epoch 3, Sample 15946: Loss: 0.1252\n",
            "Epoch 3, Sample 15947: Loss: 1.3405\n",
            "Epoch 3, Sample 15948: Loss: 0.0062\n",
            "Epoch 3, Sample 15949: Loss: 0.0303\n",
            "Epoch 3, Sample 15950: Loss: 3.6328\n",
            "Epoch 3, Sample 15951: Loss: 1.0524\n",
            "Epoch 3, Sample 15952: Loss: 0.2759\n",
            "Epoch 3, Sample 15953: Loss: 0.1627\n",
            "Epoch 3, Sample 15954: Loss: 1.5597\n",
            "Epoch 3, Sample 15955: Loss: 0.3399\n",
            "Epoch 3, Sample 15956: Loss: 0.6867\n",
            "Epoch 3, Sample 15957: Loss: 0.0270\n",
            "Epoch 3, Sample 15958: Loss: 1.5597\n",
            "Epoch 3, Sample 15959: Loss: 0.1250\n",
            "Epoch 3, Sample 15960: Loss: 0.2340\n",
            "Epoch 3, Sample 15961: Loss: 0.9785\n",
            "Epoch 3, Sample 15962: Loss: 6.1915\n",
            "Epoch 3, Sample 15963: Loss: 1.0530\n",
            "Epoch 3, Sample 15964: Loss: 0.9780\n",
            "Epoch 3, Sample 15965: Loss: 0.3332\n",
            "Epoch 3, Sample 15966: Loss: 0.6139\n",
            "Epoch 3, Sample 15967: Loss: 0.2962\n",
            "Epoch 3, Sample 15968: Loss: 0.2755\n",
            "Epoch 3, Sample 15969: Loss: 2.1901\n",
            "Epoch 3, Sample 15970: Loss: 0.1999\n",
            "Epoch 3, Sample 15971: Loss: 6.4949\n",
            "Epoch 3, Sample 15972: Loss: 0.0026\n",
            "Epoch 3, Sample 15973: Loss: 0.0972\n",
            "Epoch 3, Sample 15974: Loss: 0.3399\n",
            "Epoch 3, Sample 15975: Loss: 2.8693\n",
            "Epoch 3, Sample 15976: Loss: 1.0524\n",
            "Epoch 3, Sample 15977: Loss: 0.6867\n",
            "Epoch 3, Sample 15978: Loss: 0.2044\n",
            "Epoch 3, Sample 15979: Loss: 0.0630\n",
            "Epoch 3, Sample 15980: Loss: 0.8951\n",
            "Epoch 3, Sample 15981: Loss: 0.3441\n",
            "Epoch 3, Sample 15982: Loss: 0.3399\n",
            "Epoch 3, Sample 15983: Loss: 1.0524\n",
            "Epoch 3, Sample 15984: Loss: 0.0018\n",
            "Epoch 3, Sample 15985: Loss: 0.8951\n",
            "Epoch 3, Sample 15986: Loss: 1.1569\n",
            "Epoch 3, Sample 15987: Loss: 0.0026\n",
            "Epoch 3, Sample 15988: Loss: 0.0026\n",
            "Epoch 3, Sample 15989: Loss: 1.0155\n",
            "Epoch 3, Sample 15990: Loss: 0.4641\n",
            "Epoch 3, Sample 15991: Loss: 1.5597\n",
            "Epoch 3, Sample 15992: Loss: 0.1219\n",
            "Epoch 3, Sample 15993: Loss: 0.2182\n",
            "Epoch 3, Sample 15994: Loss: 0.1246\n",
            "Epoch 3, Sample 15995: Loss: 0.6139\n",
            "Epoch 3, Sample 15996: Loss: 7.6726\n",
            "Epoch 3, Sample 15997: Loss: 0.9780\n",
            "Epoch 3, Sample 15998: Loss: 0.5972\n",
            "Epoch 3, Sample 15999: Loss: 2.7331\n",
            "Epoch 3, Sample 16000: Loss: 0.6867\n",
            "\n",
            "Epoch 3 Average Loss: 1.0000\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 4th trial we chose these settings\n",
        "epochs = 3\n",
        "learning_rate = .005\n",
        "input_size = 20\n",
        "Neurons = 50\n",
        "activation_input = 50\n",
        "activation function = relu\n",
        "output = 1"
      ],
      "metadata": {
        "id": "XgRYRaaCyLx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "learning_rate = .005\n",
        "\n",
        "\n",
        "# Initializing Parameters\n",
        "w = 50\n",
        "\n",
        "loss_set = {}\n",
        "\n",
        "# 1. Creating a FeedForwardNetwork\n",
        "# 1.1 Structure (Architecture) of NN\n",
        "model_net4 = torch.nn.Sequential(torch.nn.Linear(20,50),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(0.33),\n",
        "\n",
        "                                 torch.nn.Linear(50,1),\n",
        "                                 torch.nn.ReLU(),\n",
        "\n",
        "                                 );\n",
        "\n",
        "# 1.2 Loss Function\n",
        "loss_mse = torch.nn.MSELoss()\n",
        "\n",
        "# 1.3 Optmization Approch\n",
        "optimizer = torch.optim.SGD(model_net4.parameters(), lr=learning_rate)\n",
        "\n",
        "w_his = []\n",
        "w_his.append(w)\n",
        "# Loop over the number of epochs\n",
        "for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over each sample in the dataset\n",
        "    for i in range(tensor_data_X.size(0)):\n",
        "\n",
        "      # 2. Forward Pass\n",
        "      output = model_net4.forward(tensor_data_X[i].reshape(-1))\n",
        "\n",
        "      # 3. FeedForward Evaluation\n",
        "      loss = loss_mse(output, tensor_data_Y[i].reshape(-1))\n",
        "      optimizer.zero_grad();\n",
        "\n",
        "      # 4. Backward Pass / Gradient Calculation\n",
        "      loss.backward()\n",
        "\n",
        "      # Store the loss for each epoch\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # 5. Back Propagation / Update Weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store the weight value for each sample of data\n",
        "      w_his.append(float(model_net4[0].weight.data[0][0]))\n",
        "\n",
        "      # Display the loss for the current sample\n",
        "      print(f\"Epoch {epoch+1}, Sample {i+1}: Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # Calculate and display average loss for the epoch\n",
        "    epoch_loss /= tensor_data_X.size(0)\n",
        "\n",
        "    # Store the loss for each sample of data\n",
        "    loss_set[epoch] = epoch_loss\n",
        "    print(f\"\\nEpoch {epoch+1} Average Loss: {epoch_loss:.4f}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "72112380f98e468696ef7235579c81b1",
            "aab43c42137f40cdacae65ae031e31fe",
            "c5def1dc6da94005a217cc6e99721358",
            "36035bd01fe54a02b4de199e19520985",
            "b9e226d409b04c04ac274557d4fb410b",
            "bf952b26701443a6a0b7f33cc9c70ae1",
            "2fb30e705e494c8ba5fabdffaa05c6aa",
            "49ee4521203a4eadb8907b6b97182198",
            "0a39981ace4b4bb68f3eb5b06cfd48f1",
            "7354902be29549c3b3d404e8ec0b6039",
            "c2351e96a8b345e8bd7c00ec9a6c78a0"
          ]
        },
        "id": "RAAyERHvIJMj",
        "outputId": "8bf7a107-8958-4e74-c4ea-3499c35acb51"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-281-91f5dcc44d66>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72112380f98e468696ef7235579c81b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 11005: Loss: 0.2832\n",
            "Epoch 3, Sample 11006: Loss: 0.2787\n",
            "Epoch 3, Sample 11007: Loss: 0.3455\n",
            "Epoch 3, Sample 11008: Loss: 0.7036\n",
            "Epoch 3, Sample 11009: Loss: 0.2630\n",
            "Epoch 3, Sample 11010: Loss: 0.0008\n",
            "Epoch 3, Sample 11011: Loss: 0.0026\n",
            "Epoch 3, Sample 11012: Loss: 0.7453\n",
            "Epoch 3, Sample 11013: Loss: 0.2728\n",
            "Epoch 3, Sample 11014: Loss: 0.2032\n",
            "Epoch 3, Sample 11015: Loss: 1.4884\n",
            "Epoch 3, Sample 11016: Loss: 0.3399\n",
            "Epoch 3, Sample 11017: Loss: 0.2339\n",
            "Epoch 3, Sample 11018: Loss: 0.0968\n",
            "Epoch 3, Sample 11019: Loss: 0.1207\n",
            "Epoch 3, Sample 11020: Loss: 0.1170\n",
            "Epoch 3, Sample 11021: Loss: 0.4663\n",
            "Epoch 3, Sample 11022: Loss: 1.6418\n",
            "Epoch 3, Sample 11023: Loss: 0.2750\n",
            "Epoch 3, Sample 11024: Loss: 0.9367\n",
            "Epoch 3, Sample 11025: Loss: 0.0025\n",
            "Epoch 3, Sample 11026: Loss: 1.1265\n",
            "Epoch 3, Sample 11027: Loss: 1.0155\n",
            "Epoch 3, Sample 11028: Loss: 0.7036\n",
            "Epoch 3, Sample 11029: Loss: 0.5871\n",
            "Epoch 3, Sample 11030: Loss: 0.0212\n",
            "Epoch 3, Sample 11031: Loss: 0.0505\n",
            "Epoch 3, Sample 11032: Loss: 1.0524\n",
            "Epoch 3, Sample 11033: Loss: 0.0106\n",
            "Epoch 3, Sample 11034: Loss: 0.1838\n",
            "Epoch 3, Sample 11035: Loss: 0.0959\n",
            "Epoch 3, Sample 11036: Loss: 0.2442\n",
            "Epoch 3, Sample 11037: Loss: 0.2098\n",
            "Epoch 3, Sample 11038: Loss: 0.3399\n",
            "Epoch 3, Sample 11039: Loss: 1.0155\n",
            "Epoch 3, Sample 11040: Loss: 1.0524\n",
            "Epoch 3, Sample 11041: Loss: 0.0391\n",
            "Epoch 3, Sample 11042: Loss: 1.0475\n",
            "Epoch 3, Sample 11043: Loss: 0.0287\n",
            "Epoch 3, Sample 11044: Loss: 0.2639\n",
            "Epoch 3, Sample 11045: Loss: 0.0630\n",
            "Epoch 3, Sample 11046: Loss: 0.3441\n",
            "Epoch 3, Sample 11047: Loss: 0.0802\n",
            "Epoch 3, Sample 11048: Loss: 0.9367\n",
            "Epoch 3, Sample 11049: Loss: 0.2759\n",
            "Epoch 3, Sample 11050: Loss: 0.0084\n",
            "Epoch 3, Sample 11051: Loss: 0.0001\n",
            "Epoch 3, Sample 11052: Loss: 1.6912\n",
            "Epoch 3, Sample 11053: Loss: 0.2032\n",
            "Epoch 3, Sample 11054: Loss: 0.0554\n",
            "Epoch 3, Sample 11055: Loss: 0.1233\n",
            "Epoch 3, Sample 11056: Loss: 0.0018\n",
            "Epoch 3, Sample 11057: Loss: 0.0061\n",
            "Epoch 3, Sample 11058: Loss: 3.2371\n",
            "Epoch 3, Sample 11059: Loss: 0.5972\n",
            "Epoch 3, Sample 11060: Loss: 0.4930\n",
            "Epoch 3, Sample 11061: Loss: 1.2417\n",
            "Epoch 3, Sample 11062: Loss: 0.0234\n",
            "Epoch 3, Sample 11063: Loss: 0.2044\n",
            "Epoch 3, Sample 11064: Loss: 0.9017\n",
            "Epoch 3, Sample 11065: Loss: 0.7036\n",
            "Epoch 3, Sample 11066: Loss: 0.0253\n",
            "Epoch 3, Sample 11067: Loss: 0.2832\n",
            "Epoch 3, Sample 11068: Loss: 1.0530\n",
            "Epoch 3, Sample 11069: Loss: 0.7036\n",
            "Epoch 3, Sample 11070: Loss: 0.9814\n",
            "Epoch 3, Sample 11071: Loss: 0.7036\n",
            "Epoch 3, Sample 11072: Loss: 0.5858\n",
            "Epoch 3, Sample 11073: Loss: 0.0358\n",
            "Epoch 3, Sample 11074: Loss: 0.0307\n",
            "Epoch 3, Sample 11075: Loss: 0.0026\n",
            "Epoch 3, Sample 11076: Loss: 0.3438\n",
            "Epoch 3, Sample 11077: Loss: 1.3887\n",
            "Epoch 3, Sample 11078: Loss: 0.2412\n",
            "Epoch 3, Sample 11079: Loss: 0.3399\n",
            "Epoch 3, Sample 11080: Loss: 0.3099\n",
            "Epoch 3, Sample 11081: Loss: 0.0145\n",
            "Epoch 3, Sample 11082: Loss: 0.0026\n",
            "Epoch 3, Sample 11083: Loss: 0.2639\n",
            "Epoch 3, Sample 11084: Loss: 0.0205\n",
            "Epoch 3, Sample 11085: Loss: 1.0524\n",
            "Epoch 3, Sample 11086: Loss: 0.3399\n",
            "Epoch 3, Sample 11087: Loss: 0.1559\n",
            "Epoch 3, Sample 11088: Loss: 1.0155\n",
            "Epoch 3, Sample 11089: Loss: 0.0022\n",
            "Epoch 3, Sample 11090: Loss: 0.0630\n",
            "Epoch 3, Sample 11091: Loss: 0.2044\n",
            "Epoch 3, Sample 11092: Loss: 0.0018\n",
            "Epoch 3, Sample 11093: Loss: 0.2040\n",
            "Epoch 3, Sample 11094: Loss: 0.0026\n",
            "Epoch 3, Sample 11095: Loss: 1.0524\n",
            "Epoch 3, Sample 11096: Loss: 0.2340\n",
            "Epoch 3, Sample 11097: Loss: 0.5078\n",
            "Epoch 3, Sample 11098: Loss: 0.0108\n",
            "Epoch 3, Sample 11099: Loss: 0.2295\n",
            "Epoch 3, Sample 11100: Loss: 0.6857\n",
            "Epoch 3, Sample 11101: Loss: 0.1170\n",
            "Epoch 3, Sample 11102: Loss: 0.2036\n",
            "Epoch 3, Sample 11103: Loss: 0.5858\n",
            "Epoch 3, Sample 11104: Loss: 0.2034\n",
            "Epoch 3, Sample 11105: Loss: 0.1969\n",
            "Epoch 3, Sample 11106: Loss: 0.2032\n",
            "Epoch 3, Sample 11107: Loss: 0.1763\n",
            "Epoch 3, Sample 11108: Loss: 0.0630\n",
            "Epoch 3, Sample 11109: Loss: 0.2340\n",
            "Epoch 3, Sample 11110: Loss: 1.0524\n",
            "Epoch 3, Sample 11111: Loss: 0.2032\n",
            "Epoch 3, Sample 11112: Loss: 0.1211\n",
            "Epoch 3, Sample 11113: Loss: 1.0524\n",
            "Epoch 3, Sample 11114: Loss: 1.0155\n",
            "Epoch 3, Sample 11115: Loss: 0.1250\n",
            "Epoch 3, Sample 11116: Loss: 0.4607\n",
            "Epoch 3, Sample 11117: Loss: 1.0524\n",
            "Epoch 3, Sample 11118: Loss: 0.0034\n",
            "Epoch 3, Sample 11119: Loss: 1.0524\n",
            "Epoch 3, Sample 11120: Loss: 0.7036\n",
            "Epoch 3, Sample 11121: Loss: 0.2044\n",
            "Epoch 3, Sample 11122: Loss: 0.1170\n",
            "Epoch 3, Sample 11123: Loss: 0.5278\n",
            "Epoch 3, Sample 11124: Loss: 0.2759\n",
            "Epoch 3, Sample 11125: Loss: 0.0630\n",
            "Epoch 3, Sample 11126: Loss: 0.7036\n",
            "Epoch 3, Sample 11127: Loss: 1.1917\n",
            "Epoch 3, Sample 11128: Loss: 0.4930\n",
            "Epoch 3, Sample 11129: Loss: 0.9367\n",
            "Epoch 3, Sample 11130: Loss: 0.3105\n",
            "Epoch 3, Sample 11131: Loss: 0.0196\n",
            "Epoch 3, Sample 11132: Loss: 1.0524\n",
            "Epoch 3, Sample 11133: Loss: 0.8494\n",
            "Epoch 3, Sample 11134: Loss: 0.0460\n",
            "Epoch 3, Sample 11135: Loss: 0.2036\n",
            "Epoch 3, Sample 11136: Loss: 0.0018\n",
            "Epoch 3, Sample 11137: Loss: 0.0424\n",
            "Epoch 3, Sample 11138: Loss: 0.6295\n",
            "Epoch 3, Sample 11139: Loss: 0.0001\n",
            "Epoch 3, Sample 11140: Loss: 0.1042\n",
            "Epoch 3, Sample 11141: Loss: 0.2759\n",
            "Epoch 3, Sample 11142: Loss: 0.4611\n",
            "Epoch 3, Sample 11143: Loss: 0.2032\n",
            "Epoch 3, Sample 11144: Loss: 0.2219\n",
            "Epoch 3, Sample 11145: Loss: 0.7036\n",
            "Epoch 3, Sample 11146: Loss: 0.0062\n",
            "Epoch 3, Sample 11147: Loss: 4.7467\n",
            "Epoch 3, Sample 11148: Loss: 0.1207\n",
            "Epoch 3, Sample 11149: Loss: 0.7036\n",
            "Epoch 3, Sample 11150: Loss: 0.0746\n",
            "Epoch 3, Sample 11151: Loss: 0.2036\n",
            "Epoch 3, Sample 11152: Loss: 0.0831\n",
            "Epoch 3, Sample 11153: Loss: 0.6990\n",
            "Epoch 3, Sample 11154: Loss: 0.0802\n",
            "Epoch 3, Sample 11155: Loss: 0.1250\n",
            "Epoch 3, Sample 11156: Loss: 0.6304\n",
            "Epoch 3, Sample 11157: Loss: 0.9785\n",
            "Epoch 3, Sample 11158: Loss: 0.8951\n",
            "Epoch 3, Sample 11159: Loss: 0.2044\n",
            "Epoch 3, Sample 11160: Loss: 0.1455\n",
            "Epoch 3, Sample 11161: Loss: 0.0026\n",
            "Epoch 3, Sample 11162: Loss: 0.0026\n",
            "Epoch 3, Sample 11163: Loss: 0.2112\n",
            "Epoch 3, Sample 11164: Loss: 0.2833\n",
            "Epoch 3, Sample 11165: Loss: 0.0144\n",
            "Epoch 3, Sample 11166: Loss: 0.2032\n",
            "Epoch 3, Sample 11167: Loss: 0.7036\n",
            "Epoch 3, Sample 11168: Loss: 0.3873\n",
            "Epoch 3, Sample 11169: Loss: 0.1887\n",
            "Epoch 3, Sample 11170: Loss: 0.4700\n",
            "Epoch 3, Sample 11171: Loss: 1.0530\n",
            "Epoch 3, Sample 11172: Loss: 0.0026\n",
            "Epoch 3, Sample 11173: Loss: 0.2036\n",
            "Epoch 3, Sample 11174: Loss: 0.1523\n",
            "Epoch 3, Sample 11175: Loss: 0.2759\n",
            "Epoch 3, Sample 11176: Loss: 0.0637\n",
            "Epoch 3, Sample 11177: Loss: 0.1128\n",
            "Epoch 3, Sample 11178: Loss: 0.8951\n",
            "Epoch 3, Sample 11179: Loss: 0.1616\n",
            "Epoch 3, Sample 11180: Loss: 0.5000\n",
            "Epoch 3, Sample 11181: Loss: 0.0380\n",
            "Epoch 3, Sample 11182: Loss: 1.0155\n",
            "Epoch 3, Sample 11183: Loss: 0.1683\n",
            "Epoch 3, Sample 11184: Loss: 1.0524\n",
            "Epoch 3, Sample 11185: Loss: 0.2314\n",
            "Epoch 3, Sample 11186: Loss: 0.4611\n",
            "Epoch 3, Sample 11187: Loss: 0.0106\n",
            "Epoch 3, Sample 11188: Loss: 0.2032\n",
            "Epoch 3, Sample 11189: Loss: 1.0155\n",
            "Epoch 3, Sample 11190: Loss: 1.8199\n",
            "Epoch 3, Sample 11191: Loss: 0.3399\n",
            "Epoch 3, Sample 11192: Loss: 0.7036\n",
            "Epoch 3, Sample 11193: Loss: 0.2639\n",
            "Epoch 3, Sample 11194: Loss: 0.2034\n",
            "Epoch 3, Sample 11195: Loss: 0.7036\n",
            "Epoch 3, Sample 11196: Loss: 0.2036\n",
            "Epoch 3, Sample 11197: Loss: 1.0524\n",
            "Epoch 3, Sample 11198: Loss: 0.0626\n",
            "Epoch 3, Sample 11199: Loss: 1.1570\n",
            "Epoch 3, Sample 11200: Loss: 1.4707\n",
            "Epoch 3, Sample 11201: Loss: 0.4579\n",
            "Epoch 3, Sample 11202: Loss: 0.0027\n",
            "Epoch 3, Sample 11203: Loss: 0.2034\n",
            "Epoch 3, Sample 11204: Loss: 0.0083\n",
            "Epoch 3, Sample 11205: Loss: 0.4611\n",
            "Epoch 3, Sample 11206: Loss: 1.0524\n",
            "Epoch 3, Sample 11207: Loss: 1.0524\n",
            "Epoch 3, Sample 11208: Loss: 0.1091\n",
            "Epoch 3, Sample 11209: Loss: 0.0630\n",
            "Epoch 3, Sample 11210: Loss: 0.2577\n",
            "Epoch 3, Sample 11211: Loss: 0.2044\n",
            "Epoch 3, Sample 11212: Loss: 0.2832\n",
            "Epoch 3, Sample 11213: Loss: 0.3441\n",
            "Epoch 3, Sample 11214: Loss: 0.4996\n",
            "Epoch 3, Sample 11215: Loss: 0.5375\n",
            "Epoch 3, Sample 11216: Loss: 0.0460\n",
            "Epoch 3, Sample 11217: Loss: 0.4360\n",
            "Epoch 3, Sample 11218: Loss: 0.5012\n",
            "Epoch 3, Sample 11219: Loss: 1.0524\n",
            "Epoch 3, Sample 11220: Loss: 0.0027\n",
            "Epoch 3, Sample 11221: Loss: 0.0108\n",
            "Epoch 3, Sample 11222: Loss: 1.0155\n",
            "Epoch 3, Sample 11223: Loss: 0.0026\n",
            "Epoch 3, Sample 11224: Loss: 0.1170\n",
            "Epoch 3, Sample 11225: Loss: 0.0018\n",
            "Epoch 3, Sample 11226: Loss: 0.2034\n",
            "Epoch 3, Sample 11227: Loss: 0.2340\n",
            "Epoch 3, Sample 11228: Loss: 2.0108\n",
            "Epoch 3, Sample 11229: Loss: 0.1225\n",
            "Epoch 3, Sample 11230: Loss: 0.1674\n",
            "Epoch 3, Sample 11231: Loss: 1.0155\n",
            "Epoch 3, Sample 11232: Loss: 0.3402\n",
            "Epoch 3, Sample 11233: Loss: 0.2340\n",
            "Epoch 3, Sample 11234: Loss: 0.0026\n",
            "Epoch 3, Sample 11235: Loss: 0.1463\n",
            "Epoch 3, Sample 11236: Loss: 0.8951\n",
            "Epoch 3, Sample 11237: Loss: 0.2044\n",
            "Epoch 3, Sample 11238: Loss: 0.4032\n",
            "Epoch 3, Sample 11239: Loss: 0.8584\n",
            "Epoch 3, Sample 11240: Loss: 0.4032\n",
            "Epoch 3, Sample 11241: Loss: 0.0234\n",
            "Epoch 3, Sample 11242: Loss: 0.6990\n",
            "Epoch 3, Sample 11243: Loss: 0.0363\n",
            "Epoch 3, Sample 11244: Loss: 0.2111\n",
            "Epoch 3, Sample 11245: Loss: 0.0625\n",
            "Epoch 3, Sample 11246: Loss: 0.3216\n",
            "Epoch 3, Sample 11247: Loss: 0.1546\n",
            "Epoch 3, Sample 11248: Loss: 0.0569\n",
            "Epoch 3, Sample 11249: Loss: 0.2098\n",
            "Epoch 3, Sample 11250: Loss: 1.0155\n",
            "Epoch 3, Sample 11251: Loss: 0.0915\n",
            "Epoch 3, Sample 11252: Loss: 0.9367\n",
            "Epoch 3, Sample 11253: Loss: 1.5670\n",
            "Epoch 3, Sample 11254: Loss: 0.1559\n",
            "Epoch 3, Sample 11255: Loss: 0.3399\n",
            "Epoch 3, Sample 11256: Loss: 0.3402\n",
            "Epoch 3, Sample 11257: Loss: 0.1250\n",
            "Epoch 3, Sample 11258: Loss: 0.4778\n",
            "Epoch 3, Sample 11259: Loss: 0.6990\n",
            "Epoch 3, Sample 11260: Loss: 1.0524\n",
            "Epoch 3, Sample 11261: Loss: 0.1948\n",
            "Epoch 3, Sample 11262: Loss: 0.0026\n",
            "Epoch 3, Sample 11263: Loss: 0.0391\n",
            "Epoch 3, Sample 11264: Loss: 0.3441\n",
            "Epoch 3, Sample 11265: Loss: 0.8951\n",
            "Epoch 3, Sample 11266: Loss: 2.1300\n",
            "Epoch 3, Sample 11267: Loss: 0.0001\n",
            "Epoch 3, Sample 11268: Loss: 0.2759\n",
            "Epoch 3, Sample 11269: Loss: 0.6304\n",
            "Epoch 3, Sample 11270: Loss: 0.6303\n",
            "Epoch 3, Sample 11271: Loss: 0.2034\n",
            "Epoch 3, Sample 11272: Loss: 0.5858\n",
            "Epoch 3, Sample 11273: Loss: 0.0018\n",
            "Epoch 3, Sample 11274: Loss: 0.3399\n",
            "Epoch 3, Sample 11275: Loss: 1.0266\n",
            "Epoch 3, Sample 11276: Loss: 0.7378\n",
            "Epoch 3, Sample 11277: Loss: 0.0915\n",
            "Epoch 3, Sample 11278: Loss: 0.2044\n",
            "Epoch 3, Sample 11279: Loss: 0.7036\n",
            "Epoch 3, Sample 11280: Loss: 0.6560\n",
            "Epoch 3, Sample 11281: Loss: 2.2434\n",
            "Epoch 3, Sample 11282: Loss: 0.0070\n",
            "Epoch 3, Sample 11283: Loss: 0.5694\n",
            "Epoch 3, Sample 11284: Loss: 0.0018\n",
            "Epoch 3, Sample 11285: Loss: 0.4930\n",
            "Epoch 3, Sample 11286: Loss: 1.4884\n",
            "Epoch 3, Sample 11287: Loss: 0.4677\n",
            "Epoch 3, Sample 11288: Loss: 0.4032\n",
            "Epoch 3, Sample 11289: Loss: 0.2759\n",
            "Epoch 3, Sample 11290: Loss: 0.5051\n",
            "Epoch 3, Sample 11291: Loss: 0.4032\n",
            "Epoch 3, Sample 11292: Loss: 0.2863\n",
            "Epoch 3, Sample 11293: Loss: 0.5871\n",
            "Epoch 3, Sample 11294: Loss: 0.3399\n",
            "Epoch 3, Sample 11295: Loss: 0.3854\n",
            "Epoch 3, Sample 11296: Loss: 0.0630\n",
            "Epoch 3, Sample 11297: Loss: 0.5488\n",
            "Epoch 3, Sample 11298: Loss: 0.2044\n",
            "Epoch 3, Sample 11299: Loss: 0.4867\n",
            "Epoch 3, Sample 11300: Loss: 0.0050\n",
            "Epoch 3, Sample 11301: Loss: 0.9067\n",
            "Epoch 3, Sample 11302: Loss: 0.2044\n",
            "Epoch 3, Sample 11303: Loss: 0.1559\n",
            "Epoch 3, Sample 11304: Loss: 0.2659\n",
            "Epoch 3, Sample 11305: Loss: 8.5039\n",
            "Epoch 3, Sample 11306: Loss: 0.0212\n",
            "Epoch 3, Sample 11307: Loss: 0.3526\n",
            "Epoch 3, Sample 11308: Loss: 2.7331\n",
            "Epoch 3, Sample 11309: Loss: 0.6990\n",
            "Epoch 3, Sample 11310: Loss: 0.3904\n",
            "Epoch 3, Sample 11311: Loss: 0.5398\n",
            "Epoch 3, Sample 11312: Loss: 0.0212\n",
            "Epoch 3, Sample 11313: Loss: 0.2182\n",
            "Epoch 3, Sample 11314: Loss: 0.3399\n",
            "Epoch 3, Sample 11315: Loss: 0.3399\n",
            "Epoch 3, Sample 11316: Loss: 0.0915\n",
            "Epoch 3, Sample 11317: Loss: 0.7036\n",
            "Epoch 3, Sample 11318: Loss: 0.0576\n",
            "Epoch 3, Sample 11319: Loss: 0.4611\n",
            "Epoch 3, Sample 11320: Loss: 0.6092\n",
            "Epoch 3, Sample 11321: Loss: 0.1523\n",
            "Epoch 3, Sample 11322: Loss: 0.3949\n",
            "Epoch 3, Sample 11323: Loss: 0.2738\n",
            "Epoch 3, Sample 11324: Loss: 0.9367\n",
            "Epoch 3, Sample 11325: Loss: 0.1040\n",
            "Epoch 3, Sample 11326: Loss: 1.0524\n",
            "Epoch 3, Sample 11327: Loss: 0.3949\n",
            "Epoch 3, Sample 11328: Loss: 0.1264\n",
            "Epoch 3, Sample 11329: Loss: 0.0013\n",
            "Epoch 3, Sample 11330: Loss: 0.2044\n",
            "Epoch 3, Sample 11331: Loss: 0.0455\n",
            "Epoch 3, Sample 11332: Loss: 0.3399\n",
            "Epoch 3, Sample 11333: Loss: 0.3025\n",
            "Epoch 3, Sample 11334: Loss: 0.0723\n",
            "Epoch 3, Sample 11335: Loss: 0.7961\n",
            "Epoch 3, Sample 11336: Loss: 0.5799\n",
            "Epoch 3, Sample 11337: Loss: 0.2729\n",
            "Epoch 3, Sample 11338: Loss: 0.4761\n",
            "Epoch 3, Sample 11339: Loss: 0.0466\n",
            "Epoch 3, Sample 11340: Loss: 0.3332\n",
            "Epoch 3, Sample 11341: Loss: 0.2044\n",
            "Epoch 3, Sample 11342: Loss: 0.7036\n",
            "Epoch 3, Sample 11343: Loss: 0.2079\n",
            "Epoch 3, Sample 11344: Loss: 0.1250\n",
            "Epoch 3, Sample 11345: Loss: 0.2014\n",
            "Epoch 3, Sample 11346: Loss: 5.6579\n",
            "Epoch 3, Sample 11347: Loss: 0.2832\n",
            "Epoch 3, Sample 11348: Loss: 0.5019\n",
            "Epoch 3, Sample 11349: Loss: 0.2252\n",
            "Epoch 3, Sample 11350: Loss: 0.3399\n",
            "Epoch 3, Sample 11351: Loss: 0.0026\n",
            "Epoch 3, Sample 11352: Loss: 0.9651\n",
            "Epoch 3, Sample 11353: Loss: 0.8951\n",
            "Epoch 3, Sample 11354: Loss: 0.3367\n",
            "Epoch 3, Sample 11355: Loss: 0.0006\n",
            "Epoch 3, Sample 11356: Loss: 0.0019\n",
            "Epoch 3, Sample 11357: Loss: 0.5972\n",
            "Epoch 3, Sample 11358: Loss: 0.2044\n",
            "Epoch 3, Sample 11359: Loss: 0.1627\n",
            "Epoch 3, Sample 11360: Loss: 0.3785\n",
            "Epoch 3, Sample 11361: Loss: 0.1635\n",
            "Epoch 3, Sample 11362: Loss: 1.1805\n",
            "Epoch 3, Sample 11363: Loss: 0.0026\n",
            "Epoch 3, Sample 11364: Loss: 0.0068\n",
            "Epoch 3, Sample 11365: Loss: 1.4348\n",
            "Epoch 3, Sample 11366: Loss: 0.2034\n",
            "Epoch 3, Sample 11367: Loss: 0.4032\n",
            "Epoch 3, Sample 11368: Loss: 0.5858\n",
            "Epoch 3, Sample 11369: Loss: 0.1220\n",
            "Epoch 3, Sample 11370: Loss: 0.1250\n",
            "Epoch 3, Sample 11371: Loss: 0.0161\n",
            "Epoch 3, Sample 11372: Loss: 0.0144\n",
            "Epoch 3, Sample 11373: Loss: 0.0967\n",
            "Epoch 3, Sample 11374: Loss: 1.0524\n",
            "Epoch 3, Sample 11375: Loss: 0.2759\n",
            "Epoch 3, Sample 11376: Loss: 0.2084\n",
            "Epoch 3, Sample 11377: Loss: 1.1563\n",
            "Epoch 3, Sample 11378: Loss: 0.5291\n",
            "Epoch 3, Sample 11379: Loss: 0.2962\n",
            "Epoch 3, Sample 11380: Loss: 0.0460\n",
            "Epoch 3, Sample 11381: Loss: 1.0524\n",
            "Epoch 3, Sample 11382: Loss: 0.0838\n",
            "Epoch 3, Sample 11383: Loss: 0.7036\n",
            "Epoch 3, Sample 11384: Loss: 2.3171\n",
            "Epoch 3, Sample 11385: Loss: 0.2079\n",
            "Epoch 3, Sample 11386: Loss: 0.1250\n",
            "Epoch 3, Sample 11387: Loss: 0.0834\n",
            "Epoch 3, Sample 11388: Loss: 0.0972\n",
            "Epoch 3, Sample 11389: Loss: 0.0129\n",
            "Epoch 3, Sample 11390: Loss: 0.5871\n",
            "Epoch 3, Sample 11391: Loss: 1.0266\n",
            "Epoch 3, Sample 11392: Loss: 0.6099\n",
            "Epoch 3, Sample 11393: Loss: 0.0700\n",
            "Epoch 3, Sample 11394: Loss: 0.3441\n",
            "Epoch 3, Sample 11395: Loss: 0.5067\n",
            "Epoch 3, Sample 11396: Loss: 1.0524\n",
            "Epoch 3, Sample 11397: Loss: 0.0567\n",
            "Epoch 3, Sample 11398: Loss: 0.7048\n",
            "Epoch 3, Sample 11399: Loss: 0.4792\n",
            "Epoch 3, Sample 11400: Loss: 0.1219\n",
            "Epoch 3, Sample 11401: Loss: 0.3803\n",
            "Epoch 3, Sample 11402: Loss: 0.7864\n",
            "Epoch 3, Sample 11403: Loss: 0.0626\n",
            "Epoch 3, Sample 11404: Loss: 0.2759\n",
            "Epoch 3, Sample 11405: Loss: 1.0524\n",
            "Epoch 3, Sample 11406: Loss: 1.0524\n",
            "Epoch 3, Sample 11407: Loss: 1.0155\n",
            "Epoch 3, Sample 11408: Loss: 1.2223\n",
            "Epoch 3, Sample 11409: Loss: 0.0018\n",
            "Epoch 3, Sample 11410: Loss: 0.0018\n",
            "Epoch 3, Sample 11411: Loss: 0.2044\n",
            "Epoch 3, Sample 11412: Loss: 0.8951\n",
            "Epoch 3, Sample 11413: Loss: 0.0101\n",
            "Epoch 3, Sample 11414: Loss: 0.2832\n",
            "Epoch 3, Sample 11415: Loss: 0.0777\n",
            "Epoch 3, Sample 11416: Loss: 0.3402\n",
            "Epoch 3, Sample 11417: Loss: 1.2718\n",
            "Epoch 3, Sample 11418: Loss: 0.0001\n",
            "Epoch 3, Sample 11419: Loss: 0.2044\n",
            "Epoch 3, Sample 11420: Loss: 0.9024\n",
            "Epoch 3, Sample 11421: Loss: 0.7453\n",
            "Epoch 3, Sample 11422: Loss: 0.2759\n",
            "Epoch 3, Sample 11423: Loss: 1.1304\n",
            "Epoch 3, Sample 11424: Loss: 0.0286\n",
            "Epoch 3, Sample 11425: Loss: 0.2034\n",
            "Epoch 3, Sample 11426: Loss: 0.2044\n",
            "Epoch 3, Sample 11427: Loss: 0.5858\n",
            "Epoch 3, Sample 11428: Loss: 1.0524\n",
            "Epoch 3, Sample 11429: Loss: 0.0018\n",
            "Epoch 3, Sample 11430: Loss: 0.5871\n",
            "Epoch 3, Sample 11431: Loss: 0.2363\n",
            "Epoch 3, Sample 11432: Loss: 0.6477\n",
            "Epoch 3, Sample 11433: Loss: 0.0026\n",
            "Epoch 3, Sample 11434: Loss: 0.0052\n",
            "Epoch 3, Sample 11435: Loss: 0.0838\n",
            "Epoch 3, Sample 11436: Loss: 0.6304\n",
            "Epoch 3, Sample 11437: Loss: 0.8203\n",
            "Epoch 3, Sample 11438: Loss: 0.2044\n",
            "Epoch 3, Sample 11439: Loss: 0.0640\n",
            "Epoch 3, Sample 11440: Loss: 0.8625\n",
            "Epoch 3, Sample 11441: Loss: 0.0448\n",
            "Epoch 3, Sample 11442: Loss: 1.0820\n",
            "Epoch 3, Sample 11443: Loss: 0.0317\n",
            "Epoch 3, Sample 11444: Loss: 1.0524\n",
            "Epoch 3, Sample 11445: Loss: 1.8099\n",
            "Epoch 3, Sample 11446: Loss: 0.3441\n",
            "Epoch 3, Sample 11447: Loss: 0.8951\n",
            "Epoch 3, Sample 11448: Loss: 0.5078\n",
            "Epoch 3, Sample 11449: Loss: 1.0524\n",
            "Epoch 3, Sample 11450: Loss: 0.9780\n",
            "Epoch 3, Sample 11451: Loss: 0.0804\n",
            "Epoch 3, Sample 11452: Loss: 0.2340\n",
            "Epoch 3, Sample 11453: Loss: 0.2832\n",
            "Epoch 3, Sample 11454: Loss: 4.6441\n",
            "Epoch 3, Sample 11455: Loss: 0.0018\n",
            "Epoch 3, Sample 11456: Loss: 0.0012\n",
            "Epoch 3, Sample 11457: Loss: 0.1210\n",
            "Epoch 3, Sample 11458: Loss: 1.0155\n",
            "Epoch 3, Sample 11459: Loss: 0.3949\n",
            "Epoch 3, Sample 11460: Loss: 0.4644\n",
            "Epoch 3, Sample 11461: Loss: 0.8484\n",
            "Epoch 3, Sample 11462: Loss: 0.1170\n",
            "Epoch 3, Sample 11463: Loss: 0.9367\n",
            "Epoch 3, Sample 11464: Loss: 0.2032\n",
            "Epoch 3, Sample 11465: Loss: 0.0022\n",
            "Epoch 3, Sample 11466: Loss: 1.7430\n",
            "Epoch 3, Sample 11467: Loss: 0.2282\n",
            "Epoch 3, Sample 11468: Loss: 0.0001\n",
            "Epoch 3, Sample 11469: Loss: 0.2639\n",
            "Epoch 3, Sample 11470: Loss: 0.5858\n",
            "Epoch 3, Sample 11471: Loss: 1.0530\n",
            "Epoch 3, Sample 11472: Loss: 0.5972\n",
            "Epoch 3, Sample 11473: Loss: 0.0142\n",
            "Epoch 3, Sample 11474: Loss: 0.0042\n",
            "Epoch 3, Sample 11475: Loss: 0.1280\n",
            "Epoch 3, Sample 11476: Loss: 0.0630\n",
            "Epoch 3, Sample 11477: Loss: 0.8951\n",
            "Epoch 3, Sample 11478: Loss: 0.7036\n",
            "Epoch 3, Sample 11479: Loss: 0.0108\n",
            "Epoch 3, Sample 11480: Loss: 0.0625\n",
            "Epoch 3, Sample 11481: Loss: 0.3441\n",
            "Epoch 3, Sample 11482: Loss: 0.0063\n",
            "Epoch 3, Sample 11483: Loss: 8.4618\n",
            "Epoch 3, Sample 11484: Loss: 0.2759\n",
            "Epoch 3, Sample 11485: Loss: 0.5972\n",
            "Epoch 3, Sample 11486: Loss: 0.1431\n",
            "Epoch 3, Sample 11487: Loss: 0.0466\n",
            "Epoch 3, Sample 11488: Loss: 0.0026\n",
            "Epoch 3, Sample 11489: Loss: 0.2034\n",
            "Epoch 3, Sample 11490: Loss: 0.0019\n",
            "Epoch 3, Sample 11491: Loss: 0.1822\n",
            "Epoch 3, Sample 11492: Loss: 0.1559\n",
            "Epoch 3, Sample 11493: Loss: 0.2328\n",
            "Epoch 3, Sample 11494: Loss: 0.4930\n",
            "Epoch 3, Sample 11495: Loss: 0.0116\n",
            "Epoch 3, Sample 11496: Loss: 0.7036\n",
            "Epoch 3, Sample 11497: Loss: 0.7036\n",
            "Epoch 3, Sample 11498: Loss: 0.2036\n",
            "Epoch 3, Sample 11499: Loss: 0.3835\n",
            "Epoch 3, Sample 11500: Loss: 0.2699\n",
            "Epoch 3, Sample 11501: Loss: 0.0110\n",
            "Epoch 3, Sample 11502: Loss: 0.3007\n",
            "Epoch 3, Sample 11503: Loss: 1.0524\n",
            "Epoch 3, Sample 11504: Loss: 0.3598\n",
            "Epoch 3, Sample 11505: Loss: 0.7036\n",
            "Epoch 3, Sample 11506: Loss: 0.0026\n",
            "Epoch 3, Sample 11507: Loss: 0.0013\n",
            "Epoch 3, Sample 11508: Loss: 0.3399\n",
            "Epoch 3, Sample 11509: Loss: 0.3441\n",
            "Epoch 3, Sample 11510: Loss: 0.0026\n",
            "Epoch 3, Sample 11511: Loss: 0.9367\n",
            "Epoch 3, Sample 11512: Loss: 0.8967\n",
            "Epoch 3, Sample 11513: Loss: 0.0692\n",
            "Epoch 3, Sample 11514: Loss: 0.0258\n",
            "Epoch 3, Sample 11515: Loss: 0.2044\n",
            "Epoch 3, Sample 11516: Loss: 5.1480\n",
            "Epoch 3, Sample 11517: Loss: 0.1588\n",
            "Epoch 3, Sample 11518: Loss: 0.0212\n",
            "Epoch 3, Sample 11519: Loss: 0.2832\n",
            "Epoch 3, Sample 11520: Loss: 0.2329\n",
            "Epoch 3, Sample 11521: Loss: 0.3399\n",
            "Epoch 3, Sample 11522: Loss: 3.0295\n",
            "Epoch 3, Sample 11523: Loss: 0.0314\n",
            "Epoch 3, Sample 11524: Loss: 0.2112\n",
            "Epoch 3, Sample 11525: Loss: 0.6942\n",
            "Epoch 3, Sample 11526: Loss: 0.6464\n",
            "Epoch 3, Sample 11527: Loss: 0.1101\n",
            "Epoch 3, Sample 11528: Loss: 0.8951\n",
            "Epoch 3, Sample 11529: Loss: 1.0155\n",
            "Epoch 3, Sample 11530: Loss: 1.0524\n",
            "Epoch 3, Sample 11531: Loss: 0.3399\n",
            "Epoch 3, Sample 11532: Loss: 0.1872\n",
            "Epoch 3, Sample 11533: Loss: 0.0084\n",
            "Epoch 3, Sample 11534: Loss: 0.0630\n",
            "Epoch 3, Sample 11535: Loss: 3.5128\n",
            "Epoch 3, Sample 11536: Loss: 0.1220\n",
            "Epoch 3, Sample 11537: Loss: 0.2558\n",
            "Epoch 3, Sample 11538: Loss: 1.0524\n",
            "Epoch 3, Sample 11539: Loss: 0.4581\n",
            "Epoch 3, Sample 11540: Loss: 2.2349\n",
            "Epoch 3, Sample 11541: Loss: 0.0018\n",
            "Epoch 3, Sample 11542: Loss: 0.7036\n",
            "Epoch 3, Sample 11543: Loss: 0.2034\n",
            "Epoch 3, Sample 11544: Loss: 0.0258\n",
            "Epoch 3, Sample 11545: Loss: 0.6141\n",
            "Epoch 3, Sample 11546: Loss: 0.1559\n",
            "Epoch 3, Sample 11547: Loss: 1.0524\n",
            "Epoch 3, Sample 11548: Loss: 1.0524\n",
            "Epoch 3, Sample 11549: Loss: 1.0155\n",
            "Epoch 3, Sample 11550: Loss: 0.6990\n",
            "Epoch 3, Sample 11551: Loss: 0.4416\n",
            "Epoch 3, Sample 11552: Loss: 0.3441\n",
            "Epoch 3, Sample 11553: Loss: 1.2740\n",
            "Epoch 3, Sample 11554: Loss: 0.7036\n",
            "Epoch 3, Sample 11555: Loss: 0.0018\n",
            "Epoch 3, Sample 11556: Loss: 0.5003\n",
            "Epoch 3, Sample 11557: Loss: 1.0155\n",
            "Epoch 3, Sample 11558: Loss: 0.2044\n",
            "Epoch 3, Sample 11559: Loss: 0.1838\n",
            "Epoch 3, Sample 11560: Loss: 0.0626\n",
            "Epoch 3, Sample 11561: Loss: 0.8613\n",
            "Epoch 3, Sample 11562: Loss: 0.5310\n",
            "Epoch 3, Sample 11563: Loss: 0.0969\n",
            "Epoch 3, Sample 11564: Loss: 0.1097\n",
            "Epoch 3, Sample 11565: Loss: 0.2112\n",
            "Epoch 3, Sample 11566: Loss: 0.2989\n",
            "Epoch 3, Sample 11567: Loss: 0.0132\n",
            "Epoch 3, Sample 11568: Loss: 0.2699\n",
            "Epoch 3, Sample 11569: Loss: 1.0524\n",
            "Epoch 3, Sample 11570: Loss: 0.2044\n",
            "Epoch 3, Sample 11571: Loss: 0.5858\n",
            "Epoch 3, Sample 11572: Loss: 0.0466\n",
            "Epoch 3, Sample 11573: Loss: 0.1817\n",
            "Epoch 3, Sample 11574: Loss: 0.1559\n",
            "Epoch 3, Sample 11575: Loss: 0.2032\n",
            "Epoch 3, Sample 11576: Loss: 0.6893\n",
            "Epoch 3, Sample 11577: Loss: 1.0524\n",
            "Epoch 3, Sample 11578: Loss: 0.2044\n",
            "Epoch 3, Sample 11579: Loss: 0.0747\n",
            "Epoch 3, Sample 11580: Loss: 0.7036\n",
            "Epoch 3, Sample 11581: Loss: 0.0499\n",
            "Epoch 3, Sample 11582: Loss: 1.8429\n",
            "Epoch 3, Sample 11583: Loss: 0.1523\n",
            "Epoch 3, Sample 11584: Loss: 1.0155\n",
            "Epoch 3, Sample 11585: Loss: 0.1654\n",
            "Epoch 3, Sample 11586: Loss: 0.5858\n",
            "Epoch 3, Sample 11587: Loss: 0.5858\n",
            "Epoch 3, Sample 11588: Loss: 0.0212\n",
            "Epoch 3, Sample 11589: Loss: 0.0501\n",
            "Epoch 3, Sample 11590: Loss: 0.0630\n",
            "Epoch 3, Sample 11591: Loss: 0.1248\n",
            "Epoch 3, Sample 11592: Loss: 0.2032\n",
            "Epoch 3, Sample 11593: Loss: 0.0018\n",
            "Epoch 3, Sample 11594: Loss: 0.2340\n",
            "Epoch 3, Sample 11595: Loss: 1.5640\n",
            "Epoch 3, Sample 11596: Loss: 0.3399\n",
            "Epoch 3, Sample 11597: Loss: 0.2034\n",
            "Epoch 3, Sample 11598: Loss: 0.4574\n",
            "Epoch 3, Sample 11599: Loss: 0.0107\n",
            "Epoch 3, Sample 11600: Loss: 0.0125\n",
            "Epoch 3, Sample 11601: Loss: 0.2044\n",
            "Epoch 3, Sample 11602: Loss: 0.4985\n",
            "Epoch 3, Sample 11603: Loss: 1.0155\n",
            "Epoch 3, Sample 11604: Loss: 0.0466\n",
            "Epoch 3, Sample 11605: Loss: 3.1073\n",
            "Epoch 3, Sample 11606: Loss: 0.3568\n",
            "Epoch 3, Sample 11607: Loss: 0.2361\n",
            "Epoch 3, Sample 11608: Loss: 0.0026\n",
            "Epoch 3, Sample 11609: Loss: 0.6092\n",
            "Epoch 3, Sample 11610: Loss: 0.3062\n",
            "Epoch 3, Sample 11611: Loss: 0.4996\n",
            "Epoch 3, Sample 11612: Loss: 1.0530\n",
            "Epoch 3, Sample 11613: Loss: 0.4191\n",
            "Epoch 3, Sample 11614: Loss: 1.0155\n",
            "Epoch 3, Sample 11615: Loss: 0.0477\n",
            "Epoch 3, Sample 11616: Loss: 6.7177\n",
            "Epoch 3, Sample 11617: Loss: 0.2044\n",
            "Epoch 3, Sample 11618: Loss: 0.2459\n",
            "Epoch 3, Sample 11619: Loss: 0.7036\n",
            "Epoch 3, Sample 11620: Loss: 0.7702\n",
            "Epoch 3, Sample 11621: Loss: 0.4996\n",
            "Epoch 3, Sample 11622: Loss: 0.2032\n",
            "Epoch 3, Sample 11623: Loss: 0.5000\n",
            "Epoch 3, Sample 11624: Loss: 0.1170\n",
            "Epoch 3, Sample 11625: Loss: 0.0460\n",
            "Epoch 3, Sample 11626: Loss: 0.2363\n",
            "Epoch 3, Sample 11627: Loss: 7.6726\n",
            "Epoch 3, Sample 11628: Loss: 1.0773\n",
            "Epoch 3, Sample 11629: Loss: 1.9595\n",
            "Epoch 3, Sample 11630: Loss: 1.0155\n",
            "Epoch 3, Sample 11631: Loss: 1.0155\n",
            "Epoch 3, Sample 11632: Loss: 0.1250\n",
            "Epoch 3, Sample 11633: Loss: 0.6139\n",
            "Epoch 3, Sample 11634: Loss: 0.1719\n",
            "Epoch 3, Sample 11635: Loss: 0.0034\n",
            "Epoch 3, Sample 11636: Loss: 0.7036\n",
            "Epoch 3, Sample 11637: Loss: 0.2032\n",
            "Epoch 3, Sample 11638: Loss: 0.2339\n",
            "Epoch 3, Sample 11639: Loss: 0.2044\n",
            "Epoch 3, Sample 11640: Loss: 0.3399\n",
            "Epoch 3, Sample 11641: Loss: 0.3399\n",
            "Epoch 3, Sample 11642: Loss: 0.0018\n",
            "Epoch 3, Sample 11643: Loss: 0.0500\n",
            "Epoch 3, Sample 11644: Loss: 0.8031\n",
            "Epoch 3, Sample 11645: Loss: 0.7036\n",
            "Epoch 3, Sample 11646: Loss: 0.8005\n",
            "Epoch 3, Sample 11647: Loss: 0.0026\n",
            "Epoch 3, Sample 11648: Loss: 0.7036\n",
            "Epoch 3, Sample 11649: Loss: 0.0018\n",
            "Epoch 3, Sample 11650: Loss: 0.5858\n",
            "Epoch 3, Sample 11651: Loss: 0.5858\n",
            "Epoch 3, Sample 11652: Loss: 0.0026\n",
            "Epoch 3, Sample 11653: Loss: 0.7036\n",
            "Epoch 3, Sample 11654: Loss: 0.0321\n",
            "Epoch 3, Sample 11655: Loss: 0.0018\n",
            "Epoch 3, Sample 11656: Loss: 0.3399\n",
            "Epoch 3, Sample 11657: Loss: 0.4032\n",
            "Epoch 3, Sample 11658: Loss: 0.0026\n",
            "Epoch 3, Sample 11659: Loss: 0.0150\n",
            "Epoch 3, Sample 11660: Loss: 0.2639\n",
            "Epoch 3, Sample 11661: Loss: 0.0007\n",
            "Epoch 3, Sample 11662: Loss: 0.6494\n",
            "Epoch 3, Sample 11663: Loss: 0.3441\n",
            "Epoch 3, Sample 11664: Loss: 1.0155\n",
            "Epoch 3, Sample 11665: Loss: 0.1170\n",
            "Epoch 3, Sample 11666: Loss: 0.2036\n",
            "Epoch 3, Sample 11667: Loss: 0.5078\n",
            "Epoch 3, Sample 11668: Loss: 0.4032\n",
            "Epoch 3, Sample 11669: Loss: 0.2832\n",
            "Epoch 3, Sample 11670: Loss: 0.2044\n",
            "Epoch 3, Sample 11671: Loss: 0.2237\n",
            "Epoch 3, Sample 11672: Loss: 0.2709\n",
            "Epoch 3, Sample 11673: Loss: 0.0001\n",
            "Epoch 3, Sample 11674: Loss: 0.1798\n",
            "Epoch 3, Sample 11675: Loss: 0.5078\n",
            "Epoch 3, Sample 11676: Loss: 0.0460\n",
            "Epoch 3, Sample 11677: Loss: 2.6384\n",
            "Epoch 3, Sample 11678: Loss: 0.2288\n",
            "Epoch 3, Sample 11679: Loss: 0.2044\n",
            "Epoch 3, Sample 11680: Loss: 0.0212\n",
            "Epoch 3, Sample 11681: Loss: 1.0524\n",
            "Epoch 3, Sample 11682: Loss: 0.5078\n",
            "Epoch 3, Sample 11683: Loss: 0.4799\n",
            "Epoch 3, Sample 11684: Loss: 1.2926\n",
            "Epoch 3, Sample 11685: Loss: 0.1170\n",
            "Epoch 3, Sample 11686: Loss: 0.0026\n",
            "Epoch 3, Sample 11687: Loss: 0.0018\n",
            "Epoch 3, Sample 11688: Loss: 0.2219\n",
            "Epoch 3, Sample 11689: Loss: 0.0120\n",
            "Epoch 3, Sample 11690: Loss: 0.0006\n",
            "Epoch 3, Sample 11691: Loss: 0.2044\n",
            "Epoch 3, Sample 11692: Loss: 0.0026\n",
            "Epoch 3, Sample 11693: Loss: 0.0498\n",
            "Epoch 3, Sample 11694: Loss: 0.5000\n",
            "Epoch 3, Sample 11695: Loss: 0.3399\n",
            "Epoch 3, Sample 11696: Loss: 0.2759\n",
            "Epoch 3, Sample 11697: Loss: 0.1791\n",
            "Epoch 3, Sample 11698: Loss: 1.4563\n",
            "Epoch 3, Sample 11699: Loss: 0.0026\n",
            "Epoch 3, Sample 11700: Loss: 0.2036\n",
            "Epoch 3, Sample 11701: Loss: 0.0001\n",
            "Epoch 3, Sample 11702: Loss: 0.0194\n",
            "Epoch 3, Sample 11703: Loss: 0.0554\n",
            "Epoch 3, Sample 11704: Loss: 0.1250\n",
            "Epoch 3, Sample 11705: Loss: 0.0095\n",
            "Epoch 3, Sample 11706: Loss: 4.9868\n",
            "Epoch 3, Sample 11707: Loss: 0.0133\n",
            "Epoch 3, Sample 11708: Loss: 2.9652\n",
            "Epoch 3, Sample 11709: Loss: 0.5762\n",
            "Epoch 3, Sample 11710: Loss: 0.0621\n",
            "Epoch 3, Sample 11711: Loss: 0.1884\n",
            "Epoch 3, Sample 11712: Loss: 0.1766\n",
            "Epoch 3, Sample 11713: Loss: 0.2759\n",
            "Epoch 3, Sample 11714: Loss: 0.2759\n",
            "Epoch 3, Sample 11715: Loss: 0.5858\n",
            "Epoch 3, Sample 11716: Loss: 1.0524\n",
            "Epoch 3, Sample 11717: Loss: 0.0630\n",
            "Epoch 3, Sample 11718: Loss: 0.5000\n",
            "Epoch 3, Sample 11719: Loss: 0.3450\n",
            "Epoch 3, Sample 11720: Loss: 1.0155\n",
            "Epoch 3, Sample 11721: Loss: 0.1250\n",
            "Epoch 3, Sample 11722: Loss: 0.2112\n",
            "Epoch 3, Sample 11723: Loss: 1.0070\n",
            "Epoch 3, Sample 11724: Loss: 0.0159\n",
            "Epoch 3, Sample 11725: Loss: 0.2112\n",
            "Epoch 3, Sample 11726: Loss: 0.2044\n",
            "Epoch 3, Sample 11727: Loss: 0.2759\n",
            "Epoch 3, Sample 11728: Loss: 0.4841\n",
            "Epoch 3, Sample 11729: Loss: 0.1559\n",
            "Epoch 3, Sample 11730: Loss: 0.3007\n",
            "Epoch 3, Sample 11731: Loss: 0.0018\n",
            "Epoch 3, Sample 11732: Loss: 0.0507\n",
            "Epoch 3, Sample 11733: Loss: 0.2183\n",
            "Epoch 3, Sample 11734: Loss: 0.3399\n",
            "Epoch 3, Sample 11735: Loss: 0.3864\n",
            "Epoch 3, Sample 11736: Loss: 0.7209\n",
            "Epoch 3, Sample 11737: Loss: 0.0026\n",
            "Epoch 3, Sample 11738: Loss: 0.0013\n",
            "Epoch 3, Sample 11739: Loss: 0.7453\n",
            "Epoch 3, Sample 11740: Loss: 0.0031\n",
            "Epoch 3, Sample 11741: Loss: 0.4685\n",
            "Epoch 3, Sample 11742: Loss: 0.0158\n",
            "Epoch 3, Sample 11743: Loss: 0.9367\n",
            "Epoch 3, Sample 11744: Loss: 0.1170\n",
            "Epoch 3, Sample 11745: Loss: 0.3441\n",
            "Epoch 3, Sample 11746: Loss: 0.5196\n",
            "Epoch 3, Sample 11747: Loss: 0.0399\n",
            "Epoch 3, Sample 11748: Loss: 0.0072\n",
            "Epoch 3, Sample 11749: Loss: 0.0630\n",
            "Epoch 3, Sample 11750: Loss: 0.1250\n",
            "Epoch 3, Sample 11751: Loss: 0.1326\n",
            "Epoch 3, Sample 11752: Loss: 0.0069\n",
            "Epoch 3, Sample 11753: Loss: 0.2832\n",
            "Epoch 3, Sample 11754: Loss: 0.2870\n",
            "Epoch 3, Sample 11755: Loss: 0.0084\n",
            "Epoch 3, Sample 11756: Loss: 1.4539\n",
            "Epoch 3, Sample 11757: Loss: 0.2036\n",
            "Epoch 3, Sample 11758: Loss: 0.8037\n",
            "Epoch 3, Sample 11759: Loss: 0.2032\n",
            "Epoch 3, Sample 11760: Loss: 0.6990\n",
            "Epoch 3, Sample 11761: Loss: 0.0134\n",
            "Epoch 3, Sample 11762: Loss: 0.0775\n",
            "Epoch 3, Sample 11763: Loss: 0.1250\n",
            "Epoch 3, Sample 11764: Loss: 0.0306\n",
            "Epoch 3, Sample 11765: Loss: 0.2546\n",
            "Epoch 3, Sample 11766: Loss: 0.0018\n",
            "Epoch 3, Sample 11767: Loss: 0.0744\n",
            "Epoch 3, Sample 11768: Loss: 0.1523\n",
            "Epoch 3, Sample 11769: Loss: 1.0155\n",
            "Epoch 3, Sample 11770: Loss: 0.5989\n",
            "Epoch 3, Sample 11771: Loss: 0.3399\n",
            "Epoch 3, Sample 11772: Loss: 1.0155\n",
            "Epoch 3, Sample 11773: Loss: 0.0580\n",
            "Epoch 3, Sample 11774: Loss: 0.1250\n",
            "Epoch 3, Sample 11775: Loss: 0.0007\n",
            "Epoch 3, Sample 11776: Loss: 1.0524\n",
            "Epoch 3, Sample 11777: Loss: 0.7638\n",
            "Epoch 3, Sample 11778: Loss: 0.2044\n",
            "Epoch 3, Sample 11779: Loss: 0.8436\n",
            "Epoch 3, Sample 11780: Loss: 0.0626\n",
            "Epoch 3, Sample 11781: Loss: 0.5000\n",
            "Epoch 3, Sample 11782: Loss: 1.0227\n",
            "Epoch 3, Sample 11783: Loss: 0.2032\n",
            "Epoch 3, Sample 11784: Loss: 0.6304\n",
            "Epoch 3, Sample 11785: Loss: 0.4841\n",
            "Epoch 3, Sample 11786: Loss: 1.0155\n",
            "Epoch 3, Sample 11787: Loss: 0.2941\n",
            "Epoch 3, Sample 11788: Loss: 0.7856\n",
            "Epoch 3, Sample 11789: Loss: 0.3949\n",
            "Epoch 3, Sample 11790: Loss: 0.4130\n",
            "Epoch 3, Sample 11791: Loss: 0.0026\n",
            "Epoch 3, Sample 11792: Loss: 0.0630\n",
            "Epoch 3, Sample 11793: Loss: 1.0155\n",
            "Epoch 3, Sample 11794: Loss: 0.0018\n",
            "Epoch 3, Sample 11795: Loss: 0.4391\n",
            "Epoch 3, Sample 11796: Loss: 0.2044\n",
            "Epoch 3, Sample 11797: Loss: 0.7453\n",
            "Epoch 3, Sample 11798: Loss: 2.7112\n",
            "Epoch 3, Sample 11799: Loss: 0.2832\n",
            "Epoch 3, Sample 11800: Loss: 0.2034\n",
            "Epoch 3, Sample 11801: Loss: 0.1598\n",
            "Epoch 3, Sample 11802: Loss: 0.0027\n",
            "Epoch 3, Sample 11803: Loss: 1.7634\n",
            "Epoch 3, Sample 11804: Loss: 0.5003\n",
            "Epoch 3, Sample 11805: Loss: 0.3961\n",
            "Epoch 3, Sample 11806: Loss: 0.0212\n",
            "Epoch 3, Sample 11807: Loss: 0.0410\n",
            "Epoch 3, Sample 11808: Loss: 0.0168\n",
            "Epoch 3, Sample 11809: Loss: 4.0894\n",
            "Epoch 3, Sample 11810: Loss: 1.3704\n",
            "Epoch 3, Sample 11811: Loss: 0.0026\n",
            "Epoch 3, Sample 11812: Loss: 0.2044\n",
            "Epoch 3, Sample 11813: Loss: 1.1825\n",
            "Epoch 3, Sample 11814: Loss: 0.2941\n",
            "Epoch 3, Sample 11815: Loss: 0.1546\n",
            "Epoch 3, Sample 11816: Loss: 0.1559\n",
            "Epoch 3, Sample 11817: Loss: 0.5858\n",
            "Epoch 3, Sample 11818: Loss: 0.3399\n",
            "Epoch 3, Sample 11819: Loss: 0.4032\n",
            "Epoch 3, Sample 11820: Loss: 0.2036\n",
            "Epoch 3, Sample 11821: Loss: 0.2639\n",
            "Epoch 3, Sample 11822: Loss: 1.0530\n",
            "Epoch 3, Sample 11823: Loss: 0.0531\n",
            "Epoch 3, Sample 11824: Loss: 0.2639\n",
            "Epoch 3, Sample 11825: Loss: 0.7036\n",
            "Epoch 3, Sample 11826: Loss: 0.8574\n",
            "Epoch 3, Sample 11827: Loss: 0.0018\n",
            "Epoch 3, Sample 11828: Loss: 0.6639\n",
            "Epoch 3, Sample 11829: Loss: 1.0530\n",
            "Epoch 3, Sample 11830: Loss: 0.2044\n",
            "Epoch 3, Sample 11831: Loss: 0.0240\n",
            "Epoch 3, Sample 11832: Loss: 0.2909\n",
            "Epoch 3, Sample 11833: Loss: 0.2044\n",
            "Epoch 3, Sample 11834: Loss: 0.2044\n",
            "Epoch 3, Sample 11835: Loss: 0.3399\n",
            "Epoch 3, Sample 11836: Loss: 0.0875\n",
            "Epoch 3, Sample 11837: Loss: 0.3592\n",
            "Epoch 3, Sample 11838: Loss: 0.0597\n",
            "Epoch 3, Sample 11839: Loss: 0.3441\n",
            "Epoch 3, Sample 11840: Loss: 0.1465\n",
            "Epoch 3, Sample 11841: Loss: 1.9728\n",
            "Epoch 3, Sample 11842: Loss: 0.7036\n",
            "Epoch 3, Sample 11843: Loss: 1.1159\n",
            "Epoch 3, Sample 11844: Loss: 0.3999\n",
            "Epoch 3, Sample 11845: Loss: 0.3584\n",
            "Epoch 3, Sample 11846: Loss: 0.3949\n",
            "Epoch 3, Sample 11847: Loss: 0.0523\n",
            "Epoch 3, Sample 11848: Loss: 0.2759\n",
            "Epoch 3, Sample 11849: Loss: 0.2759\n",
            "Epoch 3, Sample 11850: Loss: 0.2759\n",
            "Epoch 3, Sample 11851: Loss: 0.0826\n",
            "Epoch 3, Sample 11852: Loss: 0.0588\n",
            "Epoch 3, Sample 11853: Loss: 6.2657\n",
            "Epoch 3, Sample 11854: Loss: 0.8951\n",
            "Epoch 3, Sample 11855: Loss: 0.2375\n",
            "Epoch 3, Sample 11856: Loss: 0.0938\n",
            "Epoch 3, Sample 11857: Loss: 0.0018\n",
            "Epoch 3, Sample 11858: Loss: 0.0455\n",
            "Epoch 3, Sample 11859: Loss: 0.1627\n",
            "Epoch 3, Sample 11860: Loss: 0.2544\n",
            "Epoch 3, Sample 11861: Loss: 0.5375\n",
            "Epoch 3, Sample 11862: Loss: 1.0511\n",
            "Epoch 3, Sample 11863: Loss: 0.2044\n",
            "Epoch 3, Sample 11864: Loss: 0.0030\n",
            "Epoch 3, Sample 11865: Loss: 6.0792\n",
            "Epoch 3, Sample 11866: Loss: 0.7036\n",
            "Epoch 3, Sample 11867: Loss: 0.1895\n",
            "Epoch 3, Sample 11868: Loss: 0.3092\n",
            "Epoch 3, Sample 11869: Loss: 0.0406\n",
            "Epoch 3, Sample 11870: Loss: 0.0026\n",
            "Epoch 3, Sample 11871: Loss: 0.4588\n",
            "Epoch 3, Sample 11872: Loss: 0.0938\n",
            "Epoch 3, Sample 11873: Loss: 0.0466\n",
            "Epoch 3, Sample 11874: Loss: 0.0399\n",
            "Epoch 3, Sample 11875: Loss: 0.0205\n",
            "Epoch 3, Sample 11876: Loss: 1.0227\n",
            "Epoch 3, Sample 11877: Loss: 0.3399\n",
            "Epoch 3, Sample 11878: Loss: 1.0688\n",
            "Epoch 3, Sample 11879: Loss: 0.5972\n",
            "Epoch 3, Sample 11880: Loss: 0.0030\n",
            "Epoch 3, Sample 11881: Loss: 10.8925\n",
            "Epoch 3, Sample 11882: Loss: 0.5858\n",
            "Epoch 3, Sample 11883: Loss: 0.0505\n",
            "Epoch 3, Sample 11884: Loss: 0.5020\n",
            "Epoch 3, Sample 11885: Loss: 0.7036\n",
            "Epoch 3, Sample 11886: Loss: 1.0155\n",
            "Epoch 3, Sample 11887: Loss: 0.2034\n",
            "Epoch 3, Sample 11888: Loss: 0.5141\n",
            "Epoch 3, Sample 11889: Loss: 0.7036\n",
            "Epoch 3, Sample 11890: Loss: 0.2686\n",
            "Epoch 3, Sample 11891: Loss: 0.6990\n",
            "Epoch 3, Sample 11892: Loss: 0.1170\n",
            "Epoch 3, Sample 11893: Loss: 0.0026\n",
            "Epoch 3, Sample 11894: Loss: 0.2032\n",
            "Epoch 3, Sample 11895: Loss: 0.5858\n",
            "Epoch 3, Sample 11896: Loss: 0.0001\n",
            "Epoch 3, Sample 11897: Loss: 0.2639\n",
            "Epoch 3, Sample 11898: Loss: 0.1279\n",
            "Epoch 3, Sample 11899: Loss: 0.3399\n",
            "Epoch 3, Sample 11900: Loss: 8.7194\n",
            "Epoch 3, Sample 11901: Loss: 0.5003\n",
            "Epoch 3, Sample 11902: Loss: 0.3092\n",
            "Epoch 3, Sample 11903: Loss: 0.1250\n",
            "Epoch 3, Sample 11904: Loss: 0.0057\n",
            "Epoch 3, Sample 11905: Loss: 0.2832\n",
            "Epoch 3, Sample 11906: Loss: 0.3441\n",
            "Epoch 3, Sample 11907: Loss: 0.0205\n",
            "Epoch 3, Sample 11908: Loss: 0.1465\n",
            "Epoch 3, Sample 11909: Loss: 0.0026\n",
            "Epoch 3, Sample 11910: Loss: 0.3399\n",
            "Epoch 3, Sample 11911: Loss: 0.7098\n",
            "Epoch 3, Sample 11912: Loss: 0.1399\n",
            "Epoch 3, Sample 11913: Loss: 0.0625\n",
            "Epoch 3, Sample 11914: Loss: 0.2639\n",
            "Epoch 3, Sample 11915: Loss: 0.2034\n",
            "Epoch 3, Sample 11916: Loss: 0.0253\n",
            "Epoch 3, Sample 11917: Loss: 0.0642\n",
            "Epoch 3, Sample 11918: Loss: 0.0026\n",
            "Epoch 3, Sample 11919: Loss: 0.0630\n",
            "Epoch 3, Sample 11920: Loss: 0.0021\n",
            "Epoch 3, Sample 11921: Loss: 0.6990\n",
            "Epoch 3, Sample 11922: Loss: 0.3441\n",
            "Epoch 3, Sample 11923: Loss: 0.3399\n",
            "Epoch 3, Sample 11924: Loss: 0.5000\n",
            "Epoch 3, Sample 11925: Loss: 0.0630\n",
            "Epoch 3, Sample 11926: Loss: 0.7253\n",
            "Epoch 3, Sample 11927: Loss: 0.2340\n",
            "Epoch 3, Sample 11928: Loss: 0.3624\n",
            "Epoch 3, Sample 11929: Loss: 0.0094\n",
            "Epoch 3, Sample 11930: Loss: 0.8093\n",
            "Epoch 3, Sample 11931: Loss: 0.0060\n",
            "Epoch 3, Sample 11932: Loss: 0.3729\n",
            "Epoch 3, Sample 11933: Loss: 0.0554\n",
            "Epoch 3, Sample 11934: Loss: 0.9651\n",
            "Epoch 3, Sample 11935: Loss: 0.4930\n",
            "Epoch 3, Sample 11936: Loss: 0.0224\n",
            "Epoch 3, Sample 11937: Loss: 0.0335\n",
            "Epoch 3, Sample 11938: Loss: 0.1372\n",
            "Epoch 3, Sample 11939: Loss: 0.2044\n",
            "Epoch 3, Sample 11940: Loss: 1.0524\n",
            "Epoch 3, Sample 11941: Loss: 0.2044\n",
            "Epoch 3, Sample 11942: Loss: 0.0690\n",
            "Epoch 3, Sample 11943: Loss: 0.7702\n",
            "Epoch 3, Sample 11944: Loss: 0.0025\n",
            "Epoch 3, Sample 11945: Loss: 0.5858\n",
            "Epoch 3, Sample 11946: Loss: 1.0524\n",
            "Epoch 3, Sample 11947: Loss: 0.1170\n",
            "Epoch 3, Sample 11948: Loss: 0.3428\n",
            "Epoch 3, Sample 11949: Loss: 0.2036\n",
            "Epoch 3, Sample 11950: Loss: 0.3402\n",
            "Epoch 3, Sample 11951: Loss: 0.8217\n",
            "Epoch 3, Sample 11952: Loss: 0.5000\n",
            "Epoch 3, Sample 11953: Loss: 0.0838\n",
            "Epoch 3, Sample 11954: Loss: 0.0440\n",
            "Epoch 3, Sample 11955: Loss: 0.1337\n",
            "Epoch 3, Sample 11956: Loss: 0.4799\n",
            "Epoch 3, Sample 11957: Loss: 0.6652\n",
            "Epoch 3, Sample 11958: Loss: 0.0808\n",
            "Epoch 3, Sample 11959: Loss: 1.6040\n",
            "Epoch 3, Sample 11960: Loss: 0.3007\n",
            "Epoch 3, Sample 11961: Loss: 0.2759\n",
            "Epoch 3, Sample 11962: Loss: 0.0339\n",
            "Epoch 3, Sample 11963: Loss: 0.0083\n",
            "Epoch 3, Sample 11964: Loss: 0.7702\n",
            "Epoch 3, Sample 11965: Loss: 0.0018\n",
            "Epoch 3, Sample 11966: Loss: 0.2034\n",
            "Epoch 3, Sample 11967: Loss: 0.0640\n",
            "Epoch 3, Sample 11968: Loss: 5.6363\n",
            "Epoch 3, Sample 11969: Loss: 0.6990\n",
            "Epoch 3, Sample 11970: Loss: 0.5447\n",
            "Epoch 3, Sample 11971: Loss: 0.3399\n",
            "Epoch 3, Sample 11972: Loss: 0.0062\n",
            "Epoch 3, Sample 11973: Loss: 1.6145\n",
            "Epoch 3, Sample 11974: Loss: 0.4611\n",
            "Epoch 3, Sample 11975: Loss: 1.0524\n",
            "Epoch 3, Sample 11976: Loss: 0.5871\n",
            "Epoch 3, Sample 11977: Loss: 1.0524\n",
            "Epoch 3, Sample 11978: Loss: 0.2044\n",
            "Epoch 3, Sample 11979: Loss: 0.2070\n",
            "Epoch 3, Sample 11980: Loss: 0.6867\n",
            "Epoch 3, Sample 11981: Loss: 0.0000\n",
            "Epoch 3, Sample 11982: Loss: 0.5000\n",
            "Epoch 3, Sample 11983: Loss: 0.0018\n",
            "Epoch 3, Sample 11984: Loss: 0.1508\n",
            "Epoch 3, Sample 11985: Loss: 0.3506\n",
            "Epoch 3, Sample 11986: Loss: 0.4946\n",
            "Epoch 3, Sample 11987: Loss: 0.2096\n",
            "Epoch 3, Sample 11988: Loss: 0.3238\n",
            "Epoch 3, Sample 11989: Loss: 0.5993\n",
            "Epoch 3, Sample 11990: Loss: 0.2034\n",
            "Epoch 3, Sample 11991: Loss: 0.2034\n",
            "Epoch 3, Sample 11992: Loss: 0.5003\n",
            "Epoch 3, Sample 11993: Loss: 0.3598\n",
            "Epoch 3, Sample 11994: Loss: 0.0011\n",
            "Epoch 3, Sample 11995: Loss: 1.0524\n",
            "Epoch 3, Sample 11996: Loss: 0.1091\n",
            "Epoch 3, Sample 11997: Loss: 0.2036\n",
            "Epoch 3, Sample 11998: Loss: 0.1250\n",
            "Epoch 3, Sample 11999: Loss: 8.7405\n",
            "Epoch 3, Sample 12000: Loss: 0.0018\n",
            "Epoch 3, Sample 12001: Loss: 0.5539\n",
            "Epoch 3, Sample 12002: Loss: 0.0306\n",
            "Epoch 3, Sample 12003: Loss: 0.0001\n",
            "Epoch 3, Sample 12004: Loss: 0.0005\n",
            "Epoch 3, Sample 12005: Loss: 0.7344\n",
            "Epoch 3, Sample 12006: Loss: 0.1890\n",
            "Epoch 3, Sample 12007: Loss: 0.0027\n",
            "Epoch 3, Sample 12008: Loss: 0.0001\n",
            "Epoch 3, Sample 12009: Loss: 0.5809\n",
            "Epoch 3, Sample 12010: Loss: 0.0476\n",
            "Epoch 3, Sample 12011: Loss: 0.4607\n",
            "Epoch 3, Sample 12012: Loss: 0.0000\n",
            "Epoch 3, Sample 12013: Loss: 0.4930\n",
            "Epoch 3, Sample 12014: Loss: 0.1114\n",
            "Epoch 3, Sample 12015: Loss: 0.3598\n",
            "Epoch 3, Sample 12016: Loss: 0.7486\n",
            "Epoch 3, Sample 12017: Loss: 0.0007\n",
            "Epoch 3, Sample 12018: Loss: 0.0626\n",
            "Epoch 3, Sample 12019: Loss: 0.2044\n",
            "Epoch 3, Sample 12020: Loss: 0.2998\n",
            "Epoch 3, Sample 12021: Loss: 0.3949\n",
            "Epoch 3, Sample 12022: Loss: 0.3949\n",
            "Epoch 3, Sample 12023: Loss: 0.1250\n",
            "Epoch 3, Sample 12024: Loss: 1.0524\n",
            "Epoch 3, Sample 12025: Loss: 1.0524\n",
            "Epoch 3, Sample 12026: Loss: 0.2759\n",
            "Epoch 3, Sample 12027: Loss: 0.0060\n",
            "Epoch 3, Sample 12028: Loss: 0.5019\n",
            "Epoch 3, Sample 12029: Loss: 0.2219\n",
            "Epoch 3, Sample 12030: Loss: 0.4382\n",
            "Epoch 3, Sample 12031: Loss: 0.0006\n",
            "Epoch 3, Sample 12032: Loss: 0.3441\n",
            "Epoch 3, Sample 12033: Loss: 5.8533\n",
            "Epoch 3, Sample 12034: Loss: 0.3441\n",
            "Epoch 3, Sample 12035: Loss: 0.2459\n",
            "Epoch 3, Sample 12036: Loss: 0.1039\n",
            "Epoch 3, Sample 12037: Loss: 0.0018\n",
            "Epoch 3, Sample 12038: Loss: 1.9201\n",
            "Epoch 3, Sample 12039: Loss: 0.4663\n",
            "Epoch 3, Sample 12040: Loss: 0.0323\n",
            "Epoch 3, Sample 12041: Loss: 0.3367\n",
            "Epoch 3, Sample 12042: Loss: 0.0558\n",
            "Epoch 3, Sample 12043: Loss: 0.0247\n",
            "Epoch 3, Sample 12044: Loss: 0.7036\n",
            "Epoch 3, Sample 12045: Loss: 0.0026\n",
            "Epoch 3, Sample 12046: Loss: 0.2034\n",
            "Epoch 3, Sample 12047: Loss: 0.0009\n",
            "Epoch 3, Sample 12048: Loss: 0.6139\n",
            "Epoch 3, Sample 12049: Loss: 0.1559\n",
            "Epoch 3, Sample 12050: Loss: 0.5003\n",
            "Epoch 3, Sample 12051: Loss: 0.1840\n",
            "Epoch 3, Sample 12052: Loss: 0.0026\n",
            "Epoch 3, Sample 12053: Loss: 0.3584\n",
            "Epoch 3, Sample 12054: Loss: 0.1250\n",
            "Epoch 3, Sample 12055: Loss: 0.7623\n",
            "Epoch 3, Sample 12056: Loss: 0.5019\n",
            "Epoch 3, Sample 12057: Loss: 0.3882\n",
            "Epoch 3, Sample 12058: Loss: 0.2432\n",
            "Epoch 3, Sample 12059: Loss: 0.2034\n",
            "Epoch 3, Sample 12060: Loss: 0.6990\n",
            "Epoch 3, Sample 12061: Loss: 0.0031\n",
            "Epoch 3, Sample 12062: Loss: 0.0018\n",
            "Epoch 3, Sample 12063: Loss: 0.3441\n",
            "Epoch 3, Sample 12064: Loss: 0.3399\n",
            "Epoch 3, Sample 12065: Loss: 0.0201\n",
            "Epoch 3, Sample 12066: Loss: 0.0505\n",
            "Epoch 3, Sample 12067: Loss: 0.0002\n",
            "Epoch 3, Sample 12068: Loss: 0.0025\n",
            "Epoch 3, Sample 12069: Loss: 0.2032\n",
            "Epoch 3, Sample 12070: Loss: 0.4768\n",
            "Epoch 3, Sample 12071: Loss: 0.9686\n",
            "Epoch 3, Sample 12072: Loss: 5.2660\n",
            "Epoch 3, Sample 12073: Loss: 1.0155\n",
            "Epoch 3, Sample 12074: Loss: 0.7036\n",
            "Epoch 3, Sample 12075: Loss: 0.1170\n",
            "Epoch 3, Sample 12076: Loss: 0.0060\n",
            "Epoch 3, Sample 12077: Loss: 0.2044\n",
            "Epoch 3, Sample 12078: Loss: 0.0026\n",
            "Epoch 3, Sample 12079: Loss: 0.4770\n",
            "Epoch 3, Sample 12080: Loss: 0.7453\n",
            "Epoch 3, Sample 12081: Loss: 0.6867\n",
            "Epoch 3, Sample 12082: Loss: 0.7036\n",
            "Epoch 3, Sample 12083: Loss: 0.6304\n",
            "Epoch 3, Sample 12084: Loss: 0.1399\n",
            "Epoch 3, Sample 12085: Loss: 0.2759\n",
            "Epoch 3, Sample 12086: Loss: 0.8951\n",
            "Epoch 3, Sample 12087: Loss: 0.7036\n",
            "Epoch 3, Sample 12088: Loss: 1.0524\n",
            "Epoch 3, Sample 12089: Loss: 0.2044\n",
            "Epoch 3, Sample 12090: Loss: 1.0667\n",
            "Epoch 3, Sample 12091: Loss: 0.2639\n",
            "Epoch 3, Sample 12092: Loss: 0.2044\n",
            "Epoch 3, Sample 12093: Loss: 0.5261\n",
            "Epoch 3, Sample 12094: Loss: 0.0018\n",
            "Epoch 3, Sample 12095: Loss: 0.7036\n",
            "Epoch 3, Sample 12096: Loss: 0.6990\n",
            "Epoch 3, Sample 12097: Loss: 0.7036\n",
            "Epoch 3, Sample 12098: Loss: 0.0108\n",
            "Epoch 3, Sample 12099: Loss: 0.8059\n",
            "Epoch 3, Sample 12100: Loss: 0.0240\n",
            "Epoch 3, Sample 12101: Loss: 0.2036\n",
            "Epoch 3, Sample 12102: Loss: 0.2044\n",
            "Epoch 3, Sample 12103: Loss: 0.3441\n",
            "Epoch 3, Sample 12104: Loss: 0.2032\n",
            "Epoch 3, Sample 12105: Loss: 0.9882\n",
            "Epoch 3, Sample 12106: Loss: 1.0530\n",
            "Epoch 3, Sample 12107: Loss: 0.0063\n",
            "Epoch 3, Sample 12108: Loss: 0.1397\n",
            "Epoch 3, Sample 12109: Loss: 0.0116\n",
            "Epoch 3, Sample 12110: Loss: 0.0630\n",
            "Epoch 3, Sample 12111: Loss: 0.1559\n",
            "Epoch 3, Sample 12112: Loss: 0.2375\n",
            "Epoch 3, Sample 12113: Loss: 1.0524\n",
            "Epoch 3, Sample 12114: Loss: 0.7036\n",
            "Epoch 3, Sample 12115: Loss: 2.0233\n",
            "Epoch 3, Sample 12116: Loss: 2.9897\n",
            "Epoch 3, Sample 12117: Loss: 0.5972\n",
            "Epoch 3, Sample 12118: Loss: 7.3088\n",
            "Epoch 3, Sample 12119: Loss: 1.3160\n",
            "Epoch 3, Sample 12120: Loss: 0.3399\n",
            "Epoch 3, Sample 12121: Loss: 0.5196\n",
            "Epoch 3, Sample 12122: Loss: 0.2832\n",
            "Epoch 3, Sample 12123: Loss: 0.6990\n",
            "Epoch 3, Sample 12124: Loss: 0.1056\n",
            "Epoch 3, Sample 12125: Loss: 0.0145\n",
            "Epoch 3, Sample 12126: Loss: 0.0551\n",
            "Epoch 3, Sample 12127: Loss: 0.1250\n",
            "Epoch 3, Sample 12128: Loss: 0.2044\n",
            "Epoch 3, Sample 12129: Loss: 1.0530\n",
            "Epoch 3, Sample 12130: Loss: 0.0630\n",
            "Epoch 3, Sample 12131: Loss: 0.8951\n",
            "Epoch 3, Sample 12132: Loss: 0.0579\n",
            "Epoch 3, Sample 12133: Loss: 1.6310\n",
            "Epoch 3, Sample 12134: Loss: 0.2034\n",
            "Epoch 3, Sample 12135: Loss: 0.2044\n",
            "Epoch 3, Sample 12136: Loss: 0.0067\n",
            "Epoch 3, Sample 12137: Loss: 0.2759\n",
            "Epoch 3, Sample 12138: Loss: 0.2906\n",
            "Epoch 3, Sample 12139: Loss: 0.2759\n",
            "Epoch 3, Sample 12140: Loss: 0.2044\n",
            "Epoch 3, Sample 12141: Loss: 0.0144\n",
            "Epoch 3, Sample 12142: Loss: 0.0008\n",
            "Epoch 3, Sample 12143: Loss: 1.0155\n",
            "Epoch 3, Sample 12144: Loss: 0.2759\n",
            "Epoch 3, Sample 12145: Loss: 0.3402\n",
            "Epoch 3, Sample 12146: Loss: 0.5062\n",
            "Epoch 3, Sample 12147: Loss: 0.1170\n",
            "Epoch 3, Sample 12148: Loss: 0.0093\n",
            "Epoch 3, Sample 12149: Loss: 0.0626\n",
            "Epoch 3, Sample 12150: Loss: 0.1559\n",
            "Epoch 3, Sample 12151: Loss: 0.0026\n",
            "Epoch 3, Sample 12152: Loss: 1.0260\n",
            "Epoch 3, Sample 12153: Loss: 0.1250\n",
            "Epoch 3, Sample 12154: Loss: 1.0811\n",
            "Epoch 3, Sample 12155: Loss: 0.2044\n",
            "Epoch 3, Sample 12156: Loss: 0.1170\n",
            "Epoch 3, Sample 12157: Loss: 1.0530\n",
            "Epoch 3, Sample 12158: Loss: 0.0819\n",
            "Epoch 3, Sample 12159: Loss: 0.3772\n",
            "Epoch 3, Sample 12160: Loss: 0.2044\n",
            "Epoch 3, Sample 12161: Loss: 0.3399\n",
            "Epoch 3, Sample 12162: Loss: 0.0206\n",
            "Epoch 3, Sample 12163: Loss: 0.0018\n",
            "Epoch 3, Sample 12164: Loss: 0.3399\n",
            "Epoch 3, Sample 12165: Loss: 0.0703\n",
            "Epoch 3, Sample 12166: Loss: 1.2018\n",
            "Epoch 3, Sample 12167: Loss: 0.2951\n",
            "Epoch 3, Sample 12168: Loss: 0.4305\n",
            "Epoch 3, Sample 12169: Loss: 0.0212\n",
            "Epoch 3, Sample 12170: Loss: 0.7036\n",
            "Epoch 3, Sample 12171: Loss: 0.3399\n",
            "Epoch 3, Sample 12172: Loss: 0.2044\n",
            "Epoch 3, Sample 12173: Loss: 0.0013\n",
            "Epoch 3, Sample 12174: Loss: 0.1170\n",
            "Epoch 3, Sample 12175: Loss: 0.7036\n",
            "Epoch 3, Sample 12176: Loss: 0.0830\n",
            "Epoch 3, Sample 12177: Loss: 1.0524\n",
            "Epoch 3, Sample 12178: Loss: 0.0026\n",
            "Epoch 3, Sample 12179: Loss: 0.0575\n",
            "Epoch 3, Sample 12180: Loss: 0.7036\n",
            "Epoch 3, Sample 12181: Loss: 1.0524\n",
            "Epoch 3, Sample 12182: Loss: 0.0838\n",
            "Epoch 3, Sample 12183: Loss: 0.7036\n",
            "Epoch 3, Sample 12184: Loss: 0.7036\n",
            "Epoch 3, Sample 12185: Loss: 0.0034\n",
            "Epoch 3, Sample 12186: Loss: 0.4514\n",
            "Epoch 3, Sample 12187: Loss: 0.0526\n",
            "Epoch 3, Sample 12188: Loss: 0.2036\n",
            "Epoch 3, Sample 12189: Loss: 1.0524\n",
            "Epoch 3, Sample 12190: Loss: 0.0838\n",
            "Epoch 3, Sample 12191: Loss: 0.0650\n",
            "Epoch 3, Sample 12192: Loss: 0.2962\n",
            "Epoch 3, Sample 12193: Loss: 0.1270\n",
            "Epoch 3, Sample 12194: Loss: 0.0026\n",
            "Epoch 3, Sample 12195: Loss: 0.3399\n",
            "Epoch 3, Sample 12196: Loss: 0.3402\n",
            "Epoch 3, Sample 12197: Loss: 0.3441\n",
            "Epoch 3, Sample 12198: Loss: 2.3774\n",
            "Epoch 3, Sample 12199: Loss: 0.0018\n",
            "Epoch 3, Sample 12200: Loss: 0.1444\n",
            "Epoch 3, Sample 12201: Loss: 0.3399\n",
            "Epoch 3, Sample 12202: Loss: 0.1559\n",
            "Epoch 3, Sample 12203: Loss: 0.2219\n",
            "Epoch 3, Sample 12204: Loss: 0.2044\n",
            "Epoch 3, Sample 12205: Loss: 0.2759\n",
            "Epoch 3, Sample 12206: Loss: 0.5858\n",
            "Epoch 3, Sample 12207: Loss: 1.3511\n",
            "Epoch 3, Sample 12208: Loss: 0.0026\n",
            "Epoch 3, Sample 12209: Loss: 0.0415\n",
            "Epoch 3, Sample 12210: Loss: 0.1248\n",
            "Epoch 3, Sample 12211: Loss: 0.0030\n",
            "Epoch 3, Sample 12212: Loss: 0.0056\n",
            "Epoch 3, Sample 12213: Loss: 2.4988\n",
            "Epoch 3, Sample 12214: Loss: 0.5858\n",
            "Epoch 3, Sample 12215: Loss: 0.3399\n",
            "Epoch 3, Sample 12216: Loss: 0.0108\n",
            "Epoch 3, Sample 12217: Loss: 0.0026\n",
            "Epoch 3, Sample 12218: Loss: 0.3441\n",
            "Epoch 3, Sample 12219: Loss: 1.0524\n",
            "Epoch 3, Sample 12220: Loss: 0.6990\n",
            "Epoch 3, Sample 12221: Loss: 0.2044\n",
            "Epoch 3, Sample 12222: Loss: 1.6932\n",
            "Epoch 3, Sample 12223: Loss: 0.0306\n",
            "Epoch 3, Sample 12224: Loss: 0.2340\n",
            "Epoch 3, Sample 12225: Loss: 0.2034\n",
            "Epoch 3, Sample 12226: Loss: 1.0551\n",
            "Epoch 3, Sample 12227: Loss: 0.2440\n",
            "Epoch 3, Sample 12228: Loss: 0.2219\n",
            "Epoch 3, Sample 12229: Loss: 0.2666\n",
            "Epoch 3, Sample 12230: Loss: 0.1177\n",
            "Epoch 3, Sample 12231: Loss: 0.4761\n",
            "Epoch 3, Sample 12232: Loss: 0.1825\n",
            "Epoch 3, Sample 12233: Loss: 0.0000\n",
            "Epoch 3, Sample 12234: Loss: 0.2832\n",
            "Epoch 3, Sample 12235: Loss: 0.9367\n",
            "Epoch 3, Sample 12236: Loss: 0.1250\n",
            "Epoch 3, Sample 12237: Loss: 0.1687\n",
            "Epoch 3, Sample 12238: Loss: 0.0238\n",
            "Epoch 3, Sample 12239: Loss: 0.3441\n",
            "Epoch 3, Sample 12240: Loss: 0.0001\n",
            "Epoch 3, Sample 12241: Loss: 3.9629\n",
            "Epoch 3, Sample 12242: Loss: 0.6867\n",
            "Epoch 3, Sample 12243: Loss: 0.5345\n",
            "Epoch 3, Sample 12244: Loss: 0.2044\n",
            "Epoch 3, Sample 12245: Loss: 1.0155\n",
            "Epoch 3, Sample 12246: Loss: 0.6425\n",
            "Epoch 3, Sample 12247: Loss: 0.7920\n",
            "Epoch 3, Sample 12248: Loss: 0.3441\n",
            "Epoch 3, Sample 12249: Loss: 0.2112\n",
            "Epoch 3, Sample 12250: Loss: 0.7036\n",
            "Epoch 3, Sample 12251: Loss: 0.0145\n",
            "Epoch 3, Sample 12252: Loss: 0.0067\n",
            "Epoch 3, Sample 12253: Loss: 1.0524\n",
            "Epoch 3, Sample 12254: Loss: 0.0303\n",
            "Epoch 3, Sample 12255: Loss: 0.2832\n",
            "Epoch 3, Sample 12256: Loss: 2.4541\n",
            "Epoch 3, Sample 12257: Loss: 0.2032\n",
            "Epoch 3, Sample 12258: Loss: 1.0524\n",
            "Epoch 3, Sample 12259: Loss: 0.2036\n",
            "Epoch 3, Sample 12260: Loss: 0.0001\n",
            "Epoch 3, Sample 12261: Loss: 0.8951\n",
            "Epoch 3, Sample 12262: Loss: 0.5972\n",
            "Epoch 3, Sample 12263: Loss: 0.0630\n",
            "Epoch 3, Sample 12264: Loss: 0.1252\n",
            "Epoch 3, Sample 12265: Loss: 0.2731\n",
            "Epoch 3, Sample 12266: Loss: 0.4930\n",
            "Epoch 3, Sample 12267: Loss: 3.2356\n",
            "Epoch 3, Sample 12268: Loss: 0.2203\n",
            "Epoch 3, Sample 12269: Loss: 0.1170\n",
            "Epoch 3, Sample 12270: Loss: 1.0524\n",
            "Epoch 3, Sample 12271: Loss: 1.3959\n",
            "Epoch 3, Sample 12272: Loss: 1.0524\n",
            "Epoch 3, Sample 12273: Loss: 0.0431\n",
            "Epoch 3, Sample 12274: Loss: 0.4750\n",
            "Epoch 3, Sample 12275: Loss: 0.0626\n",
            "Epoch 3, Sample 12276: Loss: 2.6430\n",
            "Epoch 3, Sample 12277: Loss: 0.8484\n",
            "Epoch 3, Sample 12278: Loss: 1.0524\n",
            "Epoch 3, Sample 12279: Loss: 3.4864\n",
            "Epoch 3, Sample 12280: Loss: 0.0270\n",
            "Epoch 3, Sample 12281: Loss: 0.2032\n",
            "Epoch 3, Sample 12282: Loss: 0.1248\n",
            "Epoch 3, Sample 12283: Loss: 0.0077\n",
            "Epoch 3, Sample 12284: Loss: 0.5972\n",
            "Epoch 3, Sample 12285: Loss: 1.0155\n",
            "Epoch 3, Sample 12286: Loss: 0.4942\n",
            "Epoch 3, Sample 12287: Loss: 0.2759\n",
            "Epoch 3, Sample 12288: Loss: 0.0051\n",
            "Epoch 3, Sample 12289: Loss: 0.0026\n",
            "Epoch 3, Sample 12290: Loss: 0.0082\n",
            "Epoch 3, Sample 12291: Loss: 0.3441\n",
            "Epoch 3, Sample 12292: Loss: 0.1273\n",
            "Epoch 3, Sample 12293: Loss: 0.7036\n",
            "Epoch 3, Sample 12294: Loss: 1.2011\n",
            "Epoch 3, Sample 12295: Loss: 0.0100\n",
            "Epoch 3, Sample 12296: Loss: 0.3984\n",
            "Epoch 3, Sample 12297: Loss: 0.1273\n",
            "Epoch 3, Sample 12298: Loss: 1.0524\n",
            "Epoch 3, Sample 12299: Loss: 0.0925\n",
            "Epoch 3, Sample 12300: Loss: 0.5466\n",
            "Epoch 3, Sample 12301: Loss: 0.1113\n",
            "Epoch 3, Sample 12302: Loss: 0.4799\n",
            "Epoch 3, Sample 12303: Loss: 0.5000\n",
            "Epoch 3, Sample 12304: Loss: 0.5858\n",
            "Epoch 3, Sample 12305: Loss: 0.2938\n",
            "Epoch 3, Sample 12306: Loss: 0.0630\n",
            "Epoch 3, Sample 12307: Loss: 0.1071\n",
            "Epoch 3, Sample 12308: Loss: 0.0062\n",
            "Epoch 3, Sample 12309: Loss: 1.0530\n",
            "Epoch 3, Sample 12310: Loss: 0.7036\n",
            "Epoch 3, Sample 12311: Loss: 0.1170\n",
            "Epoch 3, Sample 12312: Loss: 1.9651\n",
            "Epoch 3, Sample 12313: Loss: 0.3399\n",
            "Epoch 3, Sample 12314: Loss: 0.1006\n",
            "Epoch 3, Sample 12315: Loss: 0.1170\n",
            "Epoch 3, Sample 12316: Loss: 0.1248\n",
            "Epoch 3, Sample 12317: Loss: 0.2044\n",
            "Epoch 3, Sample 12318: Loss: 0.1248\n",
            "Epoch 3, Sample 12319: Loss: 0.6990\n",
            "Epoch 3, Sample 12320: Loss: 0.2032\n",
            "Epoch 3, Sample 12321: Loss: 0.5062\n",
            "Epoch 3, Sample 12322: Loss: 1.0524\n",
            "Epoch 3, Sample 12323: Loss: 0.2962\n",
            "Epoch 3, Sample 12324: Loss: 1.0524\n",
            "Epoch 3, Sample 12325: Loss: 1.0524\n",
            "Epoch 3, Sample 12326: Loss: 0.9162\n",
            "Epoch 3, Sample 12327: Loss: 1.0530\n",
            "Epoch 3, Sample 12328: Loss: 0.1372\n",
            "Epoch 3, Sample 12329: Loss: 0.1559\n",
            "Epoch 3, Sample 12330: Loss: 0.0005\n",
            "Epoch 3, Sample 12331: Loss: 0.0031\n",
            "Epoch 3, Sample 12332: Loss: 3.5258\n",
            "Epoch 3, Sample 12333: Loss: 0.9024\n",
            "Epoch 3, Sample 12334: Loss: 0.0236\n",
            "Epoch 3, Sample 12335: Loss: 0.2529\n",
            "Epoch 3, Sample 12336: Loss: 0.1039\n",
            "Epoch 3, Sample 12337: Loss: 0.2119\n",
            "Epoch 3, Sample 12338: Loss: 2.3131\n",
            "Epoch 3, Sample 12339: Loss: 0.6867\n",
            "Epoch 3, Sample 12340: Loss: 0.3949\n",
            "Epoch 3, Sample 12341: Loss: 0.0026\n",
            "Epoch 3, Sample 12342: Loss: 1.0155\n",
            "Epoch 3, Sample 12343: Loss: 14.4454\n",
            "Epoch 3, Sample 12344: Loss: 0.7036\n",
            "Epoch 3, Sample 12345: Loss: 0.0001\n",
            "Epoch 3, Sample 12346: Loss: 0.4930\n",
            "Epoch 3, Sample 12347: Loss: 0.7036\n",
            "Epoch 3, Sample 12348: Loss: 0.5196\n",
            "Epoch 3, Sample 12349: Loss: 0.2036\n",
            "Epoch 3, Sample 12350: Loss: 0.0407\n",
            "Epoch 3, Sample 12351: Loss: 1.0155\n",
            "Epoch 3, Sample 12352: Loss: 0.1463\n",
            "Epoch 3, Sample 12353: Loss: 0.6092\n",
            "Epoch 3, Sample 12354: Loss: 3.8613\n",
            "Epoch 3, Sample 12355: Loss: 0.0062\n",
            "Epoch 3, Sample 12356: Loss: 0.2832\n",
            "Epoch 3, Sample 12357: Loss: 0.5858\n",
            "Epoch 3, Sample 12358: Loss: 0.3949\n",
            "Epoch 3, Sample 12359: Loss: 0.0415\n",
            "Epoch 3, Sample 12360: Loss: 0.5261\n",
            "Epoch 3, Sample 12361: Loss: 0.0026\n",
            "Epoch 3, Sample 12362: Loss: 0.7036\n",
            "Epoch 3, Sample 12363: Loss: 0.0630\n",
            "Epoch 3, Sample 12364: Loss: 1.0266\n",
            "Epoch 3, Sample 12365: Loss: 0.0357\n",
            "Epoch 3, Sample 12366: Loss: 0.3402\n",
            "Epoch 3, Sample 12367: Loss: 0.0002\n",
            "Epoch 3, Sample 12368: Loss: 0.5952\n",
            "Epoch 3, Sample 12369: Loss: 1.0524\n",
            "Epoch 3, Sample 12370: Loss: 1.0155\n",
            "Epoch 3, Sample 12371: Loss: 0.1478\n",
            "Epoch 3, Sample 12372: Loss: 1.1252\n",
            "Epoch 3, Sample 12373: Loss: 1.6582\n",
            "Epoch 3, Sample 12374: Loss: 0.1508\n",
            "Epoch 3, Sample 12375: Loss: 0.0306\n",
            "Epoch 3, Sample 12376: Loss: 0.2034\n",
            "Epoch 3, Sample 12377: Loss: 0.2044\n",
            "Epoch 3, Sample 12378: Loss: 0.8484\n",
            "Epoch 3, Sample 12379: Loss: 7.6710\n",
            "Epoch 3, Sample 12380: Loss: 0.0026\n",
            "Epoch 3, Sample 12381: Loss: 0.2034\n",
            "Epoch 3, Sample 12382: Loss: 1.2596\n",
            "Epoch 3, Sample 12383: Loss: 0.1716\n",
            "Epoch 3, Sample 12384: Loss: 0.0013\n",
            "Epoch 3, Sample 12385: Loss: 2.2902\n",
            "Epoch 3, Sample 12386: Loss: 2.3159\n",
            "Epoch 3, Sample 12387: Loss: 0.7036\n",
            "Epoch 3, Sample 12388: Loss: 0.5972\n",
            "Epoch 3, Sample 12389: Loss: 0.4799\n",
            "Epoch 3, Sample 12390: Loss: 0.0018\n",
            "Epoch 3, Sample 12391: Loss: 0.3441\n",
            "Epoch 3, Sample 12392: Loss: 0.7036\n",
            "Epoch 3, Sample 12393: Loss: 0.8613\n",
            "Epoch 3, Sample 12394: Loss: 0.5737\n",
            "Epoch 3, Sample 12395: Loss: 1.0524\n",
            "Epoch 3, Sample 12396: Loss: 0.4841\n",
            "Epoch 3, Sample 12397: Loss: 0.5936\n",
            "Epoch 3, Sample 12398: Loss: 0.2759\n",
            "Epoch 3, Sample 12399: Loss: 0.1322\n",
            "Epoch 3, Sample 12400: Loss: 1.0155\n",
            "Epoch 3, Sample 12401: Loss: 0.1181\n",
            "Epoch 3, Sample 12402: Loss: 0.7702\n",
            "Epoch 3, Sample 12403: Loss: 0.0026\n",
            "Epoch 3, Sample 12404: Loss: 0.2989\n",
            "Epoch 3, Sample 12405: Loss: 0.1170\n",
            "Epoch 3, Sample 12406: Loss: 0.0860\n",
            "Epoch 3, Sample 12407: Loss: 1.0524\n",
            "Epoch 3, Sample 12408: Loss: 0.1588\n",
            "Epoch 3, Sample 12409: Loss: 0.0026\n",
            "Epoch 3, Sample 12410: Loss: 1.7195\n",
            "Epoch 3, Sample 12411: Loss: 0.1250\n",
            "Epoch 3, Sample 12412: Loss: 0.1881\n",
            "Epoch 3, Sample 12413: Loss: 1.0524\n",
            "Epoch 3, Sample 12414: Loss: 0.0018\n",
            "Epoch 3, Sample 12415: Loss: 0.0838\n",
            "Epoch 3, Sample 12416: Loss: 0.0314\n",
            "Epoch 3, Sample 12417: Loss: 0.5858\n",
            "Epoch 3, Sample 12418: Loss: 1.0530\n",
            "Epoch 3, Sample 12419: Loss: 0.4466\n",
            "Epoch 3, Sample 12420: Loss: 0.0915\n",
            "Epoch 3, Sample 12421: Loss: 1.2198\n",
            "Epoch 3, Sample 12422: Loss: 0.2699\n",
            "Epoch 3, Sample 12423: Loss: 0.1559\n",
            "Epoch 3, Sample 12424: Loss: 0.7036\n",
            "Epoch 3, Sample 12425: Loss: 0.3631\n",
            "Epoch 3, Sample 12426: Loss: 0.7110\n",
            "Epoch 3, Sample 12427: Loss: 0.0630\n",
            "Epoch 3, Sample 12428: Loss: 0.1372\n",
            "Epoch 3, Sample 12429: Loss: 0.2034\n",
            "Epoch 3, Sample 12430: Loss: 0.5972\n",
            "Epoch 3, Sample 12431: Loss: 0.1580\n",
            "Epoch 3, Sample 12432: Loss: 0.3399\n",
            "Epoch 3, Sample 12433: Loss: 2.6122\n",
            "Epoch 3, Sample 12434: Loss: 0.7036\n",
            "Epoch 3, Sample 12435: Loss: 0.4841\n",
            "Epoch 3, Sample 12436: Loss: 0.1559\n",
            "Epoch 3, Sample 12437: Loss: 0.2032\n",
            "Epoch 3, Sample 12438: Loss: 0.0026\n",
            "Epoch 3, Sample 12439: Loss: 0.2230\n",
            "Epoch 3, Sample 12440: Loss: 1.0155\n",
            "Epoch 3, Sample 12441: Loss: 1.0524\n",
            "Epoch 3, Sample 12442: Loss: 0.2200\n",
            "Epoch 3, Sample 12443: Loss: 0.0513\n",
            "Epoch 3, Sample 12444: Loss: 5.9680\n",
            "Epoch 3, Sample 12445: Loss: 0.1009\n",
            "Epoch 3, Sample 12446: Loss: 0.5003\n",
            "Epoch 3, Sample 12447: Loss: 0.3270\n",
            "Epoch 3, Sample 12448: Loss: 0.0147\n",
            "Epoch 3, Sample 12449: Loss: 1.0524\n",
            "Epoch 3, Sample 12450: Loss: 0.4032\n",
            "Epoch 3, Sample 12451: Loss: 0.0063\n",
            "Epoch 3, Sample 12452: Loss: 0.3949\n",
            "Epoch 3, Sample 12453: Loss: 0.8951\n",
            "Epoch 3, Sample 12454: Loss: 4.0002\n",
            "Epoch 3, Sample 12455: Loss: 1.5355\n",
            "Epoch 3, Sample 12456: Loss: 0.0005\n",
            "Epoch 3, Sample 12457: Loss: 0.0483\n",
            "Epoch 3, Sample 12458: Loss: 0.7036\n",
            "Epoch 3, Sample 12459: Loss: 0.8951\n",
            "Epoch 3, Sample 12460: Loss: 0.3949\n",
            "Epoch 3, Sample 12461: Loss: 0.7188\n",
            "Epoch 3, Sample 12462: Loss: 0.5972\n",
            "Epoch 3, Sample 12463: Loss: 0.5000\n",
            "Epoch 3, Sample 12464: Loss: 0.2238\n",
            "Epoch 3, Sample 12465: Loss: 0.6304\n",
            "Epoch 3, Sample 12466: Loss: 0.0205\n",
            "Epoch 3, Sample 12467: Loss: 0.2219\n",
            "Epoch 3, Sample 12468: Loss: 0.6338\n",
            "Epoch 3, Sample 12469: Loss: 0.0636\n",
            "Epoch 3, Sample 12470: Loss: 0.2034\n",
            "Epoch 3, Sample 12471: Loss: 0.6867\n",
            "Epoch 3, Sample 12472: Loss: 0.2044\n",
            "Epoch 3, Sample 12473: Loss: 0.2036\n",
            "Epoch 3, Sample 12474: Loss: 0.0041\n",
            "Epoch 3, Sample 12475: Loss: 0.9367\n",
            "Epoch 3, Sample 12476: Loss: 0.7453\n",
            "Epoch 3, Sample 12477: Loss: 0.0364\n",
            "Epoch 3, Sample 12478: Loss: 0.1044\n",
            "Epoch 3, Sample 12479: Loss: 0.0744\n",
            "Epoch 3, Sample 12480: Loss: 0.2112\n",
            "Epoch 3, Sample 12481: Loss: 2.4715\n",
            "Epoch 3, Sample 12482: Loss: 0.4367\n",
            "Epoch 3, Sample 12483: Loss: 0.2036\n",
            "Epoch 3, Sample 12484: Loss: 0.3402\n",
            "Epoch 3, Sample 12485: Loss: 0.1842\n",
            "Epoch 3, Sample 12486: Loss: 0.4906\n",
            "Epoch 3, Sample 12487: Loss: 0.4930\n",
            "Epoch 3, Sample 12488: Loss: 0.0622\n",
            "Epoch 3, Sample 12489: Loss: 0.0635\n",
            "Epoch 3, Sample 12490: Loss: 0.7036\n",
            "Epoch 3, Sample 12491: Loss: 0.0108\n",
            "Epoch 3, Sample 12492: Loss: 0.7036\n",
            "Epoch 3, Sample 12493: Loss: 0.2044\n",
            "Epoch 3, Sample 12494: Loss: 1.0530\n",
            "Epoch 3, Sample 12495: Loss: 0.2759\n",
            "Epoch 3, Sample 12496: Loss: 0.1915\n",
            "Epoch 3, Sample 12497: Loss: 0.1170\n",
            "Epoch 3, Sample 12498: Loss: 0.2034\n",
            "Epoch 3, Sample 12499: Loss: 0.7036\n",
            "Epoch 3, Sample 12500: Loss: 0.5816\n",
            "Epoch 3, Sample 12501: Loss: 0.0018\n",
            "Epoch 3, Sample 12502: Loss: 3.3308\n",
            "Epoch 3, Sample 12503: Loss: 0.1594\n",
            "Epoch 3, Sample 12504: Loss: 0.3237\n",
            "Epoch 3, Sample 12505: Loss: 0.0108\n",
            "Epoch 3, Sample 12506: Loss: 0.1219\n",
            "Epoch 3, Sample 12507: Loss: 0.0076\n",
            "Epoch 3, Sample 12508: Loss: 0.2941\n",
            "Epoch 3, Sample 12509: Loss: 0.2044\n",
            "Epoch 3, Sample 12510: Loss: 0.4611\n",
            "Epoch 3, Sample 12511: Loss: 0.2340\n",
            "Epoch 3, Sample 12512: Loss: 0.1114\n",
            "Epoch 3, Sample 12513: Loss: 0.1056\n",
            "Epoch 3, Sample 12514: Loss: 0.7036\n",
            "Epoch 3, Sample 12515: Loss: 1.0524\n",
            "Epoch 3, Sample 12516: Loss: 0.0026\n",
            "Epoch 3, Sample 12517: Loss: 0.1248\n",
            "Epoch 3, Sample 12518: Loss: 0.0409\n",
            "Epoch 3, Sample 12519: Loss: 0.0004\n",
            "Epoch 3, Sample 12520: Loss: 0.0651\n",
            "Epoch 3, Sample 12521: Loss: 0.0013\n",
            "Epoch 3, Sample 12522: Loss: 0.0031\n",
            "Epoch 3, Sample 12523: Loss: 0.2077\n",
            "Epoch 3, Sample 12524: Loss: 0.3399\n",
            "Epoch 3, Sample 12525: Loss: 0.9367\n",
            "Epoch 3, Sample 12526: Loss: 0.3032\n",
            "Epoch 3, Sample 12527: Loss: 1.0524\n",
            "Epoch 3, Sample 12528: Loss: 0.3399\n",
            "Epoch 3, Sample 12529: Loss: 5.4386\n",
            "Epoch 3, Sample 12530: Loss: 0.2363\n",
            "Epoch 3, Sample 12531: Loss: 0.0035\n",
            "Epoch 3, Sample 12532: Loss: 0.0212\n",
            "Epoch 3, Sample 12533: Loss: 0.0027\n",
            "Epoch 3, Sample 12534: Loss: 1.0155\n",
            "Epoch 3, Sample 12535: Loss: 0.1259\n",
            "Epoch 3, Sample 12536: Loss: 0.3539\n",
            "Epoch 3, Sample 12537: Loss: 0.3402\n",
            "Epoch 3, Sample 12538: Loss: 0.8951\n",
            "Epoch 3, Sample 12539: Loss: 0.1170\n",
            "Epoch 3, Sample 12540: Loss: 0.2855\n",
            "Epoch 3, Sample 12541: Loss: 0.2044\n",
            "Epoch 3, Sample 12542: Loss: 0.1250\n",
            "Epoch 3, Sample 12543: Loss: 0.0938\n",
            "Epoch 3, Sample 12544: Loss: 0.7036\n",
            "Epoch 3, Sample 12545: Loss: 1.0524\n",
            "Epoch 3, Sample 12546: Loss: 1.2926\n",
            "Epoch 3, Sample 12547: Loss: 0.0938\n",
            "Epoch 3, Sample 12548: Loss: 0.1355\n",
            "Epoch 3, Sample 12549: Loss: 1.0293\n",
            "Epoch 3, Sample 12550: Loss: 0.0000\n",
            "Epoch 3, Sample 12551: Loss: 2.0233\n",
            "Epoch 3, Sample 12552: Loss: 0.0013\n",
            "Epoch 3, Sample 12553: Loss: 0.2044\n",
            "Epoch 3, Sample 12554: Loss: 0.1022\n",
            "Epoch 3, Sample 12555: Loss: 0.1350\n",
            "Epoch 3, Sample 12556: Loss: 0.0026\n",
            "Epoch 3, Sample 12557: Loss: 0.1233\n",
            "Epoch 3, Sample 12558: Loss: 0.1250\n",
            "Epoch 3, Sample 12559: Loss: 0.0001\n",
            "Epoch 3, Sample 12560: Loss: 0.7833\n",
            "Epoch 3, Sample 12561: Loss: 0.1250\n",
            "Epoch 3, Sample 12562: Loss: 0.0091\n",
            "Epoch 3, Sample 12563: Loss: 0.0399\n",
            "Epoch 3, Sample 12564: Loss: 0.0039\n",
            "Epoch 3, Sample 12565: Loss: 0.2277\n",
            "Epoch 3, Sample 12566: Loss: 0.2326\n",
            "Epoch 3, Sample 12567: Loss: 0.1508\n",
            "Epoch 3, Sample 12568: Loss: 0.7036\n",
            "Epoch 3, Sample 12569: Loss: 0.5283\n",
            "Epoch 3, Sample 12570: Loss: 0.0108\n",
            "Epoch 3, Sample 12571: Loss: 0.0007\n",
            "Epoch 3, Sample 12572: Loss: 0.0106\n",
            "Epoch 3, Sample 12573: Loss: 0.1288\n",
            "Epoch 3, Sample 12574: Loss: 3.2134\n",
            "Epoch 3, Sample 12575: Loss: 0.2034\n",
            "Epoch 3, Sample 12576: Loss: 0.0088\n",
            "Epoch 3, Sample 12577: Loss: 0.0466\n",
            "Epoch 3, Sample 12578: Loss: 0.7341\n",
            "Epoch 3, Sample 12579: Loss: 0.0205\n",
            "Epoch 3, Sample 12580: Loss: 0.0108\n",
            "Epoch 3, Sample 12581: Loss: 0.2989\n",
            "Epoch 3, Sample 12582: Loss: 0.0063\n",
            "Epoch 3, Sample 12583: Loss: 1.0524\n",
            "Epoch 3, Sample 12584: Loss: 0.0026\n",
            "Epoch 3, Sample 12585: Loss: 0.2160\n",
            "Epoch 3, Sample 12586: Loss: 0.5150\n",
            "Epoch 3, Sample 12587: Loss: 0.6521\n",
            "Epoch 3, Sample 12588: Loss: 1.0524\n",
            "Epoch 3, Sample 12589: Loss: 0.0055\n",
            "Epoch 3, Sample 12590: Loss: 0.1020\n",
            "Epoch 3, Sample 12591: Loss: 0.0630\n",
            "Epoch 3, Sample 12592: Loss: 0.1196\n",
            "Epoch 3, Sample 12593: Loss: 0.0378\n",
            "Epoch 3, Sample 12594: Loss: 0.9367\n",
            "Epoch 3, Sample 12595: Loss: 0.0077\n",
            "Epoch 3, Sample 12596: Loss: 0.2034\n",
            "Epoch 3, Sample 12597: Loss: 2.4326\n",
            "Epoch 3, Sample 12598: Loss: 0.2759\n",
            "Epoch 3, Sample 12599: Loss: 0.7453\n",
            "Epoch 3, Sample 12600: Loss: 0.4857\n",
            "Epoch 3, Sample 12601: Loss: 0.0022\n",
            "Epoch 3, Sample 12602: Loss: 1.0524\n",
            "Epoch 3, Sample 12603: Loss: 6.8279\n",
            "Epoch 3, Sample 12604: Loss: 0.0026\n",
            "Epoch 3, Sample 12605: Loss: 0.7036\n",
            "Epoch 3, Sample 12606: Loss: 0.0525\n",
            "Epoch 3, Sample 12607: Loss: 0.0052\n",
            "Epoch 3, Sample 12608: Loss: 0.1225\n",
            "Epoch 3, Sample 12609: Loss: 1.3034\n",
            "Epoch 3, Sample 12610: Loss: 1.0850\n",
            "Epoch 3, Sample 12611: Loss: 0.0205\n",
            "Epoch 3, Sample 12612: Loss: 0.2034\n",
            "Epoch 3, Sample 12613: Loss: 0.0221\n",
            "Epoch 3, Sample 12614: Loss: 0.0604\n",
            "Epoch 3, Sample 12615: Loss: 0.0004\n",
            "Epoch 3, Sample 12616: Loss: 2.7418\n",
            "Epoch 3, Sample 12617: Loss: 0.2044\n",
            "Epoch 3, Sample 12618: Loss: 0.2811\n",
            "Epoch 3, Sample 12619: Loss: 0.1170\n",
            "Epoch 3, Sample 12620: Loss: 0.2759\n",
            "Epoch 3, Sample 12621: Loss: 0.2044\n",
            "Epoch 3, Sample 12622: Loss: 0.5858\n",
            "Epoch 3, Sample 12623: Loss: 0.0306\n",
            "Epoch 3, Sample 12624: Loss: 1.6309\n",
            "Epoch 3, Sample 12625: Loss: 0.2962\n",
            "Epoch 3, Sample 12626: Loss: 0.3441\n",
            "Epoch 3, Sample 12627: Loss: 0.0028\n",
            "Epoch 3, Sample 12628: Loss: 0.1549\n",
            "Epoch 3, Sample 12629: Loss: 0.2032\n",
            "Epoch 3, Sample 12630: Loss: 0.0128\n",
            "Epoch 3, Sample 12631: Loss: 0.9367\n",
            "Epoch 3, Sample 12632: Loss: 0.2034\n",
            "Epoch 3, Sample 12633: Loss: 0.0099\n",
            "Epoch 3, Sample 12634: Loss: 0.0363\n",
            "Epoch 3, Sample 12635: Loss: 0.1523\n",
            "Epoch 3, Sample 12636: Loss: 0.0513\n",
            "Epoch 3, Sample 12637: Loss: 0.1214\n",
            "Epoch 3, Sample 12638: Loss: 0.2044\n",
            "Epoch 3, Sample 12639: Loss: 0.1441\n",
            "Epoch 3, Sample 12640: Loss: 0.0063\n",
            "Epoch 3, Sample 12641: Loss: 0.2871\n",
            "Epoch 3, Sample 12642: Loss: 0.1777\n",
            "Epoch 3, Sample 12643: Loss: 0.1371\n",
            "Epoch 3, Sample 12644: Loss: 1.0524\n",
            "Epoch 3, Sample 12645: Loss: 0.3568\n",
            "Epoch 3, Sample 12646: Loss: 0.7453\n",
            "Epoch 3, Sample 12647: Loss: 0.0062\n",
            "Epoch 3, Sample 12648: Loss: 0.1139\n",
            "Epoch 3, Sample 12649: Loss: 0.0630\n",
            "Epoch 3, Sample 12650: Loss: 0.4611\n",
            "Epoch 3, Sample 12651: Loss: 0.1692\n",
            "Epoch 3, Sample 12652: Loss: 0.2044\n",
            "Epoch 3, Sample 12653: Loss: 0.0431\n",
            "Epoch 3, Sample 12654: Loss: 1.0155\n",
            "Epoch 3, Sample 12655: Loss: 2.9556\n",
            "Epoch 3, Sample 12656: Loss: 1.0227\n",
            "Epoch 3, Sample 12657: Loss: 0.3441\n",
            "Epoch 3, Sample 12658: Loss: 0.4841\n",
            "Epoch 3, Sample 12659: Loss: 0.1546\n",
            "Epoch 3, Sample 12660: Loss: 0.4930\n",
            "Epoch 3, Sample 12661: Loss: 0.0018\n",
            "Epoch 3, Sample 12662: Loss: 1.2942\n",
            "Epoch 3, Sample 12663: Loss: 0.0212\n",
            "Epoch 3, Sample 12664: Loss: 0.1546\n",
            "Epoch 3, Sample 12665: Loss: 0.3399\n",
            "Epoch 3, Sample 12666: Loss: 1.2597\n",
            "Epoch 3, Sample 12667: Loss: 1.0530\n",
            "Epoch 3, Sample 12668: Loss: 0.0084\n",
            "Epoch 3, Sample 12669: Loss: 0.0633\n",
            "Epoch 3, Sample 12670: Loss: 0.0028\n",
            "Epoch 3, Sample 12671: Loss: 0.5858\n",
            "Epoch 3, Sample 12672: Loss: 0.0606\n",
            "Epoch 3, Sample 12673: Loss: 0.7453\n",
            "Epoch 3, Sample 12674: Loss: 0.0001\n",
            "Epoch 3, Sample 12675: Loss: 0.5799\n",
            "Epoch 3, Sample 12676: Loss: 0.4677\n",
            "Epoch 3, Sample 12677: Loss: 1.2351\n",
            "Epoch 3, Sample 12678: Loss: 0.3399\n",
            "Epoch 3, Sample 12679: Loss: 0.2032\n",
            "Epoch 3, Sample 12680: Loss: 3.8897\n",
            "Epoch 3, Sample 12681: Loss: 1.0524\n",
            "Epoch 3, Sample 12682: Loss: 0.3441\n",
            "Epoch 3, Sample 12683: Loss: 0.1863\n",
            "Epoch 3, Sample 12684: Loss: 0.0840\n",
            "Epoch 3, Sample 12685: Loss: 0.1555\n",
            "Epoch 3, Sample 12686: Loss: 7.1604\n",
            "Epoch 3, Sample 12687: Loss: 0.0267\n",
            "Epoch 3, Sample 12688: Loss: 0.2032\n",
            "Epoch 3, Sample 12689: Loss: 1.0524\n",
            "Epoch 3, Sample 12690: Loss: 0.2032\n",
            "Epoch 3, Sample 12691: Loss: 0.1250\n",
            "Epoch 3, Sample 12692: Loss: 0.0234\n",
            "Epoch 3, Sample 12693: Loss: 0.2219\n",
            "Epoch 3, Sample 12694: Loss: 0.2962\n",
            "Epoch 3, Sample 12695: Loss: 0.9367\n",
            "Epoch 3, Sample 12696: Loss: 0.5858\n",
            "Epoch 3, Sample 12697: Loss: 0.2044\n",
            "Epoch 3, Sample 12698: Loss: 6.2773\n",
            "Epoch 3, Sample 12699: Loss: 0.4799\n",
            "Epoch 3, Sample 12700: Loss: 0.2036\n",
            "Epoch 3, Sample 12701: Loss: 1.5356\n",
            "Epoch 3, Sample 12702: Loss: 5.6432\n",
            "Epoch 3, Sample 12703: Loss: 1.1271\n",
            "Epoch 3, Sample 12704: Loss: 1.0530\n",
            "Epoch 3, Sample 12705: Loss: 0.1248\n",
            "Epoch 3, Sample 12706: Loss: 0.2832\n",
            "Epoch 3, Sample 12707: Loss: 0.8951\n",
            "Epoch 3, Sample 12708: Loss: 0.1952\n",
            "Epoch 3, Sample 12709: Loss: 0.1394\n",
            "Epoch 3, Sample 12710: Loss: 0.2034\n",
            "Epoch 3, Sample 12711: Loss: 0.0630\n",
            "Epoch 3, Sample 12712: Loss: 0.2935\n",
            "Epoch 3, Sample 12713: Loss: 0.0086\n",
            "Epoch 3, Sample 12714: Loss: 0.0018\n",
            "Epoch 3, Sample 12715: Loss: 0.2044\n",
            "Epoch 3, Sample 12716: Loss: 0.0026\n",
            "Epoch 3, Sample 12717: Loss: 0.6990\n",
            "Epoch 3, Sample 12718: Loss: 1.0524\n",
            "Epoch 3, Sample 12719: Loss: 0.7702\n",
            "Epoch 3, Sample 12720: Loss: 0.0002\n",
            "Epoch 3, Sample 12721: Loss: 2.7606\n",
            "Epoch 3, Sample 12722: Loss: 0.4220\n",
            "Epoch 3, Sample 12723: Loss: 0.2750\n",
            "Epoch 3, Sample 12724: Loss: 0.5019\n",
            "Epoch 3, Sample 12725: Loss: 0.7036\n",
            "Epoch 3, Sample 12726: Loss: 0.7453\n",
            "Epoch 3, Sample 12727: Loss: 0.1554\n",
            "Epoch 3, Sample 12728: Loss: 0.0730\n",
            "Epoch 3, Sample 12729: Loss: 1.0155\n",
            "Epoch 3, Sample 12730: Loss: 2.6252\n",
            "Epoch 3, Sample 12731: Loss: 0.0878\n",
            "Epoch 3, Sample 12732: Loss: 0.0981\n",
            "Epoch 3, Sample 12733: Loss: 0.0460\n",
            "Epoch 3, Sample 12734: Loss: 0.4668\n",
            "Epoch 3, Sample 12735: Loss: 0.0558\n",
            "Epoch 3, Sample 12736: Loss: 0.5042\n",
            "Epoch 3, Sample 12737: Loss: 0.0640\n",
            "Epoch 3, Sample 12738: Loss: 0.7284\n",
            "Epoch 3, Sample 12739: Loss: 0.5411\n",
            "Epoch 3, Sample 12740: Loss: 1.8376\n",
            "Epoch 3, Sample 12741: Loss: 0.2832\n",
            "Epoch 3, Sample 12742: Loss: 0.2639\n",
            "Epoch 3, Sample 12743: Loss: 0.0130\n",
            "Epoch 3, Sample 12744: Loss: 1.0524\n",
            "Epoch 3, Sample 12745: Loss: 0.0874\n",
            "Epoch 3, Sample 12746: Loss: 0.0026\n",
            "Epoch 3, Sample 12747: Loss: 1.1300\n",
            "Epoch 3, Sample 12748: Loss: 0.0731\n",
            "Epoch 3, Sample 12749: Loss: 0.0018\n",
            "Epoch 3, Sample 12750: Loss: 1.0155\n",
            "Epoch 3, Sample 12751: Loss: 0.5858\n",
            "Epoch 3, Sample 12752: Loss: 0.1250\n",
            "Epoch 3, Sample 12753: Loss: 1.2484\n",
            "Epoch 3, Sample 12754: Loss: 0.9929\n",
            "Epoch 3, Sample 12755: Loss: 0.3399\n",
            "Epoch 3, Sample 12756: Loss: 0.1040\n",
            "Epoch 3, Sample 12757: Loss: 0.0590\n",
            "Epoch 3, Sample 12758: Loss: 1.0511\n",
            "Epoch 3, Sample 12759: Loss: 0.1337\n",
            "Epoch 3, Sample 12760: Loss: 0.1170\n",
            "Epoch 3, Sample 12761: Loss: 0.2112\n",
            "Epoch 3, Sample 12762: Loss: 0.3477\n",
            "Epoch 3, Sample 12763: Loss: 0.2132\n",
            "Epoch 3, Sample 12764: Loss: 0.2034\n",
            "Epoch 3, Sample 12765: Loss: 1.9658\n",
            "Epoch 3, Sample 12766: Loss: 1.1088\n",
            "Epoch 3, Sample 12767: Loss: 2.6305\n",
            "Epoch 3, Sample 12768: Loss: 0.2044\n",
            "Epoch 3, Sample 12769: Loss: 0.0205\n",
            "Epoch 3, Sample 12770: Loss: 0.0274\n",
            "Epoch 3, Sample 12771: Loss: 1.0155\n",
            "Epoch 3, Sample 12772: Loss: 0.0491\n",
            "Epoch 3, Sample 12773: Loss: 0.3399\n",
            "Epoch 3, Sample 12774: Loss: 0.6295\n",
            "Epoch 3, Sample 12775: Loss: 0.2036\n",
            "Epoch 3, Sample 12776: Loss: 0.9450\n",
            "Epoch 3, Sample 12777: Loss: 1.0530\n",
            "Epoch 3, Sample 12778: Loss: 0.7798\n",
            "Epoch 3, Sample 12779: Loss: 0.5858\n",
            "Epoch 3, Sample 12780: Loss: 0.3060\n",
            "Epoch 3, Sample 12781: Loss: 0.0215\n",
            "Epoch 3, Sample 12782: Loss: 1.0155\n",
            "Epoch 3, Sample 12783: Loss: 0.3568\n",
            "Epoch 3, Sample 12784: Loss: 0.2835\n",
            "Epoch 3, Sample 12785: Loss: 0.2175\n",
            "Epoch 3, Sample 12786: Loss: 0.2832\n",
            "Epoch 3, Sample 12787: Loss: 0.1126\n",
            "Epoch 3, Sample 12788: Loss: 0.7036\n",
            "Epoch 3, Sample 12789: Loss: 0.7036\n",
            "Epoch 3, Sample 12790: Loss: 1.0530\n",
            "Epoch 3, Sample 12791: Loss: 0.2204\n",
            "Epoch 3, Sample 12792: Loss: 0.9367\n",
            "Epoch 3, Sample 12793: Loss: 0.5196\n",
            "Epoch 3, Sample 12794: Loss: 0.2759\n",
            "Epoch 3, Sample 12795: Loss: 0.7036\n",
            "Epoch 3, Sample 12796: Loss: 0.0018\n",
            "Epoch 3, Sample 12797: Loss: 0.1252\n",
            "Epoch 3, Sample 12798: Loss: 0.2044\n",
            "Epoch 3, Sample 12799: Loss: 0.7036\n",
            "Epoch 3, Sample 12800: Loss: 0.2036\n",
            "Epoch 3, Sample 12801: Loss: 0.3402\n",
            "Epoch 3, Sample 12802: Loss: 0.3367\n",
            "Epoch 3, Sample 12803: Loss: 0.0067\n",
            "Epoch 3, Sample 12804: Loss: 0.2639\n",
            "Epoch 3, Sample 12805: Loss: 0.0615\n",
            "Epoch 3, Sample 12806: Loss: 0.0177\n",
            "Epoch 3, Sample 12807: Loss: 0.2032\n",
            "Epoch 3, Sample 12808: Loss: 0.2219\n",
            "Epoch 3, Sample 12809: Loss: 0.1246\n",
            "Epoch 3, Sample 12810: Loss: 1.0892\n",
            "Epoch 3, Sample 12811: Loss: 0.2034\n",
            "Epoch 3, Sample 12812: Loss: 0.5858\n",
            "Epoch 3, Sample 12813: Loss: 0.0224\n",
            "Epoch 3, Sample 12814: Loss: 0.2032\n",
            "Epoch 3, Sample 12815: Loss: 0.8951\n",
            "Epoch 3, Sample 12816: Loss: 0.4032\n",
            "Epoch 3, Sample 12817: Loss: 1.0155\n",
            "Epoch 3, Sample 12818: Loss: 0.0205\n",
            "Epoch 3, Sample 12819: Loss: 0.0108\n",
            "Epoch 3, Sample 12820: Loss: 0.2074\n",
            "Epoch 3, Sample 12821: Loss: 0.0173\n",
            "Epoch 3, Sample 12822: Loss: 0.2032\n",
            "Epoch 3, Sample 12823: Loss: 0.1199\n",
            "Epoch 3, Sample 12824: Loss: 0.1508\n",
            "Epoch 3, Sample 12825: Loss: 0.0714\n",
            "Epoch 3, Sample 12826: Loss: 0.2340\n",
            "Epoch 3, Sample 12827: Loss: 0.2032\n",
            "Epoch 3, Sample 12828: Loss: 0.2832\n",
            "Epoch 3, Sample 12829: Loss: 0.5858\n",
            "Epoch 3, Sample 12830: Loss: 0.0287\n",
            "Epoch 3, Sample 12831: Loss: 0.5924\n",
            "Epoch 3, Sample 12832: Loss: 0.2732\n",
            "Epoch 3, Sample 12833: Loss: 0.0031\n",
            "Epoch 3, Sample 12834: Loss: 0.0026\n",
            "Epoch 3, Sample 12835: Loss: 0.2290\n",
            "Epoch 3, Sample 12836: Loss: 0.0004\n",
            "Epoch 3, Sample 12837: Loss: 0.3279\n",
            "Epoch 3, Sample 12838: Loss: 0.5912\n",
            "Epoch 3, Sample 12839: Loss: 0.3945\n",
            "Epoch 3, Sample 12840: Loss: 0.2935\n",
            "Epoch 3, Sample 12841: Loss: 0.8038\n",
            "Epoch 3, Sample 12842: Loss: 0.0306\n",
            "Epoch 3, Sample 12843: Loss: 0.2032\n",
            "Epoch 3, Sample 12844: Loss: 0.0026\n",
            "Epoch 3, Sample 12845: Loss: 0.7036\n",
            "Epoch 3, Sample 12846: Loss: 0.5972\n",
            "Epoch 3, Sample 12847: Loss: 0.1559\n",
            "Epoch 3, Sample 12848: Loss: 0.0391\n",
            "Epoch 3, Sample 12849: Loss: 0.0915\n",
            "Epoch 3, Sample 12850: Loss: 0.4032\n",
            "Epoch 3, Sample 12851: Loss: 0.0306\n",
            "Epoch 3, Sample 12852: Loss: 0.7272\n",
            "Epoch 3, Sample 12853: Loss: 1.3676\n",
            "Epoch 3, Sample 12854: Loss: 0.2044\n",
            "Epoch 3, Sample 12855: Loss: 0.3441\n",
            "Epoch 3, Sample 12856: Loss: 0.0373\n",
            "Epoch 3, Sample 12857: Loss: 0.2032\n",
            "Epoch 3, Sample 12858: Loss: 0.4996\n",
            "Epoch 3, Sample 12859: Loss: 0.1252\n",
            "Epoch 3, Sample 12860: Loss: 0.0001\n",
            "Epoch 3, Sample 12861: Loss: 0.0002\n",
            "Epoch 3, Sample 12862: Loss: 0.8951\n",
            "Epoch 3, Sample 12863: Loss: 0.1250\n",
            "Epoch 3, Sample 12864: Loss: 0.0212\n",
            "Epoch 3, Sample 12865: Loss: 0.0680\n",
            "Epoch 3, Sample 12866: Loss: 0.0013\n",
            "Epoch 3, Sample 12867: Loss: 0.0160\n",
            "Epoch 3, Sample 12868: Loss: 0.2935\n",
            "Epoch 3, Sample 12869: Loss: 0.1639\n",
            "Epoch 3, Sample 12870: Loss: 0.8951\n",
            "Epoch 3, Sample 12871: Loss: 0.0205\n",
            "Epoch 3, Sample 12872: Loss: 0.8951\n",
            "Epoch 3, Sample 12873: Loss: 0.2032\n",
            "Epoch 3, Sample 12874: Loss: 0.6304\n",
            "Epoch 3, Sample 12875: Loss: 0.0108\n",
            "Epoch 3, Sample 12876: Loss: 0.4428\n",
            "Epoch 3, Sample 12877: Loss: 0.5695\n",
            "Epoch 3, Sample 12878: Loss: 1.0435\n",
            "Epoch 3, Sample 12879: Loss: 2.3797\n",
            "Epoch 3, Sample 12880: Loss: 0.7453\n",
            "Epoch 3, Sample 12881: Loss: 0.7793\n",
            "Epoch 3, Sample 12882: Loss: 0.4032\n",
            "Epoch 3, Sample 12883: Loss: 0.2034\n",
            "Epoch 3, Sample 12884: Loss: 0.9367\n",
            "Epoch 3, Sample 12885: Loss: 0.0252\n",
            "Epoch 3, Sample 12886: Loss: 0.2044\n",
            "Epoch 3, Sample 12887: Loss: 0.0026\n",
            "Epoch 3, Sample 12888: Loss: 0.7453\n",
            "Epoch 3, Sample 12889: Loss: 0.2832\n",
            "Epoch 3, Sample 12890: Loss: 0.0201\n",
            "Epoch 3, Sample 12891: Loss: 0.5858\n",
            "Epoch 3, Sample 12892: Loss: 0.5989\n",
            "Epoch 3, Sample 12893: Loss: 1.0524\n",
            "Epoch 3, Sample 12894: Loss: 0.0838\n",
            "Epoch 3, Sample 12895: Loss: 1.1707\n",
            "Epoch 3, Sample 12896: Loss: 0.2832\n",
            "Epoch 3, Sample 12897: Loss: 0.0011\n",
            "Epoch 3, Sample 12898: Loss: 0.0052\n",
            "Epoch 3, Sample 12899: Loss: 0.1786\n",
            "Epoch 3, Sample 12900: Loss: 1.0524\n",
            "Epoch 3, Sample 12901: Loss: 0.2647\n",
            "Epoch 3, Sample 12902: Loss: 0.0205\n",
            "Epoch 3, Sample 12903: Loss: 0.0049\n",
            "Epoch 3, Sample 12904: Loss: 0.1482\n",
            "Epoch 3, Sample 12905: Loss: 0.5972\n",
            "Epoch 3, Sample 12906: Loss: 1.0266\n",
            "Epoch 3, Sample 12907: Loss: 1.5268\n",
            "Epoch 3, Sample 12908: Loss: 0.2747\n",
            "Epoch 3, Sample 12909: Loss: 0.0001\n",
            "Epoch 3, Sample 12910: Loss: 0.0026\n",
            "Epoch 3, Sample 12911: Loss: 0.3288\n",
            "Epoch 3, Sample 12912: Loss: 0.1349\n",
            "Epoch 3, Sample 12913: Loss: 0.2322\n",
            "Epoch 3, Sample 12914: Loss: 0.5430\n",
            "Epoch 3, Sample 12915: Loss: 0.1508\n",
            "Epoch 3, Sample 12916: Loss: 0.7036\n",
            "Epoch 3, Sample 12917: Loss: 0.0018\n",
            "Epoch 3, Sample 12918: Loss: 0.0498\n",
            "Epoch 3, Sample 12919: Loss: 0.3247\n",
            "Epoch 3, Sample 12920: Loss: 0.5972\n",
            "Epoch 3, Sample 12921: Loss: 0.2219\n",
            "Epoch 3, Sample 12922: Loss: 0.6208\n",
            "Epoch 3, Sample 12923: Loss: 0.2132\n",
            "Epoch 3, Sample 12924: Loss: 0.2913\n",
            "Epoch 3, Sample 12925: Loss: 0.8509\n",
            "Epoch 3, Sample 12926: Loss: 0.2759\n",
            "Epoch 3, Sample 12927: Loss: 0.6304\n",
            "Epoch 3, Sample 12928: Loss: 0.0287\n",
            "Epoch 3, Sample 12929: Loss: 0.1170\n",
            "Epoch 3, Sample 12930: Loss: 0.1559\n",
            "Epoch 3, Sample 12931: Loss: 0.0028\n",
            "Epoch 3, Sample 12932: Loss: 0.5039\n",
            "Epoch 3, Sample 12933: Loss: 0.2034\n",
            "Epoch 3, Sample 12934: Loss: 1.0155\n",
            "Epoch 3, Sample 12935: Loss: 0.1356\n",
            "Epoch 3, Sample 12936: Loss: 0.2968\n",
            "Epoch 3, Sample 12937: Loss: 0.1982\n",
            "Epoch 3, Sample 12938: Loss: 0.0626\n",
            "Epoch 3, Sample 12939: Loss: 0.1559\n",
            "Epoch 3, Sample 12940: Loss: 1.2774\n",
            "Epoch 3, Sample 12941: Loss: 0.1588\n",
            "Epoch 3, Sample 12942: Loss: 0.1523\n",
            "Epoch 3, Sample 12943: Loss: 0.4799\n",
            "Epoch 3, Sample 12944: Loss: 0.4387\n",
            "Epoch 3, Sample 12945: Loss: 0.0972\n",
            "Epoch 3, Sample 12946: Loss: 0.0142\n",
            "Epoch 3, Sample 12947: Loss: 0.2182\n",
            "Epoch 3, Sample 12948: Loss: 0.4611\n",
            "Epoch 3, Sample 12949: Loss: 0.0108\n",
            "Epoch 3, Sample 12950: Loss: 0.0018\n",
            "Epoch 3, Sample 12951: Loss: 0.0915\n",
            "Epoch 3, Sample 12952: Loss: 0.5858\n",
            "Epoch 3, Sample 12953: Loss: 1.0573\n",
            "Epoch 3, Sample 12954: Loss: 1.0155\n",
            "Epoch 3, Sample 12955: Loss: 0.0310\n",
            "Epoch 3, Sample 12956: Loss: 0.2074\n",
            "Epoch 3, Sample 12957: Loss: 0.1432\n",
            "Epoch 3, Sample 12958: Loss: 0.3441\n",
            "Epoch 3, Sample 12959: Loss: 0.0018\n",
            "Epoch 3, Sample 12960: Loss: 0.2032\n",
            "Epoch 3, Sample 12961: Loss: 0.8951\n",
            "Epoch 3, Sample 12962: Loss: 0.0270\n",
            "Epoch 3, Sample 12963: Loss: 4.8497\n",
            "Epoch 3, Sample 12964: Loss: 0.6115\n",
            "Epoch 3, Sample 12965: Loss: 0.2044\n",
            "Epoch 3, Sample 12966: Loss: 4.6072\n",
            "Epoch 3, Sample 12967: Loss: 0.1248\n",
            "Epoch 3, Sample 12968: Loss: 0.1250\n",
            "Epoch 3, Sample 12969: Loss: 0.0363\n",
            "Epoch 3, Sample 12970: Loss: 0.2032\n",
            "Epoch 3, Sample 12971: Loss: 0.7393\n",
            "Epoch 3, Sample 12972: Loss: 0.2044\n",
            "Epoch 3, Sample 12973: Loss: 0.5858\n",
            "Epoch 3, Sample 12974: Loss: 0.0202\n",
            "Epoch 3, Sample 12975: Loss: 0.4611\n",
            "Epoch 3, Sample 12976: Loss: 0.0287\n",
            "Epoch 3, Sample 12977: Loss: 1.0524\n",
            "Epoch 3, Sample 12978: Loss: 0.2750\n",
            "Epoch 3, Sample 12979: Loss: 0.1170\n",
            "Epoch 3, Sample 12980: Loss: 0.2044\n",
            "Epoch 3, Sample 12981: Loss: 0.6990\n",
            "Epoch 3, Sample 12982: Loss: 0.7246\n",
            "Epoch 3, Sample 12983: Loss: 0.5972\n",
            "Epoch 3, Sample 12984: Loss: 1.0524\n",
            "Epoch 3, Sample 12985: Loss: 0.1250\n",
            "Epoch 3, Sample 12986: Loss: 0.8685\n",
            "Epoch 3, Sample 12987: Loss: 0.0005\n",
            "Epoch 3, Sample 12988: Loss: 0.1687\n",
            "Epoch 3, Sample 12989: Loss: 0.2759\n",
            "Epoch 3, Sample 12990: Loss: 0.3339\n",
            "Epoch 3, Sample 12991: Loss: 0.1250\n",
            "Epoch 3, Sample 12992: Loss: 0.3399\n",
            "Epoch 3, Sample 12993: Loss: 0.7943\n",
            "Epoch 3, Sample 12994: Loss: 0.6264\n",
            "Epoch 3, Sample 12995: Loss: 0.1290\n",
            "Epoch 3, Sample 12996: Loss: 0.7036\n",
            "Epoch 3, Sample 12997: Loss: 0.0026\n",
            "Epoch 3, Sample 12998: Loss: 1.0524\n",
            "Epoch 3, Sample 12999: Loss: 0.0062\n",
            "Epoch 3, Sample 13000: Loss: 0.1559\n",
            "Epoch 3, Sample 13001: Loss: 0.2044\n",
            "Epoch 3, Sample 13002: Loss: 1.0415\n",
            "Epoch 3, Sample 13003: Loss: 1.0155\n",
            "Epoch 3, Sample 13004: Loss: 1.1492\n",
            "Epoch 3, Sample 13005: Loss: 0.0026\n",
            "Epoch 3, Sample 13006: Loss: 0.0026\n",
            "Epoch 3, Sample 13007: Loss: 1.2165\n",
            "Epoch 3, Sample 13008: Loss: 0.2686\n",
            "Epoch 3, Sample 13009: Loss: 1.0524\n",
            "Epoch 3, Sample 13010: Loss: 0.1523\n",
            "Epoch 3, Sample 13011: Loss: 0.0067\n",
            "Epoch 3, Sample 13012: Loss: 0.1115\n",
            "Epoch 3, Sample 13013: Loss: 1.0524\n",
            "Epoch 3, Sample 13014: Loss: 0.2034\n",
            "Epoch 3, Sample 13015: Loss: 0.3399\n",
            "Epoch 3, Sample 13016: Loss: 0.2036\n",
            "Epoch 3, Sample 13017: Loss: 0.0947\n",
            "Epoch 3, Sample 13018: Loss: 1.0524\n",
            "Epoch 3, Sample 13019: Loss: 2.0659\n",
            "Epoch 3, Sample 13020: Loss: 0.0561\n",
            "Epoch 3, Sample 13021: Loss: 0.1464\n",
            "Epoch 3, Sample 13022: Loss: 0.2044\n",
            "Epoch 3, Sample 13023: Loss: 0.2044\n",
            "Epoch 3, Sample 13024: Loss: 0.3477\n",
            "Epoch 3, Sample 13025: Loss: 0.3865\n",
            "Epoch 3, Sample 13026: Loss: 0.5871\n",
            "Epoch 3, Sample 13027: Loss: 1.0155\n",
            "Epoch 3, Sample 13028: Loss: 0.0455\n",
            "Epoch 3, Sample 13029: Loss: 1.0155\n",
            "Epoch 3, Sample 13030: Loss: 0.0455\n",
            "Epoch 3, Sample 13031: Loss: 1.0530\n",
            "Epoch 3, Sample 13032: Loss: 0.7910\n",
            "Epoch 3, Sample 13033: Loss: 0.0142\n",
            "Epoch 3, Sample 13034: Loss: 0.3399\n",
            "Epoch 3, Sample 13035: Loss: 0.3399\n",
            "Epoch 3, Sample 13036: Loss: 0.5858\n",
            "Epoch 3, Sample 13037: Loss: 0.3805\n",
            "Epoch 3, Sample 13038: Loss: 0.3949\n",
            "Epoch 3, Sample 13039: Loss: 0.7036\n",
            "Epoch 3, Sample 13040: Loss: 0.2034\n",
            "Epoch 3, Sample 13041: Loss: 0.4845\n",
            "Epoch 3, Sample 13042: Loss: 1.0524\n",
            "Epoch 3, Sample 13043: Loss: 0.6304\n",
            "Epoch 3, Sample 13044: Loss: 0.0831\n",
            "Epoch 3, Sample 13045: Loss: 0.5871\n",
            "Epoch 3, Sample 13046: Loss: 0.0084\n",
            "Epoch 3, Sample 13047: Loss: 0.2394\n",
            "Epoch 3, Sample 13048: Loss: 0.0630\n",
            "Epoch 3, Sample 13049: Loss: 0.0242\n",
            "Epoch 3, Sample 13050: Loss: 0.2036\n",
            "Epoch 3, Sample 13051: Loss: 0.0000\n",
            "Epoch 3, Sample 13052: Loss: 0.0002\n",
            "Epoch 3, Sample 13053: Loss: 0.2034\n",
            "Epoch 3, Sample 13054: Loss: 0.2832\n",
            "Epoch 3, Sample 13055: Loss: 0.0074\n",
            "Epoch 3, Sample 13056: Loss: 0.1170\n",
            "Epoch 3, Sample 13057: Loss: 0.3441\n",
            "Epoch 3, Sample 13058: Loss: 0.2071\n",
            "Epoch 3, Sample 13059: Loss: 0.7036\n",
            "Epoch 3, Sample 13060: Loss: 0.2759\n",
            "Epoch 3, Sample 13061: Loss: 0.5858\n",
            "Epoch 3, Sample 13062: Loss: 1.0155\n",
            "Epoch 3, Sample 13063: Loss: 0.3949\n",
            "Epoch 3, Sample 13064: Loss: 1.0524\n",
            "Epoch 3, Sample 13065: Loss: 0.5310\n",
            "Epoch 3, Sample 13066: Loss: 0.6058\n",
            "Epoch 3, Sample 13067: Loss: 0.0630\n",
            "Epoch 3, Sample 13068: Loss: 0.3949\n",
            "Epoch 3, Sample 13069: Loss: 0.7036\n",
            "Epoch 3, Sample 13070: Loss: 0.2034\n",
            "Epoch 3, Sample 13071: Loss: 0.0045\n",
            "Epoch 3, Sample 13072: Loss: 0.3399\n",
            "Epoch 3, Sample 13073: Loss: 0.0001\n",
            "Epoch 3, Sample 13074: Loss: 1.0524\n",
            "Epoch 3, Sample 13075: Loss: 0.1648\n",
            "Epoch 3, Sample 13076: Loss: 0.2034\n",
            "Epoch 3, Sample 13077: Loss: 0.7036\n",
            "Epoch 3, Sample 13078: Loss: 0.3450\n",
            "Epoch 3, Sample 13079: Loss: 0.5000\n",
            "Epoch 3, Sample 13080: Loss: 0.6092\n",
            "Epoch 3, Sample 13081: Loss: 0.3354\n",
            "Epoch 3, Sample 13082: Loss: 0.0013\n",
            "Epoch 3, Sample 13083: Loss: 0.6990\n",
            "Epoch 3, Sample 13084: Loss: 0.2044\n",
            "Epoch 3, Sample 13085: Loss: 0.2141\n",
            "Epoch 3, Sample 13086: Loss: 0.5062\n",
            "Epoch 3, Sample 13087: Loss: 0.9651\n",
            "Epoch 3, Sample 13088: Loss: 0.6990\n",
            "Epoch 3, Sample 13089: Loss: 0.7453\n",
            "Epoch 3, Sample 13090: Loss: 0.3357\n",
            "Epoch 3, Sample 13091: Loss: 0.4279\n",
            "Epoch 3, Sample 13092: Loss: 0.1250\n",
            "Epoch 3, Sample 13093: Loss: 0.3399\n",
            "Epoch 3, Sample 13094: Loss: 0.0630\n",
            "Epoch 3, Sample 13095: Loss: 0.2114\n",
            "Epoch 3, Sample 13096: Loss: 0.6867\n",
            "Epoch 3, Sample 13097: Loss: 0.0108\n",
            "Epoch 3, Sample 13098: Loss: 0.5871\n",
            "Epoch 3, Sample 13099: Loss: 0.0613\n",
            "Epoch 3, Sample 13100: Loss: 3.5309\n",
            "Epoch 3, Sample 13101: Loss: 1.0250\n",
            "Epoch 3, Sample 13102: Loss: 0.5871\n",
            "Epoch 3, Sample 13103: Loss: 1.0530\n",
            "Epoch 3, Sample 13104: Loss: 0.0108\n",
            "Epoch 3, Sample 13105: Loss: 0.2044\n",
            "Epoch 3, Sample 13106: Loss: 0.1250\n",
            "Epoch 3, Sample 13107: Loss: 0.2034\n",
            "Epoch 3, Sample 13108: Loss: 0.7036\n",
            "Epoch 3, Sample 13109: Loss: 1.1487\n",
            "Epoch 3, Sample 13110: Loss: 0.8170\n",
            "Epoch 3, Sample 13111: Loss: 1.7380\n",
            "Epoch 3, Sample 13112: Loss: 0.4930\n",
            "Epoch 3, Sample 13113: Loss: 0.0707\n",
            "Epoch 3, Sample 13114: Loss: 0.6981\n",
            "Epoch 3, Sample 13115: Loss: 0.1052\n",
            "Epoch 3, Sample 13116: Loss: 0.0234\n",
            "Epoch 3, Sample 13117: Loss: 0.6990\n",
            "Epoch 3, Sample 13118: Loss: 1.0530\n",
            "Epoch 3, Sample 13119: Loss: 1.7827\n",
            "Epoch 3, Sample 13120: Loss: 0.7282\n",
            "Epoch 3, Sample 13121: Loss: 0.2044\n",
            "Epoch 3, Sample 13122: Loss: 0.6751\n",
            "Epoch 3, Sample 13123: Loss: 0.7453\n",
            "Epoch 3, Sample 13124: Loss: 0.1588\n",
            "Epoch 3, Sample 13125: Loss: 0.1170\n",
            "Epoch 3, Sample 13126: Loss: 0.1114\n",
            "Epoch 3, Sample 13127: Loss: 0.0765\n",
            "Epoch 3, Sample 13128: Loss: 0.2034\n",
            "Epoch 3, Sample 13129: Loss: 0.2034\n",
            "Epoch 3, Sample 13130: Loss: 0.4032\n",
            "Epoch 3, Sample 13131: Loss: 1.0524\n",
            "Epoch 3, Sample 13132: Loss: 0.0270\n",
            "Epoch 3, Sample 13133: Loss: 0.0026\n",
            "Epoch 3, Sample 13134: Loss: 1.4712\n",
            "Epoch 3, Sample 13135: Loss: 0.1665\n",
            "Epoch 3, Sample 13136: Loss: 0.2388\n",
            "Epoch 3, Sample 13137: Loss: 0.2639\n",
            "Epoch 3, Sample 13138: Loss: 0.3399\n",
            "Epoch 3, Sample 13139: Loss: 1.1141\n",
            "Epoch 3, Sample 13140: Loss: 0.0498\n",
            "Epoch 3, Sample 13141: Loss: 0.7453\n",
            "Epoch 3, Sample 13142: Loss: 0.0117\n",
            "Epoch 3, Sample 13143: Loss: 0.0774\n",
            "Epoch 3, Sample 13144: Loss: 0.2494\n",
            "Epoch 3, Sample 13145: Loss: 0.2044\n",
            "Epoch 3, Sample 13146: Loss: 0.1372\n",
            "Epoch 3, Sample 13147: Loss: 0.0256\n",
            "Epoch 3, Sample 13148: Loss: 0.5858\n",
            "Epoch 3, Sample 13149: Loss: 1.0155\n",
            "Epoch 3, Sample 13150: Loss: 0.0018\n",
            "Epoch 3, Sample 13151: Loss: 0.3399\n",
            "Epoch 3, Sample 13152: Loss: 0.0001\n",
            "Epoch 3, Sample 13153: Loss: 0.0001\n",
            "Epoch 3, Sample 13154: Loss: 0.0000\n",
            "Epoch 3, Sample 13155: Loss: 0.8951\n",
            "Epoch 3, Sample 13156: Loss: 6.2712\n",
            "Epoch 3, Sample 13157: Loss: 0.0015\n",
            "Epoch 3, Sample 13158: Loss: 0.0001\n",
            "Epoch 3, Sample 13159: Loss: 0.2234\n",
            "Epoch 3, Sample 13160: Loss: 0.2759\n",
            "Epoch 3, Sample 13161: Loss: 0.0581\n",
            "Epoch 3, Sample 13162: Loss: 0.1250\n",
            "Epoch 3, Sample 13163: Loss: 1.8616\n",
            "Epoch 3, Sample 13164: Loss: 0.2036\n",
            "Epoch 3, Sample 13165: Loss: 0.0909\n",
            "Epoch 3, Sample 13166: Loss: 0.0303\n",
            "Epoch 3, Sample 13167: Loss: 0.0983\n",
            "Epoch 3, Sample 13168: Loss: 0.2409\n",
            "Epoch 3, Sample 13169: Loss: 0.1625\n",
            "Epoch 3, Sample 13170: Loss: 0.3539\n",
            "Epoch 3, Sample 13171: Loss: 0.7036\n",
            "Epoch 3, Sample 13172: Loss: 0.0026\n",
            "Epoch 3, Sample 13173: Loss: 0.0001\n",
            "Epoch 3, Sample 13174: Loss: 0.4614\n",
            "Epoch 3, Sample 13175: Loss: 0.1170\n",
            "Epoch 3, Sample 13176: Loss: 1.0155\n",
            "Epoch 3, Sample 13177: Loss: 1.3781\n",
            "Epoch 3, Sample 13178: Loss: 5.8478\n",
            "Epoch 3, Sample 13179: Loss: 0.0625\n",
            "Epoch 3, Sample 13180: Loss: 0.1170\n",
            "Epoch 3, Sample 13181: Loss: 0.0026\n",
            "Epoch 3, Sample 13182: Loss: 0.1838\n",
            "Epoch 3, Sample 13183: Loss: 0.6990\n",
            "Epoch 3, Sample 13184: Loss: 0.3441\n",
            "Epoch 3, Sample 13185: Loss: 0.0026\n",
            "Epoch 3, Sample 13186: Loss: 0.2160\n",
            "Epoch 3, Sample 13187: Loss: 0.1554\n",
            "Epoch 3, Sample 13188: Loss: 0.0438\n",
            "Epoch 3, Sample 13189: Loss: 0.7036\n",
            "Epoch 3, Sample 13190: Loss: 1.0524\n",
            "Epoch 3, Sample 13191: Loss: 0.0117\n",
            "Epoch 3, Sample 13192: Loss: 0.5771\n",
            "Epoch 3, Sample 13193: Loss: 1.0530\n",
            "Epoch 3, Sample 13194: Loss: 1.0530\n",
            "Epoch 3, Sample 13195: Loss: 0.5000\n",
            "Epoch 3, Sample 13196: Loss: 1.6052\n",
            "Epoch 3, Sample 13197: Loss: 0.4607\n",
            "Epoch 3, Sample 13198: Loss: 0.8372\n",
            "Epoch 3, Sample 13199: Loss: 1.0524\n",
            "Epoch 3, Sample 13200: Loss: 0.0062\n",
            "Epoch 3, Sample 13201: Loss: 1.0530\n",
            "Epoch 3, Sample 13202: Loss: 0.2832\n",
            "Epoch 3, Sample 13203: Loss: 0.0630\n",
            "Epoch 3, Sample 13204: Loss: 0.2247\n",
            "Epoch 3, Sample 13205: Loss: 0.1838\n",
            "Epoch 3, Sample 13206: Loss: 0.3568\n",
            "Epoch 3, Sample 13207: Loss: 0.0001\n",
            "Epoch 3, Sample 13208: Loss: 0.2479\n",
            "Epoch 3, Sample 13209: Loss: 0.2032\n",
            "Epoch 3, Sample 13210: Loss: 2.6772\n",
            "Epoch 3, Sample 13211: Loss: 0.0978\n",
            "Epoch 3, Sample 13212: Loss: 0.0103\n",
            "Epoch 3, Sample 13213: Loss: 0.0777\n",
            "Epoch 3, Sample 13214: Loss: 1.0155\n",
            "Epoch 3, Sample 13215: Loss: 1.3842\n",
            "Epoch 3, Sample 13216: Loss: 0.3505\n",
            "Epoch 3, Sample 13217: Loss: 0.5868\n",
            "Epoch 3, Sample 13218: Loss: 0.7453\n",
            "Epoch 3, Sample 13219: Loss: 0.3961\n",
            "Epoch 3, Sample 13220: Loss: 0.0026\n",
            "Epoch 3, Sample 13221: Loss: 1.0524\n",
            "Epoch 3, Sample 13222: Loss: 5.9530\n",
            "Epoch 3, Sample 13223: Loss: 0.2219\n",
            "Epoch 3, Sample 13224: Loss: 0.0026\n",
            "Epoch 3, Sample 13225: Loss: 0.0212\n",
            "Epoch 3, Sample 13226: Loss: 0.0026\n",
            "Epoch 3, Sample 13227: Loss: 0.7036\n",
            "Epoch 3, Sample 13228: Loss: 0.2543\n",
            "Epoch 3, Sample 13229: Loss: 0.3598\n",
            "Epoch 3, Sample 13230: Loss: 0.0785\n",
            "Epoch 3, Sample 13231: Loss: 0.2639\n",
            "Epoch 3, Sample 13232: Loss: 1.0155\n",
            "Epoch 3, Sample 13233: Loss: 0.2148\n",
            "Epoch 3, Sample 13234: Loss: 0.0001\n",
            "Epoch 3, Sample 13235: Loss: 0.2032\n",
            "Epoch 3, Sample 13236: Loss: 0.0915\n",
            "Epoch 3, Sample 13237: Loss: 0.6092\n",
            "Epoch 3, Sample 13238: Loss: 6.1473\n",
            "Epoch 3, Sample 13239: Loss: 0.1114\n",
            "Epoch 3, Sample 13240: Loss: 6.9441\n",
            "Epoch 3, Sample 13241: Loss: 0.0026\n",
            "Epoch 3, Sample 13242: Loss: 0.0018\n",
            "Epoch 3, Sample 13243: Loss: 0.2044\n",
            "Epoch 3, Sample 13244: Loss: 0.0004\n",
            "Epoch 3, Sample 13245: Loss: 0.0099\n",
            "Epoch 3, Sample 13246: Loss: 0.1559\n",
            "Epoch 3, Sample 13247: Loss: 0.1559\n",
            "Epoch 3, Sample 13248: Loss: 0.3332\n",
            "Epoch 3, Sample 13249: Loss: 0.1250\n",
            "Epoch 3, Sample 13250: Loss: 0.0001\n",
            "Epoch 3, Sample 13251: Loss: 1.0524\n",
            "Epoch 3, Sample 13252: Loss: 5.4428\n",
            "Epoch 3, Sample 13253: Loss: 0.0026\n",
            "Epoch 3, Sample 13254: Loss: 0.2746\n",
            "Epoch 3, Sample 13255: Loss: 0.3399\n",
            "Epoch 3, Sample 13256: Loss: 0.2483\n",
            "Epoch 3, Sample 13257: Loss: 0.1265\n",
            "Epoch 3, Sample 13258: Loss: 0.0915\n",
            "Epoch 3, Sample 13259: Loss: 0.4841\n",
            "Epoch 3, Sample 13260: Loss: 1.0524\n",
            "Epoch 3, Sample 13261: Loss: 0.6543\n",
            "Epoch 3, Sample 13262: Loss: 0.4032\n",
            "Epoch 3, Sample 13263: Loss: 0.3399\n",
            "Epoch 3, Sample 13264: Loss: 0.4611\n",
            "Epoch 3, Sample 13265: Loss: 0.0000\n",
            "Epoch 3, Sample 13266: Loss: 4.7221\n",
            "Epoch 3, Sample 13267: Loss: 0.1114\n",
            "Epoch 3, Sample 13268: Loss: 0.3450\n",
            "Epoch 3, Sample 13269: Loss: 0.5858\n",
            "Epoch 3, Sample 13270: Loss: 0.0000\n",
            "Epoch 3, Sample 13271: Loss: 0.2759\n",
            "Epoch 3, Sample 13272: Loss: 0.0890\n",
            "Epoch 3, Sample 13273: Loss: 0.2759\n",
            "Epoch 3, Sample 13274: Loss: 0.1559\n",
            "Epoch 3, Sample 13275: Loss: 1.0524\n",
            "Epoch 3, Sample 13276: Loss: 0.2044\n",
            "Epoch 3, Sample 13277: Loss: 0.0364\n",
            "Epoch 3, Sample 13278: Loss: 0.3450\n",
            "Epoch 3, Sample 13279: Loss: 1.1569\n",
            "Epoch 3, Sample 13280: Loss: 2.3895\n",
            "Epoch 3, Sample 13281: Loss: 1.0524\n",
            "Epoch 3, Sample 13282: Loss: 0.2759\n",
            "Epoch 3, Sample 13283: Loss: 0.3399\n",
            "Epoch 3, Sample 13284: Loss: 0.6139\n",
            "Epoch 3, Sample 13285: Loss: 1.0155\n",
            "Epoch 3, Sample 13286: Loss: 0.0486\n",
            "Epoch 3, Sample 13287: Loss: 0.3399\n",
            "Epoch 3, Sample 13288: Loss: 0.1687\n",
            "Epoch 3, Sample 13289: Loss: 0.0026\n",
            "Epoch 3, Sample 13290: Loss: 0.2219\n",
            "Epoch 3, Sample 13291: Loss: 1.0524\n",
            "Epoch 3, Sample 13292: Loss: 0.1250\n",
            "Epoch 3, Sample 13293: Loss: 0.2558\n",
            "Epoch 3, Sample 13294: Loss: 0.4906\n",
            "Epoch 3, Sample 13295: Loss: 0.6676\n",
            "Epoch 3, Sample 13296: Loss: 0.3399\n",
            "Epoch 3, Sample 13297: Loss: 0.6509\n",
            "Epoch 3, Sample 13298: Loss: 0.5858\n",
            "Epoch 3, Sample 13299: Loss: 0.0108\n",
            "Epoch 3, Sample 13300: Loss: 0.2639\n",
            "Epoch 3, Sample 13301: Loss: 0.2941\n",
            "Epoch 3, Sample 13302: Loss: 0.2044\n",
            "Epoch 3, Sample 13303: Loss: 0.0018\n",
            "Epoch 3, Sample 13304: Loss: 0.4799\n",
            "Epoch 3, Sample 13305: Loss: 0.1791\n",
            "Epoch 3, Sample 13306: Loss: 0.0338\n",
            "Epoch 3, Sample 13307: Loss: 0.0505\n",
            "Epoch 3, Sample 13308: Loss: 0.8951\n",
            "Epoch 3, Sample 13309: Loss: 1.2184\n",
            "Epoch 3, Sample 13310: Loss: 0.0976\n",
            "Epoch 3, Sample 13311: Loss: 0.0095\n",
            "Epoch 3, Sample 13312: Loss: 1.0070\n",
            "Epoch 3, Sample 13313: Loss: 0.2044\n",
            "Epoch 3, Sample 13314: Loss: 0.2044\n",
            "Epoch 3, Sample 13315: Loss: 0.2044\n",
            "Epoch 3, Sample 13316: Loss: 0.3166\n",
            "Epoch 3, Sample 13317: Loss: 2.6760\n",
            "Epoch 3, Sample 13318: Loss: 0.0001\n",
            "Epoch 3, Sample 13319: Loss: 0.4930\n",
            "Epoch 3, Sample 13320: Loss: 0.2575\n",
            "Epoch 3, Sample 13321: Loss: 0.0026\n",
            "Epoch 3, Sample 13322: Loss: 0.3858\n",
            "Epoch 3, Sample 13323: Loss: 5.5115\n",
            "Epoch 3, Sample 13324: Loss: 1.0524\n",
            "Epoch 3, Sample 13325: Loss: 0.7036\n",
            "Epoch 3, Sample 13326: Loss: 2.4593\n",
            "Epoch 3, Sample 13327: Loss: 1.1275\n",
            "Epoch 3, Sample 13328: Loss: 0.0205\n",
            "Epoch 3, Sample 13329: Loss: 0.3576\n",
            "Epoch 3, Sample 13330: Loss: 0.0048\n",
            "Epoch 3, Sample 13331: Loss: 6.5695\n",
            "Epoch 3, Sample 13332: Loss: 0.3949\n",
            "Epoch 3, Sample 13333: Loss: 0.2759\n",
            "Epoch 3, Sample 13334: Loss: 1.0530\n",
            "Epoch 3, Sample 13335: Loss: 0.0018\n",
            "Epoch 3, Sample 13336: Loss: 0.0120\n",
            "Epoch 3, Sample 13337: Loss: 0.8951\n",
            "Epoch 3, Sample 13338: Loss: 1.0155\n",
            "Epoch 3, Sample 13339: Loss: 0.0018\n",
            "Epoch 3, Sample 13340: Loss: 0.2034\n",
            "Epoch 3, Sample 13341: Loss: 0.2832\n",
            "Epoch 3, Sample 13342: Loss: 8.4189\n",
            "Epoch 3, Sample 13343: Loss: 0.5792\n",
            "Epoch 3, Sample 13344: Loss: 0.4799\n",
            "Epoch 3, Sample 13345: Loss: 1.0524\n",
            "Epoch 3, Sample 13346: Loss: 0.6990\n",
            "Epoch 3, Sample 13347: Loss: 7.6565\n",
            "Epoch 3, Sample 13348: Loss: 0.0436\n",
            "Epoch 3, Sample 13349: Loss: 0.0005\n",
            "Epoch 3, Sample 13350: Loss: 0.3441\n",
            "Epoch 3, Sample 13351: Loss: 0.3399\n",
            "Epoch 3, Sample 13352: Loss: 1.0530\n",
            "Epoch 3, Sample 13353: Loss: 0.2713\n",
            "Epoch 3, Sample 13354: Loss: 0.3056\n",
            "Epoch 3, Sample 13355: Loss: 2.9652\n",
            "Epoch 3, Sample 13356: Loss: 1.3283\n",
            "Epoch 3, Sample 13357: Loss: 0.0060\n",
            "Epoch 3, Sample 13358: Loss: 0.4816\n",
            "Epoch 3, Sample 13359: Loss: 0.3108\n",
            "Epoch 3, Sample 13360: Loss: 0.2036\n",
            "Epoch 3, Sample 13361: Loss: 0.5972\n",
            "Epoch 3, Sample 13362: Loss: 0.0018\n",
            "Epoch 3, Sample 13363: Loss: 0.0838\n",
            "Epoch 3, Sample 13364: Loss: 0.1170\n",
            "Epoch 3, Sample 13365: Loss: 0.5858\n",
            "Epoch 3, Sample 13366: Loss: 0.3441\n",
            "Epoch 3, Sample 13367: Loss: 1.0524\n",
            "Epoch 3, Sample 13368: Loss: 0.2759\n",
            "Epoch 3, Sample 13369: Loss: 0.0026\n",
            "Epoch 3, Sample 13370: Loss: 3.2063\n",
            "Epoch 3, Sample 13371: Loss: 1.6701\n",
            "Epoch 3, Sample 13372: Loss: 0.3441\n",
            "Epoch 3, Sample 13373: Loss: 0.1372\n",
            "Epoch 3, Sample 13374: Loss: 0.0630\n",
            "Epoch 3, Sample 13375: Loss: 0.2044\n",
            "Epoch 3, Sample 13376: Loss: 0.0212\n",
            "Epoch 3, Sample 13377: Loss: 0.0026\n",
            "Epoch 3, Sample 13378: Loss: 0.0539\n",
            "Epoch 3, Sample 13379: Loss: 0.3399\n",
            "Epoch 3, Sample 13380: Loss: 1.6232\n",
            "Epoch 3, Sample 13381: Loss: 0.4311\n",
            "Epoch 3, Sample 13382: Loss: 1.0610\n",
            "Epoch 3, Sample 13383: Loss: 0.2044\n",
            "Epoch 3, Sample 13384: Loss: 0.0168\n",
            "Epoch 3, Sample 13385: Loss: 0.4799\n",
            "Epoch 3, Sample 13386: Loss: 0.0180\n",
            "Epoch 3, Sample 13387: Loss: 0.0005\n",
            "Epoch 3, Sample 13388: Loss: 0.4664\n",
            "Epoch 3, Sample 13389: Loss: 0.0640\n",
            "Epoch 3, Sample 13390: Loss: 0.0148\n",
            "Epoch 3, Sample 13391: Loss: 0.3441\n",
            "Epoch 3, Sample 13392: Loss: 0.3399\n",
            "Epoch 3, Sample 13393: Loss: 1.5270\n",
            "Epoch 3, Sample 13394: Loss: 2.9283\n",
            "Epoch 3, Sample 13395: Loss: 0.3949\n",
            "Epoch 3, Sample 13396: Loss: 1.7924\n",
            "Epoch 3, Sample 13397: Loss: 0.3506\n",
            "Epoch 3, Sample 13398: Loss: 0.2433\n",
            "Epoch 3, Sample 13399: Loss: 1.1884\n",
            "Epoch 3, Sample 13400: Loss: 0.9367\n",
            "Epoch 3, Sample 13401: Loss: 0.0734\n",
            "Epoch 3, Sample 13402: Loss: 0.2759\n",
            "Epoch 3, Sample 13403: Loss: 0.3399\n",
            "Epoch 3, Sample 13404: Loss: 0.0744\n",
            "Epoch 3, Sample 13405: Loss: 0.5549\n",
            "Epoch 3, Sample 13406: Loss: 0.0355\n",
            "Epoch 3, Sample 13407: Loss: 0.7036\n",
            "Epoch 3, Sample 13408: Loss: 1.0530\n",
            "Epoch 3, Sample 13409: Loss: 0.3399\n",
            "Epoch 3, Sample 13410: Loss: 0.0303\n",
            "Epoch 3, Sample 13411: Loss: 0.0018\n",
            "Epoch 3, Sample 13412: Loss: 0.1523\n",
            "Epoch 3, Sample 13413: Loss: 0.2044\n",
            "Epoch 3, Sample 13414: Loss: 1.0530\n",
            "Epoch 3, Sample 13415: Loss: 0.2832\n",
            "Epoch 3, Sample 13416: Loss: 1.0530\n",
            "Epoch 3, Sample 13417: Loss: 0.3399\n",
            "Epoch 3, Sample 13418: Loss: 0.2962\n",
            "Epoch 3, Sample 13419: Loss: 0.8211\n",
            "Epoch 3, Sample 13420: Loss: 0.2245\n",
            "Epoch 3, Sample 13421: Loss: 0.1559\n",
            "Epoch 3, Sample 13422: Loss: 1.0155\n",
            "Epoch 3, Sample 13423: Loss: 0.3598\n",
            "Epoch 3, Sample 13424: Loss: 1.0524\n",
            "Epoch 3, Sample 13425: Loss: 0.2483\n",
            "Epoch 3, Sample 13426: Loss: 1.0155\n",
            "Epoch 3, Sample 13427: Loss: 1.9610\n",
            "Epoch 3, Sample 13428: Loss: 0.7992\n",
            "Epoch 3, Sample 13429: Loss: 1.5542\n",
            "Epoch 3, Sample 13430: Loss: 0.1372\n",
            "Epoch 3, Sample 13431: Loss: 0.0018\n",
            "Epoch 3, Sample 13432: Loss: 0.0018\n",
            "Epoch 3, Sample 13433: Loss: 0.2340\n",
            "Epoch 3, Sample 13434: Loss: 2.3000\n",
            "Epoch 3, Sample 13435: Loss: 0.0000\n",
            "Epoch 3, Sample 13436: Loss: 0.1091\n",
            "Epoch 3, Sample 13437: Loss: 0.2034\n",
            "Epoch 3, Sample 13438: Loss: 0.0674\n",
            "Epoch 3, Sample 13439: Loss: 0.1002\n",
            "Epoch 3, Sample 13440: Loss: 2.3808\n",
            "Epoch 3, Sample 13441: Loss: 0.7036\n",
            "Epoch 3, Sample 13442: Loss: 0.3399\n",
            "Epoch 3, Sample 13443: Loss: 1.0524\n",
            "Epoch 3, Sample 13444: Loss: 0.3399\n",
            "Epoch 3, Sample 13445: Loss: 0.0026\n",
            "Epoch 3, Sample 13446: Loss: 0.1252\n",
            "Epoch 3, Sample 13447: Loss: 0.9753\n",
            "Epoch 3, Sample 13448: Loss: 0.0062\n",
            "Epoch 3, Sample 13449: Loss: 0.0117\n",
            "Epoch 3, Sample 13450: Loss: 0.1326\n",
            "Epoch 3, Sample 13451: Loss: 0.2219\n",
            "Epoch 3, Sample 13452: Loss: 0.7036\n",
            "Epoch 3, Sample 13453: Loss: 2.3765\n",
            "Epoch 3, Sample 13454: Loss: 0.2639\n",
            "Epoch 3, Sample 13455: Loss: 0.0630\n",
            "Epoch 3, Sample 13456: Loss: 1.9463\n",
            "Epoch 3, Sample 13457: Loss: 0.0429\n",
            "Epoch 3, Sample 13458: Loss: 3.1698\n",
            "Epoch 3, Sample 13459: Loss: 0.0002\n",
            "Epoch 3, Sample 13460: Loss: 0.0205\n",
            "Epoch 3, Sample 13461: Loss: 0.8872\n",
            "Epoch 3, Sample 13462: Loss: 0.7036\n",
            "Epoch 3, Sample 13463: Loss: 4.5516\n",
            "Epoch 3, Sample 13464: Loss: 0.7036\n",
            "Epoch 3, Sample 13465: Loss: 0.1252\n",
            "Epoch 3, Sample 13466: Loss: 0.0169\n",
            "Epoch 3, Sample 13467: Loss: 0.0915\n",
            "Epoch 3, Sample 13468: Loss: 0.3399\n",
            "Epoch 3, Sample 13469: Loss: 0.0018\n",
            "Epoch 3, Sample 13470: Loss: 0.0608\n",
            "Epoch 3, Sample 13471: Loss: 0.0698\n",
            "Epoch 3, Sample 13472: Loss: 0.4930\n",
            "Epoch 3, Sample 13473: Loss: 0.0103\n",
            "Epoch 3, Sample 13474: Loss: 0.0000\n",
            "Epoch 3, Sample 13475: Loss: 0.5065\n",
            "Epoch 3, Sample 13476: Loss: 0.3126\n",
            "Epoch 3, Sample 13477: Loss: 0.3260\n",
            "Epoch 3, Sample 13478: Loss: 1.0524\n",
            "Epoch 3, Sample 13479: Loss: 0.6990\n",
            "Epoch 3, Sample 13480: Loss: 0.3399\n",
            "Epoch 3, Sample 13481: Loss: 0.7036\n",
            "Epoch 3, Sample 13482: Loss: 0.0306\n",
            "Epoch 3, Sample 13483: Loss: 0.3399\n",
            "Epoch 3, Sample 13484: Loss: 0.0838\n",
            "Epoch 3, Sample 13485: Loss: 0.7036\n",
            "Epoch 3, Sample 13486: Loss: 2.1938\n",
            "Epoch 3, Sample 13487: Loss: 0.0693\n",
            "Epoch 3, Sample 13488: Loss: 0.0099\n",
            "Epoch 3, Sample 13489: Loss: 0.1989\n",
            "Epoch 3, Sample 13490: Loss: 5.5565\n",
            "Epoch 3, Sample 13491: Loss: 1.0155\n",
            "Epoch 3, Sample 13492: Loss: 0.2044\n",
            "Epoch 3, Sample 13493: Loss: 0.2759\n",
            "Epoch 3, Sample 13494: Loss: 0.4476\n",
            "Epoch 3, Sample 13495: Loss: 0.2759\n",
            "Epoch 3, Sample 13496: Loss: 14.5886\n",
            "Epoch 3, Sample 13497: Loss: 0.1170\n",
            "Epoch 3, Sample 13498: Loss: 0.9367\n",
            "Epoch 3, Sample 13499: Loss: 0.0655\n",
            "Epoch 3, Sample 13500: Loss: 0.2044\n",
            "Epoch 3, Sample 13501: Loss: 0.2032\n",
            "Epoch 3, Sample 13502: Loss: 0.7180\n",
            "Epoch 3, Sample 13503: Loss: 0.2044\n",
            "Epoch 3, Sample 13504: Loss: 0.1337\n",
            "Epoch 3, Sample 13505: Loss: 0.2219\n",
            "Epoch 3, Sample 13506: Loss: 0.1250\n",
            "Epoch 3, Sample 13507: Loss: 0.1559\n",
            "Epoch 3, Sample 13508: Loss: 0.6990\n",
            "Epoch 3, Sample 13509: Loss: 0.3441\n",
            "Epoch 3, Sample 13510: Loss: 0.4663\n",
            "Epoch 3, Sample 13511: Loss: 0.2568\n",
            "Epoch 3, Sample 13512: Loss: 0.4799\n",
            "Epoch 3, Sample 13513: Loss: 1.0524\n",
            "Epoch 3, Sample 13514: Loss: 0.2034\n",
            "Epoch 3, Sample 13515: Loss: 0.4930\n",
            "Epoch 3, Sample 13516: Loss: 0.4264\n",
            "Epoch 3, Sample 13517: Loss: 0.4930\n",
            "Epoch 3, Sample 13518: Loss: 0.3088\n",
            "Epoch 3, Sample 13519: Loss: 0.0001\n",
            "Epoch 3, Sample 13520: Loss: 0.0630\n",
            "Epoch 3, Sample 13521: Loss: 0.0212\n",
            "Epoch 3, Sample 13522: Loss: 0.2704\n",
            "Epoch 3, Sample 13523: Loss: 0.5062\n",
            "Epoch 3, Sample 13524: Loss: 0.1197\n",
            "Epoch 3, Sample 13525: Loss: 0.0026\n",
            "Epoch 3, Sample 13526: Loss: 0.4093\n",
            "Epoch 3, Sample 13527: Loss: 0.3949\n",
            "Epoch 3, Sample 13528: Loss: 0.2044\n",
            "Epoch 3, Sample 13529: Loss: 0.3626\n",
            "Epoch 3, Sample 13530: Loss: 0.0018\n",
            "Epoch 3, Sample 13531: Loss: 0.7036\n",
            "Epoch 3, Sample 13532: Loss: 0.0118\n",
            "Epoch 3, Sample 13533: Loss: 0.1248\n",
            "Epoch 3, Sample 13534: Loss: 0.5858\n",
            "Epoch 3, Sample 13535: Loss: 0.0460\n",
            "Epoch 3, Sample 13536: Loss: 0.4799\n",
            "Epoch 3, Sample 13537: Loss: 0.6990\n",
            "Epoch 3, Sample 13538: Loss: 0.7996\n",
            "Epoch 3, Sample 13539: Loss: 0.5871\n",
            "Epoch 3, Sample 13540: Loss: 0.0234\n",
            "Epoch 3, Sample 13541: Loss: 0.0875\n",
            "Epoch 3, Sample 13542: Loss: 0.0258\n",
            "Epoch 3, Sample 13543: Loss: 0.2558\n",
            "Epoch 3, Sample 13544: Loss: 1.4436\n",
            "Epoch 3, Sample 13545: Loss: 1.0524\n",
            "Epoch 3, Sample 13546: Loss: 0.3758\n",
            "Epoch 3, Sample 13547: Loss: 1.0530\n",
            "Epoch 3, Sample 13548: Loss: 0.5000\n",
            "Epoch 3, Sample 13549: Loss: 0.0108\n",
            "Epoch 3, Sample 13550: Loss: 0.3441\n",
            "Epoch 3, Sample 13551: Loss: 0.9311\n",
            "Epoch 3, Sample 13552: Loss: 0.2803\n",
            "Epoch 3, Sample 13553: Loss: 0.1624\n",
            "Epoch 3, Sample 13554: Loss: 0.2044\n",
            "Epoch 3, Sample 13555: Loss: 0.0060\n",
            "Epoch 3, Sample 13556: Loss: 0.0011\n",
            "Epoch 3, Sample 13557: Loss: 1.1003\n",
            "Epoch 3, Sample 13558: Loss: 0.0018\n",
            "Epoch 3, Sample 13559: Loss: 1.0266\n",
            "Epoch 3, Sample 13560: Loss: 0.1250\n",
            "Epoch 3, Sample 13561: Loss: 0.1170\n",
            "Epoch 3, Sample 13562: Loss: 1.0524\n",
            "Epoch 3, Sample 13563: Loss: 0.3506\n",
            "Epoch 3, Sample 13564: Loss: 0.0838\n",
            "Epoch 3, Sample 13565: Loss: 0.0779\n",
            "Epoch 3, Sample 13566: Loss: 0.6152\n",
            "Epoch 3, Sample 13567: Loss: 0.7958\n",
            "Epoch 3, Sample 13568: Loss: 0.0915\n",
            "Epoch 3, Sample 13569: Loss: 1.5442\n",
            "Epoch 3, Sample 13570: Loss: 1.0266\n",
            "Epoch 3, Sample 13571: Loss: 0.2464\n",
            "Epoch 3, Sample 13572: Loss: 0.0913\n",
            "Epoch 3, Sample 13573: Loss: 0.6669\n",
            "Epoch 3, Sample 13574: Loss: 0.5196\n",
            "Epoch 3, Sample 13575: Loss: 0.8951\n",
            "Epoch 3, Sample 13576: Loss: 0.3247\n",
            "Epoch 3, Sample 13577: Loss: 0.0026\n",
            "Epoch 3, Sample 13578: Loss: 0.0000\n",
            "Epoch 3, Sample 13579: Loss: 0.2036\n",
            "Epoch 3, Sample 13580: Loss: 0.0205\n",
            "Epoch 3, Sample 13581: Loss: 0.3399\n",
            "Epoch 3, Sample 13582: Loss: 0.9175\n",
            "Epoch 3, Sample 13583: Loss: 0.2044\n",
            "Epoch 3, Sample 13584: Loss: 0.3399\n",
            "Epoch 3, Sample 13585: Loss: 0.2367\n",
            "Epoch 3, Sample 13586: Loss: 0.1944\n",
            "Epoch 3, Sample 13587: Loss: 0.8951\n",
            "Epoch 3, Sample 13588: Loss: 0.2851\n",
            "Epoch 3, Sample 13589: Loss: 0.0040\n",
            "Epoch 3, Sample 13590: Loss: 0.2759\n",
            "Epoch 3, Sample 13591: Loss: 1.1511\n",
            "Epoch 3, Sample 13592: Loss: 0.7486\n",
            "Epoch 3, Sample 13593: Loss: 1.3674\n",
            "Epoch 3, Sample 13594: Loss: 0.3441\n",
            "Epoch 3, Sample 13595: Loss: 0.2832\n",
            "Epoch 3, Sample 13596: Loss: 0.2034\n",
            "Epoch 3, Sample 13597: Loss: 0.2855\n",
            "Epoch 3, Sample 13598: Loss: 0.1987\n",
            "Epoch 3, Sample 13599: Loss: 0.0148\n",
            "Epoch 3, Sample 13600: Loss: 0.0042\n",
            "Epoch 3, Sample 13601: Loss: 0.4930\n",
            "Epoch 3, Sample 13602: Loss: 0.0001\n",
            "Epoch 3, Sample 13603: Loss: 0.1250\n",
            "Epoch 3, Sample 13604: Loss: 0.0303\n",
            "Epoch 3, Sample 13605: Loss: 0.4365\n",
            "Epoch 3, Sample 13606: Loss: 0.2044\n",
            "Epoch 3, Sample 13607: Loss: 0.0915\n",
            "Epoch 3, Sample 13608: Loss: 0.0084\n",
            "Epoch 3, Sample 13609: Loss: 0.0491\n",
            "Epoch 3, Sample 13610: Loss: 0.2340\n",
            "Epoch 3, Sample 13611: Loss: 0.0026\n",
            "Epoch 3, Sample 13612: Loss: 0.3938\n",
            "Epoch 3, Sample 13613: Loss: 0.0042\n",
            "Epoch 3, Sample 13614: Loss: 3.0468\n",
            "Epoch 3, Sample 13615: Loss: 0.0208\n",
            "Epoch 3, Sample 13616: Loss: 1.0524\n",
            "Epoch 3, Sample 13617: Loss: 0.0630\n",
            "Epoch 3, Sample 13618: Loss: 0.0026\n",
            "Epoch 3, Sample 13619: Loss: 0.2034\n",
            "Epoch 3, Sample 13620: Loss: 2.9881\n",
            "Epoch 3, Sample 13621: Loss: 0.0026\n",
            "Epoch 3, Sample 13622: Loss: 0.1250\n",
            "Epoch 3, Sample 13623: Loss: 0.0102\n",
            "Epoch 3, Sample 13624: Loss: 0.6990\n",
            "Epoch 3, Sample 13625: Loss: 0.4367\n",
            "Epoch 3, Sample 13626: Loss: 0.2342\n",
            "Epoch 3, Sample 13627: Loss: 0.0018\n",
            "Epoch 3, Sample 13628: Loss: 2.7331\n",
            "Epoch 3, Sample 13629: Loss: 0.1508\n",
            "Epoch 3, Sample 13630: Loss: 0.1372\n",
            "Epoch 3, Sample 13631: Loss: 3.7050\n",
            "Epoch 3, Sample 13632: Loss: 0.0002\n",
            "Epoch 3, Sample 13633: Loss: 0.3758\n",
            "Epoch 3, Sample 13634: Loss: 0.3441\n",
            "Epoch 3, Sample 13635: Loss: 0.1250\n",
            "Epoch 3, Sample 13636: Loss: 0.4831\n",
            "Epoch 3, Sample 13637: Loss: 0.1508\n",
            "Epoch 3, Sample 13638: Loss: 1.0524\n",
            "Epoch 3, Sample 13639: Loss: 0.9367\n",
            "Epoch 3, Sample 13640: Loss: 1.0266\n",
            "Epoch 3, Sample 13641: Loss: 1.0524\n",
            "Epoch 3, Sample 13642: Loss: 0.1523\n",
            "Epoch 3, Sample 13643: Loss: 0.3399\n",
            "Epoch 3, Sample 13644: Loss: 1.0524\n",
            "Epoch 3, Sample 13645: Loss: 1.6878\n",
            "Epoch 3, Sample 13646: Loss: 0.0349\n",
            "Epoch 3, Sample 13647: Loss: 0.3441\n",
            "Epoch 3, Sample 13648: Loss: 0.5858\n",
            "Epoch 3, Sample 13649: Loss: 0.0108\n",
            "Epoch 3, Sample 13650: Loss: 0.8951\n",
            "Epoch 3, Sample 13651: Loss: 0.7036\n",
            "Epoch 3, Sample 13652: Loss: 0.0026\n",
            "Epoch 3, Sample 13653: Loss: 0.5000\n",
            "Epoch 3, Sample 13654: Loss: 0.3332\n",
            "Epoch 3, Sample 13655: Loss: 0.0915\n",
            "Epoch 3, Sample 13656: Loss: 1.0524\n",
            "Epoch 3, Sample 13657: Loss: 0.8976\n",
            "Epoch 3, Sample 13658: Loss: 0.1588\n",
            "Epoch 3, Sample 13659: Loss: 0.3450\n",
            "Epoch 3, Sample 13660: Loss: 0.2759\n",
            "Epoch 3, Sample 13661: Loss: 0.1206\n",
            "Epoch 3, Sample 13662: Loss: 0.0026\n",
            "Epoch 3, Sample 13663: Loss: 0.2778\n",
            "Epoch 3, Sample 13664: Loss: 0.0962\n",
            "Epoch 3, Sample 13665: Loss: 0.0000\n",
            "Epoch 3, Sample 13666: Loss: 0.2759\n",
            "Epoch 3, Sample 13667: Loss: 0.4841\n",
            "Epoch 3, Sample 13668: Loss: 0.8951\n",
            "Epoch 3, Sample 13669: Loss: 1.0155\n",
            "Epoch 3, Sample 13670: Loss: 0.0026\n",
            "Epoch 3, Sample 13671: Loss: 0.4611\n",
            "Epoch 3, Sample 13672: Loss: 0.6024\n",
            "Epoch 3, Sample 13673: Loss: 1.3111\n",
            "Epoch 3, Sample 13674: Loss: 1.6515\n",
            "Epoch 3, Sample 13675: Loss: 17.0608\n",
            "Epoch 3, Sample 13676: Loss: 0.7036\n",
            "Epoch 3, Sample 13677: Loss: 0.3279\n",
            "Epoch 3, Sample 13678: Loss: 0.7036\n",
            "Epoch 3, Sample 13679: Loss: 0.4611\n",
            "Epoch 3, Sample 13680: Loss: 0.5196\n",
            "Epoch 3, Sample 13681: Loss: 0.0218\n",
            "Epoch 3, Sample 13682: Loss: 0.2759\n",
            "Epoch 3, Sample 13683: Loss: 7.2792\n",
            "Epoch 3, Sample 13684: Loss: 0.6082\n",
            "Epoch 3, Sample 13685: Loss: 3.0925\n",
            "Epoch 3, Sample 13686: Loss: 0.4799\n",
            "Epoch 3, Sample 13687: Loss: 0.5744\n",
            "Epoch 3, Sample 13688: Loss: 0.5972\n",
            "Epoch 3, Sample 13689: Loss: 0.0026\n",
            "Epoch 3, Sample 13690: Loss: 0.3758\n",
            "Epoch 3, Sample 13691: Loss: 0.3441\n",
            "Epoch 3, Sample 13692: Loss: 0.0026\n",
            "Epoch 3, Sample 13693: Loss: 0.7036\n",
            "Epoch 3, Sample 13694: Loss: 0.3568\n",
            "Epoch 3, Sample 13695: Loss: 0.1627\n",
            "Epoch 3, Sample 13696: Loss: 0.1246\n",
            "Epoch 3, Sample 13697: Loss: 0.2034\n",
            "Epoch 3, Sample 13698: Loss: 0.2219\n",
            "Epoch 3, Sample 13699: Loss: 0.0647\n",
            "Epoch 3, Sample 13700: Loss: 0.0915\n",
            "Epoch 3, Sample 13701: Loss: 0.4032\n",
            "Epoch 3, Sample 13702: Loss: 0.3402\n",
            "Epoch 3, Sample 13703: Loss: 0.7036\n",
            "Epoch 3, Sample 13704: Loss: 0.9389\n",
            "Epoch 3, Sample 13705: Loss: 0.2034\n",
            "Epoch 3, Sample 13706: Loss: 0.0006\n",
            "Epoch 3, Sample 13707: Loss: 0.0005\n",
            "Epoch 3, Sample 13708: Loss: 0.4902\n",
            "Epoch 3, Sample 13709: Loss: 0.7036\n",
            "Epoch 3, Sample 13710: Loss: 1.0524\n",
            "Epoch 3, Sample 13711: Loss: 0.6092\n",
            "Epoch 3, Sample 13712: Loss: 0.2044\n",
            "Epoch 3, Sample 13713: Loss: 0.3399\n",
            "Epoch 3, Sample 13714: Loss: 0.3441\n",
            "Epoch 3, Sample 13715: Loss: 0.2044\n",
            "Epoch 3, Sample 13716: Loss: 0.2832\n",
            "Epoch 3, Sample 13717: Loss: 0.1326\n",
            "Epoch 3, Sample 13718: Loss: 0.0640\n",
            "Epoch 3, Sample 13719: Loss: 0.2989\n",
            "Epoch 3, Sample 13720: Loss: 0.7171\n",
            "Epoch 3, Sample 13721: Loss: 1.0530\n",
            "Epoch 3, Sample 13722: Loss: 0.4996\n",
            "Epoch 3, Sample 13723: Loss: 0.2044\n",
            "Epoch 3, Sample 13724: Loss: 0.5666\n",
            "Epoch 3, Sample 13725: Loss: 1.0155\n",
            "Epoch 3, Sample 13726: Loss: 1.0155\n",
            "Epoch 3, Sample 13727: Loss: 0.3038\n",
            "Epoch 3, Sample 13728: Loss: 0.2851\n",
            "Epoch 3, Sample 13729: Loss: 0.2034\n",
            "Epoch 3, Sample 13730: Loss: 0.1091\n",
            "Epoch 3, Sample 13731: Loss: 0.5636\n",
            "Epoch 3, Sample 13732: Loss: 6.2000\n",
            "Epoch 3, Sample 13733: Loss: 0.1817\n",
            "Epoch 3, Sample 13734: Loss: 0.7036\n",
            "Epoch 3, Sample 13735: Loss: 0.0001\n",
            "Epoch 3, Sample 13736: Loss: 1.0155\n",
            "Epoch 3, Sample 13737: Loss: 0.1770\n",
            "Epoch 3, Sample 13738: Loss: 6.7251\n",
            "Epoch 3, Sample 13739: Loss: 0.2036\n",
            "Epoch 3, Sample 13740: Loss: 0.1465\n",
            "Epoch 3, Sample 13741: Loss: 0.0205\n",
            "Epoch 3, Sample 13742: Loss: 0.2989\n",
            "Epoch 3, Sample 13743: Loss: 1.0524\n",
            "Epoch 3, Sample 13744: Loss: 1.0155\n",
            "Epoch 3, Sample 13745: Loss: 0.8484\n",
            "Epoch 3, Sample 13746: Loss: 0.4032\n",
            "Epoch 3, Sample 13747: Loss: 0.2759\n",
            "Epoch 3, Sample 13748: Loss: 0.2851\n",
            "Epoch 3, Sample 13749: Loss: 0.2036\n",
            "Epoch 3, Sample 13750: Loss: 1.5057\n",
            "Epoch 3, Sample 13751: Loss: 0.2669\n",
            "Epoch 3, Sample 13752: Loss: 1.0524\n",
            "Epoch 3, Sample 13753: Loss: 0.8145\n",
            "Epoch 3, Sample 13754: Loss: 0.2044\n",
            "Epoch 3, Sample 13755: Loss: 0.0391\n",
            "Epoch 3, Sample 13756: Loss: 0.0744\n",
            "Epoch 3, Sample 13757: Loss: 5.6741\n",
            "Epoch 3, Sample 13758: Loss: 0.2044\n",
            "Epoch 3, Sample 13759: Loss: 0.0026\n",
            "Epoch 3, Sample 13760: Loss: 2.5415\n",
            "Epoch 3, Sample 13761: Loss: 0.3949\n",
            "Epoch 3, Sample 13762: Loss: 0.5000\n",
            "Epoch 3, Sample 13763: Loss: 0.0630\n",
            "Epoch 3, Sample 13764: Loss: 1.7730\n",
            "Epoch 3, Sample 13765: Loss: 0.8951\n",
            "Epoch 3, Sample 13766: Loss: 4.8290\n",
            "Epoch 3, Sample 13767: Loss: 0.2036\n",
            "Epoch 3, Sample 13768: Loss: 0.3399\n",
            "Epoch 3, Sample 13769: Loss: 0.0026\n",
            "Epoch 3, Sample 13770: Loss: 0.8951\n",
            "Epoch 3, Sample 13771: Loss: 0.5078\n",
            "Epoch 3, Sample 13772: Loss: 0.0915\n",
            "Epoch 3, Sample 13773: Loss: 0.0014\n",
            "Epoch 3, Sample 13774: Loss: 0.4611\n",
            "Epoch 3, Sample 13775: Loss: 0.7036\n",
            "Epoch 3, Sample 13776: Loss: 0.0475\n",
            "Epoch 3, Sample 13777: Loss: 0.2044\n",
            "Epoch 3, Sample 13778: Loss: 3.3963\n",
            "Epoch 3, Sample 13779: Loss: 1.6524\n",
            "Epoch 3, Sample 13780: Loss: 0.9190\n",
            "Epoch 3, Sample 13781: Loss: 0.8103\n",
            "Epoch 3, Sample 13782: Loss: 0.0598\n",
            "Epoch 3, Sample 13783: Loss: 0.0062\n",
            "Epoch 3, Sample 13784: Loss: 0.3399\n",
            "Epoch 3, Sample 13785: Loss: 0.0625\n",
            "Epoch 3, Sample 13786: Loss: 0.7036\n",
            "Epoch 3, Sample 13787: Loss: 0.0026\n",
            "Epoch 3, Sample 13788: Loss: 0.6982\n",
            "Epoch 3, Sample 13789: Loss: 0.0006\n",
            "Epoch 3, Sample 13790: Loss: 1.4675\n",
            "Epoch 3, Sample 13791: Loss: 0.6058\n",
            "Epoch 3, Sample 13792: Loss: 0.0145\n",
            "Epoch 3, Sample 13793: Loss: 0.3441\n",
            "Epoch 3, Sample 13794: Loss: 0.0355\n",
            "Epoch 3, Sample 13795: Loss: 0.3399\n",
            "Epoch 3, Sample 13796: Loss: 0.1516\n",
            "Epoch 3, Sample 13797: Loss: 0.1476\n",
            "Epoch 3, Sample 13798: Loss: 0.0202\n",
            "Epoch 3, Sample 13799: Loss: 1.0155\n",
            "Epoch 3, Sample 13800: Loss: 0.4190\n",
            "Epoch 3, Sample 13801: Loss: 0.0084\n",
            "Epoch 3, Sample 13802: Loss: 0.0067\n",
            "Epoch 3, Sample 13803: Loss: 0.6163\n",
            "Epoch 3, Sample 13804: Loss: 0.3399\n",
            "Epoch 3, Sample 13805: Loss: 1.0524\n",
            "Epoch 3, Sample 13806: Loss: 0.1250\n",
            "Epoch 3, Sample 13807: Loss: 0.6621\n",
            "Epoch 3, Sample 13808: Loss: 0.5858\n",
            "Epoch 3, Sample 13809: Loss: 0.2879\n",
            "Epoch 3, Sample 13810: Loss: 0.3441\n",
            "Epoch 3, Sample 13811: Loss: 0.5000\n",
            "Epoch 3, Sample 13812: Loss: 0.3205\n",
            "Epoch 3, Sample 13813: Loss: 0.0707\n",
            "Epoch 3, Sample 13814: Loss: 0.0018\n",
            "Epoch 3, Sample 13815: Loss: 1.0530\n",
            "Epoch 3, Sample 13816: Loss: 0.2044\n",
            "Epoch 3, Sample 13817: Loss: 0.2044\n",
            "Epoch 3, Sample 13818: Loss: 1.0524\n",
            "Epoch 3, Sample 13819: Loss: 0.4799\n",
            "Epoch 3, Sample 13820: Loss: 0.6058\n",
            "Epoch 3, Sample 13821: Loss: 0.3560\n",
            "Epoch 3, Sample 13822: Loss: 0.2034\n",
            "Epoch 3, Sample 13823: Loss: 0.0286\n",
            "Epoch 3, Sample 13824: Loss: 0.4951\n",
            "Epoch 3, Sample 13825: Loss: 0.0626\n",
            "Epoch 3, Sample 13826: Loss: 0.2832\n",
            "Epoch 3, Sample 13827: Loss: 0.0465\n",
            "Epoch 3, Sample 13828: Loss: 0.9785\n",
            "Epoch 3, Sample 13829: Loss: 0.1170\n",
            "Epoch 3, Sample 13830: Loss: 1.0524\n",
            "Epoch 3, Sample 13831: Loss: 0.2044\n",
            "Epoch 3, Sample 13832: Loss: 0.1170\n",
            "Epoch 3, Sample 13833: Loss: 0.0508\n",
            "Epoch 3, Sample 13834: Loss: 0.0774\n",
            "Epoch 3, Sample 13835: Loss: 0.7702\n",
            "Epoch 3, Sample 13836: Loss: 0.0267\n",
            "Epoch 3, Sample 13837: Loss: 1.0524\n",
            "Epoch 3, Sample 13838: Loss: 0.0015\n",
            "Epoch 3, Sample 13839: Loss: 2.6851\n",
            "Epoch 3, Sample 13840: Loss: 0.3024\n",
            "Epoch 3, Sample 13841: Loss: 0.1252\n",
            "Epoch 3, Sample 13842: Loss: 1.0524\n",
            "Epoch 3, Sample 13843: Loss: 0.4958\n",
            "Epoch 3, Sample 13844: Loss: 0.1170\n",
            "Epoch 3, Sample 13845: Loss: 0.5000\n",
            "Epoch 3, Sample 13846: Loss: 0.0060\n",
            "Epoch 3, Sample 13847: Loss: 0.2034\n",
            "Epoch 3, Sample 13848: Loss: 0.2832\n",
            "Epoch 3, Sample 13849: Loss: 0.2219\n",
            "Epoch 3, Sample 13850: Loss: 0.4841\n",
            "Epoch 3, Sample 13851: Loss: 2.4594\n",
            "Epoch 3, Sample 13852: Loss: 0.5871\n",
            "Epoch 3, Sample 13853: Loss: 1.0530\n",
            "Epoch 3, Sample 13854: Loss: 0.0026\n",
            "Epoch 3, Sample 13855: Loss: 0.2035\n",
            "Epoch 3, Sample 13856: Loss: 0.6304\n",
            "Epoch 3, Sample 13857: Loss: 0.1326\n",
            "Epoch 3, Sample 13858: Loss: 1.0524\n",
            "Epoch 3, Sample 13859: Loss: 0.0026\n",
            "Epoch 3, Sample 13860: Loss: 3.4935\n",
            "Epoch 3, Sample 13861: Loss: 0.0010\n",
            "Epoch 3, Sample 13862: Loss: 1.0524\n",
            "Epoch 3, Sample 13863: Loss: 0.0191\n",
            "Epoch 3, Sample 13864: Loss: 0.3150\n",
            "Epoch 3, Sample 13865: Loss: 0.2759\n",
            "Epoch 3, Sample 13866: Loss: 1.0155\n",
            "Epoch 3, Sample 13867: Loss: 0.0306\n",
            "Epoch 3, Sample 13868: Loss: 0.5871\n",
            "Epoch 3, Sample 13869: Loss: 0.0303\n",
            "Epoch 3, Sample 13870: Loss: 1.0524\n",
            "Epoch 3, Sample 13871: Loss: 0.2044\n",
            "Epoch 3, Sample 13872: Loss: 0.0630\n",
            "Epoch 3, Sample 13873: Loss: 0.9367\n",
            "Epoch 3, Sample 13874: Loss: 0.0931\n",
            "Epoch 3, Sample 13875: Loss: 0.0001\n",
            "Epoch 3, Sample 13876: Loss: 0.1091\n",
            "Epoch 3, Sample 13877: Loss: 0.0018\n",
            "Epoch 3, Sample 13878: Loss: 0.0292\n",
            "Epoch 3, Sample 13879: Loss: 0.0000\n",
            "Epoch 3, Sample 13880: Loss: 0.0026\n",
            "Epoch 3, Sample 13881: Loss: 0.0148\n",
            "Epoch 3, Sample 13882: Loss: 1.2926\n",
            "Epoch 3, Sample 13883: Loss: 0.5089\n",
            "Epoch 3, Sample 13884: Loss: 0.1252\n",
            "Epoch 3, Sample 13885: Loss: 0.6092\n",
            "Epoch 3, Sample 13886: Loss: 1.8079\n",
            "Epoch 3, Sample 13887: Loss: 0.3865\n",
            "Epoch 3, Sample 13888: Loss: 0.2036\n",
            "Epoch 3, Sample 13889: Loss: 0.7185\n",
            "Epoch 3, Sample 13890: Loss: 0.0025\n",
            "Epoch 3, Sample 13891: Loss: 0.2112\n",
            "Epoch 3, Sample 13892: Loss: 0.1482\n",
            "Epoch 3, Sample 13893: Loss: 0.7036\n",
            "Epoch 3, Sample 13894: Loss: 0.7597\n",
            "Epoch 3, Sample 13895: Loss: 0.6092\n",
            "Epoch 3, Sample 13896: Loss: 0.0630\n",
            "Epoch 3, Sample 13897: Loss: 0.0744\n",
            "Epoch 3, Sample 13898: Loss: 0.4458\n",
            "Epoch 3, Sample 13899: Loss: 0.2032\n",
            "Epoch 3, Sample 13900: Loss: 1.0155\n",
            "Epoch 3, Sample 13901: Loss: 5.5065\n",
            "Epoch 3, Sample 13902: Loss: 0.0013\n",
            "Epoch 3, Sample 13903: Loss: 0.7036\n",
            "Epoch 3, Sample 13904: Loss: 1.7607\n",
            "Epoch 3, Sample 13905: Loss: 0.0815\n",
            "Epoch 3, Sample 13906: Loss: 2.6446\n",
            "Epoch 3, Sample 13907: Loss: 0.4799\n",
            "Epoch 3, Sample 13908: Loss: 0.3399\n",
            "Epoch 3, Sample 13909: Loss: 0.0008\n",
            "Epoch 3, Sample 13910: Loss: 2.4127\n",
            "Epoch 3, Sample 13911: Loss: 0.1250\n",
            "Epoch 3, Sample 13912: Loss: 0.3598\n",
            "Epoch 3, Sample 13913: Loss: 0.2034\n",
            "Epoch 3, Sample 13914: Loss: 0.1337\n",
            "Epoch 3, Sample 13915: Loss: 0.0234\n",
            "Epoch 3, Sample 13916: Loss: 0.2540\n",
            "Epoch 3, Sample 13917: Loss: 0.0093\n",
            "Epoch 3, Sample 13918: Loss: 0.4930\n",
            "Epoch 3, Sample 13919: Loss: 0.2044\n",
            "Epoch 3, Sample 13920: Loss: 0.0420\n",
            "Epoch 3, Sample 13921: Loss: 0.7036\n",
            "Epoch 3, Sample 13922: Loss: 0.1627\n",
            "Epoch 3, Sample 13923: Loss: 0.0915\n",
            "Epoch 3, Sample 13924: Loss: 0.0026\n",
            "Epoch 3, Sample 13925: Loss: 0.3399\n",
            "Epoch 3, Sample 13926: Loss: 1.0524\n",
            "Epoch 3, Sample 13927: Loss: 0.5636\n",
            "Epoch 3, Sample 13928: Loss: 0.3399\n",
            "Epoch 3, Sample 13929: Loss: 0.0102\n",
            "Epoch 3, Sample 13930: Loss: 0.2034\n",
            "Epoch 3, Sample 13931: Loss: 1.0155\n",
            "Epoch 3, Sample 13932: Loss: 0.0018\n",
            "Epoch 3, Sample 13933: Loss: 0.0518\n",
            "Epoch 3, Sample 13934: Loss: 0.0026\n",
            "Epoch 3, Sample 13935: Loss: 0.1555\n",
            "Epoch 3, Sample 13936: Loss: 0.6252\n",
            "Epoch 3, Sample 13937: Loss: 0.1336\n",
            "Epoch 3, Sample 13938: Loss: 0.2034\n",
            "Epoch 3, Sample 13939: Loss: 0.2759\n",
            "Epoch 3, Sample 13940: Loss: 0.4611\n",
            "Epoch 3, Sample 13941: Loss: 0.0630\n",
            "Epoch 3, Sample 13942: Loss: 0.1250\n",
            "Epoch 3, Sample 13943: Loss: 0.3949\n",
            "Epoch 3, Sample 13944: Loss: 1.0155\n",
            "Epoch 3, Sample 13945: Loss: 0.1559\n",
            "Epoch 3, Sample 13946: Loss: 1.0524\n",
            "Epoch 3, Sample 13947: Loss: 0.2044\n",
            "Epoch 3, Sample 13948: Loss: 0.3568\n",
            "Epoch 3, Sample 13949: Loss: 0.4588\n",
            "Epoch 3, Sample 13950: Loss: 0.5003\n",
            "Epoch 3, Sample 13951: Loss: 0.2032\n",
            "Epoch 3, Sample 13952: Loss: 1.1685\n",
            "Epoch 3, Sample 13953: Loss: 0.1250\n",
            "Epoch 3, Sample 13954: Loss: 0.2032\n",
            "Epoch 3, Sample 13955: Loss: 2.2231\n",
            "Epoch 3, Sample 13956: Loss: 0.6867\n",
            "Epoch 3, Sample 13957: Loss: 0.3949\n",
            "Epoch 3, Sample 13958: Loss: 1.4317\n",
            "Epoch 3, Sample 13959: Loss: 0.7453\n",
            "Epoch 3, Sample 13960: Loss: 1.0155\n",
            "Epoch 3, Sample 13961: Loss: 0.3399\n",
            "Epoch 3, Sample 13962: Loss: 0.7862\n",
            "Epoch 3, Sample 13963: Loss: 0.5972\n",
            "Epoch 3, Sample 13964: Loss: 0.0000\n",
            "Epoch 3, Sample 13965: Loss: 0.4607\n",
            "Epoch 3, Sample 13966: Loss: 0.3441\n",
            "Epoch 3, Sample 13967: Loss: 0.2639\n",
            "Epoch 3, Sample 13968: Loss: 0.0595\n",
            "Epoch 3, Sample 13969: Loss: 1.1569\n",
            "Epoch 3, Sample 13970: Loss: 0.7453\n",
            "Epoch 3, Sample 13971: Loss: 0.2044\n",
            "Epoch 3, Sample 13972: Loss: 0.5078\n",
            "Epoch 3, Sample 13973: Loss: 9.1026\n",
            "Epoch 3, Sample 13974: Loss: 0.9367\n",
            "Epoch 3, Sample 13975: Loss: 0.6198\n",
            "Epoch 3, Sample 13976: Loss: 0.3399\n",
            "Epoch 3, Sample 13977: Loss: 0.2044\n",
            "Epoch 3, Sample 13978: Loss: 0.0303\n",
            "Epoch 3, Sample 13979: Loss: 0.0026\n",
            "Epoch 3, Sample 13980: Loss: 0.9367\n",
            "Epoch 3, Sample 13981: Loss: 0.5972\n",
            "Epoch 3, Sample 13982: Loss: 0.1250\n",
            "Epoch 3, Sample 13983: Loss: 0.0630\n",
            "Epoch 3, Sample 13984: Loss: 0.8737\n",
            "Epoch 3, Sample 13985: Loss: 0.0630\n",
            "Epoch 3, Sample 13986: Loss: 0.0281\n",
            "Epoch 3, Sample 13987: Loss: 0.1838\n",
            "Epoch 3, Sample 13988: Loss: 4.1653\n",
            "Epoch 3, Sample 13989: Loss: 1.3940\n",
            "Epoch 3, Sample 13990: Loss: 0.4181\n",
            "Epoch 3, Sample 13991: Loss: 0.2032\n",
            "Epoch 3, Sample 13992: Loss: 0.3402\n",
            "Epoch 3, Sample 13993: Loss: 0.2034\n",
            "Epoch 3, Sample 13994: Loss: 1.0524\n",
            "Epoch 3, Sample 13995: Loss: 0.4032\n",
            "Epoch 3, Sample 13996: Loss: 0.0281\n",
            "Epoch 3, Sample 13997: Loss: 0.6990\n",
            "Epoch 3, Sample 13998: Loss: 0.0026\n",
            "Epoch 3, Sample 13999: Loss: 0.0364\n",
            "Epoch 3, Sample 14000: Loss: 1.0155\n",
            "Epoch 3, Sample 14001: Loss: 0.0838\n",
            "Epoch 3, Sample 14002: Loss: 0.3728\n",
            "Epoch 3, Sample 14003: Loss: 0.0000\n",
            "Epoch 3, Sample 14004: Loss: 0.0001\n",
            "Epoch 3, Sample 14005: Loss: 0.0933\n",
            "Epoch 3, Sample 14006: Loss: 0.2036\n",
            "Epoch 3, Sample 14007: Loss: 0.0026\n",
            "Epoch 3, Sample 14008: Loss: 0.0084\n",
            "Epoch 3, Sample 14009: Loss: 0.1399\n",
            "Epoch 3, Sample 14010: Loss: 0.7036\n",
            "Epoch 3, Sample 14011: Loss: 0.4849\n",
            "Epoch 3, Sample 14012: Loss: 0.0425\n",
            "Epoch 3, Sample 14013: Loss: 0.3441\n",
            "Epoch 3, Sample 14014: Loss: 0.4799\n",
            "Epoch 3, Sample 14015: Loss: 1.5431\n",
            "Epoch 3, Sample 14016: Loss: 1.0155\n",
            "Epoch 3, Sample 14017: Loss: 0.1592\n",
            "Epoch 3, Sample 14018: Loss: 0.0717\n",
            "Epoch 3, Sample 14019: Loss: 5.7798\n",
            "Epoch 3, Sample 14020: Loss: 12.9123\n",
            "Epoch 3, Sample 14021: Loss: 0.3399\n",
            "Epoch 3, Sample 14022: Loss: 1.0524\n",
            "Epoch 3, Sample 14023: Loss: 1.0524\n",
            "Epoch 3, Sample 14024: Loss: 0.0915\n",
            "Epoch 3, Sample 14025: Loss: 0.3399\n",
            "Epoch 3, Sample 14026: Loss: 0.0466\n",
            "Epoch 3, Sample 14027: Loss: 0.3418\n",
            "Epoch 3, Sample 14028: Loss: 0.1559\n",
            "Epoch 3, Sample 14029: Loss: 0.0003\n",
            "Epoch 3, Sample 14030: Loss: 0.9785\n",
            "Epoch 3, Sample 14031: Loss: 0.9367\n",
            "Epoch 3, Sample 14032: Loss: 0.4032\n",
            "Epoch 3, Sample 14033: Loss: 0.8399\n",
            "Epoch 3, Sample 14034: Loss: 1.0134\n",
            "Epoch 3, Sample 14035: Loss: 0.0915\n",
            "Epoch 3, Sample 14036: Loss: 1.0070\n",
            "Epoch 3, Sample 14037: Loss: 0.8951\n",
            "Epoch 3, Sample 14038: Loss: 0.4382\n",
            "Epoch 3, Sample 14039: Loss: 0.1246\n",
            "Epoch 3, Sample 14040: Loss: 0.2494\n",
            "Epoch 3, Sample 14041: Loss: 2.1112\n",
            "Epoch 3, Sample 14042: Loss: 0.0803\n",
            "Epoch 3, Sample 14043: Loss: 0.1559\n",
            "Epoch 3, Sample 14044: Loss: 0.1248\n",
            "Epoch 3, Sample 14045: Loss: 0.1250\n",
            "Epoch 3, Sample 14046: Loss: 0.1631\n",
            "Epoch 3, Sample 14047: Loss: 0.6990\n",
            "Epoch 3, Sample 14048: Loss: 0.3598\n",
            "Epoch 3, Sample 14049: Loss: 0.2044\n",
            "Epoch 3, Sample 14050: Loss: 0.0062\n",
            "Epoch 3, Sample 14051: Loss: 0.4841\n",
            "Epoch 3, Sample 14052: Loss: 0.3288\n",
            "Epoch 3, Sample 14053: Loss: 0.9367\n",
            "Epoch 3, Sample 14054: Loss: 0.1989\n",
            "Epoch 3, Sample 14055: Loss: 0.2036\n",
            "Epoch 3, Sample 14056: Loss: 1.0524\n",
            "Epoch 3, Sample 14057: Loss: 0.2036\n",
            "Epoch 3, Sample 14058: Loss: 1.0524\n",
            "Epoch 3, Sample 14059: Loss: 0.3604\n",
            "Epoch 3, Sample 14060: Loss: 0.2044\n",
            "Epoch 3, Sample 14061: Loss: 0.4611\n",
            "Epoch 3, Sample 14062: Loss: 0.3539\n",
            "Epoch 3, Sample 14063: Loss: 1.0530\n",
            "Epoch 3, Sample 14064: Loss: 0.0176\n",
            "Epoch 3, Sample 14065: Loss: 0.0018\n",
            "Epoch 3, Sample 14066: Loss: 0.1170\n",
            "Epoch 3, Sample 14067: Loss: 0.0915\n",
            "Epoch 3, Sample 14068: Loss: 0.2219\n",
            "Epoch 3, Sample 14069: Loss: 0.0063\n",
            "Epoch 3, Sample 14070: Loss: 0.0630\n",
            "Epoch 3, Sample 14071: Loss: 0.2271\n",
            "Epoch 3, Sample 14072: Loss: 0.7036\n",
            "Epoch 3, Sample 14073: Loss: 0.0528\n",
            "Epoch 3, Sample 14074: Loss: 0.0625\n",
            "Epoch 3, Sample 14075: Loss: 0.8951\n",
            "Epoch 3, Sample 14076: Loss: 0.8951\n",
            "Epoch 3, Sample 14077: Loss: 0.6092\n",
            "Epoch 3, Sample 14078: Loss: 1.3853\n",
            "Epoch 3, Sample 14079: Loss: 0.8219\n",
            "Epoch 3, Sample 14080: Loss: 0.3074\n",
            "Epoch 3, Sample 14081: Loss: 0.0140\n",
            "Epoch 3, Sample 14082: Loss: 4.0554\n",
            "Epoch 3, Sample 14083: Loss: 0.9266\n",
            "Epoch 3, Sample 14084: Loss: 0.0915\n",
            "Epoch 3, Sample 14085: Loss: 2.0108\n",
            "Epoch 3, Sample 14086: Loss: 5.8945\n",
            "Epoch 3, Sample 14087: Loss: 0.3399\n",
            "Epoch 3, Sample 14088: Loss: 0.0168\n",
            "Epoch 3, Sample 14089: Loss: 0.3441\n",
            "Epoch 3, Sample 14090: Loss: 0.2044\n",
            "Epoch 3, Sample 14091: Loss: 0.1225\n",
            "Epoch 3, Sample 14092: Loss: 0.0915\n",
            "Epoch 3, Sample 14093: Loss: 0.0000\n",
            "Epoch 3, Sample 14094: Loss: 2.1950\n",
            "Epoch 3, Sample 14095: Loss: 0.3402\n",
            "Epoch 3, Sample 14096: Loss: 1.0530\n",
            "Epoch 3, Sample 14097: Loss: 0.1170\n",
            "Epoch 3, Sample 14098: Loss: 0.1091\n",
            "Epoch 3, Sample 14099: Loss: 0.1268\n",
            "Epoch 3, Sample 14100: Loss: 0.2034\n",
            "Epoch 3, Sample 14101: Loss: 0.2044\n",
            "Epoch 3, Sample 14102: Loss: 1.0524\n",
            "Epoch 3, Sample 14103: Loss: 0.3399\n",
            "Epoch 3, Sample 14104: Loss: 4.1642\n",
            "Epoch 3, Sample 14105: Loss: 0.7036\n",
            "Epoch 3, Sample 14106: Loss: 1.0524\n",
            "Epoch 3, Sample 14107: Loss: 0.2759\n",
            "Epoch 3, Sample 14108: Loss: 0.8951\n",
            "Epoch 3, Sample 14109: Loss: 0.1092\n",
            "Epoch 3, Sample 14110: Loss: 0.7742\n",
            "Epoch 3, Sample 14111: Loss: 0.2219\n",
            "Epoch 3, Sample 14112: Loss: 0.2846\n",
            "Epoch 3, Sample 14113: Loss: 0.1248\n",
            "Epoch 3, Sample 14114: Loss: 0.3949\n",
            "Epoch 3, Sample 14115: Loss: 0.0150\n",
            "Epoch 3, Sample 14116: Loss: 0.1364\n",
            "Epoch 3, Sample 14117: Loss: 0.0229\n",
            "Epoch 3, Sample 14118: Loss: 2.7686\n",
            "Epoch 3, Sample 14119: Loss: 0.0480\n",
            "Epoch 3, Sample 14120: Loss: 0.3399\n",
            "Epoch 3, Sample 14121: Loss: 1.0511\n",
            "Epoch 3, Sample 14122: Loss: 0.1665\n",
            "Epoch 3, Sample 14123: Loss: 0.3402\n",
            "Epoch 3, Sample 14124: Loss: 0.1788\n",
            "Epoch 3, Sample 14125: Loss: 0.2832\n",
            "Epoch 3, Sample 14126: Loss: 0.5057\n",
            "Epoch 3, Sample 14127: Loss: 0.3441\n",
            "Epoch 3, Sample 14128: Loss: 0.2044\n",
            "Epoch 3, Sample 14129: Loss: 0.2938\n",
            "Epoch 3, Sample 14130: Loss: 0.0303\n",
            "Epoch 3, Sample 14131: Loss: 1.1789\n",
            "Epoch 3, Sample 14132: Loss: 0.0002\n",
            "Epoch 3, Sample 14133: Loss: 0.1262\n",
            "Epoch 3, Sample 14134: Loss: 0.0363\n",
            "Epoch 3, Sample 14135: Loss: 0.5972\n",
            "Epoch 3, Sample 14136: Loss: 0.0915\n",
            "Epoch 3, Sample 14137: Loss: 0.1240\n",
            "Epoch 3, Sample 14138: Loss: 0.3399\n",
            "Epoch 3, Sample 14139: Loss: 1.0530\n",
            "Epoch 3, Sample 14140: Loss: 0.4841\n",
            "Epoch 3, Sample 14141: Loss: 0.0069\n",
            "Epoch 3, Sample 14142: Loss: 0.1250\n",
            "Epoch 3, Sample 14143: Loss: 0.3247\n",
            "Epoch 3, Sample 14144: Loss: 0.0938\n",
            "Epoch 3, Sample 14145: Loss: 0.3949\n",
            "Epoch 3, Sample 14146: Loss: 0.5858\n",
            "Epoch 3, Sample 14147: Loss: 0.2759\n",
            "Epoch 3, Sample 14148: Loss: 0.4032\n",
            "Epoch 3, Sample 14149: Loss: 0.3399\n",
            "Epoch 3, Sample 14150: Loss: 0.6092\n",
            "Epoch 3, Sample 14151: Loss: 0.1250\n",
            "Epoch 3, Sample 14152: Loss: 0.0144\n",
            "Epoch 3, Sample 14153: Loss: 0.1773\n",
            "Epoch 3, Sample 14154: Loss: 0.4930\n",
            "Epoch 3, Sample 14155: Loss: 0.0947\n",
            "Epoch 3, Sample 14156: Loss: 0.0306\n",
            "Epoch 3, Sample 14157: Loss: 0.0108\n",
            "Epoch 3, Sample 14158: Loss: 0.6473\n",
            "Epoch 3, Sample 14159: Loss: 0.0026\n",
            "Epoch 3, Sample 14160: Loss: 0.2687\n",
            "Epoch 3, Sample 14161: Loss: 0.4799\n",
            "Epoch 3, Sample 14162: Loss: 0.0041\n",
            "Epoch 3, Sample 14163: Loss: 0.0558\n",
            "Epoch 3, Sample 14164: Loss: 0.2044\n",
            "Epoch 3, Sample 14165: Loss: 0.1031\n",
            "Epoch 3, Sample 14166: Loss: 0.2032\n",
            "Epoch 3, Sample 14167: Loss: 0.0018\n",
            "Epoch 3, Sample 14168: Loss: 1.0524\n",
            "Epoch 3, Sample 14169: Loss: 0.0103\n",
            "Epoch 3, Sample 14170: Loss: 0.5375\n",
            "Epoch 3, Sample 14171: Loss: 0.0001\n",
            "Epoch 3, Sample 14172: Loss: 4.7683\n",
            "Epoch 3, Sample 14173: Loss: 0.4799\n",
            "Epoch 3, Sample 14174: Loss: 2.0251\n",
            "Epoch 3, Sample 14175: Loss: 0.1895\n",
            "Epoch 3, Sample 14176: Loss: 0.4032\n",
            "Epoch 3, Sample 14177: Loss: 0.2832\n",
            "Epoch 3, Sample 14178: Loss: 0.5652\n",
            "Epoch 3, Sample 14179: Loss: 0.2034\n",
            "Epoch 3, Sample 14180: Loss: 0.2290\n",
            "Epoch 3, Sample 14181: Loss: 0.5858\n",
            "Epoch 3, Sample 14182: Loss: 0.5972\n",
            "Epoch 3, Sample 14183: Loss: 0.0088\n",
            "Epoch 3, Sample 14184: Loss: 0.3441\n",
            "Epoch 3, Sample 14185: Loss: 0.1372\n",
            "Epoch 3, Sample 14186: Loss: 0.2832\n",
            "Epoch 3, Sample 14187: Loss: 0.0829\n",
            "Epoch 3, Sample 14188: Loss: 0.1559\n",
            "Epoch 3, Sample 14189: Loss: 0.2699\n",
            "Epoch 3, Sample 14190: Loss: 0.3450\n",
            "Epoch 3, Sample 14191: Loss: 0.0065\n",
            "Epoch 3, Sample 14192: Loss: 0.0026\n",
            "Epoch 3, Sample 14193: Loss: 0.3584\n",
            "Epoch 3, Sample 14194: Loss: 0.1170\n",
            "Epoch 3, Sample 14195: Loss: 0.6092\n",
            "Epoch 3, Sample 14196: Loss: 0.6139\n",
            "Epoch 3, Sample 14197: Loss: 1.0524\n",
            "Epoch 3, Sample 14198: Loss: 0.6081\n",
            "Epoch 3, Sample 14199: Loss: 0.0808\n",
            "Epoch 3, Sample 14200: Loss: 0.0168\n",
            "Epoch 3, Sample 14201: Loss: 0.0590\n",
            "Epoch 3, Sample 14202: Loss: 0.3868\n",
            "Epoch 3, Sample 14203: Loss: 0.2044\n",
            "Epoch 3, Sample 14204: Loss: 0.7036\n",
            "Epoch 3, Sample 14205: Loss: 0.2044\n",
            "Epoch 3, Sample 14206: Loss: 0.1113\n",
            "Epoch 3, Sample 14207: Loss: 0.0025\n",
            "Epoch 3, Sample 14208: Loss: 1.0524\n",
            "Epoch 3, Sample 14209: Loss: 0.2689\n",
            "Epoch 3, Sample 14210: Loss: 0.0060\n",
            "Epoch 3, Sample 14211: Loss: 0.4474\n",
            "Epoch 3, Sample 14212: Loss: 1.0524\n",
            "Epoch 3, Sample 14213: Loss: 0.3949\n",
            "Epoch 3, Sample 14214: Loss: 0.4611\n",
            "Epoch 3, Sample 14215: Loss: 0.5089\n",
            "Epoch 3, Sample 14216: Loss: 1.0524\n",
            "Epoch 3, Sample 14217: Loss: 0.0306\n",
            "Epoch 3, Sample 14218: Loss: 1.4187\n",
            "Epoch 3, Sample 14219: Loss: 0.2034\n",
            "Epoch 3, Sample 14220: Loss: 0.0026\n",
            "Epoch 3, Sample 14221: Loss: 0.0026\n",
            "Epoch 3, Sample 14222: Loss: 0.5178\n",
            "Epoch 3, Sample 14223: Loss: 0.0694\n",
            "Epoch 3, Sample 14224: Loss: 0.0386\n",
            "Epoch 3, Sample 14225: Loss: 0.3949\n",
            "Epoch 3, Sample 14226: Loss: 0.2639\n",
            "Epoch 3, Sample 14227: Loss: 0.2879\n",
            "Epoch 3, Sample 14228: Loss: 0.4663\n",
            "Epoch 3, Sample 14229: Loss: 0.2340\n",
            "Epoch 3, Sample 14230: Loss: 1.0530\n",
            "Epoch 3, Sample 14231: Loss: 0.0915\n",
            "Epoch 3, Sample 14232: Loss: 0.4799\n",
            "Epoch 3, Sample 14233: Loss: 1.0524\n",
            "Epoch 3, Sample 14234: Loss: 0.3399\n",
            "Epoch 3, Sample 14235: Loss: 0.2044\n",
            "Epoch 3, Sample 14236: Loss: 0.8951\n",
            "Epoch 3, Sample 14237: Loss: 0.3399\n",
            "Epoch 3, Sample 14238: Loss: 0.2054\n",
            "Epoch 3, Sample 14239: Loss: 0.1982\n",
            "Epoch 3, Sample 14240: Loss: 0.5631\n",
            "Epoch 3, Sample 14241: Loss: 0.0838\n",
            "Epoch 3, Sample 14242: Loss: 0.0604\n",
            "Epoch 3, Sample 14243: Loss: 0.0604\n",
            "Epoch 3, Sample 14244: Loss: 0.8620\n",
            "Epoch 3, Sample 14245: Loss: 0.2112\n",
            "Epoch 3, Sample 14246: Loss: 0.0026\n",
            "Epoch 3, Sample 14247: Loss: 0.2034\n",
            "Epoch 3, Sample 14248: Loss: 0.4611\n",
            "Epoch 3, Sample 14249: Loss: 0.0318\n",
            "Epoch 3, Sample 14250: Loss: 0.0915\n",
            "Epoch 3, Sample 14251: Loss: 0.1068\n",
            "Epoch 3, Sample 14252: Loss: 0.4930\n",
            "Epoch 3, Sample 14253: Loss: 0.0738\n",
            "Epoch 3, Sample 14254: Loss: 0.2838\n",
            "Epoch 3, Sample 14255: Loss: 0.2759\n",
            "Epoch 3, Sample 14256: Loss: 0.7932\n",
            "Epoch 3, Sample 14257: Loss: 0.3568\n",
            "Epoch 3, Sample 14258: Loss: 0.1624\n",
            "Epoch 3, Sample 14259: Loss: 0.0690\n",
            "Epoch 3, Sample 14260: Loss: 0.0018\n",
            "Epoch 3, Sample 14261: Loss: 0.6990\n",
            "Epoch 3, Sample 14262: Loss: 1.0266\n",
            "Epoch 3, Sample 14263: Loss: 1.0644\n",
            "Epoch 3, Sample 14264: Loss: 0.4382\n",
            "Epoch 3, Sample 14265: Loss: 0.1190\n",
            "Epoch 3, Sample 14266: Loss: 0.1559\n",
            "Epoch 3, Sample 14267: Loss: 0.1789\n",
            "Epoch 3, Sample 14268: Loss: 12.0464\n",
            "Epoch 3, Sample 14269: Loss: 0.0018\n",
            "Epoch 3, Sample 14270: Loss: 1.2436\n",
            "Epoch 3, Sample 14271: Loss: 0.3399\n",
            "Epoch 3, Sample 14272: Loss: 0.2639\n",
            "Epoch 3, Sample 14273: Loss: 0.0718\n",
            "Epoch 3, Sample 14274: Loss: 0.1567\n",
            "Epoch 3, Sample 14275: Loss: 0.0084\n",
            "Epoch 3, Sample 14276: Loss: 0.0005\n",
            "Epoch 3, Sample 14277: Loss: 0.0001\n",
            "Epoch 3, Sample 14278: Loss: 0.0303\n",
            "Epoch 3, Sample 14279: Loss: 0.0114\n",
            "Epoch 3, Sample 14280: Loss: 0.6990\n",
            "Epoch 3, Sample 14281: Loss: 0.5799\n",
            "Epoch 3, Sample 14282: Loss: 0.0079\n",
            "Epoch 3, Sample 14283: Loss: 0.6314\n",
            "Epoch 3, Sample 14284: Loss: 0.0938\n",
            "Epoch 3, Sample 14285: Loss: 0.5003\n",
            "Epoch 3, Sample 14286: Loss: 0.2032\n",
            "Epoch 3, Sample 14287: Loss: 0.3932\n",
            "Epoch 3, Sample 14288: Loss: 0.7453\n",
            "Epoch 3, Sample 14289: Loss: 0.2182\n",
            "Epoch 3, Sample 14290: Loss: 0.2132\n",
            "Epoch 3, Sample 14291: Loss: 0.0026\n",
            "Epoch 3, Sample 14292: Loss: 1.0530\n",
            "Epoch 3, Sample 14293: Loss: 0.0001\n",
            "Epoch 3, Sample 14294: Loss: 0.2034\n",
            "Epoch 3, Sample 14295: Loss: 0.0478\n",
            "Epoch 3, Sample 14296: Loss: 0.4799\n",
            "Epoch 3, Sample 14297: Loss: 0.2044\n",
            "Epoch 3, Sample 14298: Loss: 0.0063\n",
            "Epoch 3, Sample 14299: Loss: 0.0018\n",
            "Epoch 3, Sample 14300: Loss: 0.1170\n",
            "Epoch 3, Sample 14301: Loss: 1.0524\n",
            "Epoch 3, Sample 14302: Loss: 0.5858\n",
            "Epoch 3, Sample 14303: Loss: 1.0524\n",
            "Epoch 3, Sample 14304: Loss: 0.3402\n",
            "Epoch 3, Sample 14305: Loss: 0.0685\n",
            "Epoch 3, Sample 14306: Loss: 1.0524\n",
            "Epoch 3, Sample 14307: Loss: 0.1250\n",
            "Epoch 3, Sample 14308: Loss: 0.5871\n",
            "Epoch 3, Sample 14309: Loss: 0.0469\n",
            "Epoch 3, Sample 14310: Loss: 0.0415\n",
            "Epoch 3, Sample 14311: Loss: 0.3399\n",
            "Epoch 3, Sample 14312: Loss: 0.7036\n",
            "Epoch 3, Sample 14313: Loss: 0.2098\n",
            "Epoch 3, Sample 14314: Loss: 0.8951\n",
            "Epoch 3, Sample 14315: Loss: 0.0422\n",
            "Epoch 3, Sample 14316: Loss: 0.3399\n",
            "Epoch 3, Sample 14317: Loss: 0.4930\n",
            "Epoch 3, Sample 14318: Loss: 0.7036\n",
            "Epoch 3, Sample 14319: Loss: 0.2034\n",
            "Epoch 3, Sample 14320: Loss: 0.0640\n",
            "Epoch 3, Sample 14321: Loss: 0.6304\n",
            "Epoch 3, Sample 14322: Loss: 0.0838\n",
            "Epoch 3, Sample 14323: Loss: 0.0039\n",
            "Epoch 3, Sample 14324: Loss: 0.5858\n",
            "Epoch 3, Sample 14325: Loss: 0.2032\n",
            "Epoch 3, Sample 14326: Loss: 0.0821\n",
            "Epoch 3, Sample 14327: Loss: 0.2639\n",
            "Epoch 3, Sample 14328: Loss: 0.2044\n",
            "Epoch 3, Sample 14329: Loss: 0.5972\n",
            "Epoch 3, Sample 14330: Loss: 0.0238\n",
            "Epoch 3, Sample 14331: Loss: 1.0530\n",
            "Epoch 3, Sample 14332: Loss: 0.0001\n",
            "Epoch 3, Sample 14333: Loss: 0.1250\n",
            "Epoch 3, Sample 14334: Loss: 1.0530\n",
            "Epoch 3, Sample 14335: Loss: 0.0001\n",
            "Epoch 3, Sample 14336: Loss: 0.3487\n",
            "Epoch 3, Sample 14337: Loss: 0.0238\n",
            "Epoch 3, Sample 14338: Loss: 0.2832\n",
            "Epoch 3, Sample 14339: Loss: 1.0524\n",
            "Epoch 3, Sample 14340: Loss: 0.3758\n",
            "Epoch 3, Sample 14341: Loss: 0.1066\n",
            "Epoch 3, Sample 14342: Loss: 0.8275\n",
            "Epoch 3, Sample 14343: Loss: 0.0101\n",
            "Epoch 3, Sample 14344: Loss: 0.0063\n",
            "Epoch 3, Sample 14345: Loss: 0.2975\n",
            "Epoch 3, Sample 14346: Loss: 0.0006\n",
            "Epoch 3, Sample 14347: Loss: 1.0530\n",
            "Epoch 3, Sample 14348: Loss: 0.2639\n",
            "Epoch 3, Sample 14349: Loss: 1.5122\n",
            "Epoch 3, Sample 14350: Loss: 0.0005\n",
            "Epoch 3, Sample 14351: Loss: 0.1508\n",
            "Epoch 3, Sample 14352: Loss: 0.6990\n",
            "Epoch 3, Sample 14353: Loss: 0.1009\n",
            "Epoch 3, Sample 14354: Loss: 4.8662\n",
            "Epoch 3, Sample 14355: Loss: 0.0838\n",
            "Epoch 3, Sample 14356: Loss: 0.7705\n",
            "Epoch 3, Sample 14357: Loss: 1.0524\n",
            "Epoch 3, Sample 14358: Loss: 0.0018\n",
            "Epoch 3, Sample 14359: Loss: 0.4474\n",
            "Epoch 3, Sample 14360: Loss: 0.4989\n",
            "Epoch 3, Sample 14361: Loss: 0.1261\n",
            "Epoch 3, Sample 14362: Loss: 0.7453\n",
            "Epoch 3, Sample 14363: Loss: 0.6304\n",
            "Epoch 3, Sample 14364: Loss: 0.0712\n",
            "Epoch 3, Sample 14365: Loss: 0.0744\n",
            "Epoch 3, Sample 14366: Loss: 0.0026\n",
            "Epoch 3, Sample 14367: Loss: 0.5003\n",
            "Epoch 3, Sample 14368: Loss: 0.4597\n",
            "Epoch 3, Sample 14369: Loss: 0.4466\n",
            "Epoch 3, Sample 14370: Loss: 0.2032\n",
            "Epoch 3, Sample 14371: Loss: 0.0686\n",
            "Epoch 3, Sample 14372: Loss: 0.2044\n",
            "Epoch 3, Sample 14373: Loss: 0.5636\n",
            "Epoch 3, Sample 14374: Loss: 0.5000\n",
            "Epoch 3, Sample 14375: Loss: 0.2759\n",
            "Epoch 3, Sample 14376: Loss: 0.8484\n",
            "Epoch 3, Sample 14377: Loss: 1.1569\n",
            "Epoch 3, Sample 14378: Loss: 0.7036\n",
            "Epoch 3, Sample 14379: Loss: 0.0060\n",
            "Epoch 3, Sample 14380: Loss: 1.0530\n",
            "Epoch 3, Sample 14381: Loss: 0.0630\n",
            "Epoch 3, Sample 14382: Loss: 0.0270\n",
            "Epoch 3, Sample 14383: Loss: 0.2044\n",
            "Epoch 3, Sample 14384: Loss: 1.1133\n",
            "Epoch 3, Sample 14385: Loss: 0.0363\n",
            "Epoch 3, Sample 14386: Loss: 1.0070\n",
            "Epoch 3, Sample 14387: Loss: 0.3332\n",
            "Epoch 3, Sample 14388: Loss: 0.4382\n",
            "Epoch 3, Sample 14389: Loss: 0.3805\n",
            "Epoch 3, Sample 14390: Loss: 1.7459\n",
            "Epoch 3, Sample 14391: Loss: 0.4944\n",
            "Epoch 3, Sample 14392: Loss: 0.1559\n",
            "Epoch 3, Sample 14393: Loss: 1.4305\n",
            "Epoch 3, Sample 14394: Loss: 0.5858\n",
            "Epoch 3, Sample 14395: Loss: 0.5220\n",
            "Epoch 3, Sample 14396: Loss: 0.0674\n",
            "Epoch 3, Sample 14397: Loss: 1.0530\n",
            "Epoch 3, Sample 14398: Loss: 1.0524\n",
            "Epoch 3, Sample 14399: Loss: 0.4446\n",
            "Epoch 3, Sample 14400: Loss: 0.1008\n",
            "Epoch 3, Sample 14401: Loss: 1.4411\n",
            "Epoch 3, Sample 14402: Loss: 0.0026\n",
            "Epoch 3, Sample 14403: Loss: 0.5078\n",
            "Epoch 3, Sample 14404: Loss: 1.5572\n",
            "Epoch 3, Sample 14405: Loss: 1.0524\n",
            "Epoch 3, Sample 14406: Loss: 1.6694\n",
            "Epoch 3, Sample 14407: Loss: 1.0524\n",
            "Epoch 3, Sample 14408: Loss: 0.3399\n",
            "Epoch 3, Sample 14409: Loss: 0.3669\n",
            "Epoch 3, Sample 14410: Loss: 0.0018\n",
            "Epoch 3, Sample 14411: Loss: 0.0026\n",
            "Epoch 3, Sample 14412: Loss: 0.0026\n",
            "Epoch 3, Sample 14413: Loss: 0.2032\n",
            "Epoch 3, Sample 14414: Loss: 0.1473\n",
            "Epoch 3, Sample 14415: Loss: 0.5310\n",
            "Epoch 3, Sample 14416: Loss: 0.1373\n",
            "Epoch 3, Sample 14417: Loss: 3.1546\n",
            "Epoch 3, Sample 14418: Loss: 0.2044\n",
            "Epoch 3, Sample 14419: Loss: 0.1901\n",
            "Epoch 3, Sample 14420: Loss: 0.0001\n",
            "Epoch 3, Sample 14421: Loss: 0.2266\n",
            "Epoch 3, Sample 14422: Loss: 0.6018\n",
            "Epoch 3, Sample 14423: Loss: 0.3537\n",
            "Epoch 3, Sample 14424: Loss: 0.0183\n",
            "Epoch 3, Sample 14425: Loss: 0.4799\n",
            "Epoch 3, Sample 14426: Loss: 0.4474\n",
            "Epoch 3, Sample 14427: Loss: 0.3456\n",
            "Epoch 3, Sample 14428: Loss: 0.4841\n",
            "Epoch 3, Sample 14429: Loss: 0.3237\n",
            "Epoch 3, Sample 14430: Loss: 0.6272\n",
            "Epoch 3, Sample 14431: Loss: 0.3237\n",
            "Epoch 3, Sample 14432: Loss: 0.0707\n",
            "Epoch 3, Sample 14433: Loss: 0.0755\n",
            "Epoch 3, Sample 14434: Loss: 0.0018\n",
            "Epoch 3, Sample 14435: Loss: 1.0530\n",
            "Epoch 3, Sample 14436: Loss: 0.1170\n",
            "Epoch 3, Sample 14437: Loss: 0.2832\n",
            "Epoch 3, Sample 14438: Loss: 0.2034\n",
            "Epoch 3, Sample 14439: Loss: 0.3441\n",
            "Epoch 3, Sample 14440: Loss: 0.0026\n",
            "Epoch 3, Sample 14441: Loss: 0.7453\n",
            "Epoch 3, Sample 14442: Loss: 0.3362\n",
            "Epoch 3, Sample 14443: Loss: 0.1523\n",
            "Epoch 3, Sample 14444: Loss: 0.6304\n",
            "Epoch 3, Sample 14445: Loss: 1.0155\n",
            "Epoch 3, Sample 14446: Loss: 0.9120\n",
            "Epoch 3, Sample 14447: Loss: 0.0026\n",
            "Epoch 3, Sample 14448: Loss: 0.2044\n",
            "Epoch 3, Sample 14449: Loss: 0.7036\n",
            "Epoch 3, Sample 14450: Loss: 0.1559\n",
            "Epoch 3, Sample 14451: Loss: 0.9001\n",
            "Epoch 3, Sample 14452: Loss: 0.1170\n",
            "Epoch 3, Sample 14453: Loss: 0.2032\n",
            "Epoch 3, Sample 14454: Loss: 1.0524\n",
            "Epoch 3, Sample 14455: Loss: 0.2639\n",
            "Epoch 3, Sample 14456: Loss: 0.1559\n",
            "Epoch 3, Sample 14457: Loss: 0.7036\n",
            "Epoch 3, Sample 14458: Loss: 0.2112\n",
            "Epoch 3, Sample 14459: Loss: 5.2899\n",
            "Epoch 3, Sample 14460: Loss: 0.2032\n",
            "Epoch 3, Sample 14461: Loss: 0.2970\n",
            "Epoch 3, Sample 14462: Loss: 2.4110\n",
            "Epoch 3, Sample 14463: Loss: 0.2032\n",
            "Epoch 3, Sample 14464: Loss: 1.0524\n",
            "Epoch 3, Sample 14465: Loss: 1.8304\n",
            "Epoch 3, Sample 14466: Loss: 0.5000\n",
            "Epoch 3, Sample 14467: Loss: 0.1465\n",
            "Epoch 3, Sample 14468: Loss: 0.0026\n",
            "Epoch 3, Sample 14469: Loss: 0.3175\n",
            "Epoch 3, Sample 14470: Loss: 0.2832\n",
            "Epoch 3, Sample 14471: Loss: 0.0707\n",
            "Epoch 3, Sample 14472: Loss: 0.2036\n",
            "Epoch 3, Sample 14473: Loss: 0.5000\n",
            "Epoch 3, Sample 14474: Loss: 0.0181\n",
            "Epoch 3, Sample 14475: Loss: 0.0066\n",
            "Epoch 3, Sample 14476: Loss: 0.1517\n",
            "Epoch 3, Sample 14477: Loss: 0.0554\n",
            "Epoch 3, Sample 14478: Loss: 0.7036\n",
            "Epoch 3, Sample 14479: Loss: 0.0919\n",
            "Epoch 3, Sample 14480: Loss: 0.2704\n",
            "Epoch 3, Sample 14481: Loss: 0.2459\n",
            "Epoch 3, Sample 14482: Loss: 0.0688\n",
            "Epoch 3, Sample 14483: Loss: 0.6039\n",
            "Epoch 3, Sample 14484: Loss: 1.0155\n",
            "Epoch 3, Sample 14485: Loss: 0.0062\n",
            "Epoch 3, Sample 14486: Loss: 0.4799\n",
            "Epoch 3, Sample 14487: Loss: 0.3121\n",
            "Epoch 3, Sample 14488: Loss: 0.0216\n",
            "Epoch 3, Sample 14489: Loss: 0.2014\n",
            "Epoch 3, Sample 14490: Loss: 1.5235\n",
            "Epoch 3, Sample 14491: Loss: 0.0264\n",
            "Epoch 3, Sample 14492: Loss: 0.4032\n",
            "Epoch 3, Sample 14493: Loss: 1.0524\n",
            "Epoch 3, Sample 14494: Loss: 0.0915\n",
            "Epoch 3, Sample 14495: Loss: 2.5553\n",
            "Epoch 3, Sample 14496: Loss: 0.2855\n",
            "Epoch 3, Sample 14497: Loss: 0.5003\n",
            "Epoch 3, Sample 14498: Loss: 0.0026\n",
            "Epoch 3, Sample 14499: Loss: 0.2034\n",
            "Epoch 3, Sample 14500: Loss: 0.1225\n",
            "Epoch 3, Sample 14501: Loss: 0.4799\n",
            "Epoch 3, Sample 14502: Loss: 0.3399\n",
            "Epoch 3, Sample 14503: Loss: 0.0067\n",
            "Epoch 3, Sample 14504: Loss: 1.6877\n",
            "Epoch 3, Sample 14505: Loss: 0.3459\n",
            "Epoch 3, Sample 14506: Loss: 0.2034\n",
            "Epoch 3, Sample 14507: Loss: 1.1219\n",
            "Epoch 3, Sample 14508: Loss: 0.2832\n",
            "Epoch 3, Sample 14509: Loss: 0.5350\n",
            "Epoch 3, Sample 14510: Loss: 0.0001\n",
            "Epoch 3, Sample 14511: Loss: 0.0020\n",
            "Epoch 3, Sample 14512: Loss: 0.5858\n",
            "Epoch 3, Sample 14513: Loss: 0.7036\n",
            "Epoch 3, Sample 14514: Loss: 0.2036\n",
            "Epoch 3, Sample 14515: Loss: 0.5918\n",
            "Epoch 3, Sample 14516: Loss: 0.4799\n",
            "Epoch 3, Sample 14517: Loss: 0.0429\n",
            "Epoch 3, Sample 14518: Loss: 0.1170\n",
            "Epoch 3, Sample 14519: Loss: 0.0000\n",
            "Epoch 3, Sample 14520: Loss: 0.0625\n",
            "Epoch 3, Sample 14521: Loss: 0.8951\n",
            "Epoch 3, Sample 14522: Loss: 0.3506\n",
            "Epoch 3, Sample 14523: Loss: 0.4611\n",
            "Epoch 3, Sample 14524: Loss: 1.0524\n",
            "Epoch 3, Sample 14525: Loss: 0.2639\n",
            "Epoch 3, Sample 14526: Loss: 0.2759\n",
            "Epoch 3, Sample 14527: Loss: 0.7036\n",
            "Epoch 3, Sample 14528: Loss: 0.5356\n",
            "Epoch 3, Sample 14529: Loss: 0.0030\n",
            "Epoch 3, Sample 14530: Loss: 1.7718\n",
            "Epoch 3, Sample 14531: Loss: 0.0344\n",
            "Epoch 3, Sample 14532: Loss: 0.2799\n",
            "Epoch 3, Sample 14533: Loss: 0.3399\n",
            "Epoch 3, Sample 14534: Loss: 0.7036\n",
            "Epoch 3, Sample 14535: Loss: 0.0018\n",
            "Epoch 3, Sample 14536: Loss: 0.0258\n",
            "Epoch 3, Sample 14537: Loss: 1.0530\n",
            "Epoch 3, Sample 14538: Loss: 0.5000\n",
            "Epoch 3, Sample 14539: Loss: 0.0064\n",
            "Epoch 3, Sample 14540: Loss: 0.2044\n",
            "Epoch 3, Sample 14541: Loss: 0.2032\n",
            "Epoch 3, Sample 14542: Loss: 0.3441\n",
            "Epoch 3, Sample 14543: Loss: 1.0524\n",
            "Epoch 3, Sample 14544: Loss: 0.3399\n",
            "Epoch 3, Sample 14545: Loss: 0.2036\n",
            "Epoch 3, Sample 14546: Loss: 0.0018\n",
            "Epoch 3, Sample 14547: Loss: 0.2340\n",
            "Epoch 3, Sample 14548: Loss: 0.3441\n",
            "Epoch 3, Sample 14549: Loss: 0.0000\n",
            "Epoch 3, Sample 14550: Loss: 0.0242\n",
            "Epoch 3, Sample 14551: Loss: 0.1170\n",
            "Epoch 3, Sample 14552: Loss: 0.3598\n",
            "Epoch 3, Sample 14553: Loss: 0.0492\n",
            "Epoch 3, Sample 14554: Loss: 0.2494\n",
            "Epoch 3, Sample 14555: Loss: 0.1250\n",
            "Epoch 3, Sample 14556: Loss: 0.0915\n",
            "Epoch 3, Sample 14557: Loss: 0.0630\n",
            "Epoch 3, Sample 14558: Loss: 0.3758\n",
            "Epoch 3, Sample 14559: Loss: 0.4841\n",
            "Epoch 3, Sample 14560: Loss: 0.0145\n",
            "Epoch 3, Sample 14561: Loss: 0.1989\n",
            "Epoch 3, Sample 14562: Loss: 0.2036\n",
            "Epoch 3, Sample 14563: Loss: 1.0524\n",
            "Epoch 3, Sample 14564: Loss: 0.0018\n",
            "Epoch 3, Sample 14565: Loss: 1.0524\n",
            "Epoch 3, Sample 14566: Loss: 0.3568\n",
            "Epoch 3, Sample 14567: Loss: 1.0530\n",
            "Epoch 3, Sample 14568: Loss: 0.7036\n",
            "Epoch 3, Sample 14569: Loss: 0.0001\n",
            "Epoch 3, Sample 14570: Loss: 0.9953\n",
            "Epoch 3, Sample 14571: Loss: 0.2044\n",
            "Epoch 3, Sample 14572: Loss: 0.2044\n",
            "Epoch 3, Sample 14573: Loss: 0.2044\n",
            "Epoch 3, Sample 14574: Loss: 1.0524\n",
            "Epoch 3, Sample 14575: Loss: 0.0067\n",
            "Epoch 3, Sample 14576: Loss: 0.8607\n",
            "Epoch 3, Sample 14577: Loss: 0.1047\n",
            "Epoch 3, Sample 14578: Loss: 0.7036\n",
            "Epoch 3, Sample 14579: Loss: 0.0097\n",
            "Epoch 3, Sample 14580: Loss: 0.0036\n",
            "Epoch 3, Sample 14581: Loss: 0.0025\n",
            "Epoch 3, Sample 14582: Loss: 0.3949\n",
            "Epoch 3, Sample 14583: Loss: 0.0026\n",
            "Epoch 3, Sample 14584: Loss: 0.2112\n",
            "Epoch 3, Sample 14585: Loss: 0.2044\n",
            "Epoch 3, Sample 14586: Loss: 1.0524\n",
            "Epoch 3, Sample 14587: Loss: 2.3565\n",
            "Epoch 3, Sample 14588: Loss: 0.0212\n",
            "Epoch 3, Sample 14589: Loss: 17.7846\n",
            "Epoch 3, Sample 14590: Loss: 0.2663\n",
            "Epoch 3, Sample 14591: Loss: 0.0070\n",
            "Epoch 3, Sample 14592: Loss: 0.1523\n",
            "Epoch 3, Sample 14593: Loss: 0.4527\n",
            "Epoch 3, Sample 14594: Loss: 0.7036\n",
            "Epoch 3, Sample 14595: Loss: 0.0145\n",
            "Epoch 3, Sample 14596: Loss: 0.1250\n",
            "Epoch 3, Sample 14597: Loss: 1.4050\n",
            "Epoch 3, Sample 14598: Loss: 0.0630\n",
            "Epoch 3, Sample 14599: Loss: 0.2664\n",
            "Epoch 3, Sample 14600: Loss: 0.2339\n",
            "Epoch 3, Sample 14601: Loss: 0.0625\n",
            "Epoch 3, Sample 14602: Loss: 0.3399\n",
            "Epoch 3, Sample 14603: Loss: 2.3727\n",
            "Epoch 3, Sample 14604: Loss: 1.2397\n",
            "Epoch 3, Sample 14605: Loss: 0.0667\n",
            "Epoch 3, Sample 14606: Loss: 0.0087\n",
            "Epoch 3, Sample 14607: Loss: 0.0001\n",
            "Epoch 3, Sample 14608: Loss: 0.1419\n",
            "Epoch 3, Sample 14609: Loss: 0.4930\n",
            "Epoch 3, Sample 14610: Loss: 0.0261\n",
            "Epoch 3, Sample 14611: Loss: 0.0264\n",
            "Epoch 3, Sample 14612: Loss: 0.3036\n",
            "Epoch 3, Sample 14613: Loss: 0.0630\n",
            "Epoch 3, Sample 14614: Loss: 0.0027\n",
            "Epoch 3, Sample 14615: Loss: 0.2034\n",
            "Epoch 3, Sample 14616: Loss: 0.3593\n",
            "Epoch 3, Sample 14617: Loss: 0.0630\n",
            "Epoch 3, Sample 14618: Loss: 0.0018\n",
            "Epoch 3, Sample 14619: Loss: 0.0205\n",
            "Epoch 3, Sample 14620: Loss: 0.2759\n",
            "Epoch 3, Sample 14621: Loss: 0.3441\n",
            "Epoch 3, Sample 14622: Loss: 1.0227\n",
            "Epoch 3, Sample 14623: Loss: 0.2036\n",
            "Epoch 3, Sample 14624: Loss: 0.2032\n",
            "Epoch 3, Sample 14625: Loss: 0.4930\n",
            "Epoch 3, Sample 14626: Loss: 1.0524\n",
            "Epoch 3, Sample 14627: Loss: 0.2032\n",
            "Epoch 3, Sample 14628: Loss: 0.7036\n",
            "Epoch 3, Sample 14629: Loss: 0.1337\n",
            "Epoch 3, Sample 14630: Loss: 0.0060\n",
            "Epoch 3, Sample 14631: Loss: 0.0026\n",
            "Epoch 3, Sample 14632: Loss: 1.0535\n",
            "Epoch 3, Sample 14633: Loss: 0.2034\n",
            "Epoch 3, Sample 14634: Loss: 0.6990\n",
            "Epoch 3, Sample 14635: Loss: 0.0358\n",
            "Epoch 3, Sample 14636: Loss: 0.3399\n",
            "Epoch 3, Sample 14637: Loss: 1.4007\n",
            "Epoch 3, Sample 14638: Loss: 0.0630\n",
            "Epoch 3, Sample 14639: Loss: 0.6990\n",
            "Epoch 3, Sample 14640: Loss: 0.0915\n",
            "Epoch 3, Sample 14641: Loss: 1.3519\n",
            "Epoch 3, Sample 14642: Loss: 0.1559\n",
            "Epoch 3, Sample 14643: Loss: 0.4770\n",
            "Epoch 3, Sample 14644: Loss: 0.0026\n",
            "Epoch 3, Sample 14645: Loss: 0.2340\n",
            "Epoch 3, Sample 14646: Loss: 1.7549\n",
            "Epoch 3, Sample 14647: Loss: 0.0319\n",
            "Epoch 3, Sample 14648: Loss: 0.2032\n",
            "Epoch 3, Sample 14649: Loss: 1.1569\n",
            "Epoch 3, Sample 14650: Loss: 0.0013\n",
            "Epoch 3, Sample 14651: Loss: 0.1006\n",
            "Epoch 3, Sample 14652: Loss: 0.0384\n",
            "Epoch 3, Sample 14653: Loss: 1.0155\n",
            "Epoch 3, Sample 14654: Loss: 0.0819\n",
            "Epoch 3, Sample 14655: Loss: 0.7036\n",
            "Epoch 3, Sample 14656: Loss: 0.1092\n",
            "Epoch 3, Sample 14657: Loss: 0.2034\n",
            "Epoch 3, Sample 14658: Loss: 0.1817\n",
            "Epoch 3, Sample 14659: Loss: 0.8484\n",
            "Epoch 3, Sample 14660: Loss: 0.2032\n",
            "Epoch 3, Sample 14661: Loss: 0.2044\n",
            "Epoch 3, Sample 14662: Loss: 0.3113\n",
            "Epoch 3, Sample 14663: Loss: 0.3304\n",
            "Epoch 3, Sample 14664: Loss: 0.3343\n",
            "Epoch 3, Sample 14665: Loss: 0.0920\n",
            "Epoch 3, Sample 14666: Loss: 0.1588\n",
            "Epoch 3, Sample 14667: Loss: 0.2044\n",
            "Epoch 3, Sample 14668: Loss: 0.7036\n",
            "Epoch 3, Sample 14669: Loss: 0.0026\n",
            "Epoch 3, Sample 14670: Loss: 0.4996\n",
            "Epoch 3, Sample 14671: Loss: 0.0026\n",
            "Epoch 3, Sample 14672: Loss: 0.8951\n",
            "Epoch 3, Sample 14673: Loss: 0.1250\n",
            "Epoch 3, Sample 14674: Loss: 0.1511\n",
            "Epoch 3, Sample 14675: Loss: 0.2112\n",
            "Epoch 3, Sample 14676: Loss: 0.0072\n",
            "Epoch 3, Sample 14677: Loss: 0.2639\n",
            "Epoch 3, Sample 14678: Loss: 0.1555\n",
            "Epoch 3, Sample 14679: Loss: 0.0838\n",
            "Epoch 3, Sample 14680: Loss: 0.0938\n",
            "Epoch 3, Sample 14681: Loss: 0.3399\n",
            "Epoch 3, Sample 14682: Loss: 1.0524\n",
            "Epoch 3, Sample 14683: Loss: 0.8740\n",
            "Epoch 3, Sample 14684: Loss: 0.0947\n",
            "Epoch 3, Sample 14685: Loss: 0.1588\n",
            "Epoch 3, Sample 14686: Loss: 0.0108\n",
            "Epoch 3, Sample 14687: Loss: 0.2494\n",
            "Epoch 3, Sample 14688: Loss: 0.1559\n",
            "Epoch 3, Sample 14689: Loss: 0.0001\n",
            "Epoch 3, Sample 14690: Loss: 2.7331\n",
            "Epoch 3, Sample 14691: Loss: 0.0630\n",
            "Epoch 3, Sample 14692: Loss: 0.4276\n",
            "Epoch 3, Sample 14693: Loss: 1.0155\n",
            "Epoch 3, Sample 14694: Loss: 0.5871\n",
            "Epoch 3, Sample 14695: Loss: 0.5000\n",
            "Epoch 3, Sample 14696: Loss: 0.0018\n",
            "Epoch 3, Sample 14697: Loss: 0.2812\n",
            "Epoch 3, Sample 14698: Loss: 0.0630\n",
            "Epoch 3, Sample 14699: Loss: 0.2044\n",
            "Epoch 3, Sample 14700: Loss: 0.1022\n",
            "Epoch 3, Sample 14701: Loss: 0.4587\n",
            "Epoch 3, Sample 14702: Loss: 0.2639\n",
            "Epoch 3, Sample 14703: Loss: 0.1170\n",
            "Epoch 3, Sample 14704: Loss: 0.1250\n",
            "Epoch 3, Sample 14705: Loss: 0.7036\n",
            "Epoch 3, Sample 14706: Loss: 2.8046\n",
            "Epoch 3, Sample 14707: Loss: 1.0524\n",
            "Epoch 3, Sample 14708: Loss: 0.1250\n",
            "Epoch 3, Sample 14709: Loss: 0.0849\n",
            "Epoch 3, Sample 14710: Loss: 1.0227\n",
            "Epoch 3, Sample 14711: Loss: 1.0524\n",
            "Epoch 3, Sample 14712: Loss: 0.2704\n",
            "Epoch 3, Sample 14713: Loss: 0.1337\n",
            "Epoch 3, Sample 14714: Loss: 0.0353\n",
            "Epoch 3, Sample 14715: Loss: 0.2044\n",
            "Epoch 3, Sample 14716: Loss: 0.0070\n",
            "Epoch 3, Sample 14717: Loss: 0.4930\n",
            "Epoch 3, Sample 14718: Loss: 1.2643\n",
            "Epoch 3, Sample 14719: Loss: 0.0022\n",
            "Epoch 3, Sample 14720: Loss: 0.0630\n",
            "Epoch 3, Sample 14721: Loss: 0.2851\n",
            "Epoch 3, Sample 14722: Loss: 0.2044\n",
            "Epoch 3, Sample 14723: Loss: 0.0000\n",
            "Epoch 3, Sample 14724: Loss: 0.1252\n",
            "Epoch 3, Sample 14725: Loss: 0.7036\n",
            "Epoch 3, Sample 14726: Loss: 0.6092\n",
            "Epoch 3, Sample 14727: Loss: 0.2759\n",
            "Epoch 3, Sample 14728: Loss: 1.0524\n",
            "Epoch 3, Sample 14729: Loss: 0.5328\n",
            "Epoch 3, Sample 14730: Loss: 0.2884\n",
            "Epoch 3, Sample 14731: Loss: 0.3633\n",
            "Epoch 3, Sample 14732: Loss: 0.1378\n",
            "Epoch 3, Sample 14733: Loss: 0.0915\n",
            "Epoch 3, Sample 14734: Loss: 0.0009\n",
            "Epoch 3, Sample 14735: Loss: 0.7036\n",
            "Epoch 3, Sample 14736: Loss: 0.5858\n",
            "Epoch 3, Sample 14737: Loss: 0.0212\n",
            "Epoch 3, Sample 14738: Loss: 0.1523\n",
            "Epoch 3, Sample 14739: Loss: 0.0026\n",
            "Epoch 3, Sample 14740: Loss: 0.4032\n",
            "Epoch 3, Sample 14741: Loss: 1.3641\n",
            "Epoch 3, Sample 14742: Loss: 0.0838\n",
            "Epoch 3, Sample 14743: Loss: 0.7036\n",
            "Epoch 3, Sample 14744: Loss: 0.5218\n",
            "Epoch 3, Sample 14745: Loss: 0.2759\n",
            "Epoch 3, Sample 14746: Loss: 0.3441\n",
            "Epoch 3, Sample 14747: Loss: 5.5224\n",
            "Epoch 3, Sample 14748: Loss: 0.1337\n",
            "Epoch 3, Sample 14749: Loss: 0.5871\n",
            "Epoch 3, Sample 14750: Loss: 0.7453\n",
            "Epoch 3, Sample 14751: Loss: 0.3223\n",
            "Epoch 3, Sample 14752: Loss: 0.3399\n",
            "Epoch 3, Sample 14753: Loss: 0.0270\n",
            "Epoch 3, Sample 14754: Loss: 0.2639\n",
            "Epoch 3, Sample 14755: Loss: 0.0026\n",
            "Epoch 3, Sample 14756: Loss: 0.1977\n",
            "Epoch 3, Sample 14757: Loss: 0.0356\n",
            "Epoch 3, Sample 14758: Loss: 0.4021\n",
            "Epoch 3, Sample 14759: Loss: 3.4424\n",
            "Epoch 3, Sample 14760: Loss: 0.3963\n",
            "Epoch 3, Sample 14761: Loss: 0.0363\n",
            "Epoch 3, Sample 14762: Loss: 0.5196\n",
            "Epoch 3, Sample 14763: Loss: 0.2034\n",
            "Epoch 3, Sample 14764: Loss: 1.0266\n",
            "Epoch 3, Sample 14765: Loss: 0.0303\n",
            "Epoch 3, Sample 14766: Loss: 0.1473\n",
            "Epoch 3, Sample 14767: Loss: 0.0306\n",
            "Epoch 3, Sample 14768: Loss: 1.4982\n",
            "Epoch 3, Sample 14769: Loss: 1.1176\n",
            "Epoch 3, Sample 14770: Loss: 0.2962\n",
            "Epoch 3, Sample 14771: Loss: 0.7036\n",
            "Epoch 3, Sample 14772: Loss: 0.1250\n",
            "Epoch 3, Sample 14773: Loss: 0.3399\n",
            "Epoch 3, Sample 14774: Loss: 1.0155\n",
            "Epoch 3, Sample 14775: Loss: 0.0031\n",
            "Epoch 3, Sample 14776: Loss: 1.0524\n",
            "Epoch 3, Sample 14777: Loss: 0.2219\n",
            "Epoch 3, Sample 14778: Loss: 0.7036\n",
            "Epoch 3, Sample 14779: Loss: 0.1250\n",
            "Epoch 3, Sample 14780: Loss: 0.1199\n",
            "Epoch 3, Sample 14781: Loss: 0.1218\n",
            "Epoch 3, Sample 14782: Loss: 0.0025\n",
            "Epoch 3, Sample 14783: Loss: 0.1248\n",
            "Epoch 3, Sample 14784: Loss: 0.2044\n",
            "Epoch 3, Sample 14785: Loss: 0.0084\n",
            "Epoch 3, Sample 14786: Loss: 0.1170\n",
            "Epoch 3, Sample 14787: Loss: 0.0205\n",
            "Epoch 3, Sample 14788: Loss: 0.0915\n",
            "Epoch 3, Sample 14789: Loss: 0.5858\n",
            "Epoch 3, Sample 14790: Loss: 0.1250\n",
            "Epoch 3, Sample 14791: Loss: 0.0049\n",
            "Epoch 3, Sample 14792: Loss: 1.0530\n",
            "Epoch 3, Sample 14793: Loss: 0.2086\n",
            "Epoch 3, Sample 14794: Loss: 0.0780\n",
            "Epoch 3, Sample 14795: Loss: 0.5972\n",
            "Epoch 3, Sample 14796: Loss: 0.3399\n",
            "Epoch 3, Sample 14797: Loss: 0.2558\n",
            "Epoch 3, Sample 14798: Loss: 0.2094\n",
            "Epoch 3, Sample 14799: Loss: 1.0155\n",
            "Epoch 3, Sample 14800: Loss: 0.0026\n",
            "Epoch 3, Sample 14801: Loss: 0.2044\n",
            "Epoch 3, Sample 14802: Loss: 0.6990\n",
            "Epoch 3, Sample 14803: Loss: 0.1448\n",
            "Epoch 3, Sample 14804: Loss: 0.0630\n",
            "Epoch 3, Sample 14805: Loss: 0.0088\n",
            "Epoch 3, Sample 14806: Loss: 0.8484\n",
            "Epoch 3, Sample 14807: Loss: 0.2034\n",
            "Epoch 3, Sample 14808: Loss: 0.2032\n",
            "Epoch 3, Sample 14809: Loss: 0.2759\n",
            "Epoch 3, Sample 14810: Loss: 0.1250\n",
            "Epoch 3, Sample 14811: Loss: 1.0524\n",
            "Epoch 3, Sample 14812: Loss: 1.0155\n",
            "Epoch 3, Sample 14813: Loss: 0.7561\n",
            "Epoch 3, Sample 14814: Loss: 0.3787\n",
            "Epoch 3, Sample 14815: Loss: 0.2989\n",
            "Epoch 3, Sample 14816: Loss: 0.0967\n",
            "Epoch 3, Sample 14817: Loss: 1.0266\n",
            "Epoch 3, Sample 14818: Loss: 0.0838\n",
            "Epoch 3, Sample 14819: Loss: 0.2219\n",
            "Epoch 3, Sample 14820: Loss: 0.3402\n",
            "Epoch 3, Sample 14821: Loss: 0.1291\n",
            "Epoch 3, Sample 14822: Loss: 0.2759\n",
            "Epoch 3, Sample 14823: Loss: 1.0524\n",
            "Epoch 3, Sample 14824: Loss: 0.3949\n",
            "Epoch 3, Sample 14825: Loss: 0.5636\n",
            "Epoch 3, Sample 14826: Loss: 0.0067\n",
            "Epoch 3, Sample 14827: Loss: 0.3261\n",
            "Epoch 3, Sample 14828: Loss: 0.8003\n",
            "Epoch 3, Sample 14829: Loss: 0.7036\n",
            "Epoch 3, Sample 14830: Loss: 0.0427\n",
            "Epoch 3, Sample 14831: Loss: 2.4676\n",
            "Epoch 3, Sample 14832: Loss: 0.0133\n",
            "Epoch 3, Sample 14833: Loss: 0.7453\n",
            "Epoch 3, Sample 14834: Loss: 0.3441\n",
            "Epoch 3, Sample 14835: Loss: 0.1674\n",
            "Epoch 3, Sample 14836: Loss: 0.0554\n",
            "Epoch 3, Sample 14837: Loss: 0.4382\n",
            "Epoch 3, Sample 14838: Loss: 0.2044\n",
            "Epoch 3, Sample 14839: Loss: 0.3399\n",
            "Epoch 3, Sample 14840: Loss: 0.6139\n",
            "Epoch 3, Sample 14841: Loss: 1.0524\n",
            "Epoch 3, Sample 14842: Loss: 0.3441\n",
            "Epoch 3, Sample 14843: Loss: 0.9169\n",
            "Epoch 3, Sample 14844: Loss: 19.3009\n",
            "Epoch 3, Sample 14845: Loss: 0.0313\n",
            "Epoch 3, Sample 14846: Loss: 0.2639\n",
            "Epoch 3, Sample 14847: Loss: 0.0001\n",
            "Epoch 3, Sample 14848: Loss: 0.0022\n",
            "Epoch 3, Sample 14849: Loss: 0.4264\n",
            "Epoch 3, Sample 14850: Loss: 1.0155\n",
            "Epoch 3, Sample 14851: Loss: 0.0026\n",
            "Epoch 3, Sample 14852: Loss: 0.2036\n",
            "Epoch 3, Sample 14853: Loss: 0.0026\n",
            "Epoch 3, Sample 14854: Loss: 0.9251\n",
            "Epoch 3, Sample 14855: Loss: 0.0018\n",
            "Epoch 3, Sample 14856: Loss: 0.0130\n",
            "Epoch 3, Sample 14857: Loss: 0.2832\n",
            "Epoch 3, Sample 14858: Loss: 0.2325\n",
            "Epoch 3, Sample 14859: Loss: 0.0108\n",
            "Epoch 3, Sample 14860: Loss: 0.6715\n",
            "Epoch 3, Sample 14861: Loss: 0.1365\n",
            "Epoch 3, Sample 14862: Loss: 0.3399\n",
            "Epoch 3, Sample 14863: Loss: 1.0359\n",
            "Epoch 3, Sample 14864: Loss: 0.3441\n",
            "Epoch 3, Sample 14865: Loss: 0.0391\n",
            "Epoch 3, Sample 14866: Loss: 0.0477\n",
            "Epoch 3, Sample 14867: Loss: 1.0530\n",
            "Epoch 3, Sample 14868: Loss: 0.0380\n",
            "Epoch 3, Sample 14869: Loss: 2.4100\n",
            "Epoch 3, Sample 14870: Loss: 0.0005\n",
            "Epoch 3, Sample 14871: Loss: 0.0097\n",
            "Epoch 3, Sample 14872: Loss: 0.8951\n",
            "Epoch 3, Sample 14873: Loss: 0.0233\n",
            "Epoch 3, Sample 14874: Loss: 0.0190\n",
            "Epoch 3, Sample 14875: Loss: 0.4607\n",
            "Epoch 3, Sample 14876: Loss: 0.1559\n",
            "Epoch 3, Sample 14877: Loss: 0.0018\n",
            "Epoch 3, Sample 14878: Loss: 0.9367\n",
            "Epoch 3, Sample 14879: Loss: 0.0709\n",
            "Epoch 3, Sample 14880: Loss: 0.7453\n",
            "Epoch 3, Sample 14881: Loss: 0.1248\n",
            "Epoch 3, Sample 14882: Loss: 0.3126\n",
            "Epoch 3, Sample 14883: Loss: 0.9688\n",
            "Epoch 3, Sample 14884: Loss: 0.2036\n",
            "Epoch 3, Sample 14885: Loss: 1.0530\n",
            "Epoch 3, Sample 14886: Loss: 0.1170\n",
            "Epoch 3, Sample 14887: Loss: 0.2044\n",
            "Epoch 3, Sample 14888: Loss: 0.4032\n",
            "Epoch 3, Sample 14889: Loss: 0.3441\n",
            "Epoch 3, Sample 14890: Loss: 0.3399\n",
            "Epoch 3, Sample 14891: Loss: 0.0938\n",
            "Epoch 3, Sample 14892: Loss: 0.7036\n",
            "Epoch 3, Sample 14893: Loss: 3.8016\n",
            "Epoch 3, Sample 14894: Loss: 0.0805\n",
            "Epoch 3, Sample 14895: Loss: 0.0286\n",
            "Epoch 3, Sample 14896: Loss: 0.0034\n",
            "Epoch 3, Sample 14897: Loss: 0.6092\n",
            "Epoch 3, Sample 14898: Loss: 1.0524\n",
            "Epoch 3, Sample 14899: Loss: 1.4187\n",
            "Epoch 3, Sample 14900: Loss: 0.3949\n",
            "Epoch 3, Sample 14901: Loss: 0.6867\n",
            "Epoch 3, Sample 14902: Loss: 0.1056\n",
            "Epoch 3, Sample 14903: Loss: 0.0026\n",
            "Epoch 3, Sample 14904: Loss: 0.3758\n",
            "Epoch 3, Sample 14905: Loss: 1.0524\n",
            "Epoch 3, Sample 14906: Loss: 0.5473\n",
            "Epoch 3, Sample 14907: Loss: 0.3181\n",
            "Epoch 3, Sample 14908: Loss: 0.4644\n",
            "Epoch 3, Sample 14909: Loss: 1.0155\n",
            "Epoch 3, Sample 14910: Loss: 0.0018\n",
            "Epoch 3, Sample 14911: Loss: 0.2044\n",
            "Epoch 3, Sample 14912: Loss: 0.0026\n",
            "Epoch 3, Sample 14913: Loss: 0.0205\n",
            "Epoch 3, Sample 14914: Loss: 0.0000\n",
            "Epoch 3, Sample 14915: Loss: 0.5003\n",
            "Epoch 3, Sample 14916: Loss: 0.0363\n",
            "Epoch 3, Sample 14917: Loss: 0.6990\n",
            "Epoch 3, Sample 14918: Loss: 0.3441\n",
            "Epoch 3, Sample 14919: Loss: 3.2624\n",
            "Epoch 3, Sample 14920: Loss: 0.2032\n",
            "Epoch 3, Sample 14921: Loss: 0.0150\n",
            "Epoch 3, Sample 14922: Loss: 0.1170\n",
            "Epoch 3, Sample 14923: Loss: 0.0062\n",
            "Epoch 3, Sample 14924: Loss: 0.0367\n",
            "Epoch 3, Sample 14925: Loss: 0.0626\n",
            "Epoch 3, Sample 14926: Loss: 0.0001\n",
            "Epoch 3, Sample 14927: Loss: 0.6304\n",
            "Epoch 3, Sample 14928: Loss: 0.0025\n",
            "Epoch 3, Sample 14929: Loss: 2.0186\n",
            "Epoch 3, Sample 14930: Loss: 0.0018\n",
            "Epoch 3, Sample 14931: Loss: 0.0802\n",
            "Epoch 3, Sample 14932: Loss: 0.3399\n",
            "Epoch 3, Sample 14933: Loss: 0.0108\n",
            "Epoch 3, Sample 14934: Loss: 0.8550\n",
            "Epoch 3, Sample 14935: Loss: 0.6190\n",
            "Epoch 3, Sample 14936: Loss: 0.3441\n",
            "Epoch 3, Sample 14937: Loss: 0.2182\n",
            "Epoch 3, Sample 14938: Loss: 0.0013\n",
            "Epoch 3, Sample 14939: Loss: 0.3399\n",
            "Epoch 3, Sample 14940: Loss: 0.6304\n",
            "Epoch 3, Sample 14941: Loss: 1.0239\n",
            "Epoch 3, Sample 14942: Loss: 0.1170\n",
            "Epoch 3, Sample 14943: Loss: 1.0530\n",
            "Epoch 3, Sample 14944: Loss: 0.0192\n",
            "Epoch 3, Sample 14945: Loss: 0.3399\n",
            "Epoch 3, Sample 14946: Loss: 0.4607\n",
            "Epoch 3, Sample 14947: Loss: 0.0630\n",
            "Epoch 3, Sample 14948: Loss: 0.2639\n",
            "Epoch 3, Sample 14949: Loss: 0.0062\n",
            "Epoch 3, Sample 14950: Loss: 0.5858\n",
            "Epoch 3, Sample 14951: Loss: 0.0084\n",
            "Epoch 3, Sample 14952: Loss: 0.0258\n",
            "Epoch 3, Sample 14953: Loss: 0.1397\n",
            "Epoch 3, Sample 14954: Loss: 0.1613\n",
            "Epoch 3, Sample 14955: Loss: 0.1559\n",
            "Epoch 3, Sample 14956: Loss: 0.2032\n",
            "Epoch 3, Sample 14957: Loss: 0.3011\n",
            "Epoch 3, Sample 14958: Loss: 0.3399\n",
            "Epoch 3, Sample 14959: Loss: 0.1079\n",
            "Epoch 3, Sample 14960: Loss: 0.9283\n",
            "Epoch 3, Sample 14961: Loss: 0.2219\n",
            "Epoch 3, Sample 14962: Loss: 0.0174\n",
            "Epoch 3, Sample 14963: Loss: 0.2044\n",
            "Epoch 3, Sample 14964: Loss: 0.0030\n",
            "Epoch 3, Sample 14965: Loss: 0.7036\n",
            "Epoch 3, Sample 14966: Loss: 0.0712\n",
            "Epoch 3, Sample 14967: Loss: 0.1252\n",
            "Epoch 3, Sample 14968: Loss: 0.0026\n",
            "Epoch 3, Sample 14969: Loss: 2.0108\n",
            "Epoch 3, Sample 14970: Loss: 0.0070\n",
            "Epoch 3, Sample 14971: Loss: 0.5003\n",
            "Epoch 3, Sample 14972: Loss: 0.0466\n",
            "Epoch 3, Sample 14973: Loss: 0.1246\n",
            "Epoch 3, Sample 14974: Loss: 1.0524\n",
            "Epoch 3, Sample 14975: Loss: 0.0059\n",
            "Epoch 3, Sample 14976: Loss: 0.0466\n",
            "Epoch 3, Sample 14977: Loss: 1.0524\n",
            "Epoch 3, Sample 14978: Loss: 0.2931\n",
            "Epoch 3, Sample 14979: Loss: 0.0026\n",
            "Epoch 3, Sample 14980: Loss: 0.0026\n",
            "Epoch 3, Sample 14981: Loss: 0.4799\n",
            "Epoch 3, Sample 14982: Loss: 0.8484\n",
            "Epoch 3, Sample 14983: Loss: 0.4930\n",
            "Epoch 3, Sample 14984: Loss: 1.0155\n",
            "Epoch 3, Sample 14985: Loss: 0.0026\n",
            "Epoch 3, Sample 14986: Loss: 0.0026\n",
            "Epoch 3, Sample 14987: Loss: 0.6954\n",
            "Epoch 3, Sample 14988: Loss: 1.0688\n",
            "Epoch 3, Sample 14989: Loss: 0.5789\n",
            "Epoch 3, Sample 14990: Loss: 0.0761\n",
            "Epoch 3, Sample 14991: Loss: 0.1225\n",
            "Epoch 3, Sample 14992: Loss: 1.0524\n",
            "Epoch 3, Sample 14993: Loss: 0.9785\n",
            "Epoch 3, Sample 14994: Loss: 1.1847\n",
            "Epoch 3, Sample 14995: Loss: 0.6990\n",
            "Epoch 3, Sample 14996: Loss: 0.4641\n",
            "Epoch 3, Sample 14997: Loss: 0.6990\n",
            "Epoch 3, Sample 14998: Loss: 0.6867\n",
            "Epoch 3, Sample 14999: Loss: 0.1250\n",
            "Epoch 3, Sample 15000: Loss: 0.4938\n",
            "Epoch 3, Sample 15001: Loss: 0.0018\n",
            "Epoch 3, Sample 15002: Loss: 0.2832\n",
            "Epoch 3, Sample 15003: Loss: 0.1364\n",
            "Epoch 3, Sample 15004: Loss: 0.2182\n",
            "Epoch 3, Sample 15005: Loss: 0.0013\n",
            "Epoch 3, Sample 15006: Loss: 0.1011\n",
            "Epoch 3, Sample 15007: Loss: 0.2032\n",
            "Epoch 3, Sample 15008: Loss: 0.2044\n",
            "Epoch 3, Sample 15009: Loss: 0.2219\n",
            "Epoch 3, Sample 15010: Loss: 0.3949\n",
            "Epoch 3, Sample 15011: Loss: 0.4930\n",
            "Epoch 3, Sample 15012: Loss: 0.4945\n",
            "Epoch 3, Sample 15013: Loss: 0.0006\n",
            "Epoch 3, Sample 15014: Loss: 1.0524\n",
            "Epoch 3, Sample 15015: Loss: 0.3399\n",
            "Epoch 3, Sample 15016: Loss: 0.0018\n",
            "Epoch 3, Sample 15017: Loss: 1.0524\n",
            "Epoch 3, Sample 15018: Loss: 0.7702\n",
            "Epoch 3, Sample 15019: Loss: 0.0025\n",
            "Epoch 3, Sample 15020: Loss: 2.5514\n",
            "Epoch 3, Sample 15021: Loss: 0.3402\n",
            "Epoch 3, Sample 15022: Loss: 0.7702\n",
            "Epoch 3, Sample 15023: Loss: 0.2044\n",
            "Epoch 3, Sample 15024: Loss: 0.1622\n",
            "Epoch 3, Sample 15025: Loss: 1.0155\n",
            "Epoch 3, Sample 15026: Loss: 0.0303\n",
            "Epoch 3, Sample 15027: Loss: 0.0962\n",
            "Epoch 3, Sample 15028: Loss: 0.1269\n",
            "Epoch 3, Sample 15029: Loss: 0.1039\n",
            "Epoch 3, Sample 15030: Loss: 1.0155\n",
            "Epoch 3, Sample 15031: Loss: 2.5961\n",
            "Epoch 3, Sample 15032: Loss: 0.2782\n",
            "Epoch 3, Sample 15033: Loss: 0.5450\n",
            "Epoch 3, Sample 15034: Loss: 0.0026\n",
            "Epoch 3, Sample 15035: Loss: 0.6990\n",
            "Epoch 3, Sample 15036: Loss: 0.1225\n",
            "Epoch 3, Sample 15037: Loss: 0.0013\n",
            "Epoch 3, Sample 15038: Loss: 0.0029\n",
            "Epoch 3, Sample 15039: Loss: 0.2034\n",
            "Epoch 3, Sample 15040: Loss: 0.5858\n",
            "Epoch 3, Sample 15041: Loss: 0.8951\n",
            "Epoch 3, Sample 15042: Loss: 1.0524\n",
            "Epoch 3, Sample 15043: Loss: 0.0884\n",
            "Epoch 3, Sample 15044: Loss: 0.0034\n",
            "Epoch 3, Sample 15045: Loss: 9.4598\n",
            "Epoch 3, Sample 15046: Loss: 1.0524\n",
            "Epoch 3, Sample 15047: Loss: 0.0026\n",
            "Epoch 3, Sample 15048: Loss: 1.5113\n",
            "Epoch 3, Sample 15049: Loss: 1.0294\n",
            "Epoch 3, Sample 15050: Loss: 0.7036\n",
            "Epoch 3, Sample 15051: Loss: 1.0524\n",
            "Epoch 3, Sample 15052: Loss: 0.1040\n",
            "Epoch 3, Sample 15053: Loss: 0.1170\n",
            "Epoch 3, Sample 15054: Loss: 0.2034\n",
            "Epoch 3, Sample 15055: Loss: 0.3399\n",
            "Epoch 3, Sample 15056: Loss: 1.1868\n",
            "Epoch 3, Sample 15057: Loss: 0.3984\n",
            "Epoch 3, Sample 15058: Loss: 7.4463\n",
            "Epoch 3, Sample 15059: Loss: 0.2044\n",
            "Epoch 3, Sample 15060: Loss: 1.0359\n",
            "Epoch 3, Sample 15061: Loss: 2.1320\n",
            "Epoch 3, Sample 15062: Loss: 0.3399\n",
            "Epoch 3, Sample 15063: Loss: 0.4063\n",
            "Epoch 3, Sample 15064: Loss: 0.1364\n",
            "Epoch 3, Sample 15065: Loss: 0.0633\n",
            "Epoch 3, Sample 15066: Loss: 0.3441\n",
            "Epoch 3, Sample 15067: Loss: 0.2032\n",
            "Epoch 3, Sample 15068: Loss: 0.2036\n",
            "Epoch 3, Sample 15069: Loss: 0.1250\n",
            "Epoch 3, Sample 15070: Loss: 1.0530\n",
            "Epoch 3, Sample 15071: Loss: 0.0026\n",
            "Epoch 3, Sample 15072: Loss: 0.1757\n",
            "Epoch 3, Sample 15073: Loss: 0.1627\n",
            "Epoch 3, Sample 15074: Loss: 0.4032\n",
            "Epoch 3, Sample 15075: Loss: 0.6925\n",
            "Epoch 3, Sample 15076: Loss: 0.4799\n",
            "Epoch 3, Sample 15077: Loss: 0.7036\n",
            "Epoch 3, Sample 15078: Loss: 0.2817\n",
            "Epoch 3, Sample 15079: Loss: 0.1004\n",
            "Epoch 3, Sample 15080: Loss: 0.2832\n",
            "Epoch 3, Sample 15081: Loss: 0.1170\n",
            "Epoch 3, Sample 15082: Loss: 1.1309\n",
            "Epoch 3, Sample 15083: Loss: 0.0000\n",
            "Epoch 3, Sample 15084: Loss: 0.0025\n",
            "Epoch 3, Sample 15085: Loss: 0.1055\n",
            "Epoch 3, Sample 15086: Loss: 0.3332\n",
            "Epoch 3, Sample 15087: Loss: 0.1252\n",
            "Epoch 3, Sample 15088: Loss: 0.3441\n",
            "Epoch 3, Sample 15089: Loss: 0.2032\n",
            "Epoch 3, Sample 15090: Loss: 0.0001\n",
            "Epoch 3, Sample 15091: Loss: 0.0637\n",
            "Epoch 3, Sample 15092: Loss: 0.2199\n",
            "Epoch 3, Sample 15093: Loss: 0.6990\n",
            "Epoch 3, Sample 15094: Loss: 0.0026\n",
            "Epoch 3, Sample 15095: Loss: 0.5000\n",
            "Epoch 3, Sample 15096: Loss: 0.0317\n",
            "Epoch 3, Sample 15097: Loss: 0.0026\n",
            "Epoch 3, Sample 15098: Loss: 1.5554\n",
            "Epoch 3, Sample 15099: Loss: 0.0306\n",
            "Epoch 3, Sample 15100: Loss: 0.0026\n",
            "Epoch 3, Sample 15101: Loss: 0.0026\n",
            "Epoch 3, Sample 15102: Loss: 0.7702\n",
            "Epoch 3, Sample 15103: Loss: 0.3949\n",
            "Epoch 3, Sample 15104: Loss: 1.0524\n",
            "Epoch 3, Sample 15105: Loss: 0.5003\n",
            "Epoch 3, Sample 15106: Loss: 0.2044\n",
            "Epoch 3, Sample 15107: Loss: 1.0155\n",
            "Epoch 3, Sample 15108: Loss: 0.1406\n",
            "Epoch 3, Sample 15109: Loss: 0.1248\n",
            "Epoch 3, Sample 15110: Loss: 1.0524\n",
            "Epoch 3, Sample 15111: Loss: 0.5300\n",
            "Epoch 3, Sample 15112: Loss: 0.0005\n",
            "Epoch 3, Sample 15113: Loss: 0.2065\n",
            "Epoch 3, Sample 15114: Loss: 0.0246\n",
            "Epoch 3, Sample 15115: Loss: 3.5504\n",
            "Epoch 3, Sample 15116: Loss: 0.5636\n",
            "Epoch 3, Sample 15117: Loss: 0.3441\n",
            "Epoch 3, Sample 15118: Loss: 1.0688\n",
            "Epoch 3, Sample 15119: Loss: 0.1170\n",
            "Epoch 3, Sample 15120: Loss: 1.0524\n",
            "Epoch 3, Sample 15121: Loss: 1.0524\n",
            "Epoch 3, Sample 15122: Loss: 0.0018\n",
            "Epoch 3, Sample 15123: Loss: 0.1627\n",
            "Epoch 3, Sample 15124: Loss: 0.0173\n",
            "Epoch 3, Sample 15125: Loss: 0.0630\n",
            "Epoch 3, Sample 15126: Loss: 0.0466\n",
            "Epoch 3, Sample 15127: Loss: 0.4224\n",
            "Epoch 3, Sample 15128: Loss: 0.2044\n",
            "Epoch 3, Sample 15129: Loss: 0.2034\n",
            "Epoch 3, Sample 15130: Loss: 0.4799\n",
            "Epoch 3, Sample 15131: Loss: 0.2759\n",
            "Epoch 3, Sample 15132: Loss: 0.1225\n",
            "Epoch 3, Sample 15133: Loss: 0.8339\n",
            "Epoch 3, Sample 15134: Loss: 0.0001\n",
            "Epoch 3, Sample 15135: Loss: 0.2086\n",
            "Epoch 3, Sample 15136: Loss: 0.2962\n",
            "Epoch 3, Sample 15137: Loss: 0.3872\n",
            "Epoch 3, Sample 15138: Loss: 1.0328\n",
            "Epoch 3, Sample 15139: Loss: 1.0524\n",
            "Epoch 3, Sample 15140: Loss: 0.3568\n",
            "Epoch 3, Sample 15141: Loss: 0.2044\n",
            "Epoch 3, Sample 15142: Loss: 1.0524\n",
            "Epoch 3, Sample 15143: Loss: 0.0023\n",
            "Epoch 3, Sample 15144: Loss: 0.0001\n",
            "Epoch 3, Sample 15145: Loss: 0.1501\n",
            "Epoch 3, Sample 15146: Loss: 1.0524\n",
            "Epoch 3, Sample 15147: Loss: 0.0026\n",
            "Epoch 3, Sample 15148: Loss: 0.6092\n",
            "Epoch 3, Sample 15149: Loss: 3.4914\n",
            "Epoch 3, Sample 15150: Loss: 0.1818\n",
            "Epoch 3, Sample 15151: Loss: 0.7036\n",
            "Epoch 3, Sample 15152: Loss: 0.5078\n",
            "Epoch 3, Sample 15153: Loss: 0.0625\n",
            "Epoch 3, Sample 15154: Loss: 0.1114\n",
            "Epoch 3, Sample 15155: Loss: 0.7036\n",
            "Epoch 3, Sample 15156: Loss: 0.0062\n",
            "Epoch 3, Sample 15157: Loss: 0.0773\n",
            "Epoch 3, Sample 15158: Loss: 0.0150\n",
            "Epoch 3, Sample 15159: Loss: 0.0476\n",
            "Epoch 3, Sample 15160: Loss: 1.5761\n",
            "Epoch 3, Sample 15161: Loss: 0.0258\n",
            "Epoch 3, Sample 15162: Loss: 0.4930\n",
            "Epoch 3, Sample 15163: Loss: 1.0524\n",
            "Epoch 3, Sample 15164: Loss: 1.3345\n",
            "Epoch 3, Sample 15165: Loss: 0.4588\n",
            "Epoch 3, Sample 15166: Loss: 0.1246\n",
            "Epoch 3, Sample 15167: Loss: 0.2759\n",
            "Epoch 3, Sample 15168: Loss: 1.1858\n",
            "Epoch 3, Sample 15169: Loss: 0.1924\n",
            "Epoch 3, Sample 15170: Loss: 0.5858\n",
            "Epoch 3, Sample 15171: Loss: 0.0000\n",
            "Epoch 3, Sample 15172: Loss: 0.2234\n",
            "Epoch 3, Sample 15173: Loss: 1.0204\n",
            "Epoch 3, Sample 15174: Loss: 0.0001\n",
            "Epoch 3, Sample 15175: Loss: 0.1523\n",
            "Epoch 3, Sample 15176: Loss: 0.3367\n",
            "Epoch 3, Sample 15177: Loss: 1.0524\n",
            "Epoch 3, Sample 15178: Loss: 0.3399\n",
            "Epoch 3, Sample 15179: Loss: 0.4032\n",
            "Epoch 3, Sample 15180: Loss: 0.1238\n",
            "Epoch 3, Sample 15181: Loss: 0.2034\n",
            "Epoch 3, Sample 15182: Loss: 0.1170\n",
            "Epoch 3, Sample 15183: Loss: 0.0018\n",
            "Epoch 3, Sample 15184: Loss: 0.6990\n",
            "Epoch 3, Sample 15185: Loss: 0.0212\n",
            "Epoch 3, Sample 15186: Loss: 0.4799\n",
            "Epoch 3, Sample 15187: Loss: 0.2494\n",
            "Epoch 3, Sample 15188: Loss: 0.3533\n",
            "Epoch 3, Sample 15189: Loss: 0.1677\n",
            "Epoch 3, Sample 15190: Loss: 1.0530\n",
            "Epoch 3, Sample 15191: Loss: 0.2044\n",
            "Epoch 3, Sample 15192: Loss: 0.2032\n",
            "Epoch 3, Sample 15193: Loss: 0.2032\n",
            "Epoch 3, Sample 15194: Loss: 0.2219\n",
            "Epoch 3, Sample 15195: Loss: 8.6724\n",
            "Epoch 3, Sample 15196: Loss: 0.4996\n",
            "Epoch 3, Sample 15197: Loss: 0.6304\n",
            "Epoch 3, Sample 15198: Loss: 0.0915\n",
            "Epoch 3, Sample 15199: Loss: 0.1170\n",
            "Epoch 3, Sample 15200: Loss: 1.0530\n",
            "Epoch 3, Sample 15201: Loss: 0.0049\n",
            "Epoch 3, Sample 15202: Loss: 0.0319\n",
            "Epoch 3, Sample 15203: Loss: 0.2132\n",
            "Epoch 3, Sample 15204: Loss: 0.2034\n",
            "Epoch 3, Sample 15205: Loss: 1.7381\n",
            "Epoch 3, Sample 15206: Loss: 0.1935\n",
            "Epoch 3, Sample 15207: Loss: 0.2219\n",
            "Epoch 3, Sample 15208: Loss: 0.3850\n",
            "Epoch 3, Sample 15209: Loss: 0.1480\n",
            "Epoch 3, Sample 15210: Loss: 0.0084\n",
            "Epoch 3, Sample 15211: Loss: 0.3949\n",
            "Epoch 3, Sample 15212: Loss: 0.1400\n",
            "Epoch 3, Sample 15213: Loss: 0.2112\n",
            "Epoch 3, Sample 15214: Loss: 0.3399\n",
            "Epoch 3, Sample 15215: Loss: 1.0524\n",
            "Epoch 3, Sample 15216: Loss: 0.3477\n",
            "Epoch 3, Sample 15217: Loss: 0.0415\n",
            "Epoch 3, Sample 15218: Loss: 0.1419\n",
            "Epoch 3, Sample 15219: Loss: 2.8671\n",
            "Epoch 3, Sample 15220: Loss: 0.0146\n",
            "Epoch 3, Sample 15221: Loss: 0.2759\n",
            "Epoch 3, Sample 15222: Loss: 0.3399\n",
            "Epoch 3, Sample 15223: Loss: 0.3934\n",
            "Epoch 3, Sample 15224: Loss: 0.2034\n",
            "Epoch 3, Sample 15225: Loss: 0.0630\n",
            "Epoch 3, Sample 15226: Loss: 0.0212\n",
            "Epoch 3, Sample 15227: Loss: 0.1740\n",
            "Epoch 3, Sample 15228: Loss: 1.0524\n",
            "Epoch 3, Sample 15229: Loss: 0.7036\n",
            "Epoch 3, Sample 15230: Loss: 0.2034\n",
            "Epoch 3, Sample 15231: Loss: 0.1559\n",
            "Epoch 3, Sample 15232: Loss: 0.0802\n",
            "Epoch 3, Sample 15233: Loss: 0.0938\n",
            "Epoch 3, Sample 15234: Loss: 0.1817\n",
            "Epoch 3, Sample 15235: Loss: 1.0524\n",
            "Epoch 3, Sample 15236: Loss: 0.2452\n",
            "Epoch 3, Sample 15237: Loss: 1.9382\n",
            "Epoch 3, Sample 15238: Loss: 1.0524\n",
            "Epoch 3, Sample 15239: Loss: 0.3949\n",
            "Epoch 3, Sample 15240: Loss: 0.0751\n",
            "Epoch 3, Sample 15241: Loss: 0.4607\n",
            "Epoch 3, Sample 15242: Loss: 0.3441\n",
            "Epoch 3, Sample 15243: Loss: 1.0524\n",
            "Epoch 3, Sample 15244: Loss: 0.1472\n",
            "Epoch 3, Sample 15245: Loss: 0.1170\n",
            "Epoch 3, Sample 15246: Loss: 0.7036\n",
            "Epoch 3, Sample 15247: Loss: 0.3388\n",
            "Epoch 3, Sample 15248: Loss: 0.2032\n",
            "Epoch 3, Sample 15249: Loss: 0.8951\n",
            "Epoch 3, Sample 15250: Loss: 1.0524\n",
            "Epoch 3, Sample 15251: Loss: 0.2034\n",
            "Epoch 3, Sample 15252: Loss: 0.7826\n",
            "Epoch 3, Sample 15253: Loss: 0.0026\n",
            "Epoch 3, Sample 15254: Loss: 0.6139\n",
            "Epoch 3, Sample 15255: Loss: 1.9820\n",
            "Epoch 3, Sample 15256: Loss: 1.0155\n",
            "Epoch 3, Sample 15257: Loss: 0.0067\n",
            "Epoch 3, Sample 15258: Loss: 0.1039\n",
            "Epoch 3, Sample 15259: Loss: 0.2759\n",
            "Epoch 3, Sample 15260: Loss: 0.5858\n",
            "Epoch 3, Sample 15261: Loss: 0.3441\n",
            "Epoch 3, Sample 15262: Loss: 1.0524\n",
            "Epoch 3, Sample 15263: Loss: 1.0530\n",
            "Epoch 3, Sample 15264: Loss: 0.4611\n",
            "Epoch 3, Sample 15265: Loss: 0.2759\n",
            "Epoch 3, Sample 15266: Loss: 0.0337\n",
            "Epoch 3, Sample 15267: Loss: 0.5636\n",
            "Epoch 3, Sample 15268: Loss: 0.2032\n",
            "Epoch 3, Sample 15269: Loss: 0.0682\n",
            "Epoch 3, Sample 15270: Loss: 0.0725\n",
            "Epoch 3, Sample 15271: Loss: 0.0026\n",
            "Epoch 3, Sample 15272: Loss: 1.0524\n",
            "Epoch 3, Sample 15273: Loss: 0.0000\n",
            "Epoch 3, Sample 15274: Loss: 0.2032\n",
            "Epoch 3, Sample 15275: Loss: 0.1591\n",
            "Epoch 3, Sample 15276: Loss: 0.1170\n",
            "Epoch 3, Sample 15277: Loss: 0.1980\n",
            "Epoch 3, Sample 15278: Loss: 0.1968\n",
            "Epoch 3, Sample 15279: Loss: 0.1264\n",
            "Epoch 3, Sample 15280: Loss: 0.3109\n",
            "Epoch 3, Sample 15281: Loss: 1.1569\n",
            "Epoch 3, Sample 15282: Loss: 0.0945\n",
            "Epoch 3, Sample 15283: Loss: 0.3418\n",
            "Epoch 3, Sample 15284: Loss: 0.1718\n",
            "Epoch 3, Sample 15285: Loss: 0.3972\n",
            "Epoch 3, Sample 15286: Loss: 0.0270\n",
            "Epoch 3, Sample 15287: Loss: 0.1785\n",
            "Epoch 3, Sample 15288: Loss: 0.3441\n",
            "Epoch 3, Sample 15289: Loss: 0.2044\n",
            "Epoch 3, Sample 15290: Loss: 0.1156\n",
            "Epoch 3, Sample 15291: Loss: 0.2034\n",
            "Epoch 3, Sample 15292: Loss: 0.2034\n",
            "Epoch 3, Sample 15293: Loss: 0.4799\n",
            "Epoch 3, Sample 15294: Loss: 0.1036\n",
            "Epoch 3, Sample 15295: Loss: 0.0025\n",
            "Epoch 3, Sample 15296: Loss: 0.2036\n",
            "Epoch 3, Sample 15297: Loss: 0.1397\n",
            "Epoch 3, Sample 15298: Loss: 0.1170\n",
            "Epoch 3, Sample 15299: Loss: 0.6166\n",
            "Epoch 3, Sample 15300: Loss: 0.1673\n",
            "Epoch 3, Sample 15301: Loss: 0.0000\n",
            "Epoch 3, Sample 15302: Loss: 0.0170\n",
            "Epoch 3, Sample 15303: Loss: 0.2820\n",
            "Epoch 3, Sample 15304: Loss: 0.7500\n",
            "Epoch 3, Sample 15305: Loss: 0.1040\n",
            "Epoch 3, Sample 15306: Loss: 0.3399\n",
            "Epoch 3, Sample 15307: Loss: 0.0626\n",
            "Epoch 3, Sample 15308: Loss: 0.1465\n",
            "Epoch 3, Sample 15309: Loss: 0.0819\n",
            "Epoch 3, Sample 15310: Loss: 10.3220\n",
            "Epoch 3, Sample 15311: Loss: 0.0466\n",
            "Epoch 3, Sample 15312: Loss: 1.0524\n",
            "Epoch 3, Sample 15313: Loss: 0.2639\n",
            "Epoch 3, Sample 15314: Loss: 0.3288\n",
            "Epoch 3, Sample 15315: Loss: 0.3477\n",
            "Epoch 3, Sample 15316: Loss: 0.6990\n",
            "Epoch 3, Sample 15317: Loss: 0.2044\n",
            "Epoch 3, Sample 15318: Loss: 0.3198\n",
            "Epoch 3, Sample 15319: Loss: 0.0677\n",
            "Epoch 3, Sample 15320: Loss: 1.0524\n",
            "Epoch 3, Sample 15321: Loss: 0.5799\n",
            "Epoch 3, Sample 15322: Loss: 0.4996\n",
            "Epoch 3, Sample 15323: Loss: 1.0155\n",
            "Epoch 3, Sample 15324: Loss: 0.0802\n",
            "Epoch 3, Sample 15325: Loss: 1.0524\n",
            "Epoch 3, Sample 15326: Loss: 0.0082\n",
            "Epoch 3, Sample 15327: Loss: 0.2032\n",
            "Epoch 3, Sample 15328: Loss: 0.3399\n",
            "Epoch 3, Sample 15329: Loss: 1.0524\n",
            "Epoch 3, Sample 15330: Loss: 1.0524\n",
            "Epoch 3, Sample 15331: Loss: 0.2034\n",
            "Epoch 3, Sample 15332: Loss: 0.0946\n",
            "Epoch 3, Sample 15333: Loss: 0.1546\n",
            "Epoch 3, Sample 15334: Loss: 0.1005\n",
            "Epoch 3, Sample 15335: Loss: 0.0018\n",
            "Epoch 3, Sample 15336: Loss: 0.0001\n",
            "Epoch 3, Sample 15337: Loss: 3.9764\n",
            "Epoch 3, Sample 15338: Loss: 0.0630\n",
            "Epoch 3, Sample 15339: Loss: 0.1039\n",
            "Epoch 3, Sample 15340: Loss: 0.0460\n",
            "Epoch 3, Sample 15341: Loss: 0.0270\n",
            "Epoch 3, Sample 15342: Loss: 0.7203\n",
            "Epoch 3, Sample 15343: Loss: 0.0640\n",
            "Epoch 3, Sample 15344: Loss: 0.7036\n",
            "Epoch 3, Sample 15345: Loss: 1.0524\n",
            "Epoch 3, Sample 15346: Loss: 1.0359\n",
            "Epoch 3, Sample 15347: Loss: 0.0426\n",
            "Epoch 3, Sample 15348: Loss: 0.1643\n",
            "Epoch 3, Sample 15349: Loss: 0.3392\n",
            "Epoch 3, Sample 15350: Loss: 0.2219\n",
            "Epoch 3, Sample 15351: Loss: 0.2036\n",
            "Epoch 3, Sample 15352: Loss: 0.1501\n",
            "Epoch 3, Sample 15353: Loss: 0.1559\n",
            "Epoch 3, Sample 15354: Loss: 1.0524\n",
            "Epoch 3, Sample 15355: Loss: 0.3949\n",
            "Epoch 3, Sample 15356: Loss: 0.1170\n",
            "Epoch 3, Sample 15357: Loss: 0.0488\n",
            "Epoch 3, Sample 15358: Loss: 0.0286\n",
            "Epoch 3, Sample 15359: Loss: 0.3399\n",
            "Epoch 3, Sample 15360: Loss: 2.2623\n",
            "Epoch 3, Sample 15361: Loss: 0.0001\n",
            "Epoch 3, Sample 15362: Loss: 0.3399\n",
            "Epoch 3, Sample 15363: Loss: 4.2335\n",
            "Epoch 3, Sample 15364: Loss: 1.5542\n",
            "Epoch 3, Sample 15365: Loss: 0.6990\n",
            "Epoch 3, Sample 15366: Loss: 0.1339\n",
            "Epoch 3, Sample 15367: Loss: 0.2759\n",
            "Epoch 3, Sample 15368: Loss: 0.3598\n",
            "Epoch 3, Sample 15369: Loss: 0.0915\n",
            "Epoch 3, Sample 15370: Loss: 0.7036\n",
            "Epoch 3, Sample 15371: Loss: 0.0018\n",
            "Epoch 3, Sample 15372: Loss: 0.4854\n",
            "Epoch 3, Sample 15373: Loss: 1.0530\n",
            "Epoch 3, Sample 15374: Loss: 0.2044\n",
            "Epoch 3, Sample 15375: Loss: 0.2044\n",
            "Epoch 3, Sample 15376: Loss: 0.0532\n",
            "Epoch 3, Sample 15377: Loss: 11.6686\n",
            "Epoch 3, Sample 15378: Loss: 0.6990\n",
            "Epoch 3, Sample 15379: Loss: 0.2044\n",
            "Epoch 3, Sample 15380: Loss: 0.1989\n",
            "Epoch 3, Sample 15381: Loss: 1.0524\n",
            "Epoch 3, Sample 15382: Loss: 0.5058\n",
            "Epoch 3, Sample 15383: Loss: 0.0005\n",
            "Epoch 3, Sample 15384: Loss: 0.3794\n",
            "Epoch 3, Sample 15385: Loss: 0.5000\n",
            "Epoch 3, Sample 15386: Loss: 0.9367\n",
            "Epoch 3, Sample 15387: Loss: 0.0026\n",
            "Epoch 3, Sample 15388: Loss: 2.3354\n",
            "Epoch 3, Sample 15389: Loss: 0.0063\n",
            "Epoch 3, Sample 15390: Loss: 1.0524\n",
            "Epoch 3, Sample 15391: Loss: 0.2316\n",
            "Epoch 3, Sample 15392: Loss: 0.4799\n",
            "Epoch 3, Sample 15393: Loss: 0.0041\n",
            "Epoch 3, Sample 15394: Loss: 0.0630\n",
            "Epoch 3, Sample 15395: Loss: 0.0063\n",
            "Epoch 3, Sample 15396: Loss: 0.0230\n",
            "Epoch 3, Sample 15397: Loss: 0.6092\n",
            "Epoch 3, Sample 15398: Loss: 1.1682\n",
            "Epoch 3, Sample 15399: Loss: 0.4996\n",
            "Epoch 3, Sample 15400: Loss: 0.0149\n",
            "Epoch 3, Sample 15401: Loss: 1.5640\n",
            "Epoch 3, Sample 15402: Loss: 1.0530\n",
            "Epoch 3, Sample 15403: Loss: 0.0001\n",
            "Epoch 3, Sample 15404: Loss: 0.0026\n",
            "Epoch 3, Sample 15405: Loss: 0.7924\n",
            "Epoch 3, Sample 15406: Loss: 0.5000\n",
            "Epoch 3, Sample 15407: Loss: 0.0838\n",
            "Epoch 3, Sample 15408: Loss: 0.0460\n",
            "Epoch 3, Sample 15409: Loss: 0.0001\n",
            "Epoch 3, Sample 15410: Loss: 0.0011\n",
            "Epoch 3, Sample 15411: Loss: 0.0691\n",
            "Epoch 3, Sample 15412: Loss: 0.7036\n",
            "Epoch 3, Sample 15413: Loss: 0.7453\n",
            "Epoch 3, Sample 15414: Loss: 0.2032\n",
            "Epoch 3, Sample 15415: Loss: 1.0524\n",
            "Epoch 3, Sample 15416: Loss: 0.7486\n",
            "Epoch 3, Sample 15417: Loss: 0.1170\n",
            "Epoch 3, Sample 15418: Loss: 0.5799\n",
            "Epoch 3, Sample 15419: Loss: 0.0026\n",
            "Epoch 3, Sample 15420: Loss: 0.5078\n",
            "Epoch 3, Sample 15421: Loss: 0.0777\n",
            "Epoch 3, Sample 15422: Loss: 1.0524\n",
            "Epoch 3, Sample 15423: Loss: 0.3062\n",
            "Epoch 3, Sample 15424: Loss: 0.0891\n",
            "Epoch 3, Sample 15425: Loss: 0.2032\n",
            "Epoch 3, Sample 15426: Loss: 0.0018\n",
            "Epoch 3, Sample 15427: Loss: 0.1863\n",
            "Epoch 3, Sample 15428: Loss: 0.6227\n",
            "Epoch 3, Sample 15429: Loss: 0.2329\n",
            "Epoch 3, Sample 15430: Loss: 0.0789\n",
            "Epoch 3, Sample 15431: Loss: 0.4423\n",
            "Epoch 3, Sample 15432: Loss: 0.4032\n",
            "Epoch 3, Sample 15433: Loss: 0.0915\n",
            "Epoch 3, Sample 15434: Loss: 0.2639\n",
            "Epoch 3, Sample 15435: Loss: 0.1072\n",
            "Epoch 3, Sample 15436: Loss: 0.0286\n",
            "Epoch 3, Sample 15437: Loss: 0.1684\n",
            "Epoch 3, Sample 15438: Loss: 0.8951\n",
            "Epoch 3, Sample 15439: Loss: 0.1588\n",
            "Epoch 3, Sample 15440: Loss: 0.1326\n",
            "Epoch 3, Sample 15441: Loss: 1.0524\n",
            "Epoch 3, Sample 15442: Loss: 0.5858\n",
            "Epoch 3, Sample 15443: Loss: 0.0000\n",
            "Epoch 3, Sample 15444: Loss: 0.2639\n",
            "Epoch 3, Sample 15445: Loss: 0.0039\n",
            "Epoch 3, Sample 15446: Loss: 1.0530\n",
            "Epoch 3, Sample 15447: Loss: 3.1942\n",
            "Epoch 3, Sample 15448: Loss: 0.2044\n",
            "Epoch 3, Sample 15449: Loss: 0.1170\n",
            "Epoch 3, Sample 15450: Loss: 0.0026\n",
            "Epoch 3, Sample 15451: Loss: 0.3399\n",
            "Epoch 3, Sample 15452: Loss: 0.3332\n",
            "Epoch 3, Sample 15453: Loss: 0.0625\n",
            "Epoch 3, Sample 15454: Loss: 0.7036\n",
            "Epoch 3, Sample 15455: Loss: 0.6163\n",
            "Epoch 3, Sample 15456: Loss: 0.0238\n",
            "Epoch 3, Sample 15457: Loss: 0.1351\n",
            "Epoch 3, Sample 15458: Loss: 0.0027\n",
            "Epoch 3, Sample 15459: Loss: 0.7036\n",
            "Epoch 3, Sample 15460: Loss: 0.0764\n",
            "Epoch 3, Sample 15461: Loss: 0.0630\n",
            "Epoch 3, Sample 15462: Loss: 0.0062\n",
            "Epoch 3, Sample 15463: Loss: 0.3658\n",
            "Epoch 3, Sample 15464: Loss: 0.3450\n",
            "Epoch 3, Sample 15465: Loss: 0.4575\n",
            "Epoch 3, Sample 15466: Loss: 0.0630\n",
            "Epoch 3, Sample 15467: Loss: 0.2044\n",
            "Epoch 3, Sample 15468: Loss: 0.5058\n",
            "Epoch 3, Sample 15469: Loss: 0.0436\n",
            "Epoch 3, Sample 15470: Loss: 0.2034\n",
            "Epoch 3, Sample 15471: Loss: 0.1417\n",
            "Epoch 3, Sample 15472: Loss: 0.4930\n",
            "Epoch 3, Sample 15473: Loss: 0.1559\n",
            "Epoch 3, Sample 15474: Loss: 0.3999\n",
            "Epoch 3, Sample 15475: Loss: 0.8951\n",
            "Epoch 3, Sample 15476: Loss: 0.3210\n",
            "Epoch 3, Sample 15477: Loss: 0.3584\n",
            "Epoch 3, Sample 15478: Loss: 1.0155\n",
            "Epoch 3, Sample 15479: Loss: 0.0220\n",
            "Epoch 3, Sample 15480: Loss: 0.5003\n",
            "Epoch 3, Sample 15481: Loss: 1.0155\n",
            "Epoch 3, Sample 15482: Loss: 0.7036\n",
            "Epoch 3, Sample 15483: Loss: 0.0313\n",
            "Epoch 3, Sample 15484: Loss: 0.6867\n",
            "Epoch 3, Sample 15485: Loss: 0.1399\n",
            "Epoch 3, Sample 15486: Loss: 0.3332\n",
            "Epoch 3, Sample 15487: Loss: 0.0640\n",
            "Epoch 3, Sample 15488: Loss: 0.3476\n",
            "Epoch 3, Sample 15489: Loss: 0.3418\n",
            "Epoch 3, Sample 15490: Loss: 0.1521\n",
            "Epoch 3, Sample 15491: Loss: 1.0524\n",
            "Epoch 3, Sample 15492: Loss: 1.3780\n",
            "Epoch 3, Sample 15493: Loss: 0.5000\n",
            "Epoch 3, Sample 15494: Loss: 0.5871\n",
            "Epoch 3, Sample 15495: Loss: 0.1225\n",
            "Epoch 3, Sample 15496: Loss: 0.0022\n",
            "Epoch 3, Sample 15497: Loss: 0.2355\n",
            "Epoch 3, Sample 15498: Loss: 0.1401\n",
            "Epoch 3, Sample 15499: Loss: 0.0018\n",
            "Epoch 3, Sample 15500: Loss: 1.0524\n",
            "Epoch 3, Sample 15501: Loss: 0.0001\n",
            "Epoch 3, Sample 15502: Loss: 0.7453\n",
            "Epoch 3, Sample 15503: Loss: 0.3140\n",
            "Epoch 3, Sample 15504: Loss: 0.2759\n",
            "Epoch 3, Sample 15505: Loss: 0.7821\n",
            "Epoch 3, Sample 15506: Loss: 3.6582\n",
            "Epoch 3, Sample 15507: Loss: 0.0270\n",
            "Epoch 3, Sample 15508: Loss: 0.2306\n",
            "Epoch 3, Sample 15509: Loss: 0.9367\n",
            "Epoch 3, Sample 15510: Loss: 1.0524\n",
            "Epoch 3, Sample 15511: Loss: 0.0018\n",
            "Epoch 3, Sample 15512: Loss: 0.2832\n",
            "Epoch 3, Sample 15513: Loss: 0.7036\n",
            "Epoch 3, Sample 15514: Loss: 5.0230\n",
            "Epoch 3, Sample 15515: Loss: 1.2425\n",
            "Epoch 3, Sample 15516: Loss: 0.0018\n",
            "Epoch 3, Sample 15517: Loss: 0.3441\n",
            "Epoch 3, Sample 15518: Loss: 0.2832\n",
            "Epoch 3, Sample 15519: Loss: 0.2175\n",
            "Epoch 3, Sample 15520: Loss: 0.2032\n",
            "Epoch 3, Sample 15521: Loss: 0.0240\n",
            "Epoch 3, Sample 15522: Loss: 0.0186\n",
            "Epoch 3, Sample 15523: Loss: 0.7036\n",
            "Epoch 3, Sample 15524: Loss: 0.3441\n",
            "Epoch 3, Sample 15525: Loss: 0.0212\n",
            "Epoch 3, Sample 15526: Loss: 1.0530\n",
            "Epoch 3, Sample 15527: Loss: 0.0212\n",
            "Epoch 3, Sample 15528: Loss: 0.0166\n",
            "Epoch 3, Sample 15529: Loss: 1.6971\n",
            "Epoch 3, Sample 15530: Loss: 0.8176\n",
            "Epoch 3, Sample 15531: Loss: 0.2704\n",
            "Epoch 3, Sample 15532: Loss: 0.0052\n",
            "Epoch 3, Sample 15533: Loss: 0.1588\n",
            "Epoch 3, Sample 15534: Loss: 1.1060\n",
            "Epoch 3, Sample 15535: Loss: 0.3038\n",
            "Epoch 3, Sample 15536: Loss: 0.1397\n",
            "Epoch 3, Sample 15537: Loss: 1.1632\n",
            "Epoch 3, Sample 15538: Loss: 1.0524\n",
            "Epoch 3, Sample 15539: Loss: 0.1546\n",
            "Epoch 3, Sample 15540: Loss: 0.0501\n",
            "Epoch 3, Sample 15541: Loss: 0.2851\n",
            "Epoch 3, Sample 15542: Loss: 0.3402\n",
            "Epoch 3, Sample 15543: Loss: 0.2759\n",
            "Epoch 3, Sample 15544: Loss: 0.2044\n",
            "Epoch 3, Sample 15545: Loss: 0.9367\n",
            "Epoch 3, Sample 15546: Loss: 0.2639\n",
            "Epoch 3, Sample 15547: Loss: 1.0524\n",
            "Epoch 3, Sample 15548: Loss: 0.1250\n",
            "Epoch 3, Sample 15549: Loss: 2.5192\n",
            "Epoch 3, Sample 15550: Loss: 0.0270\n",
            "Epoch 3, Sample 15551: Loss: 0.2962\n",
            "Epoch 3, Sample 15552: Loss: 0.0005\n",
            "Epoch 3, Sample 15553: Loss: 0.0171\n",
            "Epoch 3, Sample 15554: Loss: 0.8951\n",
            "Epoch 3, Sample 15555: Loss: 0.2759\n",
            "Epoch 3, Sample 15556: Loss: 1.7956\n",
            "Epoch 3, Sample 15557: Loss: 1.0266\n",
            "Epoch 3, Sample 15558: Loss: 0.0026\n",
            "Epoch 3, Sample 15559: Loss: 0.2546\n",
            "Epoch 3, Sample 15560: Loss: 1.0524\n",
            "Epoch 3, Sample 15561: Loss: 0.0145\n",
            "Epoch 3, Sample 15562: Loss: 0.3441\n",
            "Epoch 3, Sample 15563: Loss: 0.0026\n",
            "Epoch 3, Sample 15564: Loss: 0.0487\n",
            "Epoch 3, Sample 15565: Loss: 1.0524\n",
            "Epoch 3, Sample 15566: Loss: 0.1559\n",
            "Epoch 3, Sample 15567: Loss: 0.7845\n",
            "Epoch 3, Sample 15568: Loss: 0.2032\n",
            "Epoch 3, Sample 15569: Loss: 0.0915\n",
            "Epoch 3, Sample 15570: Loss: 0.2759\n",
            "Epoch 3, Sample 15571: Loss: 1.0524\n",
            "Epoch 3, Sample 15572: Loss: 0.3758\n",
            "Epoch 3, Sample 15573: Loss: 0.6139\n",
            "Epoch 3, Sample 15574: Loss: 1.0524\n",
            "Epoch 3, Sample 15575: Loss: 0.0018\n",
            "Epoch 3, Sample 15576: Loss: 1.1789\n",
            "Epoch 3, Sample 15577: Loss: 0.0183\n",
            "Epoch 3, Sample 15578: Loss: 0.0245\n",
            "Epoch 3, Sample 15579: Loss: 1.0524\n",
            "Epoch 3, Sample 15580: Loss: 0.2044\n",
            "Epoch 3, Sample 15581: Loss: 0.6201\n",
            "Epoch 3, Sample 15582: Loss: 0.2759\n",
            "Epoch 3, Sample 15583: Loss: 0.0630\n",
            "Epoch 3, Sample 15584: Loss: 0.1170\n",
            "Epoch 3, Sample 15585: Loss: 0.0001\n",
            "Epoch 3, Sample 15586: Loss: 0.2036\n",
            "Epoch 3, Sample 15587: Loss: 0.0018\n",
            "Epoch 3, Sample 15588: Loss: 1.0530\n",
            "Epoch 3, Sample 15589: Loss: 1.0524\n",
            "Epoch 3, Sample 15590: Loss: 1.4515\n",
            "Epoch 3, Sample 15591: Loss: 0.1248\n",
            "Epoch 3, Sample 15592: Loss: 0.0505\n",
            "Epoch 3, Sample 15593: Loss: 0.7315\n",
            "Epoch 3, Sample 15594: Loss: 0.4611\n",
            "Epoch 3, Sample 15595: Loss: 0.0630\n",
            "Epoch 3, Sample 15596: Loss: 1.0524\n",
            "Epoch 3, Sample 15597: Loss: 0.8874\n",
            "Epoch 3, Sample 15598: Loss: 0.5458\n",
            "Epoch 3, Sample 15599: Loss: 0.1248\n",
            "Epoch 3, Sample 15600: Loss: 0.2879\n",
            "Epoch 3, Sample 15601: Loss: 0.2832\n",
            "Epoch 3, Sample 15602: Loss: 0.1482\n",
            "Epoch 3, Sample 15603: Loss: 0.1250\n",
            "Epoch 3, Sample 15604: Loss: 0.9651\n",
            "Epoch 3, Sample 15605: Loss: 0.3247\n",
            "Epoch 3, Sample 15606: Loss: 1.0524\n",
            "Epoch 3, Sample 15607: Loss: 0.1924\n",
            "Epoch 3, Sample 15608: Loss: 0.1089\n",
            "Epoch 3, Sample 15609: Loss: 0.0026\n",
            "Epoch 3, Sample 15610: Loss: 0.4466\n",
            "Epoch 3, Sample 15611: Loss: 1.0524\n",
            "Epoch 3, Sample 15612: Loss: 0.7036\n",
            "Epoch 3, Sample 15613: Loss: 0.2044\n",
            "Epoch 3, Sample 15614: Loss: 0.4996\n",
            "Epoch 3, Sample 15615: Loss: 0.2034\n",
            "Epoch 3, Sample 15616: Loss: 0.2545\n",
            "Epoch 3, Sample 15617: Loss: 0.2639\n",
            "Epoch 3, Sample 15618: Loss: 0.6092\n",
            "Epoch 3, Sample 15619: Loss: 0.2044\n",
            "Epoch 3, Sample 15620: Loss: 0.2032\n",
            "Epoch 3, Sample 15621: Loss: 0.0838\n",
            "Epoch 3, Sample 15622: Loss: 0.1627\n",
            "Epoch 3, Sample 15623: Loss: 0.2639\n",
            "Epoch 3, Sample 15624: Loss: 0.5871\n",
            "Epoch 3, Sample 15625: Loss: 0.5014\n",
            "Epoch 3, Sample 15626: Loss: 0.3399\n",
            "Epoch 3, Sample 15627: Loss: 1.0524\n",
            "Epoch 3, Sample 15628: Loss: 0.2124\n",
            "Epoch 3, Sample 15629: Loss: 0.0026\n",
            "Epoch 3, Sample 15630: Loss: 0.1170\n",
            "Epoch 3, Sample 15631: Loss: 0.1989\n",
            "Epoch 3, Sample 15632: Loss: 0.1559\n",
            "Epoch 3, Sample 15633: Loss: 0.4611\n",
            "Epoch 3, Sample 15634: Loss: 0.4663\n",
            "Epoch 3, Sample 15635: Loss: 0.2032\n",
            "Epoch 3, Sample 15636: Loss: 0.2759\n",
            "Epoch 3, Sample 15637: Loss: 0.1337\n",
            "Epoch 3, Sample 15638: Loss: 0.5989\n",
            "Epoch 3, Sample 15639: Loss: 0.4930\n",
            "Epoch 3, Sample 15640: Loss: 0.2034\n",
            "Epoch 3, Sample 15641: Loss: 1.0524\n",
            "Epoch 3, Sample 15642: Loss: 0.1559\n",
            "Epoch 3, Sample 15643: Loss: 0.5019\n",
            "Epoch 3, Sample 15644: Loss: 1.0155\n",
            "Epoch 3, Sample 15645: Loss: 0.0145\n",
            "Epoch 3, Sample 15646: Loss: 0.3399\n",
            "Epoch 3, Sample 15647: Loss: 0.1626\n",
            "Epoch 3, Sample 15648: Loss: 0.6220\n",
            "Epoch 3, Sample 15649: Loss: 0.1170\n",
            "Epoch 3, Sample 15650: Loss: 0.7036\n",
            "Epoch 3, Sample 15651: Loss: 0.0145\n",
            "Epoch 3, Sample 15652: Loss: 0.7036\n",
            "Epoch 3, Sample 15653: Loss: 0.1170\n",
            "Epoch 3, Sample 15654: Loss: 0.5858\n",
            "Epoch 3, Sample 15655: Loss: 0.6180\n",
            "Epoch 3, Sample 15656: Loss: 0.7036\n",
            "Epoch 3, Sample 15657: Loss: 0.1336\n",
            "Epoch 3, Sample 15658: Loss: 0.0915\n",
            "Epoch 3, Sample 15659: Loss: 0.5000\n",
            "Epoch 3, Sample 15660: Loss: 0.2044\n",
            "Epoch 3, Sample 15661: Loss: 0.0178\n",
            "Epoch 3, Sample 15662: Loss: 0.0134\n",
            "Epoch 3, Sample 15663: Loss: 0.5074\n",
            "Epoch 3, Sample 15664: Loss: 0.7316\n",
            "Epoch 3, Sample 15665: Loss: 0.2528\n",
            "Epoch 3, Sample 15666: Loss: 0.7203\n",
            "Epoch 3, Sample 15667: Loss: 1.0155\n",
            "Epoch 3, Sample 15668: Loss: 1.0266\n",
            "Epoch 3, Sample 15669: Loss: 1.1155\n",
            "Epoch 3, Sample 15670: Loss: 0.1962\n",
            "Epoch 3, Sample 15671: Loss: 0.0972\n",
            "Epoch 3, Sample 15672: Loss: 0.1250\n",
            "Epoch 3, Sample 15673: Loss: 0.2989\n",
            "Epoch 3, Sample 15674: Loss: 0.0025\n",
            "Epoch 3, Sample 15675: Loss: 0.6059\n",
            "Epoch 3, Sample 15676: Loss: 0.4930\n",
            "Epoch 3, Sample 15677: Loss: 1.0524\n",
            "Epoch 3, Sample 15678: Loss: 0.3402\n",
            "Epoch 3, Sample 15679: Loss: 0.2112\n",
            "Epoch 3, Sample 15680: Loss: 1.0524\n",
            "Epoch 3, Sample 15681: Loss: 0.0025\n",
            "Epoch 3, Sample 15682: Loss: 0.3568\n",
            "Epoch 3, Sample 15683: Loss: 1.7140\n",
            "Epoch 3, Sample 15684: Loss: 0.1817\n",
            "Epoch 3, Sample 15685: Loss: 0.1036\n",
            "Epoch 3, Sample 15686: Loss: 0.6295\n",
            "Epoch 3, Sample 15687: Loss: 2.0222\n",
            "Epoch 3, Sample 15688: Loss: 0.3328\n",
            "Epoch 3, Sample 15689: Loss: 0.0054\n",
            "Epoch 3, Sample 15690: Loss: 0.2044\n",
            "Epoch 3, Sample 15691: Loss: 0.1844\n",
            "Epoch 3, Sample 15692: Loss: 0.2044\n",
            "Epoch 3, Sample 15693: Loss: 2.6858\n",
            "Epoch 3, Sample 15694: Loss: 1.0524\n",
            "Epoch 3, Sample 15695: Loss: 0.4550\n",
            "Epoch 3, Sample 15696: Loss: 0.7036\n",
            "Epoch 3, Sample 15697: Loss: 0.7453\n",
            "Epoch 3, Sample 15698: Loss: 0.3399\n",
            "Epoch 3, Sample 15699: Loss: 0.0026\n",
            "Epoch 3, Sample 15700: Loss: 0.0630\n",
            "Epoch 3, Sample 15701: Loss: 0.0026\n",
            "Epoch 3, Sample 15702: Loss: 0.0129\n",
            "Epoch 3, Sample 15703: Loss: 0.3247\n",
            "Epoch 3, Sample 15704: Loss: 0.0625\n",
            "Epoch 3, Sample 15705: Loss: 0.6990\n",
            "Epoch 3, Sample 15706: Loss: 0.3402\n",
            "Epoch 3, Sample 15707: Loss: 0.0795\n",
            "Epoch 3, Sample 15708: Loss: 0.0014\n",
            "Epoch 3, Sample 15709: Loss: 0.0028\n",
            "Epoch 3, Sample 15710: Loss: 0.3441\n",
            "Epoch 3, Sample 15711: Loss: 0.2759\n",
            "Epoch 3, Sample 15712: Loss: 0.6648\n",
            "Epoch 3, Sample 15713: Loss: 0.2467\n",
            "Epoch 3, Sample 15714: Loss: 0.6990\n",
            "Epoch 3, Sample 15715: Loss: 0.3399\n",
            "Epoch 3, Sample 15716: Loss: 0.1996\n",
            "Epoch 3, Sample 15717: Loss: 2.7331\n",
            "Epoch 3, Sample 15718: Loss: 0.1250\n",
            "Epoch 3, Sample 15719: Loss: 0.6852\n",
            "Epoch 3, Sample 15720: Loss: 0.1941\n",
            "Epoch 3, Sample 15721: Loss: 0.0024\n",
            "Epoch 3, Sample 15722: Loss: 0.0306\n",
            "Epoch 3, Sample 15723: Loss: 0.3949\n",
            "Epoch 3, Sample 15724: Loss: 2.9718\n",
            "Epoch 3, Sample 15725: Loss: 0.5451\n",
            "Epoch 3, Sample 15726: Loss: 0.1030\n",
            "Epoch 3, Sample 15727: Loss: 1.9151\n",
            "Epoch 3, Sample 15728: Loss: 1.0155\n",
            "Epoch 3, Sample 15729: Loss: 0.3949\n",
            "Epoch 3, Sample 15730: Loss: 0.6139\n",
            "Epoch 3, Sample 15731: Loss: 0.1559\n",
            "Epoch 3, Sample 15732: Loss: 2.2434\n",
            "Epoch 3, Sample 15733: Loss: 0.3332\n",
            "Epoch 3, Sample 15734: Loss: 0.1170\n",
            "Epoch 3, Sample 15735: Loss: 0.0505\n",
            "Epoch 3, Sample 15736: Loss: 0.9269\n",
            "Epoch 3, Sample 15737: Loss: 0.8951\n",
            "Epoch 3, Sample 15738: Loss: 0.4996\n",
            "Epoch 3, Sample 15739: Loss: 0.2219\n",
            "Epoch 3, Sample 15740: Loss: 0.2032\n",
            "Epoch 3, Sample 15741: Loss: 0.2044\n",
            "Epoch 3, Sample 15742: Loss: 0.4996\n",
            "Epoch 3, Sample 15743: Loss: 0.2219\n",
            "Epoch 3, Sample 15744: Loss: 0.3399\n",
            "Epoch 3, Sample 15745: Loss: 0.0460\n",
            "Epoch 3, Sample 15746: Loss: 0.1559\n",
            "Epoch 3, Sample 15747: Loss: 0.0630\n",
            "Epoch 3, Sample 15748: Loss: 0.1250\n",
            "Epoch 3, Sample 15749: Loss: 0.7486\n",
            "Epoch 3, Sample 15750: Loss: 0.0026\n",
            "Epoch 3, Sample 15751: Loss: 0.2044\n",
            "Epoch 3, Sample 15752: Loss: 0.1559\n",
            "Epoch 3, Sample 15753: Loss: 0.0018\n",
            "Epoch 3, Sample 15754: Loss: 0.0590\n",
            "Epoch 3, Sample 15755: Loss: 0.5000\n",
            "Epoch 3, Sample 15756: Loss: 0.0026\n",
            "Epoch 3, Sample 15757: Loss: 0.1229\n",
            "Epoch 3, Sample 15758: Loss: 0.1246\n",
            "Epoch 3, Sample 15759: Loss: 0.9367\n",
            "Epoch 3, Sample 15760: Loss: 0.1170\n",
            "Epoch 3, Sample 15761: Loss: 0.1206\n",
            "Epoch 3, Sample 15762: Loss: 0.4799\n",
            "Epoch 3, Sample 15763: Loss: 0.7453\n",
            "Epoch 3, Sample 15764: Loss: 0.6990\n",
            "Epoch 3, Sample 15765: Loss: 0.5003\n",
            "Epoch 3, Sample 15766: Loss: 1.0155\n",
            "Epoch 3, Sample 15767: Loss: 1.0524\n",
            "Epoch 3, Sample 15768: Loss: 0.3441\n",
            "Epoch 3, Sample 15769: Loss: 0.1219\n",
            "Epoch 3, Sample 15770: Loss: 0.0230\n",
            "Epoch 3, Sample 15771: Loss: 0.3539\n",
            "Epoch 3, Sample 15772: Loss: 0.6990\n",
            "Epoch 3, Sample 15773: Loss: 0.0042\n",
            "Epoch 3, Sample 15774: Loss: 0.7036\n",
            "Epoch 3, Sample 15775: Loss: 0.5871\n",
            "Epoch 3, Sample 15776: Loss: 0.3949\n",
            "Epoch 3, Sample 15777: Loss: 0.3441\n",
            "Epoch 3, Sample 15778: Loss: 0.0144\n",
            "Epoch 3, Sample 15779: Loss: 1.1569\n",
            "Epoch 3, Sample 15780: Loss: 0.1399\n",
            "Epoch 3, Sample 15781: Loss: 0.7036\n",
            "Epoch 3, Sample 15782: Loss: 0.1968\n",
            "Epoch 3, Sample 15783: Loss: 0.1397\n",
            "Epoch 3, Sample 15784: Loss: 0.8231\n",
            "Epoch 3, Sample 15785: Loss: 0.5003\n",
            "Epoch 3, Sample 15786: Loss: 0.9694\n",
            "Epoch 3, Sample 15787: Loss: 0.2034\n",
            "Epoch 3, Sample 15788: Loss: 1.0530\n",
            "Epoch 3, Sample 15789: Loss: 0.3441\n",
            "Epoch 3, Sample 15790: Loss: 0.1654\n",
            "Epoch 3, Sample 15791: Loss: 0.3399\n",
            "Epoch 3, Sample 15792: Loss: 0.4611\n",
            "Epoch 3, Sample 15793: Loss: 1.0524\n",
            "Epoch 3, Sample 15794: Loss: 1.0524\n",
            "Epoch 3, Sample 15795: Loss: 1.0524\n",
            "Epoch 3, Sample 15796: Loss: 0.0036\n",
            "Epoch 3, Sample 15797: Loss: 0.7486\n",
            "Epoch 3, Sample 15798: Loss: 0.1250\n",
            "Epoch 3, Sample 15799: Loss: 0.0166\n",
            "Epoch 3, Sample 15800: Loss: 1.0524\n",
            "Epoch 3, Sample 15801: Loss: 0.2034\n",
            "Epoch 3, Sample 15802: Loss: 0.3441\n",
            "Epoch 3, Sample 15803: Loss: 0.0838\n",
            "Epoch 3, Sample 15804: Loss: 0.4930\n",
            "Epoch 3, Sample 15805: Loss: 0.0076\n",
            "Epoch 3, Sample 15806: Loss: 0.2302\n",
            "Epoch 3, Sample 15807: Loss: 0.0935\n",
            "Epoch 3, Sample 15808: Loss: 1.0524\n",
            "Epoch 3, Sample 15809: Loss: 0.2541\n",
            "Epoch 3, Sample 15810: Loss: 0.0554\n",
            "Epoch 3, Sample 15811: Loss: 0.7036\n",
            "Epoch 3, Sample 15812: Loss: 0.3191\n",
            "Epoch 3, Sample 15813: Loss: 0.0145\n",
            "Epoch 3, Sample 15814: Loss: 0.2034\n",
            "Epoch 3, Sample 15815: Loss: 0.3441\n",
            "Epoch 3, Sample 15816: Loss: 0.2508\n",
            "Epoch 3, Sample 15817: Loss: 0.0018\n",
            "Epoch 3, Sample 15818: Loss: 0.0212\n",
            "Epoch 3, Sample 15819: Loss: 0.0004\n",
            "Epoch 3, Sample 15820: Loss: 0.3154\n",
            "Epoch 3, Sample 15821: Loss: 0.2314\n",
            "Epoch 3, Sample 15822: Loss: 0.4032\n",
            "Epoch 3, Sample 15823: Loss: 0.2989\n",
            "Epoch 3, Sample 15824: Loss: 0.2340\n",
            "Epoch 3, Sample 15825: Loss: 0.0026\n",
            "Epoch 3, Sample 15826: Loss: 0.0026\n",
            "Epoch 3, Sample 15827: Loss: 0.2983\n",
            "Epoch 3, Sample 15828: Loss: 6.0469\n",
            "Epoch 3, Sample 15829: Loss: 0.2232\n",
            "Epoch 3, Sample 15830: Loss: 0.9367\n",
            "Epoch 3, Sample 15831: Loss: 1.0524\n",
            "Epoch 3, Sample 15832: Loss: 0.2044\n",
            "Epoch 3, Sample 15833: Loss: 0.1170\n",
            "Epoch 3, Sample 15834: Loss: 0.0460\n",
            "Epoch 3, Sample 15835: Loss: 0.2935\n",
            "Epoch 3, Sample 15836: Loss: 0.1693\n",
            "Epoch 3, Sample 15837: Loss: 0.2044\n",
            "Epoch 3, Sample 15838: Loss: 0.2704\n",
            "Epoch 3, Sample 15839: Loss: 0.6139\n",
            "Epoch 3, Sample 15840: Loss: 2.6860\n",
            "Epoch 3, Sample 15841: Loss: 8.3178\n",
            "Epoch 3, Sample 15842: Loss: 0.1250\n",
            "Epoch 3, Sample 15843: Loss: 0.1170\n",
            "Epoch 3, Sample 15844: Loss: 0.0608\n",
            "Epoch 3, Sample 15845: Loss: 0.7036\n",
            "Epoch 3, Sample 15846: Loss: 0.4799\n",
            "Epoch 3, Sample 15847: Loss: 0.0026\n",
            "Epoch 3, Sample 15848: Loss: 0.2759\n",
            "Epoch 3, Sample 15849: Loss: 0.3949\n",
            "Epoch 3, Sample 15850: Loss: 0.4689\n",
            "Epoch 3, Sample 15851: Loss: 0.4104\n",
            "Epoch 3, Sample 15852: Loss: 0.0313\n",
            "Epoch 3, Sample 15853: Loss: 0.0018\n",
            "Epoch 3, Sample 15854: Loss: 0.8951\n",
            "Epoch 3, Sample 15855: Loss: 0.4382\n",
            "Epoch 3, Sample 15856: Loss: 0.3758\n",
            "Epoch 3, Sample 15857: Loss: 0.0018\n",
            "Epoch 3, Sample 15858: Loss: 0.0026\n",
            "Epoch 3, Sample 15859: Loss: 0.4902\n",
            "Epoch 3, Sample 15860: Loss: 0.2034\n",
            "Epoch 3, Sample 15861: Loss: 0.0688\n",
            "Epoch 3, Sample 15862: Loss: 0.3399\n",
            "Epoch 3, Sample 15863: Loss: 0.1019\n",
            "Epoch 3, Sample 15864: Loss: 0.2032\n",
            "Epoch 3, Sample 15865: Loss: 0.9367\n",
            "Epoch 3, Sample 15866: Loss: 0.2036\n",
            "Epoch 3, Sample 15867: Loss: 0.3021\n",
            "Epoch 3, Sample 15868: Loss: 2.1901\n",
            "Epoch 3, Sample 15869: Loss: 0.2032\n",
            "Epoch 3, Sample 15870: Loss: 0.8951\n",
            "Epoch 3, Sample 15871: Loss: 0.1250\n",
            "Epoch 3, Sample 15872: Loss: 0.1896\n",
            "Epoch 3, Sample 15873: Loss: 0.3441\n",
            "Epoch 3, Sample 15874: Loss: 0.1399\n",
            "Epoch 3, Sample 15875: Loss: 0.1807\n",
            "Epoch 3, Sample 15876: Loss: 0.1164\n",
            "Epoch 3, Sample 15877: Loss: 0.2759\n",
            "Epoch 3, Sample 15878: Loss: 0.0026\n",
            "Epoch 3, Sample 15879: Loss: 0.1559\n",
            "Epoch 3, Sample 15880: Loss: 0.1233\n",
            "Epoch 3, Sample 15881: Loss: 0.2034\n",
            "Epoch 3, Sample 15882: Loss: 0.1170\n",
            "Epoch 3, Sample 15883: Loss: 0.0435\n",
            "Epoch 3, Sample 15884: Loss: 0.8951\n",
            "Epoch 3, Sample 15885: Loss: 0.2759\n",
            "Epoch 3, Sample 15886: Loss: 0.1170\n",
            "Epoch 3, Sample 15887: Loss: 0.1170\n",
            "Epoch 3, Sample 15888: Loss: 0.2832\n",
            "Epoch 3, Sample 15889: Loss: 0.0004\n",
            "Epoch 3, Sample 15890: Loss: 0.0057\n",
            "Epoch 3, Sample 15891: Loss: 0.2340\n",
            "Epoch 3, Sample 15892: Loss: 0.1903\n",
            "Epoch 3, Sample 15893: Loss: 0.2044\n",
            "Epoch 3, Sample 15894: Loss: 0.2778\n",
            "Epoch 3, Sample 15895: Loss: 1.0155\n",
            "Epoch 3, Sample 15896: Loss: 0.4799\n",
            "Epoch 3, Sample 15897: Loss: 0.0026\n",
            "Epoch 3, Sample 15898: Loss: 0.0001\n",
            "Epoch 3, Sample 15899: Loss: 0.0061\n",
            "Epoch 3, Sample 15900: Loss: 0.3399\n",
            "Epoch 3, Sample 15901: Loss: 0.6304\n",
            "Epoch 3, Sample 15902: Loss: 0.3590\n",
            "Epoch 3, Sample 15903: Loss: 0.1860\n",
            "Epoch 3, Sample 15904: Loss: 0.5858\n",
            "Epoch 3, Sample 15905: Loss: 0.2034\n",
            "Epoch 3, Sample 15906: Loss: 0.0205\n",
            "Epoch 3, Sample 15907: Loss: 0.6990\n",
            "Epoch 3, Sample 15908: Loss: 0.5858\n",
            "Epoch 3, Sample 15909: Loss: 0.8951\n",
            "Epoch 3, Sample 15910: Loss: 0.2121\n",
            "Epoch 3, Sample 15911: Loss: 0.0625\n",
            "Epoch 3, Sample 15912: Loss: 0.1830\n",
            "Epoch 3, Sample 15913: Loss: 0.0001\n",
            "Epoch 3, Sample 15914: Loss: 13.3051\n",
            "Epoch 3, Sample 15915: Loss: 0.0630\n",
            "Epoch 3, Sample 15916: Loss: 0.0108\n",
            "Epoch 3, Sample 15917: Loss: 0.2032\n",
            "Epoch 3, Sample 15918: Loss: 0.0290\n",
            "Epoch 3, Sample 15919: Loss: 0.1232\n",
            "Epoch 3, Sample 15920: Loss: 0.5196\n",
            "Epoch 3, Sample 15921: Loss: 0.3126\n",
            "Epoch 3, Sample 15922: Loss: 0.7036\n",
            "Epoch 3, Sample 15923: Loss: 0.7036\n",
            "Epoch 3, Sample 15924: Loss: 0.4799\n",
            "Epoch 3, Sample 15925: Loss: 0.0026\n",
            "Epoch 3, Sample 15926: Loss: 0.0014\n",
            "Epoch 3, Sample 15927: Loss: 1.0530\n",
            "Epoch 3, Sample 15928: Loss: 0.0838\n",
            "Epoch 3, Sample 15929: Loss: 0.0020\n",
            "Epoch 3, Sample 15930: Loss: 0.3758\n",
            "Epoch 3, Sample 15931: Loss: 0.0306\n",
            "Epoch 3, Sample 15932: Loss: 0.3450\n",
            "Epoch 3, Sample 15933: Loss: 0.5653\n",
            "Epoch 3, Sample 15934: Loss: 0.0001\n",
            "Epoch 3, Sample 15935: Loss: 0.1003\n",
            "Epoch 3, Sample 15936: Loss: 1.0702\n",
            "Epoch 3, Sample 15937: Loss: 0.5089\n",
            "Epoch 3, Sample 15938: Loss: 0.5996\n",
            "Epoch 3, Sample 15939: Loss: 0.0626\n",
            "Epoch 3, Sample 15940: Loss: 0.6990\n",
            "Epoch 3, Sample 15941: Loss: 0.6110\n",
            "Epoch 3, Sample 15942: Loss: 0.1588\n",
            "Epoch 3, Sample 15943: Loss: 0.2935\n",
            "Epoch 3, Sample 15944: Loss: 0.3399\n",
            "Epoch 3, Sample 15945: Loss: 0.0253\n",
            "Epoch 3, Sample 15946: Loss: 0.1252\n",
            "Epoch 3, Sample 15947: Loss: 0.4013\n",
            "Epoch 3, Sample 15948: Loss: 0.0062\n",
            "Epoch 3, Sample 15949: Loss: 0.1430\n",
            "Epoch 3, Sample 15950: Loss: 0.3591\n",
            "Epoch 3, Sample 15951: Loss: 1.0524\n",
            "Epoch 3, Sample 15952: Loss: 0.2759\n",
            "Epoch 3, Sample 15953: Loss: 0.1627\n",
            "Epoch 3, Sample 15954: Loss: 0.3333\n",
            "Epoch 3, Sample 15955: Loss: 0.3399\n",
            "Epoch 3, Sample 15956: Loss: 0.6867\n",
            "Epoch 3, Sample 15957: Loss: 0.7098\n",
            "Epoch 3, Sample 15958: Loss: 0.0778\n",
            "Epoch 3, Sample 15959: Loss: 0.1250\n",
            "Epoch 3, Sample 15960: Loss: 0.2340\n",
            "Epoch 3, Sample 15961: Loss: 0.4503\n",
            "Epoch 3, Sample 15962: Loss: 0.0624\n",
            "Epoch 3, Sample 15963: Loss: 1.0530\n",
            "Epoch 3, Sample 15964: Loss: 0.3565\n",
            "Epoch 3, Sample 15965: Loss: 0.3332\n",
            "Epoch 3, Sample 15966: Loss: 0.6139\n",
            "Epoch 3, Sample 15967: Loss: 0.2962\n",
            "Epoch 3, Sample 15968: Loss: 0.1022\n",
            "Epoch 3, Sample 15969: Loss: 0.0429\n",
            "Epoch 3, Sample 15970: Loss: 0.1999\n",
            "Epoch 3, Sample 15971: Loss: 0.2459\n",
            "Epoch 3, Sample 15972: Loss: 0.0026\n",
            "Epoch 3, Sample 15973: Loss: 0.8093\n",
            "Epoch 3, Sample 15974: Loss: 0.3399\n",
            "Epoch 3, Sample 15975: Loss: 0.0643\n",
            "Epoch 3, Sample 15976: Loss: 1.0524\n",
            "Epoch 3, Sample 15977: Loss: 0.6867\n",
            "Epoch 3, Sample 15978: Loss: 0.2044\n",
            "Epoch 3, Sample 15979: Loss: 0.0630\n",
            "Epoch 3, Sample 15980: Loss: 0.8951\n",
            "Epoch 3, Sample 15981: Loss: 0.3441\n",
            "Epoch 3, Sample 15982: Loss: 0.3399\n",
            "Epoch 3, Sample 15983: Loss: 1.0524\n",
            "Epoch 3, Sample 15984: Loss: 0.0018\n",
            "Epoch 3, Sample 15985: Loss: 0.8951\n",
            "Epoch 3, Sample 15986: Loss: 0.0152\n",
            "Epoch 3, Sample 15987: Loss: 0.0026\n",
            "Epoch 3, Sample 15988: Loss: 0.0026\n",
            "Epoch 3, Sample 15989: Loss: 1.0155\n",
            "Epoch 3, Sample 15990: Loss: 0.4641\n",
            "Epoch 3, Sample 15991: Loss: 0.0000\n",
            "Epoch 3, Sample 15992: Loss: 0.1219\n",
            "Epoch 3, Sample 15993: Loss: 0.2182\n",
            "Epoch 3, Sample 15994: Loss: 0.1246\n",
            "Epoch 3, Sample 15995: Loss: 0.6139\n",
            "Epoch 3, Sample 15996: Loss: 5.8902\n",
            "Epoch 3, Sample 15997: Loss: 0.0041\n",
            "Epoch 3, Sample 15998: Loss: 0.5972\n",
            "Epoch 3, Sample 15999: Loss: 0.0002\n",
            "Epoch 3, Sample 16000: Loss: 0.6867\n",
            "\n",
            "Epoch 3 Average Loss: 0.5507\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 5th trial we chose these settings\n",
        "epochs = 3\n",
        "learning_rate = .005\n",
        "input_size = 20\n",
        "Neurons = 30\n",
        "activation_input = 30\n",
        "activation function = relu\n",
        "output = 1"
      ],
      "metadata": {
        "id": "SIbSEz3Hc4Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "learning_rate = .005\n",
        "\n",
        "\n",
        "# Initializing Parameters\n",
        "w = 50\n",
        "\n",
        "loss_set = {}\n",
        "\n",
        "# 1. Creating a FeedForwardNetwork\n",
        "# 1.1 Structure (Architecture) of NN\n",
        "model_net5 = torch.nn.Sequential(torch.nn.Linear(20,30),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(0.33),\n",
        "\n",
        "                                 torch.nn.Linear(30,1),\n",
        "                                 torch.nn.ReLU(),\n",
        "\n",
        "                                 );\n",
        "\n",
        "# 1.2 Loss Function\n",
        "loss_mse = torch.nn.MSELoss()\n",
        "\n",
        "# 1.3 Optmization Approch\n",
        "optimizer = torch.optim.SGD(model_net5.parameters(), lr=learning_rate)\n",
        "\n",
        "w_his = []\n",
        "w_his.append(w)\n",
        "# Loop over the number of epochs\n",
        "for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over each sample in the dataset\n",
        "    for i in range(tensor_data_X.size(0)):\n",
        "\n",
        "      # 2. Forward Pass\n",
        "      output = model_net5.forward(tensor_data_X[i].reshape(-1))\n",
        "\n",
        "      # 3. FeedForward Evaluation\n",
        "      loss = loss_mse(output, tensor_data_Y[i].reshape(-1))\n",
        "      optimizer.zero_grad();\n",
        "\n",
        "      # 4. Backward Pass / Gradient Calculation\n",
        "      loss.backward()\n",
        "\n",
        "      # Store the loss for each epoch\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # 5. Back Propagation / Update Weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store the weight value for each sample of data\n",
        "      w_his.append(float(model_net5[0].weight.data[0][0]))\n",
        "\n",
        "      # Display the loss for the current sample\n",
        "      print(f\"Epoch {epoch+1}, Sample {i+1}: Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # Calculate and display average loss for the epoch\n",
        "    epoch_loss /= tensor_data_X.size(0)\n",
        "\n",
        "    # Store the loss for each sample of data\n",
        "    loss_set[epoch] = epoch_loss\n",
        "    print(f\"\\nEpoch {epoch+1} Average Loss: {epoch_loss:.4f}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "81924f3010e5497f8a9ec9c4f1c0e40f",
            "bfe441742f53496bb7cfab8e4daee78b",
            "79e1566b97bd4052a6f031a7ea8e9022",
            "238cb37d23444dcab5985b5223f929e3",
            "ff99a18a923946b0b1dfaed33c310dc2",
            "03b8bcbb15c14137b9998ffbb8f61a4f",
            "cf8f8e94bac2460e94d1a5ef5cec3f6f",
            "6f73f589463e4c9bba39ba2588e3b6df",
            "5f1976a0751545baadfcde92d7f0f3f7",
            "5f7f849e237d475bbc95eb51a8b69f10",
            "5a8aca56d02c42a6883b3c1e5762564f"
          ]
        },
        "id": "LyVT4WzNIrN9",
        "outputId": "20dbfc42-6af7-4c1d-f3b5-c5892e988b97"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-282-badd8fb447d0>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81924f3010e5497f8a9ec9c4f1c0e40f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 11005: Loss: 0.2832\n",
            "Epoch 3, Sample 11006: Loss: 0.0009\n",
            "Epoch 3, Sample 11007: Loss: 0.0003\n",
            "Epoch 3, Sample 11008: Loss: 0.7036\n",
            "Epoch 3, Sample 11009: Loss: 0.0864\n",
            "Epoch 3, Sample 11010: Loss: 0.0008\n",
            "Epoch 3, Sample 11011: Loss: 0.0026\n",
            "Epoch 3, Sample 11012: Loss: 0.7453\n",
            "Epoch 3, Sample 11013: Loss: 0.4118\n",
            "Epoch 3, Sample 11014: Loss: 0.2032\n",
            "Epoch 3, Sample 11015: Loss: 0.1733\n",
            "Epoch 3, Sample 11016: Loss: 0.3399\n",
            "Epoch 3, Sample 11017: Loss: 0.2339\n",
            "Epoch 3, Sample 11018: Loss: 1.0228\n",
            "Epoch 3, Sample 11019: Loss: 0.0505\n",
            "Epoch 3, Sample 11020: Loss: 0.1170\n",
            "Epoch 3, Sample 11021: Loss: 0.4663\n",
            "Epoch 3, Sample 11022: Loss: 1.6418\n",
            "Epoch 3, Sample 11023: Loss: 0.2750\n",
            "Epoch 3, Sample 11024: Loss: 0.9367\n",
            "Epoch 3, Sample 11025: Loss: 0.0025\n",
            "Epoch 3, Sample 11026: Loss: 1.1265\n",
            "Epoch 3, Sample 11027: Loss: 1.0155\n",
            "Epoch 3, Sample 11028: Loss: 0.7036\n",
            "Epoch 3, Sample 11029: Loss: 0.5871\n",
            "Epoch 3, Sample 11030: Loss: 0.0212\n",
            "Epoch 3, Sample 11031: Loss: 0.0505\n",
            "Epoch 3, Sample 11032: Loss: 1.0524\n",
            "Epoch 3, Sample 11033: Loss: 0.0946\n",
            "Epoch 3, Sample 11034: Loss: 0.1838\n",
            "Epoch 3, Sample 11035: Loss: 1.0493\n",
            "Epoch 3, Sample 11036: Loss: 0.5570\n",
            "Epoch 3, Sample 11037: Loss: 0.2098\n",
            "Epoch 3, Sample 11038: Loss: 0.8300\n",
            "Epoch 3, Sample 11039: Loss: 1.0155\n",
            "Epoch 3, Sample 11040: Loss: 1.0524\n",
            "Epoch 3, Sample 11041: Loss: 0.0391\n",
            "Epoch 3, Sample 11042: Loss: 3.4482\n",
            "Epoch 3, Sample 11043: Loss: 0.6244\n",
            "Epoch 3, Sample 11044: Loss: 0.2639\n",
            "Epoch 3, Sample 11045: Loss: 0.0630\n",
            "Epoch 3, Sample 11046: Loss: 0.3441\n",
            "Epoch 3, Sample 11047: Loss: 0.0058\n",
            "Epoch 3, Sample 11048: Loss: 0.9367\n",
            "Epoch 3, Sample 11049: Loss: 0.2759\n",
            "Epoch 3, Sample 11050: Loss: 0.0084\n",
            "Epoch 3, Sample 11051: Loss: 0.0001\n",
            "Epoch 3, Sample 11052: Loss: 1.5542\n",
            "Epoch 3, Sample 11053: Loss: 0.2032\n",
            "Epoch 3, Sample 11054: Loss: 0.0554\n",
            "Epoch 3, Sample 11055: Loss: 0.1248\n",
            "Epoch 3, Sample 11056: Loss: 0.0018\n",
            "Epoch 3, Sample 11057: Loss: 0.0520\n",
            "Epoch 3, Sample 11058: Loss: 1.9306\n",
            "Epoch 3, Sample 11059: Loss: 1.9129\n",
            "Epoch 3, Sample 11060: Loss: 0.0625\n",
            "Epoch 3, Sample 11061: Loss: 1.1957\n",
            "Epoch 3, Sample 11062: Loss: 0.0234\n",
            "Epoch 3, Sample 11063: Loss: 0.2044\n",
            "Epoch 3, Sample 11064: Loss: 0.9017\n",
            "Epoch 3, Sample 11065: Loss: 0.7036\n",
            "Epoch 3, Sample 11066: Loss: 0.0208\n",
            "Epoch 3, Sample 11067: Loss: 0.1207\n",
            "Epoch 3, Sample 11068: Loss: 1.0530\n",
            "Epoch 3, Sample 11069: Loss: 0.7036\n",
            "Epoch 3, Sample 11070: Loss: 0.2639\n",
            "Epoch 3, Sample 11071: Loss: 0.7036\n",
            "Epoch 3, Sample 11072: Loss: 0.5858\n",
            "Epoch 3, Sample 11073: Loss: 0.0059\n",
            "Epoch 3, Sample 11074: Loss: 0.0003\n",
            "Epoch 3, Sample 11075: Loss: 0.0185\n",
            "Epoch 3, Sample 11076: Loss: 0.2362\n",
            "Epoch 3, Sample 11077: Loss: 0.4367\n",
            "Epoch 3, Sample 11078: Loss: 0.2412\n",
            "Epoch 3, Sample 11079: Loss: 0.3399\n",
            "Epoch 3, Sample 11080: Loss: 0.0054\n",
            "Epoch 3, Sample 11081: Loss: 0.0145\n",
            "Epoch 3, Sample 11082: Loss: 0.0026\n",
            "Epoch 3, Sample 11083: Loss: 0.2639\n",
            "Epoch 3, Sample 11084: Loss: 0.0205\n",
            "Epoch 3, Sample 11085: Loss: 1.0524\n",
            "Epoch 3, Sample 11086: Loss: 0.3399\n",
            "Epoch 3, Sample 11087: Loss: 0.1559\n",
            "Epoch 3, Sample 11088: Loss: 1.0155\n",
            "Epoch 3, Sample 11089: Loss: 0.0022\n",
            "Epoch 3, Sample 11090: Loss: 0.0630\n",
            "Epoch 3, Sample 11091: Loss: 0.2044\n",
            "Epoch 3, Sample 11092: Loss: 0.0018\n",
            "Epoch 3, Sample 11093: Loss: 0.1937\n",
            "Epoch 3, Sample 11094: Loss: 0.0026\n",
            "Epoch 3, Sample 11095: Loss: 1.0524\n",
            "Epoch 3, Sample 11096: Loss: 0.2340\n",
            "Epoch 3, Sample 11097: Loss: 0.5078\n",
            "Epoch 3, Sample 11098: Loss: 0.0108\n",
            "Epoch 3, Sample 11099: Loss: 0.2295\n",
            "Epoch 3, Sample 11100: Loss: 0.4405\n",
            "Epoch 3, Sample 11101: Loss: 0.1170\n",
            "Epoch 3, Sample 11102: Loss: 0.2036\n",
            "Epoch 3, Sample 11103: Loss: 0.5858\n",
            "Epoch 3, Sample 11104: Loss: 0.2034\n",
            "Epoch 3, Sample 11105: Loss: 0.0013\n",
            "Epoch 3, Sample 11106: Loss: 0.2032\n",
            "Epoch 3, Sample 11107: Loss: 0.0422\n",
            "Epoch 3, Sample 11108: Loss: 0.0630\n",
            "Epoch 3, Sample 11109: Loss: 0.2340\n",
            "Epoch 3, Sample 11110: Loss: 1.0524\n",
            "Epoch 3, Sample 11111: Loss: 0.2032\n",
            "Epoch 3, Sample 11112: Loss: 0.0531\n",
            "Epoch 3, Sample 11113: Loss: 1.0524\n",
            "Epoch 3, Sample 11114: Loss: 1.0155\n",
            "Epoch 3, Sample 11115: Loss: 0.1250\n",
            "Epoch 3, Sample 11116: Loss: 0.4607\n",
            "Epoch 3, Sample 11117: Loss: 1.0524\n",
            "Epoch 3, Sample 11118: Loss: 0.0034\n",
            "Epoch 3, Sample 11119: Loss: 1.0524\n",
            "Epoch 3, Sample 11120: Loss: 0.7036\n",
            "Epoch 3, Sample 11121: Loss: 0.2044\n",
            "Epoch 3, Sample 11122: Loss: 0.1170\n",
            "Epoch 3, Sample 11123: Loss: 0.5278\n",
            "Epoch 3, Sample 11124: Loss: 0.2759\n",
            "Epoch 3, Sample 11125: Loss: 0.0630\n",
            "Epoch 3, Sample 11126: Loss: 0.7036\n",
            "Epoch 3, Sample 11127: Loss: 1.4361\n",
            "Epoch 3, Sample 11128: Loss: 0.4930\n",
            "Epoch 3, Sample 11129: Loss: 0.9367\n",
            "Epoch 3, Sample 11130: Loss: 0.1792\n",
            "Epoch 3, Sample 11131: Loss: 0.1250\n",
            "Epoch 3, Sample 11132: Loss: 1.0524\n",
            "Epoch 3, Sample 11133: Loss: 0.6951\n",
            "Epoch 3, Sample 11134: Loss: 0.0460\n",
            "Epoch 3, Sample 11135: Loss: 0.2036\n",
            "Epoch 3, Sample 11136: Loss: 0.0018\n",
            "Epoch 3, Sample 11137: Loss: 0.3703\n",
            "Epoch 3, Sample 11138: Loss: 1.2013\n",
            "Epoch 3, Sample 11139: Loss: 0.0001\n",
            "Epoch 3, Sample 11140: Loss: 0.1564\n",
            "Epoch 3, Sample 11141: Loss: 0.2759\n",
            "Epoch 3, Sample 11142: Loss: 0.4611\n",
            "Epoch 3, Sample 11143: Loss: 0.2032\n",
            "Epoch 3, Sample 11144: Loss: 0.2219\n",
            "Epoch 3, Sample 11145: Loss: 0.7036\n",
            "Epoch 3, Sample 11146: Loss: 0.0062\n",
            "Epoch 3, Sample 11147: Loss: 4.7284\n",
            "Epoch 3, Sample 11148: Loss: 0.1458\n",
            "Epoch 3, Sample 11149: Loss: 0.7036\n",
            "Epoch 3, Sample 11150: Loss: 0.3329\n",
            "Epoch 3, Sample 11151: Loss: 0.2036\n",
            "Epoch 3, Sample 11152: Loss: 0.0161\n",
            "Epoch 3, Sample 11153: Loss: 0.6990\n",
            "Epoch 3, Sample 11154: Loss: 0.0802\n",
            "Epoch 3, Sample 11155: Loss: 0.1250\n",
            "Epoch 3, Sample 11156: Loss: 0.6304\n",
            "Epoch 3, Sample 11157: Loss: 0.9785\n",
            "Epoch 3, Sample 11158: Loss: 0.8951\n",
            "Epoch 3, Sample 11159: Loss: 0.2044\n",
            "Epoch 3, Sample 11160: Loss: 1.8485\n",
            "Epoch 3, Sample 11161: Loss: 0.0051\n",
            "Epoch 3, Sample 11162: Loss: 0.0026\n",
            "Epoch 3, Sample 11163: Loss: 0.2112\n",
            "Epoch 3, Sample 11164: Loss: 0.0499\n",
            "Epoch 3, Sample 11165: Loss: 0.0144\n",
            "Epoch 3, Sample 11166: Loss: 0.2032\n",
            "Epoch 3, Sample 11167: Loss: 0.7036\n",
            "Epoch 3, Sample 11168: Loss: 0.3873\n",
            "Epoch 3, Sample 11169: Loss: 0.8464\n",
            "Epoch 3, Sample 11170: Loss: 1.5542\n",
            "Epoch 3, Sample 11171: Loss: 1.0530\n",
            "Epoch 3, Sample 11172: Loss: 0.0026\n",
            "Epoch 3, Sample 11173: Loss: 0.2036\n",
            "Epoch 3, Sample 11174: Loss: 0.1523\n",
            "Epoch 3, Sample 11175: Loss: 0.2759\n",
            "Epoch 3, Sample 11176: Loss: 0.0637\n",
            "Epoch 3, Sample 11177: Loss: 2.5276\n",
            "Epoch 3, Sample 11178: Loss: 0.8951\n",
            "Epoch 3, Sample 11179: Loss: 0.1616\n",
            "Epoch 3, Sample 11180: Loss: 0.5000\n",
            "Epoch 3, Sample 11181: Loss: 0.6329\n",
            "Epoch 3, Sample 11182: Loss: 1.0155\n",
            "Epoch 3, Sample 11183: Loss: 0.0009\n",
            "Epoch 3, Sample 11184: Loss: 1.0524\n",
            "Epoch 3, Sample 11185: Loss: 0.0016\n",
            "Epoch 3, Sample 11186: Loss: 0.4611\n",
            "Epoch 3, Sample 11187: Loss: 0.4700\n",
            "Epoch 3, Sample 11188: Loss: 0.2032\n",
            "Epoch 3, Sample 11189: Loss: 1.0155\n",
            "Epoch 3, Sample 11190: Loss: 2.1787\n",
            "Epoch 3, Sample 11191: Loss: 0.3399\n",
            "Epoch 3, Sample 11192: Loss: 0.7036\n",
            "Epoch 3, Sample 11193: Loss: 0.2639\n",
            "Epoch 3, Sample 11194: Loss: 0.2034\n",
            "Epoch 3, Sample 11195: Loss: 0.7036\n",
            "Epoch 3, Sample 11196: Loss: 0.2036\n",
            "Epoch 3, Sample 11197: Loss: 1.0524\n",
            "Epoch 3, Sample 11198: Loss: 0.0626\n",
            "Epoch 3, Sample 11199: Loss: 1.0530\n",
            "Epoch 3, Sample 11200: Loss: 2.1247\n",
            "Epoch 3, Sample 11201: Loss: 1.1436\n",
            "Epoch 3, Sample 11202: Loss: 0.0027\n",
            "Epoch 3, Sample 11203: Loss: 0.2034\n",
            "Epoch 3, Sample 11204: Loss: 0.7583\n",
            "Epoch 3, Sample 11205: Loss: 0.4611\n",
            "Epoch 3, Sample 11206: Loss: 1.0524\n",
            "Epoch 3, Sample 11207: Loss: 1.0524\n",
            "Epoch 3, Sample 11208: Loss: 0.1456\n",
            "Epoch 3, Sample 11209: Loss: 0.0630\n",
            "Epoch 3, Sample 11210: Loss: 0.0026\n",
            "Epoch 3, Sample 11211: Loss: 0.2044\n",
            "Epoch 3, Sample 11212: Loss: 0.2832\n",
            "Epoch 3, Sample 11213: Loss: 0.3441\n",
            "Epoch 3, Sample 11214: Loss: 0.4996\n",
            "Epoch 3, Sample 11215: Loss: 0.1262\n",
            "Epoch 3, Sample 11216: Loss: 0.0460\n",
            "Epoch 3, Sample 11217: Loss: 0.9100\n",
            "Epoch 3, Sample 11218: Loss: 0.2210\n",
            "Epoch 3, Sample 11219: Loss: 1.0524\n",
            "Epoch 3, Sample 11220: Loss: 0.0033\n",
            "Epoch 3, Sample 11221: Loss: 0.0108\n",
            "Epoch 3, Sample 11222: Loss: 1.0155\n",
            "Epoch 3, Sample 11223: Loss: 0.0238\n",
            "Epoch 3, Sample 11224: Loss: 0.1170\n",
            "Epoch 3, Sample 11225: Loss: 0.0018\n",
            "Epoch 3, Sample 11226: Loss: 0.2034\n",
            "Epoch 3, Sample 11227: Loss: 0.2340\n",
            "Epoch 3, Sample 11228: Loss: 0.2637\n",
            "Epoch 3, Sample 11229: Loss: 0.1225\n",
            "Epoch 3, Sample 11230: Loss: 0.1674\n",
            "Epoch 3, Sample 11231: Loss: 1.0155\n",
            "Epoch 3, Sample 11232: Loss: 0.3402\n",
            "Epoch 3, Sample 11233: Loss: 0.2340\n",
            "Epoch 3, Sample 11234: Loss: 0.0026\n",
            "Epoch 3, Sample 11235: Loss: 0.1463\n",
            "Epoch 3, Sample 11236: Loss: 0.8951\n",
            "Epoch 3, Sample 11237: Loss: 0.2044\n",
            "Epoch 3, Sample 11238: Loss: 0.4032\n",
            "Epoch 3, Sample 11239: Loss: 0.8584\n",
            "Epoch 3, Sample 11240: Loss: 0.4032\n",
            "Epoch 3, Sample 11241: Loss: 0.1330\n",
            "Epoch 3, Sample 11242: Loss: 0.6990\n",
            "Epoch 3, Sample 11243: Loss: 0.0363\n",
            "Epoch 3, Sample 11244: Loss: 0.0018\n",
            "Epoch 3, Sample 11245: Loss: 0.0625\n",
            "Epoch 3, Sample 11246: Loss: 0.5283\n",
            "Epoch 3, Sample 11247: Loss: 0.1546\n",
            "Epoch 3, Sample 11248: Loss: 0.1962\n",
            "Epoch 3, Sample 11249: Loss: 0.2098\n",
            "Epoch 3, Sample 11250: Loss: 1.0155\n",
            "Epoch 3, Sample 11251: Loss: 0.0915\n",
            "Epoch 3, Sample 11252: Loss: 0.9367\n",
            "Epoch 3, Sample 11253: Loss: 0.3992\n",
            "Epoch 3, Sample 11254: Loss: 0.1559\n",
            "Epoch 3, Sample 11255: Loss: 0.3399\n",
            "Epoch 3, Sample 11256: Loss: 0.3402\n",
            "Epoch 3, Sample 11257: Loss: 0.0721\n",
            "Epoch 3, Sample 11258: Loss: 0.4266\n",
            "Epoch 3, Sample 11259: Loss: 0.6990\n",
            "Epoch 3, Sample 11260: Loss: 1.0524\n",
            "Epoch 3, Sample 11261: Loss: 0.1891\n",
            "Epoch 3, Sample 11262: Loss: 0.0026\n",
            "Epoch 3, Sample 11263: Loss: 1.7249\n",
            "Epoch 3, Sample 11264: Loss: 0.3441\n",
            "Epoch 3, Sample 11265: Loss: 0.8951\n",
            "Epoch 3, Sample 11266: Loss: 1.8063\n",
            "Epoch 3, Sample 11267: Loss: 0.0001\n",
            "Epoch 3, Sample 11268: Loss: 0.2759\n",
            "Epoch 3, Sample 11269: Loss: 0.6304\n",
            "Epoch 3, Sample 11270: Loss: 0.3369\n",
            "Epoch 3, Sample 11271: Loss: 0.2034\n",
            "Epoch 3, Sample 11272: Loss: 0.5858\n",
            "Epoch 3, Sample 11273: Loss: 0.0018\n",
            "Epoch 3, Sample 11274: Loss: 0.3399\n",
            "Epoch 3, Sample 11275: Loss: 1.0266\n",
            "Epoch 3, Sample 11276: Loss: 0.2259\n",
            "Epoch 3, Sample 11277: Loss: 0.6007\n",
            "Epoch 3, Sample 11278: Loss: 0.2044\n",
            "Epoch 3, Sample 11279: Loss: 0.7036\n",
            "Epoch 3, Sample 11280: Loss: 0.5010\n",
            "Epoch 3, Sample 11281: Loss: 2.2434\n",
            "Epoch 3, Sample 11282: Loss: 0.1041\n",
            "Epoch 3, Sample 11283: Loss: 1.0211\n",
            "Epoch 3, Sample 11284: Loss: 0.0018\n",
            "Epoch 3, Sample 11285: Loss: 0.4930\n",
            "Epoch 3, Sample 11286: Loss: 1.4884\n",
            "Epoch 3, Sample 11287: Loss: 0.0442\n",
            "Epoch 3, Sample 11288: Loss: 0.4032\n",
            "Epoch 3, Sample 11289: Loss: 0.2759\n",
            "Epoch 3, Sample 11290: Loss: 0.3070\n",
            "Epoch 3, Sample 11291: Loss: 0.4032\n",
            "Epoch 3, Sample 11292: Loss: 0.1984\n",
            "Epoch 3, Sample 11293: Loss: 0.5871\n",
            "Epoch 3, Sample 11294: Loss: 0.3399\n",
            "Epoch 3, Sample 11295: Loss: 0.2621\n",
            "Epoch 3, Sample 11296: Loss: 0.0630\n",
            "Epoch 3, Sample 11297: Loss: 0.9335\n",
            "Epoch 3, Sample 11298: Loss: 0.2044\n",
            "Epoch 3, Sample 11299: Loss: 0.4867\n",
            "Epoch 3, Sample 11300: Loss: 0.0450\n",
            "Epoch 3, Sample 11301: Loss: 2.4948\n",
            "Epoch 3, Sample 11302: Loss: 0.2044\n",
            "Epoch 3, Sample 11303: Loss: 0.1559\n",
            "Epoch 3, Sample 11304: Loss: 0.2659\n",
            "Epoch 3, Sample 11305: Loss: 6.2640\n",
            "Epoch 3, Sample 11306: Loss: 0.0212\n",
            "Epoch 3, Sample 11307: Loss: 0.7621\n",
            "Epoch 3, Sample 11308: Loss: 0.6606\n",
            "Epoch 3, Sample 11309: Loss: 0.6990\n",
            "Epoch 3, Sample 11310: Loss: 0.8200\n",
            "Epoch 3, Sample 11311: Loss: 1.2843\n",
            "Epoch 3, Sample 11312: Loss: 0.0212\n",
            "Epoch 3, Sample 11313: Loss: 0.2182\n",
            "Epoch 3, Sample 11314: Loss: 0.3399\n",
            "Epoch 3, Sample 11315: Loss: 0.3399\n",
            "Epoch 3, Sample 11316: Loss: 0.0915\n",
            "Epoch 3, Sample 11317: Loss: 0.7036\n",
            "Epoch 3, Sample 11318: Loss: 0.0576\n",
            "Epoch 3, Sample 11319: Loss: 0.4611\n",
            "Epoch 3, Sample 11320: Loss: 0.6092\n",
            "Epoch 3, Sample 11321: Loss: 0.1523\n",
            "Epoch 3, Sample 11322: Loss: 0.3949\n",
            "Epoch 3, Sample 11323: Loss: 0.2738\n",
            "Epoch 3, Sample 11324: Loss: 0.9367\n",
            "Epoch 3, Sample 11325: Loss: 0.1040\n",
            "Epoch 3, Sample 11326: Loss: 1.0524\n",
            "Epoch 3, Sample 11327: Loss: 0.3949\n",
            "Epoch 3, Sample 11328: Loss: 0.1264\n",
            "Epoch 3, Sample 11329: Loss: 0.0013\n",
            "Epoch 3, Sample 11330: Loss: 0.2044\n",
            "Epoch 3, Sample 11331: Loss: 0.0455\n",
            "Epoch 3, Sample 11332: Loss: 0.3399\n",
            "Epoch 3, Sample 11333: Loss: 0.4065\n",
            "Epoch 3, Sample 11334: Loss: 0.0501\n",
            "Epoch 3, Sample 11335: Loss: 0.8350\n",
            "Epoch 3, Sample 11336: Loss: 0.5799\n",
            "Epoch 3, Sample 11337: Loss: 0.2729\n",
            "Epoch 3, Sample 11338: Loss: 0.4761\n",
            "Epoch 3, Sample 11339: Loss: 0.0466\n",
            "Epoch 3, Sample 11340: Loss: 0.3332\n",
            "Epoch 3, Sample 11341: Loss: 0.2044\n",
            "Epoch 3, Sample 11342: Loss: 0.7036\n",
            "Epoch 3, Sample 11343: Loss: 0.2079\n",
            "Epoch 3, Sample 11344: Loss: 0.1250\n",
            "Epoch 3, Sample 11345: Loss: 0.2014\n",
            "Epoch 3, Sample 11346: Loss: 4.4103\n",
            "Epoch 3, Sample 11347: Loss: 0.2832\n",
            "Epoch 3, Sample 11348: Loss: 0.5019\n",
            "Epoch 3, Sample 11349: Loss: 1.3460\n",
            "Epoch 3, Sample 11350: Loss: 0.3399\n",
            "Epoch 3, Sample 11351: Loss: 0.2564\n",
            "Epoch 3, Sample 11352: Loss: 0.9651\n",
            "Epoch 3, Sample 11353: Loss: 0.8951\n",
            "Epoch 3, Sample 11354: Loss: 0.3367\n",
            "Epoch 3, Sample 11355: Loss: 0.0456\n",
            "Epoch 3, Sample 11356: Loss: 0.0684\n",
            "Epoch 3, Sample 11357: Loss: 0.5972\n",
            "Epoch 3, Sample 11358: Loss: 0.2044\n",
            "Epoch 3, Sample 11359: Loss: 0.1627\n",
            "Epoch 3, Sample 11360: Loss: 0.8499\n",
            "Epoch 3, Sample 11361: Loss: 0.1225\n",
            "Epoch 3, Sample 11362: Loss: 2.5274\n",
            "Epoch 3, Sample 11363: Loss: 0.0026\n",
            "Epoch 3, Sample 11364: Loss: 0.0068\n",
            "Epoch 3, Sample 11365: Loss: 1.9738\n",
            "Epoch 3, Sample 11366: Loss: 0.2034\n",
            "Epoch 3, Sample 11367: Loss: 0.4032\n",
            "Epoch 3, Sample 11368: Loss: 0.5858\n",
            "Epoch 3, Sample 11369: Loss: 0.1175\n",
            "Epoch 3, Sample 11370: Loss: 0.1250\n",
            "Epoch 3, Sample 11371: Loss: 0.0161\n",
            "Epoch 3, Sample 11372: Loss: 0.0144\n",
            "Epoch 3, Sample 11373: Loss: 0.0001\n",
            "Epoch 3, Sample 11374: Loss: 1.0524\n",
            "Epoch 3, Sample 11375: Loss: 0.2759\n",
            "Epoch 3, Sample 11376: Loss: 0.2084\n",
            "Epoch 3, Sample 11377: Loss: 0.0916\n",
            "Epoch 3, Sample 11378: Loss: 0.2183\n",
            "Epoch 3, Sample 11379: Loss: 0.2962\n",
            "Epoch 3, Sample 11380: Loss: 0.0460\n",
            "Epoch 3, Sample 11381: Loss: 1.0524\n",
            "Epoch 3, Sample 11382: Loss: 0.0838\n",
            "Epoch 3, Sample 11383: Loss: 0.7036\n",
            "Epoch 3, Sample 11384: Loss: 3.1299\n",
            "Epoch 3, Sample 11385: Loss: 0.2079\n",
            "Epoch 3, Sample 11386: Loss: 0.1250\n",
            "Epoch 3, Sample 11387: Loss: 0.0834\n",
            "Epoch 3, Sample 11388: Loss: 0.0972\n",
            "Epoch 3, Sample 11389: Loss: 0.0904\n",
            "Epoch 3, Sample 11390: Loss: 0.5871\n",
            "Epoch 3, Sample 11391: Loss: 1.0266\n",
            "Epoch 3, Sample 11392: Loss: 0.6099\n",
            "Epoch 3, Sample 11393: Loss: 0.0700\n",
            "Epoch 3, Sample 11394: Loss: 0.3441\n",
            "Epoch 3, Sample 11395: Loss: 0.3260\n",
            "Epoch 3, Sample 11396: Loss: 1.0524\n",
            "Epoch 3, Sample 11397: Loss: 0.0567\n",
            "Epoch 3, Sample 11398: Loss: 0.3777\n",
            "Epoch 3, Sample 11399: Loss: 0.4792\n",
            "Epoch 3, Sample 11400: Loss: 0.1219\n",
            "Epoch 3, Sample 11401: Loss: 0.2044\n",
            "Epoch 3, Sample 11402: Loss: 0.0026\n",
            "Epoch 3, Sample 11403: Loss: 0.0626\n",
            "Epoch 3, Sample 11404: Loss: 0.2759\n",
            "Epoch 3, Sample 11405: Loss: 1.0524\n",
            "Epoch 3, Sample 11406: Loss: 1.0524\n",
            "Epoch 3, Sample 11407: Loss: 1.0155\n",
            "Epoch 3, Sample 11408: Loss: 1.8616\n",
            "Epoch 3, Sample 11409: Loss: 0.0018\n",
            "Epoch 3, Sample 11410: Loss: 0.0018\n",
            "Epoch 3, Sample 11411: Loss: 0.2044\n",
            "Epoch 3, Sample 11412: Loss: 0.8951\n",
            "Epoch 3, Sample 11413: Loss: 0.0101\n",
            "Epoch 3, Sample 11414: Loss: 0.2832\n",
            "Epoch 3, Sample 11415: Loss: 0.0777\n",
            "Epoch 3, Sample 11416: Loss: 1.1005\n",
            "Epoch 3, Sample 11417: Loss: 0.0382\n",
            "Epoch 3, Sample 11418: Loss: 0.0001\n",
            "Epoch 3, Sample 11419: Loss: 0.2044\n",
            "Epoch 3, Sample 11420: Loss: 0.9024\n",
            "Epoch 3, Sample 11421: Loss: 0.7453\n",
            "Epoch 3, Sample 11422: Loss: 0.2759\n",
            "Epoch 3, Sample 11423: Loss: 0.7036\n",
            "Epoch 3, Sample 11424: Loss: 0.0286\n",
            "Epoch 3, Sample 11425: Loss: 0.2034\n",
            "Epoch 3, Sample 11426: Loss: 0.2044\n",
            "Epoch 3, Sample 11427: Loss: 0.5858\n",
            "Epoch 3, Sample 11428: Loss: 1.0524\n",
            "Epoch 3, Sample 11429: Loss: 0.0018\n",
            "Epoch 3, Sample 11430: Loss: 0.5871\n",
            "Epoch 3, Sample 11431: Loss: 0.0354\n",
            "Epoch 3, Sample 11432: Loss: 0.2044\n",
            "Epoch 3, Sample 11433: Loss: 0.7569\n",
            "Epoch 3, Sample 11434: Loss: 0.1463\n",
            "Epoch 3, Sample 11435: Loss: 0.0838\n",
            "Epoch 3, Sample 11436: Loss: 0.6304\n",
            "Epoch 3, Sample 11437: Loss: 0.2468\n",
            "Epoch 3, Sample 11438: Loss: 0.2044\n",
            "Epoch 3, Sample 11439: Loss: 0.0640\n",
            "Epoch 3, Sample 11440: Loss: 0.8625\n",
            "Epoch 3, Sample 11441: Loss: 0.4014\n",
            "Epoch 3, Sample 11442: Loss: 1.2833\n",
            "Epoch 3, Sample 11443: Loss: 0.1580\n",
            "Epoch 3, Sample 11444: Loss: 1.0524\n",
            "Epoch 3, Sample 11445: Loss: 0.9093\n",
            "Epoch 3, Sample 11446: Loss: 0.3441\n",
            "Epoch 3, Sample 11447: Loss: 0.8951\n",
            "Epoch 3, Sample 11448: Loss: 0.5078\n",
            "Epoch 3, Sample 11449: Loss: 1.0524\n",
            "Epoch 3, Sample 11450: Loss: 0.9780\n",
            "Epoch 3, Sample 11451: Loss: 0.1366\n",
            "Epoch 3, Sample 11452: Loss: 0.2340\n",
            "Epoch 3, Sample 11453: Loss: 0.2832\n",
            "Epoch 3, Sample 11454: Loss: 4.1031\n",
            "Epoch 3, Sample 11455: Loss: 0.0018\n",
            "Epoch 3, Sample 11456: Loss: 0.0073\n",
            "Epoch 3, Sample 11457: Loss: 0.1210\n",
            "Epoch 3, Sample 11458: Loss: 1.0155\n",
            "Epoch 3, Sample 11459: Loss: 0.3949\n",
            "Epoch 3, Sample 11460: Loss: 1.6401\n",
            "Epoch 3, Sample 11461: Loss: 0.8484\n",
            "Epoch 3, Sample 11462: Loss: 1.0190\n",
            "Epoch 3, Sample 11463: Loss: 0.9367\n",
            "Epoch 3, Sample 11464: Loss: 0.2032\n",
            "Epoch 3, Sample 11465: Loss: 0.0022\n",
            "Epoch 3, Sample 11466: Loss: 0.1884\n",
            "Epoch 3, Sample 11467: Loss: 0.0318\n",
            "Epoch 3, Sample 11468: Loss: 0.0001\n",
            "Epoch 3, Sample 11469: Loss: 0.2639\n",
            "Epoch 3, Sample 11470: Loss: 0.5858\n",
            "Epoch 3, Sample 11471: Loss: 1.0530\n",
            "Epoch 3, Sample 11472: Loss: 0.5972\n",
            "Epoch 3, Sample 11473: Loss: 0.0142\n",
            "Epoch 3, Sample 11474: Loss: 0.2029\n",
            "Epoch 3, Sample 11475: Loss: 0.0568\n",
            "Epoch 3, Sample 11476: Loss: 0.0630\n",
            "Epoch 3, Sample 11477: Loss: 0.8951\n",
            "Epoch 3, Sample 11478: Loss: 0.7036\n",
            "Epoch 3, Sample 11479: Loss: 0.0108\n",
            "Epoch 3, Sample 11480: Loss: 0.0625\n",
            "Epoch 3, Sample 11481: Loss: 0.3441\n",
            "Epoch 3, Sample 11482: Loss: 0.0063\n",
            "Epoch 3, Sample 11483: Loss: 15.3507\n",
            "Epoch 3, Sample 11484: Loss: 0.2759\n",
            "Epoch 3, Sample 11485: Loss: 0.5972\n",
            "Epoch 3, Sample 11486: Loss: 0.4169\n",
            "Epoch 3, Sample 11487: Loss: 0.0466\n",
            "Epoch 3, Sample 11488: Loss: 0.0026\n",
            "Epoch 3, Sample 11489: Loss: 0.2034\n",
            "Epoch 3, Sample 11490: Loss: 0.0045\n",
            "Epoch 3, Sample 11491: Loss: 0.1822\n",
            "Epoch 3, Sample 11492: Loss: 0.1559\n",
            "Epoch 3, Sample 11493: Loss: 1.3691\n",
            "Epoch 3, Sample 11494: Loss: 0.4930\n",
            "Epoch 3, Sample 11495: Loss: 0.0116\n",
            "Epoch 3, Sample 11496: Loss: 0.7036\n",
            "Epoch 3, Sample 11497: Loss: 0.7036\n",
            "Epoch 3, Sample 11498: Loss: 0.2036\n",
            "Epoch 3, Sample 11499: Loss: 0.4609\n",
            "Epoch 3, Sample 11500: Loss: 0.2699\n",
            "Epoch 3, Sample 11501: Loss: 0.0110\n",
            "Epoch 3, Sample 11502: Loss: 0.3007\n",
            "Epoch 3, Sample 11503: Loss: 1.0524\n",
            "Epoch 3, Sample 11504: Loss: 0.3598\n",
            "Epoch 3, Sample 11505: Loss: 0.7036\n",
            "Epoch 3, Sample 11506: Loss: 0.0026\n",
            "Epoch 3, Sample 11507: Loss: 0.0013\n",
            "Epoch 3, Sample 11508: Loss: 0.3399\n",
            "Epoch 3, Sample 11509: Loss: 0.3441\n",
            "Epoch 3, Sample 11510: Loss: 0.0026\n",
            "Epoch 3, Sample 11511: Loss: 0.9367\n",
            "Epoch 3, Sample 11512: Loss: 0.9193\n",
            "Epoch 3, Sample 11513: Loss: 0.5724\n",
            "Epoch 3, Sample 11514: Loss: 0.0258\n",
            "Epoch 3, Sample 11515: Loss: 0.2044\n",
            "Epoch 3, Sample 11516: Loss: 2.3633\n",
            "Epoch 3, Sample 11517: Loss: 0.1588\n",
            "Epoch 3, Sample 11518: Loss: 0.0212\n",
            "Epoch 3, Sample 11519: Loss: 0.2832\n",
            "Epoch 3, Sample 11520: Loss: 0.2329\n",
            "Epoch 3, Sample 11521: Loss: 0.3399\n",
            "Epoch 3, Sample 11522: Loss: 1.3012\n",
            "Epoch 3, Sample 11523: Loss: 0.0307\n",
            "Epoch 3, Sample 11524: Loss: 0.2112\n",
            "Epoch 3, Sample 11525: Loss: 0.6696\n",
            "Epoch 3, Sample 11526: Loss: 3.3895\n",
            "Epoch 3, Sample 11527: Loss: 0.2679\n",
            "Epoch 3, Sample 11528: Loss: 0.8951\n",
            "Epoch 3, Sample 11529: Loss: 1.0155\n",
            "Epoch 3, Sample 11530: Loss: 1.0524\n",
            "Epoch 3, Sample 11531: Loss: 0.3399\n",
            "Epoch 3, Sample 11532: Loss: 0.3073\n",
            "Epoch 3, Sample 11533: Loss: 0.0084\n",
            "Epoch 3, Sample 11534: Loss: 0.0630\n",
            "Epoch 3, Sample 11535: Loss: 2.5237\n",
            "Epoch 3, Sample 11536: Loss: 0.0840\n",
            "Epoch 3, Sample 11537: Loss: 0.2558\n",
            "Epoch 3, Sample 11538: Loss: 1.0524\n",
            "Epoch 3, Sample 11539: Loss: 1.0444\n",
            "Epoch 3, Sample 11540: Loss: 1.8895\n",
            "Epoch 3, Sample 11541: Loss: 0.0018\n",
            "Epoch 3, Sample 11542: Loss: 0.7036\n",
            "Epoch 3, Sample 11543: Loss: 0.2034\n",
            "Epoch 3, Sample 11544: Loss: 0.0258\n",
            "Epoch 3, Sample 11545: Loss: 1.0403\n",
            "Epoch 3, Sample 11546: Loss: 0.1559\n",
            "Epoch 3, Sample 11547: Loss: 1.0524\n",
            "Epoch 3, Sample 11548: Loss: 1.0524\n",
            "Epoch 3, Sample 11549: Loss: 1.0155\n",
            "Epoch 3, Sample 11550: Loss: 0.6990\n",
            "Epoch 3, Sample 11551: Loss: 0.6604\n",
            "Epoch 3, Sample 11552: Loss: 0.3441\n",
            "Epoch 3, Sample 11553: Loss: 1.4337\n",
            "Epoch 3, Sample 11554: Loss: 0.7036\n",
            "Epoch 3, Sample 11555: Loss: 0.0018\n",
            "Epoch 3, Sample 11556: Loss: 0.5003\n",
            "Epoch 3, Sample 11557: Loss: 1.0155\n",
            "Epoch 3, Sample 11558: Loss: 0.2044\n",
            "Epoch 3, Sample 11559: Loss: 0.1838\n",
            "Epoch 3, Sample 11560: Loss: 0.0626\n",
            "Epoch 3, Sample 11561: Loss: 1.8251\n",
            "Epoch 3, Sample 11562: Loss: 0.5310\n",
            "Epoch 3, Sample 11563: Loss: 0.0142\n",
            "Epoch 3, Sample 11564: Loss: 0.2807\n",
            "Epoch 3, Sample 11565: Loss: 0.2112\n",
            "Epoch 3, Sample 11566: Loss: 0.2989\n",
            "Epoch 3, Sample 11567: Loss: 0.1085\n",
            "Epoch 3, Sample 11568: Loss: 0.2699\n",
            "Epoch 3, Sample 11569: Loss: 1.0524\n",
            "Epoch 3, Sample 11570: Loss: 0.2044\n",
            "Epoch 3, Sample 11571: Loss: 0.5858\n",
            "Epoch 3, Sample 11572: Loss: 0.0466\n",
            "Epoch 3, Sample 11573: Loss: 0.1817\n",
            "Epoch 3, Sample 11574: Loss: 0.1559\n",
            "Epoch 3, Sample 11575: Loss: 0.2032\n",
            "Epoch 3, Sample 11576: Loss: 0.6893\n",
            "Epoch 3, Sample 11577: Loss: 1.0524\n",
            "Epoch 3, Sample 11578: Loss: 0.2044\n",
            "Epoch 3, Sample 11579: Loss: 0.1252\n",
            "Epoch 3, Sample 11580: Loss: 0.7036\n",
            "Epoch 3, Sample 11581: Loss: 0.1082\n",
            "Epoch 3, Sample 11582: Loss: 2.1447\n",
            "Epoch 3, Sample 11583: Loss: 0.1523\n",
            "Epoch 3, Sample 11584: Loss: 1.0155\n",
            "Epoch 3, Sample 11585: Loss: 0.1654\n",
            "Epoch 3, Sample 11586: Loss: 0.5858\n",
            "Epoch 3, Sample 11587: Loss: 0.5858\n",
            "Epoch 3, Sample 11588: Loss: 0.0212\n",
            "Epoch 3, Sample 11589: Loss: 0.0501\n",
            "Epoch 3, Sample 11590: Loss: 0.0630\n",
            "Epoch 3, Sample 11591: Loss: 0.1248\n",
            "Epoch 3, Sample 11592: Loss: 0.2032\n",
            "Epoch 3, Sample 11593: Loss: 0.0018\n",
            "Epoch 3, Sample 11594: Loss: 0.2340\n",
            "Epoch 3, Sample 11595: Loss: 0.2044\n",
            "Epoch 3, Sample 11596: Loss: 0.3399\n",
            "Epoch 3, Sample 11597: Loss: 0.2034\n",
            "Epoch 3, Sample 11598: Loss: 0.0064\n",
            "Epoch 3, Sample 11599: Loss: 0.0561\n",
            "Epoch 3, Sample 11600: Loss: 0.0327\n",
            "Epoch 3, Sample 11601: Loss: 0.2044\n",
            "Epoch 3, Sample 11602: Loss: 0.6757\n",
            "Epoch 3, Sample 11603: Loss: 1.0155\n",
            "Epoch 3, Sample 11604: Loss: 0.0466\n",
            "Epoch 3, Sample 11605: Loss: 1.3122\n",
            "Epoch 3, Sample 11606: Loss: 0.3568\n",
            "Epoch 3, Sample 11607: Loss: 0.2361\n",
            "Epoch 3, Sample 11608: Loss: 0.0026\n",
            "Epoch 3, Sample 11609: Loss: 0.6092\n",
            "Epoch 3, Sample 11610: Loss: 0.3062\n",
            "Epoch 3, Sample 11611: Loss: 0.4996\n",
            "Epoch 3, Sample 11612: Loss: 1.0530\n",
            "Epoch 3, Sample 11613: Loss: 0.3054\n",
            "Epoch 3, Sample 11614: Loss: 1.0155\n",
            "Epoch 3, Sample 11615: Loss: 0.0477\n",
            "Epoch 3, Sample 11616: Loss: 5.7271\n",
            "Epoch 3, Sample 11617: Loss: 0.2044\n",
            "Epoch 3, Sample 11618: Loss: 0.2459\n",
            "Epoch 3, Sample 11619: Loss: 0.7036\n",
            "Epoch 3, Sample 11620: Loss: 0.7702\n",
            "Epoch 3, Sample 11621: Loss: 0.4996\n",
            "Epoch 3, Sample 11622: Loss: 0.2032\n",
            "Epoch 3, Sample 11623: Loss: 0.5000\n",
            "Epoch 3, Sample 11624: Loss: 0.1170\n",
            "Epoch 3, Sample 11625: Loss: 0.0460\n",
            "Epoch 3, Sample 11626: Loss: 0.2363\n",
            "Epoch 3, Sample 11627: Loss: 7.6726\n",
            "Epoch 3, Sample 11628: Loss: 0.2044\n",
            "Epoch 3, Sample 11629: Loss: 0.8959\n",
            "Epoch 3, Sample 11630: Loss: 1.0155\n",
            "Epoch 3, Sample 11631: Loss: 1.0155\n",
            "Epoch 3, Sample 11632: Loss: 0.1250\n",
            "Epoch 3, Sample 11633: Loss: 0.6139\n",
            "Epoch 3, Sample 11634: Loss: 0.0630\n",
            "Epoch 3, Sample 11635: Loss: 0.0034\n",
            "Epoch 3, Sample 11636: Loss: 0.7036\n",
            "Epoch 3, Sample 11637: Loss: 0.2032\n",
            "Epoch 3, Sample 11638: Loss: 0.2339\n",
            "Epoch 3, Sample 11639: Loss: 0.2044\n",
            "Epoch 3, Sample 11640: Loss: 0.3399\n",
            "Epoch 3, Sample 11641: Loss: 0.3399\n",
            "Epoch 3, Sample 11642: Loss: 0.0018\n",
            "Epoch 3, Sample 11643: Loss: 0.0253\n",
            "Epoch 3, Sample 11644: Loss: 0.2494\n",
            "Epoch 3, Sample 11645: Loss: 0.7036\n",
            "Epoch 3, Sample 11646: Loss: 0.1988\n",
            "Epoch 3, Sample 11647: Loss: 0.0026\n",
            "Epoch 3, Sample 11648: Loss: 1.0207\n",
            "Epoch 3, Sample 11649: Loss: 0.0018\n",
            "Epoch 3, Sample 11650: Loss: 0.5858\n",
            "Epoch 3, Sample 11651: Loss: 0.5858\n",
            "Epoch 3, Sample 11652: Loss: 0.0026\n",
            "Epoch 3, Sample 11653: Loss: 0.7036\n",
            "Epoch 3, Sample 11654: Loss: 0.1703\n",
            "Epoch 3, Sample 11655: Loss: 0.0018\n",
            "Epoch 3, Sample 11656: Loss: 0.3399\n",
            "Epoch 3, Sample 11657: Loss: 0.4032\n",
            "Epoch 3, Sample 11658: Loss: 0.0026\n",
            "Epoch 3, Sample 11659: Loss: 0.0150\n",
            "Epoch 3, Sample 11660: Loss: 0.2639\n",
            "Epoch 3, Sample 11661: Loss: 0.2280\n",
            "Epoch 3, Sample 11662: Loss: 0.5196\n",
            "Epoch 3, Sample 11663: Loss: 0.3441\n",
            "Epoch 3, Sample 11664: Loss: 1.0155\n",
            "Epoch 3, Sample 11665: Loss: 0.1170\n",
            "Epoch 3, Sample 11666: Loss: 0.2036\n",
            "Epoch 3, Sample 11667: Loss: 0.5078\n",
            "Epoch 3, Sample 11668: Loss: 0.4032\n",
            "Epoch 3, Sample 11669: Loss: 0.2832\n",
            "Epoch 3, Sample 11670: Loss: 0.2044\n",
            "Epoch 3, Sample 11671: Loss: 0.7662\n",
            "Epoch 3, Sample 11672: Loss: 0.2709\n",
            "Epoch 3, Sample 11673: Loss: 0.0001\n",
            "Epoch 3, Sample 11674: Loss: 0.9383\n",
            "Epoch 3, Sample 11675: Loss: 0.5078\n",
            "Epoch 3, Sample 11676: Loss: 0.0460\n",
            "Epoch 3, Sample 11677: Loss: 2.6384\n",
            "Epoch 3, Sample 11678: Loss: 0.1517\n",
            "Epoch 3, Sample 11679: Loss: 0.2044\n",
            "Epoch 3, Sample 11680: Loss: 0.0212\n",
            "Epoch 3, Sample 11681: Loss: 1.0524\n",
            "Epoch 3, Sample 11682: Loss: 0.5078\n",
            "Epoch 3, Sample 11683: Loss: 0.4799\n",
            "Epoch 3, Sample 11684: Loss: 1.2926\n",
            "Epoch 3, Sample 11685: Loss: 0.1170\n",
            "Epoch 3, Sample 11686: Loss: 0.4139\n",
            "Epoch 3, Sample 11687: Loss: 0.0018\n",
            "Epoch 3, Sample 11688: Loss: 0.2219\n",
            "Epoch 3, Sample 11689: Loss: 0.1756\n",
            "Epoch 3, Sample 11690: Loss: 0.0006\n",
            "Epoch 3, Sample 11691: Loss: 0.2044\n",
            "Epoch 3, Sample 11692: Loss: 0.0026\n",
            "Epoch 3, Sample 11693: Loss: 0.0498\n",
            "Epoch 3, Sample 11694: Loss: 0.5000\n",
            "Epoch 3, Sample 11695: Loss: 0.3399\n",
            "Epoch 3, Sample 11696: Loss: 1.6808\n",
            "Epoch 3, Sample 11697: Loss: 0.1791\n",
            "Epoch 3, Sample 11698: Loss: 1.5570\n",
            "Epoch 3, Sample 11699: Loss: 0.0026\n",
            "Epoch 3, Sample 11700: Loss: 0.2036\n",
            "Epoch 3, Sample 11701: Loss: 0.0615\n",
            "Epoch 3, Sample 11702: Loss: 0.0045\n",
            "Epoch 3, Sample 11703: Loss: 0.0554\n",
            "Epoch 3, Sample 11704: Loss: 0.1250\n",
            "Epoch 3, Sample 11705: Loss: 0.3469\n",
            "Epoch 3, Sample 11706: Loss: 4.7751\n",
            "Epoch 3, Sample 11707: Loss: 0.0133\n",
            "Epoch 3, Sample 11708: Loss: 2.9652\n",
            "Epoch 3, Sample 11709: Loss: 0.3788\n",
            "Epoch 3, Sample 11710: Loss: 0.0685\n",
            "Epoch 3, Sample 11711: Loss: 0.0441\n",
            "Epoch 3, Sample 11712: Loss: 0.0506\n",
            "Epoch 3, Sample 11713: Loss: 0.2759\n",
            "Epoch 3, Sample 11714: Loss: 0.2759\n",
            "Epoch 3, Sample 11715: Loss: 0.5858\n",
            "Epoch 3, Sample 11716: Loss: 1.0524\n",
            "Epoch 3, Sample 11717: Loss: 0.0630\n",
            "Epoch 3, Sample 11718: Loss: 0.5000\n",
            "Epoch 3, Sample 11719: Loss: 0.3450\n",
            "Epoch 3, Sample 11720: Loss: 1.0155\n",
            "Epoch 3, Sample 11721: Loss: 0.1250\n",
            "Epoch 3, Sample 11722: Loss: 0.2112\n",
            "Epoch 3, Sample 11723: Loss: 1.0070\n",
            "Epoch 3, Sample 11724: Loss: 0.4048\n",
            "Epoch 3, Sample 11725: Loss: 0.2112\n",
            "Epoch 3, Sample 11726: Loss: 0.2044\n",
            "Epoch 3, Sample 11727: Loss: 0.2759\n",
            "Epoch 3, Sample 11728: Loss: 0.4841\n",
            "Epoch 3, Sample 11729: Loss: 0.1559\n",
            "Epoch 3, Sample 11730: Loss: 0.3007\n",
            "Epoch 3, Sample 11731: Loss: 0.0018\n",
            "Epoch 3, Sample 11732: Loss: 0.0507\n",
            "Epoch 3, Sample 11733: Loss: 0.0853\n",
            "Epoch 3, Sample 11734: Loss: 0.3399\n",
            "Epoch 3, Sample 11735: Loss: 0.5300\n",
            "Epoch 3, Sample 11736: Loss: 2.0039\n",
            "Epoch 3, Sample 11737: Loss: 0.0026\n",
            "Epoch 3, Sample 11738: Loss: 0.0013\n",
            "Epoch 3, Sample 11739: Loss: 0.7453\n",
            "Epoch 3, Sample 11740: Loss: 0.0020\n",
            "Epoch 3, Sample 11741: Loss: 0.0895\n",
            "Epoch 3, Sample 11742: Loss: 0.4258\n",
            "Epoch 3, Sample 11743: Loss: 0.9367\n",
            "Epoch 3, Sample 11744: Loss: 0.1170\n",
            "Epoch 3, Sample 11745: Loss: 0.3441\n",
            "Epoch 3, Sample 11746: Loss: 1.7998\n",
            "Epoch 3, Sample 11747: Loss: 0.1913\n",
            "Epoch 3, Sample 11748: Loss: 0.0072\n",
            "Epoch 3, Sample 11749: Loss: 0.0630\n",
            "Epoch 3, Sample 11750: Loss: 0.1250\n",
            "Epoch 3, Sample 11751: Loss: 0.1326\n",
            "Epoch 3, Sample 11752: Loss: 0.0945\n",
            "Epoch 3, Sample 11753: Loss: 0.2832\n",
            "Epoch 3, Sample 11754: Loss: 0.0972\n",
            "Epoch 3, Sample 11755: Loss: 0.0084\n",
            "Epoch 3, Sample 11756: Loss: 0.9371\n",
            "Epoch 3, Sample 11757: Loss: 0.2036\n",
            "Epoch 3, Sample 11758: Loss: 0.4644\n",
            "Epoch 3, Sample 11759: Loss: 0.2032\n",
            "Epoch 3, Sample 11760: Loss: 0.6990\n",
            "Epoch 3, Sample 11761: Loss: 0.0368\n",
            "Epoch 3, Sample 11762: Loss: 0.0775\n",
            "Epoch 3, Sample 11763: Loss: 0.1250\n",
            "Epoch 3, Sample 11764: Loss: 0.0306\n",
            "Epoch 3, Sample 11765: Loss: 1.1433\n",
            "Epoch 3, Sample 11766: Loss: 0.0018\n",
            "Epoch 3, Sample 11767: Loss: 0.0744\n",
            "Epoch 3, Sample 11768: Loss: 0.1523\n",
            "Epoch 3, Sample 11769: Loss: 1.0155\n",
            "Epoch 3, Sample 11770: Loss: 0.5989\n",
            "Epoch 3, Sample 11771: Loss: 0.3399\n",
            "Epoch 3, Sample 11772: Loss: 1.0155\n",
            "Epoch 3, Sample 11773: Loss: 0.0257\n",
            "Epoch 3, Sample 11774: Loss: 0.1250\n",
            "Epoch 3, Sample 11775: Loss: 0.0007\n",
            "Epoch 3, Sample 11776: Loss: 1.0524\n",
            "Epoch 3, Sample 11777: Loss: 0.7638\n",
            "Epoch 3, Sample 11778: Loss: 0.2044\n",
            "Epoch 3, Sample 11779: Loss: 0.2759\n",
            "Epoch 3, Sample 11780: Loss: 0.0626\n",
            "Epoch 3, Sample 11781: Loss: 0.5000\n",
            "Epoch 3, Sample 11782: Loss: 1.0227\n",
            "Epoch 3, Sample 11783: Loss: 0.2032\n",
            "Epoch 3, Sample 11784: Loss: 0.6304\n",
            "Epoch 3, Sample 11785: Loss: 0.4841\n",
            "Epoch 3, Sample 11786: Loss: 1.0155\n",
            "Epoch 3, Sample 11787: Loss: 0.2941\n",
            "Epoch 3, Sample 11788: Loss: 0.9988\n",
            "Epoch 3, Sample 11789: Loss: 0.3949\n",
            "Epoch 3, Sample 11790: Loss: 0.0039\n",
            "Epoch 3, Sample 11791: Loss: 0.0026\n",
            "Epoch 3, Sample 11792: Loss: 0.0630\n",
            "Epoch 3, Sample 11793: Loss: 1.0155\n",
            "Epoch 3, Sample 11794: Loss: 0.0018\n",
            "Epoch 3, Sample 11795: Loss: 0.1340\n",
            "Epoch 3, Sample 11796: Loss: 0.2044\n",
            "Epoch 3, Sample 11797: Loss: 0.7453\n",
            "Epoch 3, Sample 11798: Loss: 3.8197\n",
            "Epoch 3, Sample 11799: Loss: 0.2832\n",
            "Epoch 3, Sample 11800: Loss: 0.2034\n",
            "Epoch 3, Sample 11801: Loss: 0.0630\n",
            "Epoch 3, Sample 11802: Loss: 0.5899\n",
            "Epoch 3, Sample 11803: Loss: 1.8716\n",
            "Epoch 3, Sample 11804: Loss: 0.5003\n",
            "Epoch 3, Sample 11805: Loss: 0.1753\n",
            "Epoch 3, Sample 11806: Loss: 0.0212\n",
            "Epoch 3, Sample 11807: Loss: 0.0070\n",
            "Epoch 3, Sample 11808: Loss: 0.0168\n",
            "Epoch 3, Sample 11809: Loss: 2.9998\n",
            "Epoch 3, Sample 11810: Loss: 0.0026\n",
            "Epoch 3, Sample 11811: Loss: 0.0026\n",
            "Epoch 3, Sample 11812: Loss: 0.2044\n",
            "Epoch 3, Sample 11813: Loss: 0.2269\n",
            "Epoch 3, Sample 11814: Loss: 0.2941\n",
            "Epoch 3, Sample 11815: Loss: 0.1546\n",
            "Epoch 3, Sample 11816: Loss: 0.1559\n",
            "Epoch 3, Sample 11817: Loss: 0.5858\n",
            "Epoch 3, Sample 11818: Loss: 0.3399\n",
            "Epoch 3, Sample 11819: Loss: 0.4032\n",
            "Epoch 3, Sample 11820: Loss: 0.2036\n",
            "Epoch 3, Sample 11821: Loss: 0.2639\n",
            "Epoch 3, Sample 11822: Loss: 1.0530\n",
            "Epoch 3, Sample 11823: Loss: 0.0091\n",
            "Epoch 3, Sample 11824: Loss: 0.2639\n",
            "Epoch 3, Sample 11825: Loss: 0.7036\n",
            "Epoch 3, Sample 11826: Loss: 0.3154\n",
            "Epoch 3, Sample 11827: Loss: 0.3674\n",
            "Epoch 3, Sample 11828: Loss: 0.2572\n",
            "Epoch 3, Sample 11829: Loss: 1.0530\n",
            "Epoch 3, Sample 11830: Loss: 0.2044\n",
            "Epoch 3, Sample 11831: Loss: 0.0240\n",
            "Epoch 3, Sample 11832: Loss: 1.2952\n",
            "Epoch 3, Sample 11833: Loss: 0.2044\n",
            "Epoch 3, Sample 11834: Loss: 0.2044\n",
            "Epoch 3, Sample 11835: Loss: 0.3399\n",
            "Epoch 3, Sample 11836: Loss: 0.0875\n",
            "Epoch 3, Sample 11837: Loss: 0.3149\n",
            "Epoch 3, Sample 11838: Loss: 0.1207\n",
            "Epoch 3, Sample 11839: Loss: 0.3441\n",
            "Epoch 3, Sample 11840: Loss: 0.4156\n",
            "Epoch 3, Sample 11841: Loss: 4.5492\n",
            "Epoch 3, Sample 11842: Loss: 0.7036\n",
            "Epoch 3, Sample 11843: Loss: 0.7036\n",
            "Epoch 3, Sample 11844: Loss: 0.0738\n",
            "Epoch 3, Sample 11845: Loss: 0.3584\n",
            "Epoch 3, Sample 11846: Loss: 0.3949\n",
            "Epoch 3, Sample 11847: Loss: 0.0261\n",
            "Epoch 3, Sample 11848: Loss: 0.2759\n",
            "Epoch 3, Sample 11849: Loss: 0.2759\n",
            "Epoch 3, Sample 11850: Loss: 0.2759\n",
            "Epoch 3, Sample 11851: Loss: 0.0510\n",
            "Epoch 3, Sample 11852: Loss: 0.3696\n",
            "Epoch 3, Sample 11853: Loss: 4.0074\n",
            "Epoch 3, Sample 11854: Loss: 0.8951\n",
            "Epoch 3, Sample 11855: Loss: 0.2375\n",
            "Epoch 3, Sample 11856: Loss: 0.0938\n",
            "Epoch 3, Sample 11857: Loss: 0.0018\n",
            "Epoch 3, Sample 11858: Loss: 0.0455\n",
            "Epoch 3, Sample 11859: Loss: 0.1627\n",
            "Epoch 3, Sample 11860: Loss: 0.0026\n",
            "Epoch 3, Sample 11861: Loss: 0.5375\n",
            "Epoch 3, Sample 11862: Loss: 1.0511\n",
            "Epoch 3, Sample 11863: Loss: 0.9031\n",
            "Epoch 3, Sample 11864: Loss: 0.0030\n",
            "Epoch 3, Sample 11865: Loss: 4.3324\n",
            "Epoch 3, Sample 11866: Loss: 0.7036\n",
            "Epoch 3, Sample 11867: Loss: 0.0432\n",
            "Epoch 3, Sample 11868: Loss: 0.3092\n",
            "Epoch 3, Sample 11869: Loss: 0.0028\n",
            "Epoch 3, Sample 11870: Loss: 0.0026\n",
            "Epoch 3, Sample 11871: Loss: 0.4588\n",
            "Epoch 3, Sample 11872: Loss: 0.0938\n",
            "Epoch 3, Sample 11873: Loss: 0.0466\n",
            "Epoch 3, Sample 11874: Loss: 0.4866\n",
            "Epoch 3, Sample 11875: Loss: 0.0205\n",
            "Epoch 3, Sample 11876: Loss: 1.0227\n",
            "Epoch 3, Sample 11877: Loss: 0.3399\n",
            "Epoch 3, Sample 11878: Loss: 1.0688\n",
            "Epoch 3, Sample 11879: Loss: 0.5972\n",
            "Epoch 3, Sample 11880: Loss: 0.0030\n",
            "Epoch 3, Sample 11881: Loss: 11.5326\n",
            "Epoch 3, Sample 11882: Loss: 0.5858\n",
            "Epoch 3, Sample 11883: Loss: 0.0505\n",
            "Epoch 3, Sample 11884: Loss: 0.0013\n",
            "Epoch 3, Sample 11885: Loss: 0.7036\n",
            "Epoch 3, Sample 11886: Loss: 1.0155\n",
            "Epoch 3, Sample 11887: Loss: 0.2034\n",
            "Epoch 3, Sample 11888: Loss: 0.5141\n",
            "Epoch 3, Sample 11889: Loss: 0.7036\n",
            "Epoch 3, Sample 11890: Loss: 0.2686\n",
            "Epoch 3, Sample 11891: Loss: 0.6990\n",
            "Epoch 3, Sample 11892: Loss: 0.1170\n",
            "Epoch 3, Sample 11893: Loss: 0.0026\n",
            "Epoch 3, Sample 11894: Loss: 0.2032\n",
            "Epoch 3, Sample 11895: Loss: 0.5858\n",
            "Epoch 3, Sample 11896: Loss: 0.0956\n",
            "Epoch 3, Sample 11897: Loss: 0.2639\n",
            "Epoch 3, Sample 11898: Loss: 0.5986\n",
            "Epoch 3, Sample 11899: Loss: 0.3399\n",
            "Epoch 3, Sample 11900: Loss: 8.7194\n",
            "Epoch 3, Sample 11901: Loss: 0.5003\n",
            "Epoch 3, Sample 11902: Loss: 0.3092\n",
            "Epoch 3, Sample 11903: Loss: 0.1250\n",
            "Epoch 3, Sample 11904: Loss: 0.0120\n",
            "Epoch 3, Sample 11905: Loss: 0.2832\n",
            "Epoch 3, Sample 11906: Loss: 0.3441\n",
            "Epoch 3, Sample 11907: Loss: 0.0205\n",
            "Epoch 3, Sample 11908: Loss: 1.5374\n",
            "Epoch 3, Sample 11909: Loss: 0.0026\n",
            "Epoch 3, Sample 11910: Loss: 0.3399\n",
            "Epoch 3, Sample 11911: Loss: 0.8985\n",
            "Epoch 3, Sample 11912: Loss: 0.1399\n",
            "Epoch 3, Sample 11913: Loss: 0.0625\n",
            "Epoch 3, Sample 11914: Loss: 0.2639\n",
            "Epoch 3, Sample 11915: Loss: 0.2034\n",
            "Epoch 3, Sample 11916: Loss: 0.0223\n",
            "Epoch 3, Sample 11917: Loss: 0.3916\n",
            "Epoch 3, Sample 11918: Loss: 0.0026\n",
            "Epoch 3, Sample 11919: Loss: 0.0630\n",
            "Epoch 3, Sample 11920: Loss: 0.0005\n",
            "Epoch 3, Sample 11921: Loss: 0.6990\n",
            "Epoch 3, Sample 11922: Loss: 0.3441\n",
            "Epoch 3, Sample 11923: Loss: 0.3399\n",
            "Epoch 3, Sample 11924: Loss: 0.5000\n",
            "Epoch 3, Sample 11925: Loss: 0.0630\n",
            "Epoch 3, Sample 11926: Loss: 0.6929\n",
            "Epoch 3, Sample 11927: Loss: 0.2340\n",
            "Epoch 3, Sample 11928: Loss: 0.3624\n",
            "Epoch 3, Sample 11929: Loss: 0.1293\n",
            "Epoch 3, Sample 11930: Loss: 0.4367\n",
            "Epoch 3, Sample 11931: Loss: 0.0060\n",
            "Epoch 3, Sample 11932: Loss: 0.1785\n",
            "Epoch 3, Sample 11933: Loss: 0.0554\n",
            "Epoch 3, Sample 11934: Loss: 0.9651\n",
            "Epoch 3, Sample 11935: Loss: 0.4930\n",
            "Epoch 3, Sample 11936: Loss: 0.5778\n",
            "Epoch 3, Sample 11937: Loss: 0.0131\n",
            "Epoch 3, Sample 11938: Loss: 0.1372\n",
            "Epoch 3, Sample 11939: Loss: 0.2044\n",
            "Epoch 3, Sample 11940: Loss: 1.0524\n",
            "Epoch 3, Sample 11941: Loss: 0.2044\n",
            "Epoch 3, Sample 11942: Loss: 0.0001\n",
            "Epoch 3, Sample 11943: Loss: 0.7702\n",
            "Epoch 3, Sample 11944: Loss: 0.0025\n",
            "Epoch 3, Sample 11945: Loss: 0.5858\n",
            "Epoch 3, Sample 11946: Loss: 1.0524\n",
            "Epoch 3, Sample 11947: Loss: 0.1170\n",
            "Epoch 3, Sample 11948: Loss: 0.0212\n",
            "Epoch 3, Sample 11949: Loss: 0.2036\n",
            "Epoch 3, Sample 11950: Loss: 2.8983\n",
            "Epoch 3, Sample 11951: Loss: 0.8217\n",
            "Epoch 3, Sample 11952: Loss: 0.5000\n",
            "Epoch 3, Sample 11953: Loss: 0.0838\n",
            "Epoch 3, Sample 11954: Loss: 0.0122\n",
            "Epoch 3, Sample 11955: Loss: 0.1337\n",
            "Epoch 3, Sample 11956: Loss: 0.4799\n",
            "Epoch 3, Sample 11957: Loss: 0.2685\n",
            "Epoch 3, Sample 11958: Loss: 0.0293\n",
            "Epoch 3, Sample 11959: Loss: 2.9757\n",
            "Epoch 3, Sample 11960: Loss: 0.3007\n",
            "Epoch 3, Sample 11961: Loss: 0.2759\n",
            "Epoch 3, Sample 11962: Loss: 0.0951\n",
            "Epoch 3, Sample 11963: Loss: 0.0083\n",
            "Epoch 3, Sample 11964: Loss: 0.7702\n",
            "Epoch 3, Sample 11965: Loss: 0.0018\n",
            "Epoch 3, Sample 11966: Loss: 0.2034\n",
            "Epoch 3, Sample 11967: Loss: 0.0640\n",
            "Epoch 3, Sample 11968: Loss: 4.0893\n",
            "Epoch 3, Sample 11969: Loss: 0.6990\n",
            "Epoch 3, Sample 11970: Loss: 0.4841\n",
            "Epoch 3, Sample 11971: Loss: 0.3399\n",
            "Epoch 3, Sample 11972: Loss: 0.0062\n",
            "Epoch 3, Sample 11973: Loss: 0.4799\n",
            "Epoch 3, Sample 11974: Loss: 0.4611\n",
            "Epoch 3, Sample 11975: Loss: 1.0524\n",
            "Epoch 3, Sample 11976: Loss: 0.5871\n",
            "Epoch 3, Sample 11977: Loss: 1.0524\n",
            "Epoch 3, Sample 11978: Loss: 0.2044\n",
            "Epoch 3, Sample 11979: Loss: 0.2113\n",
            "Epoch 3, Sample 11980: Loss: 0.6867\n",
            "Epoch 3, Sample 11981: Loss: 0.0000\n",
            "Epoch 3, Sample 11982: Loss: 0.5000\n",
            "Epoch 3, Sample 11983: Loss: 0.0018\n",
            "Epoch 3, Sample 11984: Loss: 0.1508\n",
            "Epoch 3, Sample 11985: Loss: 0.3506\n",
            "Epoch 3, Sample 11986: Loss: 0.5776\n",
            "Epoch 3, Sample 11987: Loss: 0.9194\n",
            "Epoch 3, Sample 11988: Loss: 0.0347\n",
            "Epoch 3, Sample 11989: Loss: 0.2098\n",
            "Epoch 3, Sample 11990: Loss: 0.2034\n",
            "Epoch 3, Sample 11991: Loss: 0.2034\n",
            "Epoch 3, Sample 11992: Loss: 0.5003\n",
            "Epoch 3, Sample 11993: Loss: 0.3598\n",
            "Epoch 3, Sample 11994: Loss: 0.0000\n",
            "Epoch 3, Sample 11995: Loss: 1.0524\n",
            "Epoch 3, Sample 11996: Loss: 0.1091\n",
            "Epoch 3, Sample 11997: Loss: 0.2036\n",
            "Epoch 3, Sample 11998: Loss: 0.1250\n",
            "Epoch 3, Sample 11999: Loss: 8.7405\n",
            "Epoch 3, Sample 12000: Loss: 0.0018\n",
            "Epoch 3, Sample 12001: Loss: 1.0216\n",
            "Epoch 3, Sample 12002: Loss: 0.0306\n",
            "Epoch 3, Sample 12003: Loss: 0.0001\n",
            "Epoch 3, Sample 12004: Loss: 0.0687\n",
            "Epoch 3, Sample 12005: Loss: 0.7344\n",
            "Epoch 3, Sample 12006: Loss: 0.1890\n",
            "Epoch 3, Sample 12007: Loss: 1.5542\n",
            "Epoch 3, Sample 12008: Loss: 0.0001\n",
            "Epoch 3, Sample 12009: Loss: 0.2044\n",
            "Epoch 3, Sample 12010: Loss: 0.0476\n",
            "Epoch 3, Sample 12011: Loss: 0.4607\n",
            "Epoch 3, Sample 12012: Loss: 0.0000\n",
            "Epoch 3, Sample 12013: Loss: 0.4930\n",
            "Epoch 3, Sample 12014: Loss: 0.1114\n",
            "Epoch 3, Sample 12015: Loss: 0.3598\n",
            "Epoch 3, Sample 12016: Loss: 0.3886\n",
            "Epoch 3, Sample 12017: Loss: 0.9082\n",
            "Epoch 3, Sample 12018: Loss: 0.0626\n",
            "Epoch 3, Sample 12019: Loss: 0.2044\n",
            "Epoch 3, Sample 12020: Loss: 0.5217\n",
            "Epoch 3, Sample 12021: Loss: 0.3949\n",
            "Epoch 3, Sample 12022: Loss: 0.3949\n",
            "Epoch 3, Sample 12023: Loss: 0.1250\n",
            "Epoch 3, Sample 12024: Loss: 1.0524\n",
            "Epoch 3, Sample 12025: Loss: 1.0524\n",
            "Epoch 3, Sample 12026: Loss: 0.2759\n",
            "Epoch 3, Sample 12027: Loss: 0.0060\n",
            "Epoch 3, Sample 12028: Loss: 0.5019\n",
            "Epoch 3, Sample 12029: Loss: 0.2219\n",
            "Epoch 3, Sample 12030: Loss: 0.5029\n",
            "Epoch 3, Sample 12031: Loss: 0.0006\n",
            "Epoch 3, Sample 12032: Loss: 0.3441\n",
            "Epoch 3, Sample 12033: Loss: 7.0008\n",
            "Epoch 3, Sample 12034: Loss: 0.3441\n",
            "Epoch 3, Sample 12035: Loss: 0.2459\n",
            "Epoch 3, Sample 12036: Loss: 0.1039\n",
            "Epoch 3, Sample 12037: Loss: 0.0018\n",
            "Epoch 3, Sample 12038: Loss: 0.3761\n",
            "Epoch 3, Sample 12039: Loss: 0.4663\n",
            "Epoch 3, Sample 12040: Loss: 0.0193\n",
            "Epoch 3, Sample 12041: Loss: 0.3367\n",
            "Epoch 3, Sample 12042: Loss: 0.0558\n",
            "Epoch 3, Sample 12043: Loss: 0.0247\n",
            "Epoch 3, Sample 12044: Loss: 0.7036\n",
            "Epoch 3, Sample 12045: Loss: 0.0026\n",
            "Epoch 3, Sample 12046: Loss: 0.2034\n",
            "Epoch 3, Sample 12047: Loss: 0.0009\n",
            "Epoch 3, Sample 12048: Loss: 0.6139\n",
            "Epoch 3, Sample 12049: Loss: 0.1559\n",
            "Epoch 3, Sample 12050: Loss: 0.5003\n",
            "Epoch 3, Sample 12051: Loss: 0.0231\n",
            "Epoch 3, Sample 12052: Loss: 0.0026\n",
            "Epoch 3, Sample 12053: Loss: 0.3584\n",
            "Epoch 3, Sample 12054: Loss: 0.1250\n",
            "Epoch 3, Sample 12055: Loss: 0.0625\n",
            "Epoch 3, Sample 12056: Loss: 0.5019\n",
            "Epoch 3, Sample 12057: Loss: 0.3342\n",
            "Epoch 3, Sample 12058: Loss: 0.6502\n",
            "Epoch 3, Sample 12059: Loss: 0.2034\n",
            "Epoch 3, Sample 12060: Loss: 0.6990\n",
            "Epoch 3, Sample 12061: Loss: 0.0082\n",
            "Epoch 3, Sample 12062: Loss: 0.0018\n",
            "Epoch 3, Sample 12063: Loss: 0.3441\n",
            "Epoch 3, Sample 12064: Loss: 0.3399\n",
            "Epoch 3, Sample 12065: Loss: 0.0201\n",
            "Epoch 3, Sample 12066: Loss: 0.0505\n",
            "Epoch 3, Sample 12067: Loss: 0.0002\n",
            "Epoch 3, Sample 12068: Loss: 0.0025\n",
            "Epoch 3, Sample 12069: Loss: 0.2032\n",
            "Epoch 3, Sample 12070: Loss: 0.7669\n",
            "Epoch 3, Sample 12071: Loss: 0.1531\n",
            "Epoch 3, Sample 12072: Loss: 5.7732\n",
            "Epoch 3, Sample 12073: Loss: 1.0155\n",
            "Epoch 3, Sample 12074: Loss: 0.7036\n",
            "Epoch 3, Sample 12075: Loss: 0.1170\n",
            "Epoch 3, Sample 12076: Loss: 0.2377\n",
            "Epoch 3, Sample 12077: Loss: 0.2044\n",
            "Epoch 3, Sample 12078: Loss: 0.0026\n",
            "Epoch 3, Sample 12079: Loss: 1.8745\n",
            "Epoch 3, Sample 12080: Loss: 0.7453\n",
            "Epoch 3, Sample 12081: Loss: 0.6867\n",
            "Epoch 3, Sample 12082: Loss: 0.7036\n",
            "Epoch 3, Sample 12083: Loss: 0.6304\n",
            "Epoch 3, Sample 12084: Loss: 0.1399\n",
            "Epoch 3, Sample 12085: Loss: 0.2759\n",
            "Epoch 3, Sample 12086: Loss: 0.8951\n",
            "Epoch 3, Sample 12087: Loss: 0.7036\n",
            "Epoch 3, Sample 12088: Loss: 1.0524\n",
            "Epoch 3, Sample 12089: Loss: 0.2044\n",
            "Epoch 3, Sample 12090: Loss: 3.3150\n",
            "Epoch 3, Sample 12091: Loss: 0.2639\n",
            "Epoch 3, Sample 12092: Loss: 0.2044\n",
            "Epoch 3, Sample 12093: Loss: 0.5314\n",
            "Epoch 3, Sample 12094: Loss: 0.0018\n",
            "Epoch 3, Sample 12095: Loss: 0.7036\n",
            "Epoch 3, Sample 12096: Loss: 0.6990\n",
            "Epoch 3, Sample 12097: Loss: 0.7036\n",
            "Epoch 3, Sample 12098: Loss: 0.0108\n",
            "Epoch 3, Sample 12099: Loss: 0.0008\n",
            "Epoch 3, Sample 12100: Loss: 0.2408\n",
            "Epoch 3, Sample 12101: Loss: 0.2036\n",
            "Epoch 3, Sample 12102: Loss: 0.2044\n",
            "Epoch 3, Sample 12103: Loss: 0.3441\n",
            "Epoch 3, Sample 12104: Loss: 0.2032\n",
            "Epoch 3, Sample 12105: Loss: 3.1859\n",
            "Epoch 3, Sample 12106: Loss: 1.0530\n",
            "Epoch 3, Sample 12107: Loss: 0.0063\n",
            "Epoch 3, Sample 12108: Loss: 0.1397\n",
            "Epoch 3, Sample 12109: Loss: 0.0116\n",
            "Epoch 3, Sample 12110: Loss: 0.0630\n",
            "Epoch 3, Sample 12111: Loss: 0.1559\n",
            "Epoch 3, Sample 12112: Loss: 0.2375\n",
            "Epoch 3, Sample 12113: Loss: 1.0524\n",
            "Epoch 3, Sample 12114: Loss: 0.7036\n",
            "Epoch 3, Sample 12115: Loss: 2.0233\n",
            "Epoch 3, Sample 12116: Loss: 2.5622\n",
            "Epoch 3, Sample 12117: Loss: 0.5972\n",
            "Epoch 3, Sample 12118: Loss: 7.6084\n",
            "Epoch 3, Sample 12119: Loss: 0.8250\n",
            "Epoch 3, Sample 12120: Loss: 0.3399\n",
            "Epoch 3, Sample 12121: Loss: 0.7005\n",
            "Epoch 3, Sample 12122: Loss: 0.2832\n",
            "Epoch 3, Sample 12123: Loss: 0.6990\n",
            "Epoch 3, Sample 12124: Loss: 0.1056\n",
            "Epoch 3, Sample 12125: Loss: 0.0145\n",
            "Epoch 3, Sample 12126: Loss: 0.0018\n",
            "Epoch 3, Sample 12127: Loss: 0.0777\n",
            "Epoch 3, Sample 12128: Loss: 0.2044\n",
            "Epoch 3, Sample 12129: Loss: 1.0530\n",
            "Epoch 3, Sample 12130: Loss: 0.0630\n",
            "Epoch 3, Sample 12131: Loss: 0.8951\n",
            "Epoch 3, Sample 12132: Loss: 0.3095\n",
            "Epoch 3, Sample 12133: Loss: 1.6630\n",
            "Epoch 3, Sample 12134: Loss: 0.2034\n",
            "Epoch 3, Sample 12135: Loss: 0.2044\n",
            "Epoch 3, Sample 12136: Loss: 0.0207\n",
            "Epoch 3, Sample 12137: Loss: 0.2759\n",
            "Epoch 3, Sample 12138: Loss: 0.1822\n",
            "Epoch 3, Sample 12139: Loss: 0.2759\n",
            "Epoch 3, Sample 12140: Loss: 0.2044\n",
            "Epoch 3, Sample 12141: Loss: 0.0144\n",
            "Epoch 3, Sample 12142: Loss: 0.5166\n",
            "Epoch 3, Sample 12143: Loss: 1.0155\n",
            "Epoch 3, Sample 12144: Loss: 0.2759\n",
            "Epoch 3, Sample 12145: Loss: 0.3402\n",
            "Epoch 3, Sample 12146: Loss: 0.5062\n",
            "Epoch 3, Sample 12147: Loss: 0.1170\n",
            "Epoch 3, Sample 12148: Loss: 0.2943\n",
            "Epoch 3, Sample 12149: Loss: 0.0626\n",
            "Epoch 3, Sample 12150: Loss: 0.1559\n",
            "Epoch 3, Sample 12151: Loss: 0.0026\n",
            "Epoch 3, Sample 12152: Loss: 0.0947\n",
            "Epoch 3, Sample 12153: Loss: 0.1250\n",
            "Epoch 3, Sample 12154: Loss: 0.4832\n",
            "Epoch 3, Sample 12155: Loss: 0.2044\n",
            "Epoch 3, Sample 12156: Loss: 0.1170\n",
            "Epoch 3, Sample 12157: Loss: 1.0530\n",
            "Epoch 3, Sample 12158: Loss: 0.0819\n",
            "Epoch 3, Sample 12159: Loss: 0.6754\n",
            "Epoch 3, Sample 12160: Loss: 0.2044\n",
            "Epoch 3, Sample 12161: Loss: 0.3399\n",
            "Epoch 3, Sample 12162: Loss: 0.0206\n",
            "Epoch 3, Sample 12163: Loss: 0.0018\n",
            "Epoch 3, Sample 12164: Loss: 0.3399\n",
            "Epoch 3, Sample 12165: Loss: 0.0477\n",
            "Epoch 3, Sample 12166: Loss: 0.4033\n",
            "Epoch 3, Sample 12167: Loss: 0.8324\n",
            "Epoch 3, Sample 12168: Loss: 0.9107\n",
            "Epoch 3, Sample 12169: Loss: 0.0212\n",
            "Epoch 3, Sample 12170: Loss: 0.7036\n",
            "Epoch 3, Sample 12171: Loss: 0.3399\n",
            "Epoch 3, Sample 12172: Loss: 0.2044\n",
            "Epoch 3, Sample 12173: Loss: 0.0013\n",
            "Epoch 3, Sample 12174: Loss: 0.3092\n",
            "Epoch 3, Sample 12175: Loss: 0.7036\n",
            "Epoch 3, Sample 12176: Loss: 0.0830\n",
            "Epoch 3, Sample 12177: Loss: 1.0524\n",
            "Epoch 3, Sample 12178: Loss: 0.0026\n",
            "Epoch 3, Sample 12179: Loss: 0.7019\n",
            "Epoch 3, Sample 12180: Loss: 0.7036\n",
            "Epoch 3, Sample 12181: Loss: 1.0524\n",
            "Epoch 3, Sample 12182: Loss: 0.0838\n",
            "Epoch 3, Sample 12183: Loss: 0.7036\n",
            "Epoch 3, Sample 12184: Loss: 0.7036\n",
            "Epoch 3, Sample 12185: Loss: 0.0034\n",
            "Epoch 3, Sample 12186: Loss: 0.4514\n",
            "Epoch 3, Sample 12187: Loss: 0.0003\n",
            "Epoch 3, Sample 12188: Loss: 0.2036\n",
            "Epoch 3, Sample 12189: Loss: 1.0524\n",
            "Epoch 3, Sample 12190: Loss: 0.0838\n",
            "Epoch 3, Sample 12191: Loss: 0.0172\n",
            "Epoch 3, Sample 12192: Loss: 0.2962\n",
            "Epoch 3, Sample 12193: Loss: 0.0187\n",
            "Epoch 3, Sample 12194: Loss: 0.3297\n",
            "Epoch 3, Sample 12195: Loss: 0.3399\n",
            "Epoch 3, Sample 12196: Loss: 0.3402\n",
            "Epoch 3, Sample 12197: Loss: 0.3441\n",
            "Epoch 3, Sample 12198: Loss: 1.1767\n",
            "Epoch 3, Sample 12199: Loss: 0.0018\n",
            "Epoch 3, Sample 12200: Loss: 0.0005\n",
            "Epoch 3, Sample 12201: Loss: 0.3399\n",
            "Epoch 3, Sample 12202: Loss: 0.1559\n",
            "Epoch 3, Sample 12203: Loss: 0.2219\n",
            "Epoch 3, Sample 12204: Loss: 0.2044\n",
            "Epoch 3, Sample 12205: Loss: 0.2759\n",
            "Epoch 3, Sample 12206: Loss: 0.5858\n",
            "Epoch 3, Sample 12207: Loss: 0.5117\n",
            "Epoch 3, Sample 12208: Loss: 0.0026\n",
            "Epoch 3, Sample 12209: Loss: 0.0415\n",
            "Epoch 3, Sample 12210: Loss: 0.1248\n",
            "Epoch 3, Sample 12211: Loss: 0.0030\n",
            "Epoch 3, Sample 12212: Loss: 0.2052\n",
            "Epoch 3, Sample 12213: Loss: 0.8953\n",
            "Epoch 3, Sample 12214: Loss: 0.5858\n",
            "Epoch 3, Sample 12215: Loss: 0.3399\n",
            "Epoch 3, Sample 12216: Loss: 0.0108\n",
            "Epoch 3, Sample 12217: Loss: 0.0026\n",
            "Epoch 3, Sample 12218: Loss: 0.3441\n",
            "Epoch 3, Sample 12219: Loss: 1.0524\n",
            "Epoch 3, Sample 12220: Loss: 0.6990\n",
            "Epoch 3, Sample 12221: Loss: 0.2044\n",
            "Epoch 3, Sample 12222: Loss: 1.3906\n",
            "Epoch 3, Sample 12223: Loss: 0.0306\n",
            "Epoch 3, Sample 12224: Loss: 0.2340\n",
            "Epoch 3, Sample 12225: Loss: 0.2034\n",
            "Epoch 3, Sample 12226: Loss: 1.0551\n",
            "Epoch 3, Sample 12227: Loss: 0.1248\n",
            "Epoch 3, Sample 12228: Loss: 0.2219\n",
            "Epoch 3, Sample 12229: Loss: 0.0638\n",
            "Epoch 3, Sample 12230: Loss: 0.0511\n",
            "Epoch 3, Sample 12231: Loss: 0.4761\n",
            "Epoch 3, Sample 12232: Loss: 0.0505\n",
            "Epoch 3, Sample 12233: Loss: 0.0000\n",
            "Epoch 3, Sample 12234: Loss: 0.2832\n",
            "Epoch 3, Sample 12235: Loss: 0.9367\n",
            "Epoch 3, Sample 12236: Loss: 0.1250\n",
            "Epoch 3, Sample 12237: Loss: 0.1687\n",
            "Epoch 3, Sample 12238: Loss: 0.0238\n",
            "Epoch 3, Sample 12239: Loss: 0.3441\n",
            "Epoch 3, Sample 12240: Loss: 0.0031\n",
            "Epoch 3, Sample 12241: Loss: 3.9629\n",
            "Epoch 3, Sample 12242: Loss: 0.6867\n",
            "Epoch 3, Sample 12243: Loss: 0.0060\n",
            "Epoch 3, Sample 12244: Loss: 0.2044\n",
            "Epoch 3, Sample 12245: Loss: 1.0155\n",
            "Epoch 3, Sample 12246: Loss: 0.3214\n",
            "Epoch 3, Sample 12247: Loss: 1.5295\n",
            "Epoch 3, Sample 12248: Loss: 0.3441\n",
            "Epoch 3, Sample 12249: Loss: 0.2112\n",
            "Epoch 3, Sample 12250: Loss: 0.7036\n",
            "Epoch 3, Sample 12251: Loss: 0.0145\n",
            "Epoch 3, Sample 12252: Loss: 0.0067\n",
            "Epoch 3, Sample 12253: Loss: 1.0524\n",
            "Epoch 3, Sample 12254: Loss: 0.0303\n",
            "Epoch 3, Sample 12255: Loss: 0.2832\n",
            "Epoch 3, Sample 12256: Loss: 2.4541\n",
            "Epoch 3, Sample 12257: Loss: 0.2032\n",
            "Epoch 3, Sample 12258: Loss: 1.0524\n",
            "Epoch 3, Sample 12259: Loss: 0.2036\n",
            "Epoch 3, Sample 12260: Loss: 0.0209\n",
            "Epoch 3, Sample 12261: Loss: 0.8951\n",
            "Epoch 3, Sample 12262: Loss: 0.5972\n",
            "Epoch 3, Sample 12263: Loss: 0.0630\n",
            "Epoch 3, Sample 12264: Loss: 0.1252\n",
            "Epoch 3, Sample 12265: Loss: 0.6792\n",
            "Epoch 3, Sample 12266: Loss: 0.4930\n",
            "Epoch 3, Sample 12267: Loss: 4.7526\n",
            "Epoch 3, Sample 12268: Loss: 0.2044\n",
            "Epoch 3, Sample 12269: Loss: 0.1170\n",
            "Epoch 3, Sample 12270: Loss: 1.0524\n",
            "Epoch 3, Sample 12271: Loss: 2.6056\n",
            "Epoch 3, Sample 12272: Loss: 1.0524\n",
            "Epoch 3, Sample 12273: Loss: 0.0636\n",
            "Epoch 3, Sample 12274: Loss: 0.3903\n",
            "Epoch 3, Sample 12275: Loss: 0.0626\n",
            "Epoch 3, Sample 12276: Loss: 2.7841\n",
            "Epoch 3, Sample 12277: Loss: 0.8484\n",
            "Epoch 3, Sample 12278: Loss: 1.0524\n",
            "Epoch 3, Sample 12279: Loss: 1.8153\n",
            "Epoch 3, Sample 12280: Loss: 0.0270\n",
            "Epoch 3, Sample 12281: Loss: 0.2032\n",
            "Epoch 3, Sample 12282: Loss: 0.1248\n",
            "Epoch 3, Sample 12283: Loss: 0.0010\n",
            "Epoch 3, Sample 12284: Loss: 0.5972\n",
            "Epoch 3, Sample 12285: Loss: 1.0155\n",
            "Epoch 3, Sample 12286: Loss: 0.7555\n",
            "Epoch 3, Sample 12287: Loss: 0.2759\n",
            "Epoch 3, Sample 12288: Loss: 0.1308\n",
            "Epoch 3, Sample 12289: Loss: 0.1405\n",
            "Epoch 3, Sample 12290: Loss: 0.0082\n",
            "Epoch 3, Sample 12291: Loss: 0.3441\n",
            "Epoch 3, Sample 12292: Loss: 0.1273\n",
            "Epoch 3, Sample 12293: Loss: 0.7036\n",
            "Epoch 3, Sample 12294: Loss: 0.9336\n",
            "Epoch 3, Sample 12295: Loss: 0.0006\n",
            "Epoch 3, Sample 12296: Loss: 0.3294\n",
            "Epoch 3, Sample 12297: Loss: 0.2006\n",
            "Epoch 3, Sample 12298: Loss: 1.0524\n",
            "Epoch 3, Sample 12299: Loss: 0.2970\n",
            "Epoch 3, Sample 12300: Loss: 0.7404\n",
            "Epoch 3, Sample 12301: Loss: 0.1113\n",
            "Epoch 3, Sample 12302: Loss: 0.4799\n",
            "Epoch 3, Sample 12303: Loss: 0.5000\n",
            "Epoch 3, Sample 12304: Loss: 0.5858\n",
            "Epoch 3, Sample 12305: Loss: 0.2938\n",
            "Epoch 3, Sample 12306: Loss: 0.0630\n",
            "Epoch 3, Sample 12307: Loss: 0.0290\n",
            "Epoch 3, Sample 12308: Loss: 0.6407\n",
            "Epoch 3, Sample 12309: Loss: 1.0530\n",
            "Epoch 3, Sample 12310: Loss: 3.9539\n",
            "Epoch 3, Sample 12311: Loss: 0.1170\n",
            "Epoch 3, Sample 12312: Loss: 0.0385\n",
            "Epoch 3, Sample 12313: Loss: 0.3399\n",
            "Epoch 3, Sample 12314: Loss: 0.2604\n",
            "Epoch 3, Sample 12315: Loss: 0.1170\n",
            "Epoch 3, Sample 12316: Loss: 0.1248\n",
            "Epoch 3, Sample 12317: Loss: 0.2044\n",
            "Epoch 3, Sample 12318: Loss: 0.1248\n",
            "Epoch 3, Sample 12319: Loss: 0.6990\n",
            "Epoch 3, Sample 12320: Loss: 0.2032\n",
            "Epoch 3, Sample 12321: Loss: 0.5062\n",
            "Epoch 3, Sample 12322: Loss: 1.0524\n",
            "Epoch 3, Sample 12323: Loss: 0.2962\n",
            "Epoch 3, Sample 12324: Loss: 1.0524\n",
            "Epoch 3, Sample 12325: Loss: 1.0524\n",
            "Epoch 3, Sample 12326: Loss: 0.7403\n",
            "Epoch 3, Sample 12327: Loss: 1.0530\n",
            "Epoch 3, Sample 12328: Loss: 0.1372\n",
            "Epoch 3, Sample 12329: Loss: 0.1559\n",
            "Epoch 3, Sample 12330: Loss: 0.0005\n",
            "Epoch 3, Sample 12331: Loss: 0.0031\n",
            "Epoch 3, Sample 12332: Loss: 2.9009\n",
            "Epoch 3, Sample 12333: Loss: 0.9024\n",
            "Epoch 3, Sample 12334: Loss: 0.0080\n",
            "Epoch 3, Sample 12335: Loss: 0.3563\n",
            "Epoch 3, Sample 12336: Loss: 0.1039\n",
            "Epoch 3, Sample 12337: Loss: 0.6103\n",
            "Epoch 3, Sample 12338: Loss: 0.9127\n",
            "Epoch 3, Sample 12339: Loss: 0.6867\n",
            "Epoch 3, Sample 12340: Loss: 0.3949\n",
            "Epoch 3, Sample 12341: Loss: 0.0026\n",
            "Epoch 3, Sample 12342: Loss: 1.0155\n",
            "Epoch 3, Sample 12343: Loss: 17.5467\n",
            "Epoch 3, Sample 12344: Loss: 0.7036\n",
            "Epoch 3, Sample 12345: Loss: 0.0001\n",
            "Epoch 3, Sample 12346: Loss: 0.4930\n",
            "Epoch 3, Sample 12347: Loss: 0.7036\n",
            "Epoch 3, Sample 12348: Loss: 0.5196\n",
            "Epoch 3, Sample 12349: Loss: 0.2036\n",
            "Epoch 3, Sample 12350: Loss: 0.6291\n",
            "Epoch 3, Sample 12351: Loss: 1.0155\n",
            "Epoch 3, Sample 12352: Loss: 0.1463\n",
            "Epoch 3, Sample 12353: Loss: 0.6092\n",
            "Epoch 3, Sample 12354: Loss: 0.4167\n",
            "Epoch 3, Sample 12355: Loss: 0.0062\n",
            "Epoch 3, Sample 12356: Loss: 0.2832\n",
            "Epoch 3, Sample 12357: Loss: 0.5858\n",
            "Epoch 3, Sample 12358: Loss: 0.3949\n",
            "Epoch 3, Sample 12359: Loss: 0.0415\n",
            "Epoch 3, Sample 12360: Loss: 0.8673\n",
            "Epoch 3, Sample 12361: Loss: 0.0026\n",
            "Epoch 3, Sample 12362: Loss: 0.7036\n",
            "Epoch 3, Sample 12363: Loss: 0.0630\n",
            "Epoch 3, Sample 12364: Loss: 1.0266\n",
            "Epoch 3, Sample 12365: Loss: 0.2848\n",
            "Epoch 3, Sample 12366: Loss: 0.3402\n",
            "Epoch 3, Sample 12367: Loss: 0.3155\n",
            "Epoch 3, Sample 12368: Loss: 1.0276\n",
            "Epoch 3, Sample 12369: Loss: 1.0524\n",
            "Epoch 3, Sample 12370: Loss: 1.0155\n",
            "Epoch 3, Sample 12371: Loss: 0.1478\n",
            "Epoch 3, Sample 12372: Loss: 0.3399\n",
            "Epoch 3, Sample 12373: Loss: 0.5894\n",
            "Epoch 3, Sample 12374: Loss: 0.1508\n",
            "Epoch 3, Sample 12375: Loss: 0.0306\n",
            "Epoch 3, Sample 12376: Loss: 0.2034\n",
            "Epoch 3, Sample 12377: Loss: 0.2044\n",
            "Epoch 3, Sample 12378: Loss: 0.8484\n",
            "Epoch 3, Sample 12379: Loss: 7.6710\n",
            "Epoch 3, Sample 12380: Loss: 0.0026\n",
            "Epoch 3, Sample 12381: Loss: 0.2034\n",
            "Epoch 3, Sample 12382: Loss: 2.9131\n",
            "Epoch 3, Sample 12383: Loss: 0.2499\n",
            "Epoch 3, Sample 12384: Loss: 0.0013\n",
            "Epoch 3, Sample 12385: Loss: 1.0269\n",
            "Epoch 3, Sample 12386: Loss: 3.6563\n",
            "Epoch 3, Sample 12387: Loss: 0.7036\n",
            "Epoch 3, Sample 12388: Loss: 0.5972\n",
            "Epoch 3, Sample 12389: Loss: 0.4799\n",
            "Epoch 3, Sample 12390: Loss: 0.0018\n",
            "Epoch 3, Sample 12391: Loss: 0.3441\n",
            "Epoch 3, Sample 12392: Loss: 0.7036\n",
            "Epoch 3, Sample 12393: Loss: 0.2910\n",
            "Epoch 3, Sample 12394: Loss: 0.3845\n",
            "Epoch 3, Sample 12395: Loss: 1.0524\n",
            "Epoch 3, Sample 12396: Loss: 0.4841\n",
            "Epoch 3, Sample 12397: Loss: 0.4303\n",
            "Epoch 3, Sample 12398: Loss: 0.2759\n",
            "Epoch 3, Sample 12399: Loss: 0.0028\n",
            "Epoch 3, Sample 12400: Loss: 1.0155\n",
            "Epoch 3, Sample 12401: Loss: 0.0553\n",
            "Epoch 3, Sample 12402: Loss: 0.7702\n",
            "Epoch 3, Sample 12403: Loss: 0.0026\n",
            "Epoch 3, Sample 12404: Loss: 0.2989\n",
            "Epoch 3, Sample 12405: Loss: 0.1170\n",
            "Epoch 3, Sample 12406: Loss: 0.0860\n",
            "Epoch 3, Sample 12407: Loss: 1.0524\n",
            "Epoch 3, Sample 12408: Loss: 0.1588\n",
            "Epoch 3, Sample 12409: Loss: 0.0026\n",
            "Epoch 3, Sample 12410: Loss: 1.7195\n",
            "Epoch 3, Sample 12411: Loss: 0.0398\n",
            "Epoch 3, Sample 12412: Loss: 0.1868\n",
            "Epoch 3, Sample 12413: Loss: 1.0524\n",
            "Epoch 3, Sample 12414: Loss: 0.0018\n",
            "Epoch 3, Sample 12415: Loss: 1.4820\n",
            "Epoch 3, Sample 12416: Loss: 0.1250\n",
            "Epoch 3, Sample 12417: Loss: 0.5858\n",
            "Epoch 3, Sample 12418: Loss: 1.0530\n",
            "Epoch 3, Sample 12419: Loss: 0.4466\n",
            "Epoch 3, Sample 12420: Loss: 0.0915\n",
            "Epoch 3, Sample 12421: Loss: 1.2198\n",
            "Epoch 3, Sample 12422: Loss: 0.2699\n",
            "Epoch 3, Sample 12423: Loss: 0.1559\n",
            "Epoch 3, Sample 12424: Loss: 0.7036\n",
            "Epoch 3, Sample 12425: Loss: 0.1662\n",
            "Epoch 3, Sample 12426: Loss: 1.4318\n",
            "Epoch 3, Sample 12427: Loss: 0.0630\n",
            "Epoch 3, Sample 12428: Loss: 0.1372\n",
            "Epoch 3, Sample 12429: Loss: 0.2034\n",
            "Epoch 3, Sample 12430: Loss: 0.5972\n",
            "Epoch 3, Sample 12431: Loss: 0.0029\n",
            "Epoch 3, Sample 12432: Loss: 0.3399\n",
            "Epoch 3, Sample 12433: Loss: 2.2608\n",
            "Epoch 3, Sample 12434: Loss: 0.7036\n",
            "Epoch 3, Sample 12435: Loss: 0.4841\n",
            "Epoch 3, Sample 12436: Loss: 0.1559\n",
            "Epoch 3, Sample 12437: Loss: 0.2032\n",
            "Epoch 3, Sample 12438: Loss: 0.0026\n",
            "Epoch 3, Sample 12439: Loss: 0.0283\n",
            "Epoch 3, Sample 12440: Loss: 1.0155\n",
            "Epoch 3, Sample 12441: Loss: 1.0524\n",
            "Epoch 3, Sample 12442: Loss: 0.2200\n",
            "Epoch 3, Sample 12443: Loss: 0.0513\n",
            "Epoch 3, Sample 12444: Loss: 1.4460\n",
            "Epoch 3, Sample 12445: Loss: 0.2024\n",
            "Epoch 3, Sample 12446: Loss: 0.5003\n",
            "Epoch 3, Sample 12447: Loss: 1.2513\n",
            "Epoch 3, Sample 12448: Loss: 0.0147\n",
            "Epoch 3, Sample 12449: Loss: 1.0524\n",
            "Epoch 3, Sample 12450: Loss: 0.4032\n",
            "Epoch 3, Sample 12451: Loss: 0.0063\n",
            "Epoch 3, Sample 12452: Loss: 0.3949\n",
            "Epoch 3, Sample 12453: Loss: 0.8951\n",
            "Epoch 3, Sample 12454: Loss: 4.0002\n",
            "Epoch 3, Sample 12455: Loss: 0.5673\n",
            "Epoch 3, Sample 12456: Loss: 0.0005\n",
            "Epoch 3, Sample 12457: Loss: 0.0137\n",
            "Epoch 3, Sample 12458: Loss: 0.7036\n",
            "Epoch 3, Sample 12459: Loss: 0.8951\n",
            "Epoch 3, Sample 12460: Loss: 0.3949\n",
            "Epoch 3, Sample 12461: Loss: 0.0963\n",
            "Epoch 3, Sample 12462: Loss: 0.5972\n",
            "Epoch 3, Sample 12463: Loss: 0.5000\n",
            "Epoch 3, Sample 12464: Loss: 0.0382\n",
            "Epoch 3, Sample 12465: Loss: 0.6304\n",
            "Epoch 3, Sample 12466: Loss: 0.0205\n",
            "Epoch 3, Sample 12467: Loss: 0.2219\n",
            "Epoch 3, Sample 12468: Loss: 1.5905\n",
            "Epoch 3, Sample 12469: Loss: 0.2005\n",
            "Epoch 3, Sample 12470: Loss: 0.2034\n",
            "Epoch 3, Sample 12471: Loss: 0.6867\n",
            "Epoch 3, Sample 12472: Loss: 0.2044\n",
            "Epoch 3, Sample 12473: Loss: 0.2036\n",
            "Epoch 3, Sample 12474: Loss: 0.0041\n",
            "Epoch 3, Sample 12475: Loss: 0.9367\n",
            "Epoch 3, Sample 12476: Loss: 0.7453\n",
            "Epoch 3, Sample 12477: Loss: 0.0364\n",
            "Epoch 3, Sample 12478: Loss: 0.4134\n",
            "Epoch 3, Sample 12479: Loss: 0.0744\n",
            "Epoch 3, Sample 12480: Loss: 0.2112\n",
            "Epoch 3, Sample 12481: Loss: 2.4315\n",
            "Epoch 3, Sample 12482: Loss: 0.4367\n",
            "Epoch 3, Sample 12483: Loss: 0.2036\n",
            "Epoch 3, Sample 12484: Loss: 0.3402\n",
            "Epoch 3, Sample 12485: Loss: 0.0017\n",
            "Epoch 3, Sample 12486: Loss: 0.4906\n",
            "Epoch 3, Sample 12487: Loss: 0.1646\n",
            "Epoch 3, Sample 12488: Loss: 0.4876\n",
            "Epoch 3, Sample 12489: Loss: 0.0027\n",
            "Epoch 3, Sample 12490: Loss: 0.7036\n",
            "Epoch 3, Sample 12491: Loss: 0.0108\n",
            "Epoch 3, Sample 12492: Loss: 0.7036\n",
            "Epoch 3, Sample 12493: Loss: 0.2044\n",
            "Epoch 3, Sample 12494: Loss: 1.0530\n",
            "Epoch 3, Sample 12495: Loss: 0.2759\n",
            "Epoch 3, Sample 12496: Loss: 1.1424\n",
            "Epoch 3, Sample 12497: Loss: 0.1170\n",
            "Epoch 3, Sample 12498: Loss: 0.2034\n",
            "Epoch 3, Sample 12499: Loss: 0.7036\n",
            "Epoch 3, Sample 12500: Loss: 0.0026\n",
            "Epoch 3, Sample 12501: Loss: 0.0018\n",
            "Epoch 3, Sample 12502: Loss: 2.9529\n",
            "Epoch 3, Sample 12503: Loss: 0.1594\n",
            "Epoch 3, Sample 12504: Loss: 0.1691\n",
            "Epoch 3, Sample 12505: Loss: 0.0108\n",
            "Epoch 3, Sample 12506: Loss: 0.1219\n",
            "Epoch 3, Sample 12507: Loss: 0.1164\n",
            "Epoch 3, Sample 12508: Loss: 0.2941\n",
            "Epoch 3, Sample 12509: Loss: 0.2044\n",
            "Epoch 3, Sample 12510: Loss: 0.4611\n",
            "Epoch 3, Sample 12511: Loss: 0.2340\n",
            "Epoch 3, Sample 12512: Loss: 0.1114\n",
            "Epoch 3, Sample 12513: Loss: 0.1056\n",
            "Epoch 3, Sample 12514: Loss: 0.7036\n",
            "Epoch 3, Sample 12515: Loss: 1.0524\n",
            "Epoch 3, Sample 12516: Loss: 0.0026\n",
            "Epoch 3, Sample 12517: Loss: 0.1248\n",
            "Epoch 3, Sample 12518: Loss: 0.0012\n",
            "Epoch 3, Sample 12519: Loss: 0.0270\n",
            "Epoch 3, Sample 12520: Loss: 0.1248\n",
            "Epoch 3, Sample 12521: Loss: 0.0013\n",
            "Epoch 3, Sample 12522: Loss: 0.0031\n",
            "Epoch 3, Sample 12523: Loss: 0.1239\n",
            "Epoch 3, Sample 12524: Loss: 0.3399\n",
            "Epoch 3, Sample 12525: Loss: 0.9367\n",
            "Epoch 3, Sample 12526: Loss: 0.8151\n",
            "Epoch 3, Sample 12527: Loss: 1.0524\n",
            "Epoch 3, Sample 12528: Loss: 0.3399\n",
            "Epoch 3, Sample 12529: Loss: 5.0906\n",
            "Epoch 3, Sample 12530: Loss: 0.2363\n",
            "Epoch 3, Sample 12531: Loss: 0.6950\n",
            "Epoch 3, Sample 12532: Loss: 0.0212\n",
            "Epoch 3, Sample 12533: Loss: 0.0027\n",
            "Epoch 3, Sample 12534: Loss: 1.0155\n",
            "Epoch 3, Sample 12535: Loss: 0.0625\n",
            "Epoch 3, Sample 12536: Loss: 0.3539\n",
            "Epoch 3, Sample 12537: Loss: 0.3402\n",
            "Epoch 3, Sample 12538: Loss: 0.8951\n",
            "Epoch 3, Sample 12539: Loss: 0.1170\n",
            "Epoch 3, Sample 12540: Loss: 0.2855\n",
            "Epoch 3, Sample 12541: Loss: 0.2044\n",
            "Epoch 3, Sample 12542: Loss: 0.1250\n",
            "Epoch 3, Sample 12543: Loss: 0.0938\n",
            "Epoch 3, Sample 12544: Loss: 0.7036\n",
            "Epoch 3, Sample 12545: Loss: 1.0524\n",
            "Epoch 3, Sample 12546: Loss: 1.2926\n",
            "Epoch 3, Sample 12547: Loss: 0.0938\n",
            "Epoch 3, Sample 12548: Loss: 0.1355\n",
            "Epoch 3, Sample 12549: Loss: 1.6059\n",
            "Epoch 3, Sample 12550: Loss: 0.0000\n",
            "Epoch 3, Sample 12551: Loss: 2.0233\n",
            "Epoch 3, Sample 12552: Loss: 0.0013\n",
            "Epoch 3, Sample 12553: Loss: 0.2044\n",
            "Epoch 3, Sample 12554: Loss: 0.0189\n",
            "Epoch 3, Sample 12555: Loss: 0.0031\n",
            "Epoch 3, Sample 12556: Loss: 0.0026\n",
            "Epoch 3, Sample 12557: Loss: 0.1233\n",
            "Epoch 3, Sample 12558: Loss: 0.3284\n",
            "Epoch 3, Sample 12559: Loss: 0.0604\n",
            "Epoch 3, Sample 12560: Loss: 0.0388\n",
            "Epoch 3, Sample 12561: Loss: 0.1250\n",
            "Epoch 3, Sample 12562: Loss: 0.2885\n",
            "Epoch 3, Sample 12563: Loss: 0.1211\n",
            "Epoch 3, Sample 12564: Loss: 0.0000\n",
            "Epoch 3, Sample 12565: Loss: 0.0031\n",
            "Epoch 3, Sample 12566: Loss: 0.0057\n",
            "Epoch 3, Sample 12567: Loss: 0.1508\n",
            "Epoch 3, Sample 12568: Loss: 0.7036\n",
            "Epoch 3, Sample 12569: Loss: 0.1714\n",
            "Epoch 3, Sample 12570: Loss: 0.0108\n",
            "Epoch 3, Sample 12571: Loss: 0.0007\n",
            "Epoch 3, Sample 12572: Loss: 0.0106\n",
            "Epoch 3, Sample 12573: Loss: 0.2307\n",
            "Epoch 3, Sample 12574: Loss: 3.0693\n",
            "Epoch 3, Sample 12575: Loss: 0.2034\n",
            "Epoch 3, Sample 12576: Loss: 0.4010\n",
            "Epoch 3, Sample 12577: Loss: 0.0466\n",
            "Epoch 3, Sample 12578: Loss: 0.8314\n",
            "Epoch 3, Sample 12579: Loss: 0.0205\n",
            "Epoch 3, Sample 12580: Loss: 0.0108\n",
            "Epoch 3, Sample 12581: Loss: 0.2989\n",
            "Epoch 3, Sample 12582: Loss: 0.0063\n",
            "Epoch 3, Sample 12583: Loss: 1.0524\n",
            "Epoch 3, Sample 12584: Loss: 0.0026\n",
            "Epoch 3, Sample 12585: Loss: 0.2242\n",
            "Epoch 3, Sample 12586: Loss: 0.0458\n",
            "Epoch 3, Sample 12587: Loss: 0.3960\n",
            "Epoch 3, Sample 12588: Loss: 1.0524\n",
            "Epoch 3, Sample 12589: Loss: 0.1021\n",
            "Epoch 3, Sample 12590: Loss: 0.0618\n",
            "Epoch 3, Sample 12591: Loss: 0.0630\n",
            "Epoch 3, Sample 12592: Loss: 0.0637\n",
            "Epoch 3, Sample 12593: Loss: 0.0992\n",
            "Epoch 3, Sample 12594: Loss: 0.9367\n",
            "Epoch 3, Sample 12595: Loss: 0.0002\n",
            "Epoch 3, Sample 12596: Loss: 0.2034\n",
            "Epoch 3, Sample 12597: Loss: 2.4326\n",
            "Epoch 3, Sample 12598: Loss: 0.2759\n",
            "Epoch 3, Sample 12599: Loss: 0.7453\n",
            "Epoch 3, Sample 12600: Loss: 0.1094\n",
            "Epoch 3, Sample 12601: Loss: 0.0022\n",
            "Epoch 3, Sample 12602: Loss: 1.0524\n",
            "Epoch 3, Sample 12603: Loss: 11.0746\n",
            "Epoch 3, Sample 12604: Loss: 0.0026\n",
            "Epoch 3, Sample 12605: Loss: 0.7036\n",
            "Epoch 3, Sample 12606: Loss: 0.0495\n",
            "Epoch 3, Sample 12607: Loss: 0.0080\n",
            "Epoch 3, Sample 12608: Loss: 0.1225\n",
            "Epoch 3, Sample 12609: Loss: 0.8137\n",
            "Epoch 3, Sample 12610: Loss: 0.1998\n",
            "Epoch 3, Sample 12611: Loss: 0.0205\n",
            "Epoch 3, Sample 12612: Loss: 0.2034\n",
            "Epoch 3, Sample 12613: Loss: 0.0025\n",
            "Epoch 3, Sample 12614: Loss: 0.0604\n",
            "Epoch 3, Sample 12615: Loss: 0.1889\n",
            "Epoch 3, Sample 12616: Loss: 1.3412\n",
            "Epoch 3, Sample 12617: Loss: 0.2044\n",
            "Epoch 3, Sample 12618: Loss: 0.2811\n",
            "Epoch 3, Sample 12619: Loss: 0.1170\n",
            "Epoch 3, Sample 12620: Loss: 0.2759\n",
            "Epoch 3, Sample 12621: Loss: 0.2044\n",
            "Epoch 3, Sample 12622: Loss: 0.5858\n",
            "Epoch 3, Sample 12623: Loss: 0.0306\n",
            "Epoch 3, Sample 12624: Loss: 3.2044\n",
            "Epoch 3, Sample 12625: Loss: 0.2962\n",
            "Epoch 3, Sample 12626: Loss: 0.3441\n",
            "Epoch 3, Sample 12627: Loss: 0.0073\n",
            "Epoch 3, Sample 12628: Loss: 0.1549\n",
            "Epoch 3, Sample 12629: Loss: 0.2032\n",
            "Epoch 3, Sample 12630: Loss: 0.0033\n",
            "Epoch 3, Sample 12631: Loss: 0.9367\n",
            "Epoch 3, Sample 12632: Loss: 0.2034\n",
            "Epoch 3, Sample 12633: Loss: 0.0099\n",
            "Epoch 3, Sample 12634: Loss: 0.0363\n",
            "Epoch 3, Sample 12635: Loss: 0.1523\n",
            "Epoch 3, Sample 12636: Loss: 0.0513\n",
            "Epoch 3, Sample 12637: Loss: 0.1417\n",
            "Epoch 3, Sample 12638: Loss: 0.2044\n",
            "Epoch 3, Sample 12639: Loss: 1.0908\n",
            "Epoch 3, Sample 12640: Loss: 0.0063\n",
            "Epoch 3, Sample 12641: Loss: 0.2161\n",
            "Epoch 3, Sample 12642: Loss: 0.1777\n",
            "Epoch 3, Sample 12643: Loss: 0.3306\n",
            "Epoch 3, Sample 12644: Loss: 1.0524\n",
            "Epoch 3, Sample 12645: Loss: 0.3568\n",
            "Epoch 3, Sample 12646: Loss: 0.7453\n",
            "Epoch 3, Sample 12647: Loss: 0.0062\n",
            "Epoch 3, Sample 12648: Loss: 0.0205\n",
            "Epoch 3, Sample 12649: Loss: 0.0630\n",
            "Epoch 3, Sample 12650: Loss: 0.4611\n",
            "Epoch 3, Sample 12651: Loss: 0.1692\n",
            "Epoch 3, Sample 12652: Loss: 0.2044\n",
            "Epoch 3, Sample 12653: Loss: 0.0065\n",
            "Epoch 3, Sample 12654: Loss: 1.0155\n",
            "Epoch 3, Sample 12655: Loss: 2.1792\n",
            "Epoch 3, Sample 12656: Loss: 1.6389\n",
            "Epoch 3, Sample 12657: Loss: 0.3441\n",
            "Epoch 3, Sample 12658: Loss: 0.4841\n",
            "Epoch 3, Sample 12659: Loss: 0.1546\n",
            "Epoch 3, Sample 12660: Loss: 0.4930\n",
            "Epoch 3, Sample 12661: Loss: 0.0018\n",
            "Epoch 3, Sample 12662: Loss: 1.3589\n",
            "Epoch 3, Sample 12663: Loss: 0.0212\n",
            "Epoch 3, Sample 12664: Loss: 0.1546\n",
            "Epoch 3, Sample 12665: Loss: 0.3399\n",
            "Epoch 3, Sample 12666: Loss: 0.2044\n",
            "Epoch 3, Sample 12667: Loss: 1.0530\n",
            "Epoch 3, Sample 12668: Loss: 0.0084\n",
            "Epoch 3, Sample 12669: Loss: 0.0059\n",
            "Epoch 3, Sample 12670: Loss: 0.0028\n",
            "Epoch 3, Sample 12671: Loss: 0.5858\n",
            "Epoch 3, Sample 12672: Loss: 0.0387\n",
            "Epoch 3, Sample 12673: Loss: 0.7453\n",
            "Epoch 3, Sample 12674: Loss: 0.0001\n",
            "Epoch 3, Sample 12675: Loss: 0.5799\n",
            "Epoch 3, Sample 12676: Loss: 0.2484\n",
            "Epoch 3, Sample 12677: Loss: 1.3135\n",
            "Epoch 3, Sample 12678: Loss: 0.3399\n",
            "Epoch 3, Sample 12679: Loss: 0.2032\n",
            "Epoch 3, Sample 12680: Loss: 3.4576\n",
            "Epoch 3, Sample 12681: Loss: 1.0524\n",
            "Epoch 3, Sample 12682: Loss: 0.3441\n",
            "Epoch 3, Sample 12683: Loss: 0.1863\n",
            "Epoch 3, Sample 12684: Loss: 0.0840\n",
            "Epoch 3, Sample 12685: Loss: 0.1555\n",
            "Epoch 3, Sample 12686: Loss: 5.1386\n",
            "Epoch 3, Sample 12687: Loss: 0.0924\n",
            "Epoch 3, Sample 12688: Loss: 0.2032\n",
            "Epoch 3, Sample 12689: Loss: 1.0524\n",
            "Epoch 3, Sample 12690: Loss: 0.2032\n",
            "Epoch 3, Sample 12691: Loss: 0.1250\n",
            "Epoch 3, Sample 12692: Loss: 0.0234\n",
            "Epoch 3, Sample 12693: Loss: 0.2219\n",
            "Epoch 3, Sample 12694: Loss: 0.2962\n",
            "Epoch 3, Sample 12695: Loss: 0.9367\n",
            "Epoch 3, Sample 12696: Loss: 0.5858\n",
            "Epoch 3, Sample 12697: Loss: 0.2044\n",
            "Epoch 3, Sample 12698: Loss: 7.1239\n",
            "Epoch 3, Sample 12699: Loss: 0.4799\n",
            "Epoch 3, Sample 12700: Loss: 0.2036\n",
            "Epoch 3, Sample 12701: Loss: 0.2276\n",
            "Epoch 3, Sample 12702: Loss: 5.0803\n",
            "Epoch 3, Sample 12703: Loss: 0.0004\n",
            "Epoch 3, Sample 12704: Loss: 1.0530\n",
            "Epoch 3, Sample 12705: Loss: 0.1248\n",
            "Epoch 3, Sample 12706: Loss: 0.2832\n",
            "Epoch 3, Sample 12707: Loss: 0.8951\n",
            "Epoch 3, Sample 12708: Loss: 0.1890\n",
            "Epoch 3, Sample 12709: Loss: 0.1394\n",
            "Epoch 3, Sample 12710: Loss: 0.2034\n",
            "Epoch 3, Sample 12711: Loss: 0.0630\n",
            "Epoch 3, Sample 12712: Loss: 0.2935\n",
            "Epoch 3, Sample 12713: Loss: 0.0013\n",
            "Epoch 3, Sample 12714: Loss: 0.0018\n",
            "Epoch 3, Sample 12715: Loss: 0.2044\n",
            "Epoch 3, Sample 12716: Loss: 0.2240\n",
            "Epoch 3, Sample 12717: Loss: 0.6990\n",
            "Epoch 3, Sample 12718: Loss: 1.0524\n",
            "Epoch 3, Sample 12719: Loss: 0.7702\n",
            "Epoch 3, Sample 12720: Loss: 0.0002\n",
            "Epoch 3, Sample 12721: Loss: 2.3039\n",
            "Epoch 3, Sample 12722: Loss: 0.4220\n",
            "Epoch 3, Sample 12723: Loss: 0.2750\n",
            "Epoch 3, Sample 12724: Loss: 0.5019\n",
            "Epoch 3, Sample 12725: Loss: 0.7036\n",
            "Epoch 3, Sample 12726: Loss: 0.7453\n",
            "Epoch 3, Sample 12727: Loss: 0.1946\n",
            "Epoch 3, Sample 12728: Loss: 0.0092\n",
            "Epoch 3, Sample 12729: Loss: 1.0155\n",
            "Epoch 3, Sample 12730: Loss: 1.0155\n",
            "Epoch 3, Sample 12731: Loss: 0.3356\n",
            "Epoch 3, Sample 12732: Loss: 0.0981\n",
            "Epoch 3, Sample 12733: Loss: 0.0460\n",
            "Epoch 3, Sample 12734: Loss: 0.1156\n",
            "Epoch 3, Sample 12735: Loss: 0.0558\n",
            "Epoch 3, Sample 12736: Loss: 0.4328\n",
            "Epoch 3, Sample 12737: Loss: 0.0640\n",
            "Epoch 3, Sample 12738: Loss: 0.5328\n",
            "Epoch 3, Sample 12739: Loss: 0.0075\n",
            "Epoch 3, Sample 12740: Loss: 0.5560\n",
            "Epoch 3, Sample 12741: Loss: 0.2832\n",
            "Epoch 3, Sample 12742: Loss: 0.2639\n",
            "Epoch 3, Sample 12743: Loss: 0.0027\n",
            "Epoch 3, Sample 12744: Loss: 1.0524\n",
            "Epoch 3, Sample 12745: Loss: 0.0002\n",
            "Epoch 3, Sample 12746: Loss: 0.0026\n",
            "Epoch 3, Sample 12747: Loss: 0.3090\n",
            "Epoch 3, Sample 12748: Loss: 0.0731\n",
            "Epoch 3, Sample 12749: Loss: 0.0018\n",
            "Epoch 3, Sample 12750: Loss: 1.0155\n",
            "Epoch 3, Sample 12751: Loss: 0.5858\n",
            "Epoch 3, Sample 12752: Loss: 0.1250\n",
            "Epoch 3, Sample 12753: Loss: 1.2931\n",
            "Epoch 3, Sample 12754: Loss: 7.7941\n",
            "Epoch 3, Sample 12755: Loss: 0.3399\n",
            "Epoch 3, Sample 12756: Loss: 0.1040\n",
            "Epoch 3, Sample 12757: Loss: 0.0590\n",
            "Epoch 3, Sample 12758: Loss: 1.0511\n",
            "Epoch 3, Sample 12759: Loss: 0.1337\n",
            "Epoch 3, Sample 12760: Loss: 0.1170\n",
            "Epoch 3, Sample 12761: Loss: 0.2112\n",
            "Epoch 3, Sample 12762: Loss: 1.4058\n",
            "Epoch 3, Sample 12763: Loss: 0.2132\n",
            "Epoch 3, Sample 12764: Loss: 0.2034\n",
            "Epoch 3, Sample 12765: Loss: 1.9658\n",
            "Epoch 3, Sample 12766: Loss: 0.0017\n",
            "Epoch 3, Sample 12767: Loss: 6.0812\n",
            "Epoch 3, Sample 12768: Loss: 0.2044\n",
            "Epoch 3, Sample 12769: Loss: 0.0205\n",
            "Epoch 3, Sample 12770: Loss: 0.0274\n",
            "Epoch 3, Sample 12771: Loss: 1.0155\n",
            "Epoch 3, Sample 12772: Loss: 0.0513\n",
            "Epoch 3, Sample 12773: Loss: 0.3399\n",
            "Epoch 3, Sample 12774: Loss: 0.3092\n",
            "Epoch 3, Sample 12775: Loss: 0.2036\n",
            "Epoch 3, Sample 12776: Loss: 0.6304\n",
            "Epoch 3, Sample 12777: Loss: 1.0530\n",
            "Epoch 3, Sample 12778: Loss: 0.6315\n",
            "Epoch 3, Sample 12779: Loss: 1.7451\n",
            "Epoch 3, Sample 12780: Loss: 0.4759\n",
            "Epoch 3, Sample 12781: Loss: 0.6177\n",
            "Epoch 3, Sample 12782: Loss: 1.0155\n",
            "Epoch 3, Sample 12783: Loss: 0.3568\n",
            "Epoch 3, Sample 12784: Loss: 0.3233\n",
            "Epoch 3, Sample 12785: Loss: 0.2175\n",
            "Epoch 3, Sample 12786: Loss: 0.2832\n",
            "Epoch 3, Sample 12787: Loss: 0.0001\n",
            "Epoch 3, Sample 12788: Loss: 0.7036\n",
            "Epoch 3, Sample 12789: Loss: 0.7036\n",
            "Epoch 3, Sample 12790: Loss: 1.0530\n",
            "Epoch 3, Sample 12791: Loss: 0.2204\n",
            "Epoch 3, Sample 12792: Loss: 0.9367\n",
            "Epoch 3, Sample 12793: Loss: 0.5196\n",
            "Epoch 3, Sample 12794: Loss: 0.2759\n",
            "Epoch 3, Sample 12795: Loss: 0.7036\n",
            "Epoch 3, Sample 12796: Loss: 0.0018\n",
            "Epoch 3, Sample 12797: Loss: 0.1252\n",
            "Epoch 3, Sample 12798: Loss: 0.2044\n",
            "Epoch 3, Sample 12799: Loss: 0.7036\n",
            "Epoch 3, Sample 12800: Loss: 0.2036\n",
            "Epoch 3, Sample 12801: Loss: 0.3402\n",
            "Epoch 3, Sample 12802: Loss: 0.3367\n",
            "Epoch 3, Sample 12803: Loss: 0.0067\n",
            "Epoch 3, Sample 12804: Loss: 0.2639\n",
            "Epoch 3, Sample 12805: Loss: 0.0001\n",
            "Epoch 3, Sample 12806: Loss: 0.0930\n",
            "Epoch 3, Sample 12807: Loss: 0.2032\n",
            "Epoch 3, Sample 12808: Loss: 0.2219\n",
            "Epoch 3, Sample 12809: Loss: 0.1246\n",
            "Epoch 3, Sample 12810: Loss: 0.3549\n",
            "Epoch 3, Sample 12811: Loss: 0.2034\n",
            "Epoch 3, Sample 12812: Loss: 0.5858\n",
            "Epoch 3, Sample 12813: Loss: 0.0207\n",
            "Epoch 3, Sample 12814: Loss: 0.2032\n",
            "Epoch 3, Sample 12815: Loss: 0.8951\n",
            "Epoch 3, Sample 12816: Loss: 0.4032\n",
            "Epoch 3, Sample 12817: Loss: 1.0155\n",
            "Epoch 3, Sample 12818: Loss: 0.0205\n",
            "Epoch 3, Sample 12819: Loss: 0.0108\n",
            "Epoch 3, Sample 12820: Loss: 0.2074\n",
            "Epoch 3, Sample 12821: Loss: 0.0000\n",
            "Epoch 3, Sample 12822: Loss: 0.2032\n",
            "Epoch 3, Sample 12823: Loss: 0.2887\n",
            "Epoch 3, Sample 12824: Loss: 0.1508\n",
            "Epoch 3, Sample 12825: Loss: 0.0714\n",
            "Epoch 3, Sample 12826: Loss: 0.2340\n",
            "Epoch 3, Sample 12827: Loss: 0.2032\n",
            "Epoch 3, Sample 12828: Loss: 0.2832\n",
            "Epoch 3, Sample 12829: Loss: 0.5858\n",
            "Epoch 3, Sample 12830: Loss: 0.0026\n",
            "Epoch 3, Sample 12831: Loss: 0.5913\n",
            "Epoch 3, Sample 12832: Loss: 0.0251\n",
            "Epoch 3, Sample 12833: Loss: 0.0031\n",
            "Epoch 3, Sample 12834: Loss: 0.0026\n",
            "Epoch 3, Sample 12835: Loss: 0.2290\n",
            "Epoch 3, Sample 12836: Loss: 0.0017\n",
            "Epoch 3, Sample 12837: Loss: 1.6805\n",
            "Epoch 3, Sample 12838: Loss: 0.0027\n",
            "Epoch 3, Sample 12839: Loss: 0.3945\n",
            "Epoch 3, Sample 12840: Loss: 0.2935\n",
            "Epoch 3, Sample 12841: Loss: 0.2704\n",
            "Epoch 3, Sample 12842: Loss: 0.0306\n",
            "Epoch 3, Sample 12843: Loss: 0.2032\n",
            "Epoch 3, Sample 12844: Loss: 0.0026\n",
            "Epoch 3, Sample 12845: Loss: 0.7036\n",
            "Epoch 3, Sample 12846: Loss: 0.5972\n",
            "Epoch 3, Sample 12847: Loss: 0.1559\n",
            "Epoch 3, Sample 12848: Loss: 0.0391\n",
            "Epoch 3, Sample 12849: Loss: 0.0915\n",
            "Epoch 3, Sample 12850: Loss: 0.4032\n",
            "Epoch 3, Sample 12851: Loss: 0.0306\n",
            "Epoch 3, Sample 12852: Loss: 0.5824\n",
            "Epoch 3, Sample 12853: Loss: 0.5014\n",
            "Epoch 3, Sample 12854: Loss: 0.2044\n",
            "Epoch 3, Sample 12855: Loss: 0.3441\n",
            "Epoch 3, Sample 12856: Loss: 0.0007\n",
            "Epoch 3, Sample 12857: Loss: 0.2032\n",
            "Epoch 3, Sample 12858: Loss: 0.4996\n",
            "Epoch 3, Sample 12859: Loss: 0.1252\n",
            "Epoch 3, Sample 12860: Loss: 0.0015\n",
            "Epoch 3, Sample 12861: Loss: 0.0002\n",
            "Epoch 3, Sample 12862: Loss: 0.8951\n",
            "Epoch 3, Sample 12863: Loss: 0.1250\n",
            "Epoch 3, Sample 12864: Loss: 0.0212\n",
            "Epoch 3, Sample 12865: Loss: 0.0680\n",
            "Epoch 3, Sample 12866: Loss: 0.0013\n",
            "Epoch 3, Sample 12867: Loss: 0.0918\n",
            "Epoch 3, Sample 12868: Loss: 0.2935\n",
            "Epoch 3, Sample 12869: Loss: 0.0001\n",
            "Epoch 3, Sample 12870: Loss: 0.8951\n",
            "Epoch 3, Sample 12871: Loss: 0.0205\n",
            "Epoch 3, Sample 12872: Loss: 0.8951\n",
            "Epoch 3, Sample 12873: Loss: 0.2032\n",
            "Epoch 3, Sample 12874: Loss: 0.3382\n",
            "Epoch 3, Sample 12875: Loss: 0.0108\n",
            "Epoch 3, Sample 12876: Loss: 0.3949\n",
            "Epoch 3, Sample 12877: Loss: 2.1340\n",
            "Epoch 3, Sample 12878: Loss: 1.6299\n",
            "Epoch 3, Sample 12879: Loss: 7.4209\n",
            "Epoch 3, Sample 12880: Loss: 0.7453\n",
            "Epoch 3, Sample 12881: Loss: 0.0785\n",
            "Epoch 3, Sample 12882: Loss: 0.4032\n",
            "Epoch 3, Sample 12883: Loss: 0.2034\n",
            "Epoch 3, Sample 12884: Loss: 0.9367\n",
            "Epoch 3, Sample 12885: Loss: 0.0697\n",
            "Epoch 3, Sample 12886: Loss: 0.2044\n",
            "Epoch 3, Sample 12887: Loss: 0.0026\n",
            "Epoch 3, Sample 12888: Loss: 0.7453\n",
            "Epoch 3, Sample 12889: Loss: 0.2832\n",
            "Epoch 3, Sample 12890: Loss: 0.0201\n",
            "Epoch 3, Sample 12891: Loss: 0.5858\n",
            "Epoch 3, Sample 12892: Loss: 0.5989\n",
            "Epoch 3, Sample 12893: Loss: 1.0524\n",
            "Epoch 3, Sample 12894: Loss: 0.0838\n",
            "Epoch 3, Sample 12895: Loss: 0.3716\n",
            "Epoch 3, Sample 12896: Loss: 0.2832\n",
            "Epoch 3, Sample 12897: Loss: 0.0011\n",
            "Epoch 3, Sample 12898: Loss: 0.0025\n",
            "Epoch 3, Sample 12899: Loss: 0.1786\n",
            "Epoch 3, Sample 12900: Loss: 1.0524\n",
            "Epoch 3, Sample 12901: Loss: 0.0357\n",
            "Epoch 3, Sample 12902: Loss: 0.0205\n",
            "Epoch 3, Sample 12903: Loss: 0.0049\n",
            "Epoch 3, Sample 12904: Loss: 0.1482\n",
            "Epoch 3, Sample 12905: Loss: 0.5972\n",
            "Epoch 3, Sample 12906: Loss: 1.0266\n",
            "Epoch 3, Sample 12907: Loss: 0.2650\n",
            "Epoch 3, Sample 12908: Loss: 0.5765\n",
            "Epoch 3, Sample 12909: Loss: 0.0001\n",
            "Epoch 3, Sample 12910: Loss: 0.3431\n",
            "Epoch 3, Sample 12911: Loss: 0.3288\n",
            "Epoch 3, Sample 12912: Loss: 0.1349\n",
            "Epoch 3, Sample 12913: Loss: 0.1548\n",
            "Epoch 3, Sample 12914: Loss: 0.1463\n",
            "Epoch 3, Sample 12915: Loss: 0.1508\n",
            "Epoch 3, Sample 12916: Loss: 0.7036\n",
            "Epoch 3, Sample 12917: Loss: 0.0018\n",
            "Epoch 3, Sample 12918: Loss: 0.0498\n",
            "Epoch 3, Sample 12919: Loss: 0.3247\n",
            "Epoch 3, Sample 12920: Loss: 0.5972\n",
            "Epoch 3, Sample 12921: Loss: 0.2219\n",
            "Epoch 3, Sample 12922: Loss: 0.0015\n",
            "Epoch 3, Sample 12923: Loss: 0.1296\n",
            "Epoch 3, Sample 12924: Loss: 0.2101\n",
            "Epoch 3, Sample 12925: Loss: 0.4762\n",
            "Epoch 3, Sample 12926: Loss: 0.2759\n",
            "Epoch 3, Sample 12927: Loss: 0.6304\n",
            "Epoch 3, Sample 12928: Loss: 0.0287\n",
            "Epoch 3, Sample 12929: Loss: 0.1170\n",
            "Epoch 3, Sample 12930: Loss: 0.1559\n",
            "Epoch 3, Sample 12931: Loss: 0.0284\n",
            "Epoch 3, Sample 12932: Loss: 0.0001\n",
            "Epoch 3, Sample 12933: Loss: 0.2034\n",
            "Epoch 3, Sample 12934: Loss: 1.0155\n",
            "Epoch 3, Sample 12935: Loss: 0.1356\n",
            "Epoch 3, Sample 12936: Loss: 0.5513\n",
            "Epoch 3, Sample 12937: Loss: 0.0230\n",
            "Epoch 3, Sample 12938: Loss: 0.0626\n",
            "Epoch 3, Sample 12939: Loss: 0.1559\n",
            "Epoch 3, Sample 12940: Loss: 1.7765\n",
            "Epoch 3, Sample 12941: Loss: 0.1588\n",
            "Epoch 3, Sample 12942: Loss: 0.1523\n",
            "Epoch 3, Sample 12943: Loss: 0.4799\n",
            "Epoch 3, Sample 12944: Loss: 0.4025\n",
            "Epoch 3, Sample 12945: Loss: 0.0972\n",
            "Epoch 3, Sample 12946: Loss: 0.0001\n",
            "Epoch 3, Sample 12947: Loss: 0.2182\n",
            "Epoch 3, Sample 12948: Loss: 0.4611\n",
            "Epoch 3, Sample 12949: Loss: 0.0108\n",
            "Epoch 3, Sample 12950: Loss: 0.0018\n",
            "Epoch 3, Sample 12951: Loss: 0.0915\n",
            "Epoch 3, Sample 12952: Loss: 0.5858\n",
            "Epoch 3, Sample 12953: Loss: 2.2208\n",
            "Epoch 3, Sample 12954: Loss: 1.0155\n",
            "Epoch 3, Sample 12955: Loss: 0.0082\n",
            "Epoch 3, Sample 12956: Loss: 0.4840\n",
            "Epoch 3, Sample 12957: Loss: 0.0671\n",
            "Epoch 3, Sample 12958: Loss: 0.3441\n",
            "Epoch 3, Sample 12959: Loss: 0.0018\n",
            "Epoch 3, Sample 12960: Loss: 0.2032\n",
            "Epoch 3, Sample 12961: Loss: 0.8951\n",
            "Epoch 3, Sample 12962: Loss: 0.0270\n",
            "Epoch 3, Sample 12963: Loss: 6.8218\n",
            "Epoch 3, Sample 12964: Loss: 0.1334\n",
            "Epoch 3, Sample 12965: Loss: 0.2044\n",
            "Epoch 3, Sample 12966: Loss: 6.3289\n",
            "Epoch 3, Sample 12967: Loss: 0.2258\n",
            "Epoch 3, Sample 12968: Loss: 0.1250\n",
            "Epoch 3, Sample 12969: Loss: 0.0363\n",
            "Epoch 3, Sample 12970: Loss: 0.2032\n",
            "Epoch 3, Sample 12971: Loss: 0.6839\n",
            "Epoch 3, Sample 12972: Loss: 0.2044\n",
            "Epoch 3, Sample 12973: Loss: 0.5858\n",
            "Epoch 3, Sample 12974: Loss: 1.0669\n",
            "Epoch 3, Sample 12975: Loss: 0.4611\n",
            "Epoch 3, Sample 12976: Loss: 0.0287\n",
            "Epoch 3, Sample 12977: Loss: 1.0524\n",
            "Epoch 3, Sample 12978: Loss: 0.2750\n",
            "Epoch 3, Sample 12979: Loss: 0.1170\n",
            "Epoch 3, Sample 12980: Loss: 0.2044\n",
            "Epoch 3, Sample 12981: Loss: 0.6990\n",
            "Epoch 3, Sample 12982: Loss: 0.0406\n",
            "Epoch 3, Sample 12983: Loss: 0.5972\n",
            "Epoch 3, Sample 12984: Loss: 1.0524\n",
            "Epoch 3, Sample 12985: Loss: 0.1250\n",
            "Epoch 3, Sample 12986: Loss: 0.0431\n",
            "Epoch 3, Sample 12987: Loss: 0.0005\n",
            "Epoch 3, Sample 12988: Loss: 0.1687\n",
            "Epoch 3, Sample 12989: Loss: 0.2759\n",
            "Epoch 3, Sample 12990: Loss: 0.6720\n",
            "Epoch 3, Sample 12991: Loss: 0.1250\n",
            "Epoch 3, Sample 12992: Loss: 0.3399\n",
            "Epoch 3, Sample 12993: Loss: 0.0267\n",
            "Epoch 3, Sample 12994: Loss: 0.5763\n",
            "Epoch 3, Sample 12995: Loss: 0.0930\n",
            "Epoch 3, Sample 12996: Loss: 0.7036\n",
            "Epoch 3, Sample 12997: Loss: 0.0026\n",
            "Epoch 3, Sample 12998: Loss: 1.0524\n",
            "Epoch 3, Sample 12999: Loss: 0.0062\n",
            "Epoch 3, Sample 13000: Loss: 0.1559\n",
            "Epoch 3, Sample 13001: Loss: 0.2044\n",
            "Epoch 3, Sample 13002: Loss: 1.0865\n",
            "Epoch 3, Sample 13003: Loss: 1.0155\n",
            "Epoch 3, Sample 13004: Loss: 0.1165\n",
            "Epoch 3, Sample 13005: Loss: 0.0026\n",
            "Epoch 3, Sample 13006: Loss: 0.0026\n",
            "Epoch 3, Sample 13007: Loss: 0.1363\n",
            "Epoch 3, Sample 13008: Loss: 0.2177\n",
            "Epoch 3, Sample 13009: Loss: 1.0524\n",
            "Epoch 3, Sample 13010: Loss: 0.1523\n",
            "Epoch 3, Sample 13011: Loss: 0.0067\n",
            "Epoch 3, Sample 13012: Loss: 0.0037\n",
            "Epoch 3, Sample 13013: Loss: 1.0524\n",
            "Epoch 3, Sample 13014: Loss: 0.2034\n",
            "Epoch 3, Sample 13015: Loss: 0.3399\n",
            "Epoch 3, Sample 13016: Loss: 0.2036\n",
            "Epoch 3, Sample 13017: Loss: 0.0947\n",
            "Epoch 3, Sample 13018: Loss: 1.0524\n",
            "Epoch 3, Sample 13019: Loss: 2.1465\n",
            "Epoch 3, Sample 13020: Loss: 0.1559\n",
            "Epoch 3, Sample 13021: Loss: 0.0715\n",
            "Epoch 3, Sample 13022: Loss: 0.2044\n",
            "Epoch 3, Sample 13023: Loss: 0.2044\n",
            "Epoch 3, Sample 13024: Loss: 0.3477\n",
            "Epoch 3, Sample 13025: Loss: 1.6672\n",
            "Epoch 3, Sample 13026: Loss: 0.5871\n",
            "Epoch 3, Sample 13027: Loss: 1.0155\n",
            "Epoch 3, Sample 13028: Loss: 0.0455\n",
            "Epoch 3, Sample 13029: Loss: 1.0155\n",
            "Epoch 3, Sample 13030: Loss: 0.0455\n",
            "Epoch 3, Sample 13031: Loss: 1.0530\n",
            "Epoch 3, Sample 13032: Loss: 0.1965\n",
            "Epoch 3, Sample 13033: Loss: 0.1387\n",
            "Epoch 3, Sample 13034: Loss: 0.3399\n",
            "Epoch 3, Sample 13035: Loss: 0.3399\n",
            "Epoch 3, Sample 13036: Loss: 0.5858\n",
            "Epoch 3, Sample 13037: Loss: 0.3805\n",
            "Epoch 3, Sample 13038: Loss: 0.3949\n",
            "Epoch 3, Sample 13039: Loss: 0.7036\n",
            "Epoch 3, Sample 13040: Loss: 0.2034\n",
            "Epoch 3, Sample 13041: Loss: 0.4845\n",
            "Epoch 3, Sample 13042: Loss: 1.0524\n",
            "Epoch 3, Sample 13043: Loss: 3.4368\n",
            "Epoch 3, Sample 13044: Loss: 0.3247\n",
            "Epoch 3, Sample 13045: Loss: 0.5871\n",
            "Epoch 3, Sample 13046: Loss: 1.3024\n",
            "Epoch 3, Sample 13047: Loss: 0.4988\n",
            "Epoch 3, Sample 13048: Loss: 0.0630\n",
            "Epoch 3, Sample 13049: Loss: 0.0000\n",
            "Epoch 3, Sample 13050: Loss: 0.2036\n",
            "Epoch 3, Sample 13051: Loss: 0.0000\n",
            "Epoch 3, Sample 13052: Loss: 0.0002\n",
            "Epoch 3, Sample 13053: Loss: 0.2034\n",
            "Epoch 3, Sample 13054: Loss: 0.2832\n",
            "Epoch 3, Sample 13055: Loss: 0.0008\n",
            "Epoch 3, Sample 13056: Loss: 0.1170\n",
            "Epoch 3, Sample 13057: Loss: 0.3441\n",
            "Epoch 3, Sample 13058: Loss: 0.0190\n",
            "Epoch 3, Sample 13059: Loss: 0.7036\n",
            "Epoch 3, Sample 13060: Loss: 0.2759\n",
            "Epoch 3, Sample 13061: Loss: 0.5858\n",
            "Epoch 3, Sample 13062: Loss: 1.0155\n",
            "Epoch 3, Sample 13063: Loss: 0.3949\n",
            "Epoch 3, Sample 13064: Loss: 1.0524\n",
            "Epoch 3, Sample 13065: Loss: 0.5310\n",
            "Epoch 3, Sample 13066: Loss: 0.6058\n",
            "Epoch 3, Sample 13067: Loss: 0.0630\n",
            "Epoch 3, Sample 13068: Loss: 0.3949\n",
            "Epoch 3, Sample 13069: Loss: 0.7036\n",
            "Epoch 3, Sample 13070: Loss: 0.2034\n",
            "Epoch 3, Sample 13071: Loss: 0.0278\n",
            "Epoch 3, Sample 13072: Loss: 0.3399\n",
            "Epoch 3, Sample 13073: Loss: 0.0246\n",
            "Epoch 3, Sample 13074: Loss: 1.0524\n",
            "Epoch 3, Sample 13075: Loss: 0.0205\n",
            "Epoch 3, Sample 13076: Loss: 0.2034\n",
            "Epoch 3, Sample 13077: Loss: 0.7036\n",
            "Epoch 3, Sample 13078: Loss: 0.3450\n",
            "Epoch 3, Sample 13079: Loss: 0.5000\n",
            "Epoch 3, Sample 13080: Loss: 0.6092\n",
            "Epoch 3, Sample 13081: Loss: 0.6755\n",
            "Epoch 3, Sample 13082: Loss: 0.0013\n",
            "Epoch 3, Sample 13083: Loss: 0.6990\n",
            "Epoch 3, Sample 13084: Loss: 0.2044\n",
            "Epoch 3, Sample 13085: Loss: 0.1014\n",
            "Epoch 3, Sample 13086: Loss: 0.5062\n",
            "Epoch 3, Sample 13087: Loss: 0.9651\n",
            "Epoch 3, Sample 13088: Loss: 0.6990\n",
            "Epoch 3, Sample 13089: Loss: 0.7453\n",
            "Epoch 3, Sample 13090: Loss: 1.6313\n",
            "Epoch 3, Sample 13091: Loss: 1.0214\n",
            "Epoch 3, Sample 13092: Loss: 0.1250\n",
            "Epoch 3, Sample 13093: Loss: 0.3399\n",
            "Epoch 3, Sample 13094: Loss: 0.0630\n",
            "Epoch 3, Sample 13095: Loss: 0.2114\n",
            "Epoch 3, Sample 13096: Loss: 0.6867\n",
            "Epoch 3, Sample 13097: Loss: 0.0108\n",
            "Epoch 3, Sample 13098: Loss: 0.5871\n",
            "Epoch 3, Sample 13099: Loss: 0.0914\n",
            "Epoch 3, Sample 13100: Loss: 1.5904\n",
            "Epoch 3, Sample 13101: Loss: 0.6101\n",
            "Epoch 3, Sample 13102: Loss: 0.5871\n",
            "Epoch 3, Sample 13103: Loss: 1.0530\n",
            "Epoch 3, Sample 13104: Loss: 0.0108\n",
            "Epoch 3, Sample 13105: Loss: 0.2044\n",
            "Epoch 3, Sample 13106: Loss: 0.1250\n",
            "Epoch 3, Sample 13107: Loss: 0.2034\n",
            "Epoch 3, Sample 13108: Loss: 0.7036\n",
            "Epoch 3, Sample 13109: Loss: 0.2057\n",
            "Epoch 3, Sample 13110: Loss: 0.2313\n",
            "Epoch 3, Sample 13111: Loss: 2.3413\n",
            "Epoch 3, Sample 13112: Loss: 0.4930\n",
            "Epoch 3, Sample 13113: Loss: 0.0707\n",
            "Epoch 3, Sample 13114: Loss: 0.6981\n",
            "Epoch 3, Sample 13115: Loss: 0.0915\n",
            "Epoch 3, Sample 13116: Loss: 0.0234\n",
            "Epoch 3, Sample 13117: Loss: 0.6990\n",
            "Epoch 3, Sample 13118: Loss: 1.0530\n",
            "Epoch 3, Sample 13119: Loss: 1.9204\n",
            "Epoch 3, Sample 13120: Loss: 0.5113\n",
            "Epoch 3, Sample 13121: Loss: 0.2044\n",
            "Epoch 3, Sample 13122: Loss: 1.5791\n",
            "Epoch 3, Sample 13123: Loss: 0.7453\n",
            "Epoch 3, Sample 13124: Loss: 0.1588\n",
            "Epoch 3, Sample 13125: Loss: 0.1170\n",
            "Epoch 3, Sample 13126: Loss: 0.1114\n",
            "Epoch 3, Sample 13127: Loss: 1.5007\n",
            "Epoch 3, Sample 13128: Loss: 0.2034\n",
            "Epoch 3, Sample 13129: Loss: 0.2034\n",
            "Epoch 3, Sample 13130: Loss: 0.4032\n",
            "Epoch 3, Sample 13131: Loss: 1.0524\n",
            "Epoch 3, Sample 13132: Loss: 0.0270\n",
            "Epoch 3, Sample 13133: Loss: 0.0026\n",
            "Epoch 3, Sample 13134: Loss: 1.0132\n",
            "Epoch 3, Sample 13135: Loss: 0.1664\n",
            "Epoch 3, Sample 13136: Loss: 0.8847\n",
            "Epoch 3, Sample 13137: Loss: 0.2639\n",
            "Epoch 3, Sample 13138: Loss: 0.3399\n",
            "Epoch 3, Sample 13139: Loss: 0.3426\n",
            "Epoch 3, Sample 13140: Loss: 0.0498\n",
            "Epoch 3, Sample 13141: Loss: 0.7453\n",
            "Epoch 3, Sample 13142: Loss: 0.0117\n",
            "Epoch 3, Sample 13143: Loss: 0.0791\n",
            "Epoch 3, Sample 13144: Loss: 0.2494\n",
            "Epoch 3, Sample 13145: Loss: 0.2044\n",
            "Epoch 3, Sample 13146: Loss: 0.1372\n",
            "Epoch 3, Sample 13147: Loss: 0.0180\n",
            "Epoch 3, Sample 13148: Loss: 0.5858\n",
            "Epoch 3, Sample 13149: Loss: 1.0155\n",
            "Epoch 3, Sample 13150: Loss: 0.0018\n",
            "Epoch 3, Sample 13151: Loss: 0.3399\n",
            "Epoch 3, Sample 13152: Loss: 0.0001\n",
            "Epoch 3, Sample 13153: Loss: 0.0001\n",
            "Epoch 3, Sample 13154: Loss: 0.0196\n",
            "Epoch 3, Sample 13155: Loss: 0.8951\n",
            "Epoch 3, Sample 13156: Loss: 5.5916\n",
            "Epoch 3, Sample 13157: Loss: 0.6880\n",
            "Epoch 3, Sample 13158: Loss: 0.0005\n",
            "Epoch 3, Sample 13159: Loss: 0.3700\n",
            "Epoch 3, Sample 13160: Loss: 0.2759\n",
            "Epoch 3, Sample 13161: Loss: 0.0545\n",
            "Epoch 3, Sample 13162: Loss: 0.1250\n",
            "Epoch 3, Sample 13163: Loss: 1.8616\n",
            "Epoch 3, Sample 13164: Loss: 0.2036\n",
            "Epoch 3, Sample 13165: Loss: 0.0102\n",
            "Epoch 3, Sample 13166: Loss: 0.0303\n",
            "Epoch 3, Sample 13167: Loss: 0.0229\n",
            "Epoch 3, Sample 13168: Loss: 0.2176\n",
            "Epoch 3, Sample 13169: Loss: 0.1625\n",
            "Epoch 3, Sample 13170: Loss: 0.3539\n",
            "Epoch 3, Sample 13171: Loss: 0.7036\n",
            "Epoch 3, Sample 13172: Loss: 0.0026\n",
            "Epoch 3, Sample 13173: Loss: 0.0000\n",
            "Epoch 3, Sample 13174: Loss: 0.4820\n",
            "Epoch 3, Sample 13175: Loss: 0.1170\n",
            "Epoch 3, Sample 13176: Loss: 1.0155\n",
            "Epoch 3, Sample 13177: Loss: 1.7082\n",
            "Epoch 3, Sample 13178: Loss: 7.9882\n",
            "Epoch 3, Sample 13179: Loss: 0.0625\n",
            "Epoch 3, Sample 13180: Loss: 0.1170\n",
            "Epoch 3, Sample 13181: Loss: 0.0026\n",
            "Epoch 3, Sample 13182: Loss: 0.1838\n",
            "Epoch 3, Sample 13183: Loss: 0.6990\n",
            "Epoch 3, Sample 13184: Loss: 0.3441\n",
            "Epoch 3, Sample 13185: Loss: 0.0026\n",
            "Epoch 3, Sample 13186: Loss: 0.2160\n",
            "Epoch 3, Sample 13187: Loss: 1.2504\n",
            "Epoch 3, Sample 13188: Loss: 0.0438\n",
            "Epoch 3, Sample 13189: Loss: 0.7036\n",
            "Epoch 3, Sample 13190: Loss: 1.0524\n",
            "Epoch 3, Sample 13191: Loss: 0.0117\n",
            "Epoch 3, Sample 13192: Loss: 0.0006\n",
            "Epoch 3, Sample 13193: Loss: 1.0530\n",
            "Epoch 3, Sample 13194: Loss: 1.0530\n",
            "Epoch 3, Sample 13195: Loss: 0.5000\n",
            "Epoch 3, Sample 13196: Loss: 0.2759\n",
            "Epoch 3, Sample 13197: Loss: 0.4607\n",
            "Epoch 3, Sample 13198: Loss: 0.6120\n",
            "Epoch 3, Sample 13199: Loss: 1.0524\n",
            "Epoch 3, Sample 13200: Loss: 0.0062\n",
            "Epoch 3, Sample 13201: Loss: 1.0530\n",
            "Epoch 3, Sample 13202: Loss: 0.2832\n",
            "Epoch 3, Sample 13203: Loss: 0.0630\n",
            "Epoch 3, Sample 13204: Loss: 0.1880\n",
            "Epoch 3, Sample 13205: Loss: 0.1838\n",
            "Epoch 3, Sample 13206: Loss: 0.3568\n",
            "Epoch 3, Sample 13207: Loss: 0.0114\n",
            "Epoch 3, Sample 13208: Loss: 0.2044\n",
            "Epoch 3, Sample 13209: Loss: 0.2032\n",
            "Epoch 3, Sample 13210: Loss: 3.3246\n",
            "Epoch 3, Sample 13211: Loss: 0.5039\n",
            "Epoch 3, Sample 13212: Loss: 0.0582\n",
            "Epoch 3, Sample 13213: Loss: 0.3433\n",
            "Epoch 3, Sample 13214: Loss: 1.0155\n",
            "Epoch 3, Sample 13215: Loss: 1.3842\n",
            "Epoch 3, Sample 13216: Loss: 0.4634\n",
            "Epoch 3, Sample 13217: Loss: 0.2418\n",
            "Epoch 3, Sample 13218: Loss: 0.7453\n",
            "Epoch 3, Sample 13219: Loss: 0.0067\n",
            "Epoch 3, Sample 13220: Loss: 0.0026\n",
            "Epoch 3, Sample 13221: Loss: 1.0524\n",
            "Epoch 3, Sample 13222: Loss: 5.9530\n",
            "Epoch 3, Sample 13223: Loss: 0.2219\n",
            "Epoch 3, Sample 13224: Loss: 0.0026\n",
            "Epoch 3, Sample 13225: Loss: 0.0212\n",
            "Epoch 3, Sample 13226: Loss: 0.0026\n",
            "Epoch 3, Sample 13227: Loss: 0.7036\n",
            "Epoch 3, Sample 13228: Loss: 0.0243\n",
            "Epoch 3, Sample 13229: Loss: 0.3598\n",
            "Epoch 3, Sample 13230: Loss: 0.0006\n",
            "Epoch 3, Sample 13231: Loss: 0.2639\n",
            "Epoch 3, Sample 13232: Loss: 1.0155\n",
            "Epoch 3, Sample 13233: Loss: 1.5019\n",
            "Epoch 3, Sample 13234: Loss: 0.0001\n",
            "Epoch 3, Sample 13235: Loss: 0.2032\n",
            "Epoch 3, Sample 13236: Loss: 0.0915\n",
            "Epoch 3, Sample 13237: Loss: 0.6092\n",
            "Epoch 3, Sample 13238: Loss: 10.3238\n",
            "Epoch 3, Sample 13239: Loss: 0.1114\n",
            "Epoch 3, Sample 13240: Loss: 6.9441\n",
            "Epoch 3, Sample 13241: Loss: 0.0026\n",
            "Epoch 3, Sample 13242: Loss: 0.0018\n",
            "Epoch 3, Sample 13243: Loss: 0.2044\n",
            "Epoch 3, Sample 13244: Loss: 0.4590\n",
            "Epoch 3, Sample 13245: Loss: 0.0967\n",
            "Epoch 3, Sample 13246: Loss: 0.1559\n",
            "Epoch 3, Sample 13247: Loss: 0.1559\n",
            "Epoch 3, Sample 13248: Loss: 0.3332\n",
            "Epoch 3, Sample 13249: Loss: 0.1250\n",
            "Epoch 3, Sample 13250: Loss: 0.0001\n",
            "Epoch 3, Sample 13251: Loss: 1.0524\n",
            "Epoch 3, Sample 13252: Loss: 5.3451\n",
            "Epoch 3, Sample 13253: Loss: 0.0026\n",
            "Epoch 3, Sample 13254: Loss: 0.4877\n",
            "Epoch 3, Sample 13255: Loss: 0.3399\n",
            "Epoch 3, Sample 13256: Loss: 0.2483\n",
            "Epoch 3, Sample 13257: Loss: 0.0009\n",
            "Epoch 3, Sample 13258: Loss: 0.0915\n",
            "Epoch 3, Sample 13259: Loss: 0.4841\n",
            "Epoch 3, Sample 13260: Loss: 1.0524\n",
            "Epoch 3, Sample 13261: Loss: 0.0026\n",
            "Epoch 3, Sample 13262: Loss: 0.4032\n",
            "Epoch 3, Sample 13263: Loss: 0.3399\n",
            "Epoch 3, Sample 13264: Loss: 0.4611\n",
            "Epoch 3, Sample 13265: Loss: 0.0000\n",
            "Epoch 3, Sample 13266: Loss: 5.5857\n",
            "Epoch 3, Sample 13267: Loss: 0.1114\n",
            "Epoch 3, Sample 13268: Loss: 0.3450\n",
            "Epoch 3, Sample 13269: Loss: 0.5858\n",
            "Epoch 3, Sample 13270: Loss: 0.0000\n",
            "Epoch 3, Sample 13271: Loss: 0.2759\n",
            "Epoch 3, Sample 13272: Loss: 0.0008\n",
            "Epoch 3, Sample 13273: Loss: 0.2759\n",
            "Epoch 3, Sample 13274: Loss: 0.1559\n",
            "Epoch 3, Sample 13275: Loss: 1.0524\n",
            "Epoch 3, Sample 13276: Loss: 0.2044\n",
            "Epoch 3, Sample 13277: Loss: 0.0364\n",
            "Epoch 3, Sample 13278: Loss: 0.3450\n",
            "Epoch 3, Sample 13279: Loss: 1.1569\n",
            "Epoch 3, Sample 13280: Loss: 1.5916\n",
            "Epoch 3, Sample 13281: Loss: 1.0524\n",
            "Epoch 3, Sample 13282: Loss: 0.2759\n",
            "Epoch 3, Sample 13283: Loss: 0.3399\n",
            "Epoch 3, Sample 13284: Loss: 0.6139\n",
            "Epoch 3, Sample 13285: Loss: 1.0155\n",
            "Epoch 3, Sample 13286: Loss: 0.0486\n",
            "Epoch 3, Sample 13287: Loss: 0.3399\n",
            "Epoch 3, Sample 13288: Loss: 0.1687\n",
            "Epoch 3, Sample 13289: Loss: 0.0026\n",
            "Epoch 3, Sample 13290: Loss: 0.2219\n",
            "Epoch 3, Sample 13291: Loss: 1.0524\n",
            "Epoch 3, Sample 13292: Loss: 0.1250\n",
            "Epoch 3, Sample 13293: Loss: 0.2558\n",
            "Epoch 3, Sample 13294: Loss: 0.4906\n",
            "Epoch 3, Sample 13295: Loss: 0.5858\n",
            "Epoch 3, Sample 13296: Loss: 0.3399\n",
            "Epoch 3, Sample 13297: Loss: 0.0274\n",
            "Epoch 3, Sample 13298: Loss: 0.5858\n",
            "Epoch 3, Sample 13299: Loss: 0.0108\n",
            "Epoch 3, Sample 13300: Loss: 0.2639\n",
            "Epoch 3, Sample 13301: Loss: 0.2941\n",
            "Epoch 3, Sample 13302: Loss: 0.2044\n",
            "Epoch 3, Sample 13303: Loss: 0.0018\n",
            "Epoch 3, Sample 13304: Loss: 0.4799\n",
            "Epoch 3, Sample 13305: Loss: 0.1791\n",
            "Epoch 3, Sample 13306: Loss: 0.0000\n",
            "Epoch 3, Sample 13307: Loss: 0.0505\n",
            "Epoch 3, Sample 13308: Loss: 0.8951\n",
            "Epoch 3, Sample 13309: Loss: 1.4865\n",
            "Epoch 3, Sample 13310: Loss: 0.5998\n",
            "Epoch 3, Sample 13311: Loss: 1.0053\n",
            "Epoch 3, Sample 13312: Loss: 1.0070\n",
            "Epoch 3, Sample 13313: Loss: 0.2044\n",
            "Epoch 3, Sample 13314: Loss: 0.2044\n",
            "Epoch 3, Sample 13315: Loss: 0.2044\n",
            "Epoch 3, Sample 13316: Loss: 0.3166\n",
            "Epoch 3, Sample 13317: Loss: 4.3474\n",
            "Epoch 3, Sample 13318: Loss: 0.0001\n",
            "Epoch 3, Sample 13319: Loss: 0.4930\n",
            "Epoch 3, Sample 13320: Loss: 0.1268\n",
            "Epoch 3, Sample 13321: Loss: 4.4924\n",
            "Epoch 3, Sample 13322: Loss: 0.4414\n",
            "Epoch 3, Sample 13323: Loss: 9.7668\n",
            "Epoch 3, Sample 13324: Loss: 1.0524\n",
            "Epoch 3, Sample 13325: Loss: 0.7036\n",
            "Epoch 3, Sample 13326: Loss: 0.9591\n",
            "Epoch 3, Sample 13327: Loss: 0.2005\n",
            "Epoch 3, Sample 13328: Loss: 0.0205\n",
            "Epoch 3, Sample 13329: Loss: 0.2489\n",
            "Epoch 3, Sample 13330: Loss: 0.0376\n",
            "Epoch 3, Sample 13331: Loss: 6.5695\n",
            "Epoch 3, Sample 13332: Loss: 0.3949\n",
            "Epoch 3, Sample 13333: Loss: 0.2759\n",
            "Epoch 3, Sample 13334: Loss: 1.0530\n",
            "Epoch 3, Sample 13335: Loss: 0.0018\n",
            "Epoch 3, Sample 13336: Loss: 0.0758\n",
            "Epoch 3, Sample 13337: Loss: 0.8951\n",
            "Epoch 3, Sample 13338: Loss: 1.0155\n",
            "Epoch 3, Sample 13339: Loss: 0.0018\n",
            "Epoch 3, Sample 13340: Loss: 0.2034\n",
            "Epoch 3, Sample 13341: Loss: 0.2832\n",
            "Epoch 3, Sample 13342: Loss: 5.6766\n",
            "Epoch 3, Sample 13343: Loss: 0.0933\n",
            "Epoch 3, Sample 13344: Loss: 2.7647\n",
            "Epoch 3, Sample 13345: Loss: 1.0524\n",
            "Epoch 3, Sample 13346: Loss: 0.6990\n",
            "Epoch 3, Sample 13347: Loss: 7.0086\n",
            "Epoch 3, Sample 13348: Loss: 3.9977\n",
            "Epoch 3, Sample 13349: Loss: 0.0595\n",
            "Epoch 3, Sample 13350: Loss: 0.3441\n",
            "Epoch 3, Sample 13351: Loss: 0.3399\n",
            "Epoch 3, Sample 13352: Loss: 1.0530\n",
            "Epoch 3, Sample 13353: Loss: 0.2713\n",
            "Epoch 3, Sample 13354: Loss: 1.0033\n",
            "Epoch 3, Sample 13355: Loss: 2.9652\n",
            "Epoch 3, Sample 13356: Loss: 3.6044\n",
            "Epoch 3, Sample 13357: Loss: 0.0060\n",
            "Epoch 3, Sample 13358: Loss: 1.2275\n",
            "Epoch 3, Sample 13359: Loss: 0.3235\n",
            "Epoch 3, Sample 13360: Loss: 0.2036\n",
            "Epoch 3, Sample 13361: Loss: 0.5972\n",
            "Epoch 3, Sample 13362: Loss: 0.0018\n",
            "Epoch 3, Sample 13363: Loss: 0.0838\n",
            "Epoch 3, Sample 13364: Loss: 0.1170\n",
            "Epoch 3, Sample 13365: Loss: 0.5858\n",
            "Epoch 3, Sample 13366: Loss: 0.3441\n",
            "Epoch 3, Sample 13367: Loss: 1.0524\n",
            "Epoch 3, Sample 13368: Loss: 0.2759\n",
            "Epoch 3, Sample 13369: Loss: 0.9359\n",
            "Epoch 3, Sample 13370: Loss: 2.3143\n",
            "Epoch 3, Sample 13371: Loss: 0.3128\n",
            "Epoch 3, Sample 13372: Loss: 0.3441\n",
            "Epoch 3, Sample 13373: Loss: 0.0018\n",
            "Epoch 3, Sample 13374: Loss: 0.0630\n",
            "Epoch 3, Sample 13375: Loss: 0.2044\n",
            "Epoch 3, Sample 13376: Loss: 0.0212\n",
            "Epoch 3, Sample 13377: Loss: 0.0026\n",
            "Epoch 3, Sample 13378: Loss: 0.0539\n",
            "Epoch 3, Sample 13379: Loss: 0.3399\n",
            "Epoch 3, Sample 13380: Loss: 0.3677\n",
            "Epoch 3, Sample 13381: Loss: 0.8841\n",
            "Epoch 3, Sample 13382: Loss: 0.7036\n",
            "Epoch 3, Sample 13383: Loss: 0.2044\n",
            "Epoch 3, Sample 13384: Loss: 0.0405\n",
            "Epoch 3, Sample 13385: Loss: 0.4799\n",
            "Epoch 3, Sample 13386: Loss: 0.0032\n",
            "Epoch 3, Sample 13387: Loss: 0.0005\n",
            "Epoch 3, Sample 13388: Loss: 0.0025\n",
            "Epoch 3, Sample 13389: Loss: 0.0640\n",
            "Epoch 3, Sample 13390: Loss: 0.0148\n",
            "Epoch 3, Sample 13391: Loss: 0.3441\n",
            "Epoch 3, Sample 13392: Loss: 0.3399\n",
            "Epoch 3, Sample 13393: Loss: 1.0698\n",
            "Epoch 3, Sample 13394: Loss: 2.9283\n",
            "Epoch 3, Sample 13395: Loss: 0.3949\n",
            "Epoch 3, Sample 13396: Loss: 2.4323\n",
            "Epoch 3, Sample 13397: Loss: 0.3506\n",
            "Epoch 3, Sample 13398: Loss: 0.0513\n",
            "Epoch 3, Sample 13399: Loss: 1.1884\n",
            "Epoch 3, Sample 13400: Loss: 0.9367\n",
            "Epoch 3, Sample 13401: Loss: 0.5196\n",
            "Epoch 3, Sample 13402: Loss: 0.2759\n",
            "Epoch 3, Sample 13403: Loss: 0.3399\n",
            "Epoch 3, Sample 13404: Loss: 0.0420\n",
            "Epoch 3, Sample 13405: Loss: 0.3628\n",
            "Epoch 3, Sample 13406: Loss: 0.9143\n",
            "Epoch 3, Sample 13407: Loss: 0.7036\n",
            "Epoch 3, Sample 13408: Loss: 1.0530\n",
            "Epoch 3, Sample 13409: Loss: 0.3399\n",
            "Epoch 3, Sample 13410: Loss: 0.0303\n",
            "Epoch 3, Sample 13411: Loss: 0.0018\n",
            "Epoch 3, Sample 13412: Loss: 0.1523\n",
            "Epoch 3, Sample 13413: Loss: 0.2044\n",
            "Epoch 3, Sample 13414: Loss: 1.0530\n",
            "Epoch 3, Sample 13415: Loss: 0.2832\n",
            "Epoch 3, Sample 13416: Loss: 1.0530\n",
            "Epoch 3, Sample 13417: Loss: 0.3399\n",
            "Epoch 3, Sample 13418: Loss: 0.2962\n",
            "Epoch 3, Sample 13419: Loss: 0.8211\n",
            "Epoch 3, Sample 13420: Loss: 0.6969\n",
            "Epoch 3, Sample 13421: Loss: 0.1559\n",
            "Epoch 3, Sample 13422: Loss: 1.0155\n",
            "Epoch 3, Sample 13423: Loss: 0.3598\n",
            "Epoch 3, Sample 13424: Loss: 1.0524\n",
            "Epoch 3, Sample 13425: Loss: 0.2483\n",
            "Epoch 3, Sample 13426: Loss: 1.0155\n",
            "Epoch 3, Sample 13427: Loss: 0.1175\n",
            "Epoch 3, Sample 13428: Loss: 1.1383\n",
            "Epoch 3, Sample 13429: Loss: 1.5542\n",
            "Epoch 3, Sample 13430: Loss: 0.1372\n",
            "Epoch 3, Sample 13431: Loss: 0.0018\n",
            "Epoch 3, Sample 13432: Loss: 0.0018\n",
            "Epoch 3, Sample 13433: Loss: 0.2340\n",
            "Epoch 3, Sample 13434: Loss: 0.2639\n",
            "Epoch 3, Sample 13435: Loss: 0.0000\n",
            "Epoch 3, Sample 13436: Loss: 0.1091\n",
            "Epoch 3, Sample 13437: Loss: 0.2034\n",
            "Epoch 3, Sample 13438: Loss: 0.2543\n",
            "Epoch 3, Sample 13439: Loss: 0.1496\n",
            "Epoch 3, Sample 13440: Loss: 2.7342\n",
            "Epoch 3, Sample 13441: Loss: 0.7036\n",
            "Epoch 3, Sample 13442: Loss: 0.3399\n",
            "Epoch 3, Sample 13443: Loss: 1.0524\n",
            "Epoch 3, Sample 13444: Loss: 0.3399\n",
            "Epoch 3, Sample 13445: Loss: 0.0026\n",
            "Epoch 3, Sample 13446: Loss: 0.3764\n",
            "Epoch 3, Sample 13447: Loss: 0.4493\n",
            "Epoch 3, Sample 13448: Loss: 0.0062\n",
            "Epoch 3, Sample 13449: Loss: 0.0117\n",
            "Epoch 3, Sample 13450: Loss: 0.1326\n",
            "Epoch 3, Sample 13451: Loss: 0.2219\n",
            "Epoch 3, Sample 13452: Loss: 0.7036\n",
            "Epoch 3, Sample 13453: Loss: 3.3666\n",
            "Epoch 3, Sample 13454: Loss: 0.2639\n",
            "Epoch 3, Sample 13455: Loss: 0.0630\n",
            "Epoch 3, Sample 13456: Loss: 0.1066\n",
            "Epoch 3, Sample 13457: Loss: 0.0429\n",
            "Epoch 3, Sample 13458: Loss: 1.3489\n",
            "Epoch 3, Sample 13459: Loss: 0.8197\n",
            "Epoch 3, Sample 13460: Loss: 0.0205\n",
            "Epoch 3, Sample 13461: Loss: 0.3159\n",
            "Epoch 3, Sample 13462: Loss: 0.7036\n",
            "Epoch 3, Sample 13463: Loss: 4.5516\n",
            "Epoch 3, Sample 13464: Loss: 0.7036\n",
            "Epoch 3, Sample 13465: Loss: 0.1252\n",
            "Epoch 3, Sample 13466: Loss: 0.2646\n",
            "Epoch 3, Sample 13467: Loss: 0.0915\n",
            "Epoch 3, Sample 13468: Loss: 0.3399\n",
            "Epoch 3, Sample 13469: Loss: 0.0018\n",
            "Epoch 3, Sample 13470: Loss: 0.0182\n",
            "Epoch 3, Sample 13471: Loss: 0.0801\n",
            "Epoch 3, Sample 13472: Loss: 0.4930\n",
            "Epoch 3, Sample 13473: Loss: 0.0103\n",
            "Epoch 3, Sample 13474: Loss: 0.0000\n",
            "Epoch 3, Sample 13475: Loss: 0.0026\n",
            "Epoch 3, Sample 13476: Loss: 0.3126\n",
            "Epoch 3, Sample 13477: Loss: 0.3260\n",
            "Epoch 3, Sample 13478: Loss: 1.0524\n",
            "Epoch 3, Sample 13479: Loss: 0.6990\n",
            "Epoch 3, Sample 13480: Loss: 0.3399\n",
            "Epoch 3, Sample 13481: Loss: 0.7036\n",
            "Epoch 3, Sample 13482: Loss: 0.0306\n",
            "Epoch 3, Sample 13483: Loss: 0.3399\n",
            "Epoch 3, Sample 13484: Loss: 0.0838\n",
            "Epoch 3, Sample 13485: Loss: 0.7036\n",
            "Epoch 3, Sample 13486: Loss: 0.5326\n",
            "Epoch 3, Sample 13487: Loss: 0.2727\n",
            "Epoch 3, Sample 13488: Loss: 0.0099\n",
            "Epoch 3, Sample 13489: Loss: 0.1989\n",
            "Epoch 3, Sample 13490: Loss: 1.8355\n",
            "Epoch 3, Sample 13491: Loss: 1.0155\n",
            "Epoch 3, Sample 13492: Loss: 0.2044\n",
            "Epoch 3, Sample 13493: Loss: 0.2759\n",
            "Epoch 3, Sample 13494: Loss: 0.1639\n",
            "Epoch 3, Sample 13495: Loss: 0.2759\n",
            "Epoch 3, Sample 13496: Loss: 13.5304\n",
            "Epoch 3, Sample 13497: Loss: 0.1170\n",
            "Epoch 3, Sample 13498: Loss: 0.9367\n",
            "Epoch 3, Sample 13499: Loss: 0.0013\n",
            "Epoch 3, Sample 13500: Loss: 0.5660\n",
            "Epoch 3, Sample 13501: Loss: 0.2032\n",
            "Epoch 3, Sample 13502: Loss: 0.9096\n",
            "Epoch 3, Sample 13503: Loss: 0.2044\n",
            "Epoch 3, Sample 13504: Loss: 0.1337\n",
            "Epoch 3, Sample 13505: Loss: 0.2219\n",
            "Epoch 3, Sample 13506: Loss: 0.1569\n",
            "Epoch 3, Sample 13507: Loss: 0.1559\n",
            "Epoch 3, Sample 13508: Loss: 0.6990\n",
            "Epoch 3, Sample 13509: Loss: 0.3441\n",
            "Epoch 3, Sample 13510: Loss: 0.4663\n",
            "Epoch 3, Sample 13511: Loss: 0.2568\n",
            "Epoch 3, Sample 13512: Loss: 0.4799\n",
            "Epoch 3, Sample 13513: Loss: 1.0524\n",
            "Epoch 3, Sample 13514: Loss: 0.2034\n",
            "Epoch 3, Sample 13515: Loss: 0.4930\n",
            "Epoch 3, Sample 13516: Loss: 0.1250\n",
            "Epoch 3, Sample 13517: Loss: 0.4930\n",
            "Epoch 3, Sample 13518: Loss: 0.6839\n",
            "Epoch 3, Sample 13519: Loss: 0.0001\n",
            "Epoch 3, Sample 13520: Loss: 0.0630\n",
            "Epoch 3, Sample 13521: Loss: 0.0212\n",
            "Epoch 3, Sample 13522: Loss: 0.2704\n",
            "Epoch 3, Sample 13523: Loss: 0.5062\n",
            "Epoch 3, Sample 13524: Loss: 0.0026\n",
            "Epoch 3, Sample 13525: Loss: 0.0026\n",
            "Epoch 3, Sample 13526: Loss: 0.5284\n",
            "Epoch 3, Sample 13527: Loss: 0.3949\n",
            "Epoch 3, Sample 13528: Loss: 0.2044\n",
            "Epoch 3, Sample 13529: Loss: 0.3626\n",
            "Epoch 3, Sample 13530: Loss: 0.0018\n",
            "Epoch 3, Sample 13531: Loss: 0.7036\n",
            "Epoch 3, Sample 13532: Loss: 1.0285\n",
            "Epoch 3, Sample 13533: Loss: 0.1248\n",
            "Epoch 3, Sample 13534: Loss: 0.5858\n",
            "Epoch 3, Sample 13535: Loss: 0.0460\n",
            "Epoch 3, Sample 13536: Loss: 0.4799\n",
            "Epoch 3, Sample 13537: Loss: 0.6990\n",
            "Epoch 3, Sample 13538: Loss: 0.0001\n",
            "Epoch 3, Sample 13539: Loss: 0.5871\n",
            "Epoch 3, Sample 13540: Loss: 0.0234\n",
            "Epoch 3, Sample 13541: Loss: 0.0875\n",
            "Epoch 3, Sample 13542: Loss: 0.0258\n",
            "Epoch 3, Sample 13543: Loss: 0.2558\n",
            "Epoch 3, Sample 13544: Loss: 2.3209\n",
            "Epoch 3, Sample 13545: Loss: 1.0524\n",
            "Epoch 3, Sample 13546: Loss: 0.3758\n",
            "Epoch 3, Sample 13547: Loss: 1.0530\n",
            "Epoch 3, Sample 13548: Loss: 0.5000\n",
            "Epoch 3, Sample 13549: Loss: 0.0108\n",
            "Epoch 3, Sample 13550: Loss: 0.3441\n",
            "Epoch 3, Sample 13551: Loss: 0.0475\n",
            "Epoch 3, Sample 13552: Loss: 0.1225\n",
            "Epoch 3, Sample 13553: Loss: 0.7186\n",
            "Epoch 3, Sample 13554: Loss: 0.2044\n",
            "Epoch 3, Sample 13555: Loss: 0.0060\n",
            "Epoch 3, Sample 13556: Loss: 0.4353\n",
            "Epoch 3, Sample 13557: Loss: 1.4777\n",
            "Epoch 3, Sample 13558: Loss: 0.0018\n",
            "Epoch 3, Sample 13559: Loss: 1.0266\n",
            "Epoch 3, Sample 13560: Loss: 0.1250\n",
            "Epoch 3, Sample 13561: Loss: 0.1170\n",
            "Epoch 3, Sample 13562: Loss: 1.0524\n",
            "Epoch 3, Sample 13563: Loss: 0.3506\n",
            "Epoch 3, Sample 13564: Loss: 0.0838\n",
            "Epoch 3, Sample 13565: Loss: 0.7922\n",
            "Epoch 3, Sample 13566: Loss: 0.6152\n",
            "Epoch 3, Sample 13567: Loss: 3.4956\n",
            "Epoch 3, Sample 13568: Loss: 0.0915\n",
            "Epoch 3, Sample 13569: Loss: 0.2044\n",
            "Epoch 3, Sample 13570: Loss: 1.0266\n",
            "Epoch 3, Sample 13571: Loss: 0.0139\n",
            "Epoch 3, Sample 13572: Loss: 0.0487\n",
            "Epoch 3, Sample 13573: Loss: 1.7195\n",
            "Epoch 3, Sample 13574: Loss: 0.5196\n",
            "Epoch 3, Sample 13575: Loss: 0.8951\n",
            "Epoch 3, Sample 13576: Loss: 0.3247\n",
            "Epoch 3, Sample 13577: Loss: 0.0026\n",
            "Epoch 3, Sample 13578: Loss: 0.0000\n",
            "Epoch 3, Sample 13579: Loss: 0.2036\n",
            "Epoch 3, Sample 13580: Loss: 0.0205\n",
            "Epoch 3, Sample 13581: Loss: 0.3399\n",
            "Epoch 3, Sample 13582: Loss: 0.0489\n",
            "Epoch 3, Sample 13583: Loss: 0.2044\n",
            "Epoch 3, Sample 13584: Loss: 0.3399\n",
            "Epoch 3, Sample 13585: Loss: 1.5485\n",
            "Epoch 3, Sample 13586: Loss: 0.0025\n",
            "Epoch 3, Sample 13587: Loss: 0.8951\n",
            "Epoch 3, Sample 13588: Loss: 0.2851\n",
            "Epoch 3, Sample 13589: Loss: 0.0031\n",
            "Epoch 3, Sample 13590: Loss: 0.2759\n",
            "Epoch 3, Sample 13591: Loss: 0.0398\n",
            "Epoch 3, Sample 13592: Loss: 0.7486\n",
            "Epoch 3, Sample 13593: Loss: 1.0214\n",
            "Epoch 3, Sample 13594: Loss: 0.3441\n",
            "Epoch 3, Sample 13595: Loss: 0.2832\n",
            "Epoch 3, Sample 13596: Loss: 0.2034\n",
            "Epoch 3, Sample 13597: Loss: 0.2855\n",
            "Epoch 3, Sample 13598: Loss: 0.1843\n",
            "Epoch 3, Sample 13599: Loss: 0.0148\n",
            "Epoch 3, Sample 13600: Loss: 0.0026\n",
            "Epoch 3, Sample 13601: Loss: 0.4930\n",
            "Epoch 3, Sample 13602: Loss: 0.0001\n",
            "Epoch 3, Sample 13603: Loss: 0.1250\n",
            "Epoch 3, Sample 13604: Loss: 0.0303\n",
            "Epoch 3, Sample 13605: Loss: 0.0456\n",
            "Epoch 3, Sample 13606: Loss: 0.2044\n",
            "Epoch 3, Sample 13607: Loss: 0.0915\n",
            "Epoch 3, Sample 13608: Loss: 0.0084\n",
            "Epoch 3, Sample 13609: Loss: 0.0028\n",
            "Epoch 3, Sample 13610: Loss: 0.2340\n",
            "Epoch 3, Sample 13611: Loss: 0.0026\n",
            "Epoch 3, Sample 13612: Loss: 0.3938\n",
            "Epoch 3, Sample 13613: Loss: 0.0042\n",
            "Epoch 3, Sample 13614: Loss: 2.3064\n",
            "Epoch 3, Sample 13615: Loss: 0.0787\n",
            "Epoch 3, Sample 13616: Loss: 1.0524\n",
            "Epoch 3, Sample 13617: Loss: 0.0630\n",
            "Epoch 3, Sample 13618: Loss: 0.0026\n",
            "Epoch 3, Sample 13619: Loss: 0.2034\n",
            "Epoch 3, Sample 13620: Loss: 3.4934\n",
            "Epoch 3, Sample 13621: Loss: 0.0026\n",
            "Epoch 3, Sample 13622: Loss: 0.1250\n",
            "Epoch 3, Sample 13623: Loss: 0.0102\n",
            "Epoch 3, Sample 13624: Loss: 0.6990\n",
            "Epoch 3, Sample 13625: Loss: 0.4367\n",
            "Epoch 3, Sample 13626: Loss: 0.0535\n",
            "Epoch 3, Sample 13627: Loss: 0.0018\n",
            "Epoch 3, Sample 13628: Loss: 2.7331\n",
            "Epoch 3, Sample 13629: Loss: 0.1508\n",
            "Epoch 3, Sample 13630: Loss: 0.1372\n",
            "Epoch 3, Sample 13631: Loss: 3.2908\n",
            "Epoch 3, Sample 13632: Loss: 0.0002\n",
            "Epoch 3, Sample 13633: Loss: 0.3758\n",
            "Epoch 3, Sample 13634: Loss: 0.3441\n",
            "Epoch 3, Sample 13635: Loss: 0.1250\n",
            "Epoch 3, Sample 13636: Loss: 0.3648\n",
            "Epoch 3, Sample 13637: Loss: 0.1508\n",
            "Epoch 3, Sample 13638: Loss: 1.0524\n",
            "Epoch 3, Sample 13639: Loss: 0.9367\n",
            "Epoch 3, Sample 13640: Loss: 1.0266\n",
            "Epoch 3, Sample 13641: Loss: 1.0524\n",
            "Epoch 3, Sample 13642: Loss: 0.1523\n",
            "Epoch 3, Sample 13643: Loss: 0.3399\n",
            "Epoch 3, Sample 13644: Loss: 1.0524\n",
            "Epoch 3, Sample 13645: Loss: 1.5631\n",
            "Epoch 3, Sample 13646: Loss: 0.7547\n",
            "Epoch 3, Sample 13647: Loss: 0.3441\n",
            "Epoch 3, Sample 13648: Loss: 0.5858\n",
            "Epoch 3, Sample 13649: Loss: 0.0108\n",
            "Epoch 3, Sample 13650: Loss: 0.8951\n",
            "Epoch 3, Sample 13651: Loss: 0.7036\n",
            "Epoch 3, Sample 13652: Loss: 0.0026\n",
            "Epoch 3, Sample 13653: Loss: 0.5917\n",
            "Epoch 3, Sample 13654: Loss: 0.1082\n",
            "Epoch 3, Sample 13655: Loss: 0.0915\n",
            "Epoch 3, Sample 13656: Loss: 1.0524\n",
            "Epoch 3, Sample 13657: Loss: 1.2933\n",
            "Epoch 3, Sample 13658: Loss: 0.1588\n",
            "Epoch 3, Sample 13659: Loss: 0.3450\n",
            "Epoch 3, Sample 13660: Loss: 0.2759\n",
            "Epoch 3, Sample 13661: Loss: 0.0017\n",
            "Epoch 3, Sample 13662: Loss: 0.0026\n",
            "Epoch 3, Sample 13663: Loss: 0.2778\n",
            "Epoch 3, Sample 13664: Loss: 0.0962\n",
            "Epoch 3, Sample 13665: Loss: 0.0000\n",
            "Epoch 3, Sample 13666: Loss: 0.2759\n",
            "Epoch 3, Sample 13667: Loss: 0.4841\n",
            "Epoch 3, Sample 13668: Loss: 0.8951\n",
            "Epoch 3, Sample 13669: Loss: 1.0155\n",
            "Epoch 3, Sample 13670: Loss: 0.0026\n",
            "Epoch 3, Sample 13671: Loss: 0.4611\n",
            "Epoch 3, Sample 13672: Loss: 0.3438\n",
            "Epoch 3, Sample 13673: Loss: 0.9469\n",
            "Epoch 3, Sample 13674: Loss: 0.5525\n",
            "Epoch 3, Sample 13675: Loss: 12.9441\n",
            "Epoch 3, Sample 13676: Loss: 0.7036\n",
            "Epoch 3, Sample 13677: Loss: 1.5098\n",
            "Epoch 3, Sample 13678: Loss: 2.0353\n",
            "Epoch 3, Sample 13679: Loss: 0.4611\n",
            "Epoch 3, Sample 13680: Loss: 0.5196\n",
            "Epoch 3, Sample 13681: Loss: 0.7666\n",
            "Epoch 3, Sample 13682: Loss: 0.2759\n",
            "Epoch 3, Sample 13683: Loss: 7.3726\n",
            "Epoch 3, Sample 13684: Loss: 0.0426\n",
            "Epoch 3, Sample 13685: Loss: 2.3999\n",
            "Epoch 3, Sample 13686: Loss: 0.4799\n",
            "Epoch 3, Sample 13687: Loss: 0.5744\n",
            "Epoch 3, Sample 13688: Loss: 0.5972\n",
            "Epoch 3, Sample 13689: Loss: 0.0026\n",
            "Epoch 3, Sample 13690: Loss: 0.3758\n",
            "Epoch 3, Sample 13691: Loss: 0.3441\n",
            "Epoch 3, Sample 13692: Loss: 0.0026\n",
            "Epoch 3, Sample 13693: Loss: 0.7036\n",
            "Epoch 3, Sample 13694: Loss: 0.3568\n",
            "Epoch 3, Sample 13695: Loss: 0.1627\n",
            "Epoch 3, Sample 13696: Loss: 0.1246\n",
            "Epoch 3, Sample 13697: Loss: 0.2034\n",
            "Epoch 3, Sample 13698: Loss: 0.2219\n",
            "Epoch 3, Sample 13699: Loss: 0.5887\n",
            "Epoch 3, Sample 13700: Loss: 0.0915\n",
            "Epoch 3, Sample 13701: Loss: 0.4032\n",
            "Epoch 3, Sample 13702: Loss: 0.3402\n",
            "Epoch 3, Sample 13703: Loss: 0.7036\n",
            "Epoch 3, Sample 13704: Loss: 0.0084\n",
            "Epoch 3, Sample 13705: Loss: 0.2034\n",
            "Epoch 3, Sample 13706: Loss: 0.0006\n",
            "Epoch 3, Sample 13707: Loss: 0.0005\n",
            "Epoch 3, Sample 13708: Loss: 0.4902\n",
            "Epoch 3, Sample 13709: Loss: 0.7036\n",
            "Epoch 3, Sample 13710: Loss: 1.0524\n",
            "Epoch 3, Sample 13711: Loss: 0.6092\n",
            "Epoch 3, Sample 13712: Loss: 0.2044\n",
            "Epoch 3, Sample 13713: Loss: 0.3399\n",
            "Epoch 3, Sample 13714: Loss: 0.3441\n",
            "Epoch 3, Sample 13715: Loss: 0.2044\n",
            "Epoch 3, Sample 13716: Loss: 0.2832\n",
            "Epoch 3, Sample 13717: Loss: 0.1326\n",
            "Epoch 3, Sample 13718: Loss: 0.0640\n",
            "Epoch 3, Sample 13719: Loss: 0.2989\n",
            "Epoch 3, Sample 13720: Loss: 0.6931\n",
            "Epoch 3, Sample 13721: Loss: 1.0530\n",
            "Epoch 3, Sample 13722: Loss: 0.4996\n",
            "Epoch 3, Sample 13723: Loss: 0.2044\n",
            "Epoch 3, Sample 13724: Loss: 0.1546\n",
            "Epoch 3, Sample 13725: Loss: 1.0155\n",
            "Epoch 3, Sample 13726: Loss: 1.0155\n",
            "Epoch 3, Sample 13727: Loss: 0.1710\n",
            "Epoch 3, Sample 13728: Loss: 0.2851\n",
            "Epoch 3, Sample 13729: Loss: 0.2034\n",
            "Epoch 3, Sample 13730: Loss: 0.1091\n",
            "Epoch 3, Sample 13731: Loss: 0.1885\n",
            "Epoch 3, Sample 13732: Loss: 3.9461\n",
            "Epoch 3, Sample 13733: Loss: 0.1817\n",
            "Epoch 3, Sample 13734: Loss: 0.7036\n",
            "Epoch 3, Sample 13735: Loss: 0.0001\n",
            "Epoch 3, Sample 13736: Loss: 1.0155\n",
            "Epoch 3, Sample 13737: Loss: 0.1770\n",
            "Epoch 3, Sample 13738: Loss: 3.2695\n",
            "Epoch 3, Sample 13739: Loss: 0.2036\n",
            "Epoch 3, Sample 13740: Loss: 0.1465\n",
            "Epoch 3, Sample 13741: Loss: 0.0205\n",
            "Epoch 3, Sample 13742: Loss: 0.2989\n",
            "Epoch 3, Sample 13743: Loss: 1.0524\n",
            "Epoch 3, Sample 13744: Loss: 1.0155\n",
            "Epoch 3, Sample 13745: Loss: 0.8484\n",
            "Epoch 3, Sample 13746: Loss: 0.4032\n",
            "Epoch 3, Sample 13747: Loss: 0.2759\n",
            "Epoch 3, Sample 13748: Loss: 0.2851\n",
            "Epoch 3, Sample 13749: Loss: 0.2036\n",
            "Epoch 3, Sample 13750: Loss: 0.6545\n",
            "Epoch 3, Sample 13751: Loss: 0.2771\n",
            "Epoch 3, Sample 13752: Loss: 1.0524\n",
            "Epoch 3, Sample 13753: Loss: 1.9466\n",
            "Epoch 3, Sample 13754: Loss: 0.2044\n",
            "Epoch 3, Sample 13755: Loss: 0.0391\n",
            "Epoch 3, Sample 13756: Loss: 0.0744\n",
            "Epoch 3, Sample 13757: Loss: 0.5551\n",
            "Epoch 3, Sample 13758: Loss: 0.2044\n",
            "Epoch 3, Sample 13759: Loss: 0.0026\n",
            "Epoch 3, Sample 13760: Loss: 1.5918\n",
            "Epoch 3, Sample 13761: Loss: 0.3949\n",
            "Epoch 3, Sample 13762: Loss: 0.5000\n",
            "Epoch 3, Sample 13763: Loss: 0.0630\n",
            "Epoch 3, Sample 13764: Loss: 3.7602\n",
            "Epoch 3, Sample 13765: Loss: 0.8951\n",
            "Epoch 3, Sample 13766: Loss: 3.0731\n",
            "Epoch 3, Sample 13767: Loss: 0.2036\n",
            "Epoch 3, Sample 13768: Loss: 0.3399\n",
            "Epoch 3, Sample 13769: Loss: 0.0026\n",
            "Epoch 3, Sample 13770: Loss: 0.8951\n",
            "Epoch 3, Sample 13771: Loss: 0.5078\n",
            "Epoch 3, Sample 13772: Loss: 0.0915\n",
            "Epoch 3, Sample 13773: Loss: 0.8771\n",
            "Epoch 3, Sample 13774: Loss: 0.4611\n",
            "Epoch 3, Sample 13775: Loss: 0.7036\n",
            "Epoch 3, Sample 13776: Loss: 0.3734\n",
            "Epoch 3, Sample 13777: Loss: 0.2044\n",
            "Epoch 3, Sample 13778: Loss: 2.7166\n",
            "Epoch 3, Sample 13779: Loss: 2.0484\n",
            "Epoch 3, Sample 13780: Loss: 0.6618\n",
            "Epoch 3, Sample 13781: Loss: 0.7570\n",
            "Epoch 3, Sample 13782: Loss: 0.0511\n",
            "Epoch 3, Sample 13783: Loss: 0.0062\n",
            "Epoch 3, Sample 13784: Loss: 0.3399\n",
            "Epoch 3, Sample 13785: Loss: 0.0625\n",
            "Epoch 3, Sample 13786: Loss: 0.7036\n",
            "Epoch 3, Sample 13787: Loss: 0.0026\n",
            "Epoch 3, Sample 13788: Loss: 0.9874\n",
            "Epoch 3, Sample 13789: Loss: 0.1283\n",
            "Epoch 3, Sample 13790: Loss: 0.5976\n",
            "Epoch 3, Sample 13791: Loss: 0.6058\n",
            "Epoch 3, Sample 13792: Loss: 0.0145\n",
            "Epoch 3, Sample 13793: Loss: 0.3441\n",
            "Epoch 3, Sample 13794: Loss: 0.8269\n",
            "Epoch 3, Sample 13795: Loss: 0.3399\n",
            "Epoch 3, Sample 13796: Loss: 0.1516\n",
            "Epoch 3, Sample 13797: Loss: 0.0063\n",
            "Epoch 3, Sample 13798: Loss: 0.0202\n",
            "Epoch 3, Sample 13799: Loss: 1.0155\n",
            "Epoch 3, Sample 13800: Loss: 0.0065\n",
            "Epoch 3, Sample 13801: Loss: 0.0084\n",
            "Epoch 3, Sample 13802: Loss: 0.0067\n",
            "Epoch 3, Sample 13803: Loss: 0.1605\n",
            "Epoch 3, Sample 13804: Loss: 0.3399\n",
            "Epoch 3, Sample 13805: Loss: 1.0524\n",
            "Epoch 3, Sample 13806: Loss: 0.1250\n",
            "Epoch 3, Sample 13807: Loss: 0.3464\n",
            "Epoch 3, Sample 13808: Loss: 0.5858\n",
            "Epoch 3, Sample 13809: Loss: 0.2879\n",
            "Epoch 3, Sample 13810: Loss: 0.3441\n",
            "Epoch 3, Sample 13811: Loss: 0.5000\n",
            "Epoch 3, Sample 13812: Loss: 0.4474\n",
            "Epoch 3, Sample 13813: Loss: 0.9317\n",
            "Epoch 3, Sample 13814: Loss: 0.0018\n",
            "Epoch 3, Sample 13815: Loss: 1.0530\n",
            "Epoch 3, Sample 13816: Loss: 0.2044\n",
            "Epoch 3, Sample 13817: Loss: 0.2044\n",
            "Epoch 3, Sample 13818: Loss: 1.0524\n",
            "Epoch 3, Sample 13819: Loss: 0.4799\n",
            "Epoch 3, Sample 13820: Loss: 0.6058\n",
            "Epoch 3, Sample 13821: Loss: 1.1506\n",
            "Epoch 3, Sample 13822: Loss: 0.2034\n",
            "Epoch 3, Sample 13823: Loss: 0.0286\n",
            "Epoch 3, Sample 13824: Loss: 0.0482\n",
            "Epoch 3, Sample 13825: Loss: 0.0626\n",
            "Epoch 3, Sample 13826: Loss: 0.2832\n",
            "Epoch 3, Sample 13827: Loss: 0.1892\n",
            "Epoch 3, Sample 13828: Loss: 0.0013\n",
            "Epoch 3, Sample 13829: Loss: 0.1170\n",
            "Epoch 3, Sample 13830: Loss: 1.0524\n",
            "Epoch 3, Sample 13831: Loss: 0.2044\n",
            "Epoch 3, Sample 13832: Loss: 0.1170\n",
            "Epoch 3, Sample 13833: Loss: 0.1257\n",
            "Epoch 3, Sample 13834: Loss: 0.0774\n",
            "Epoch 3, Sample 13835: Loss: 0.7702\n",
            "Epoch 3, Sample 13836: Loss: 0.0267\n",
            "Epoch 3, Sample 13837: Loss: 1.0524\n",
            "Epoch 3, Sample 13838: Loss: 0.0475\n",
            "Epoch 3, Sample 13839: Loss: 2.6851\n",
            "Epoch 3, Sample 13840: Loss: 0.3024\n",
            "Epoch 3, Sample 13841: Loss: 0.1252\n",
            "Epoch 3, Sample 13842: Loss: 1.0524\n",
            "Epoch 3, Sample 13843: Loss: 0.3598\n",
            "Epoch 3, Sample 13844: Loss: 0.1170\n",
            "Epoch 3, Sample 13845: Loss: 0.5000\n",
            "Epoch 3, Sample 13846: Loss: 0.0060\n",
            "Epoch 3, Sample 13847: Loss: 0.2034\n",
            "Epoch 3, Sample 13848: Loss: 0.2832\n",
            "Epoch 3, Sample 13849: Loss: 0.2219\n",
            "Epoch 3, Sample 13850: Loss: 0.4841\n",
            "Epoch 3, Sample 13851: Loss: 0.2344\n",
            "Epoch 3, Sample 13852: Loss: 0.5871\n",
            "Epoch 3, Sample 13853: Loss: 1.0530\n",
            "Epoch 3, Sample 13854: Loss: 0.0063\n",
            "Epoch 3, Sample 13855: Loss: 0.0344\n",
            "Epoch 3, Sample 13856: Loss: 0.6304\n",
            "Epoch 3, Sample 13857: Loss: 0.1326\n",
            "Epoch 3, Sample 13858: Loss: 1.0524\n",
            "Epoch 3, Sample 13859: Loss: 0.0026\n",
            "Epoch 3, Sample 13860: Loss: 4.2658\n",
            "Epoch 3, Sample 13861: Loss: 0.0010\n",
            "Epoch 3, Sample 13862: Loss: 1.0524\n",
            "Epoch 3, Sample 13863: Loss: 0.0444\n",
            "Epoch 3, Sample 13864: Loss: 0.0818\n",
            "Epoch 3, Sample 13865: Loss: 0.2759\n",
            "Epoch 3, Sample 13866: Loss: 1.0155\n",
            "Epoch 3, Sample 13867: Loss: 0.0306\n",
            "Epoch 3, Sample 13868: Loss: 0.5871\n",
            "Epoch 3, Sample 13869: Loss: 0.1409\n",
            "Epoch 3, Sample 13870: Loss: 1.0524\n",
            "Epoch 3, Sample 13871: Loss: 0.2044\n",
            "Epoch 3, Sample 13872: Loss: 0.0630\n",
            "Epoch 3, Sample 13873: Loss: 0.9367\n",
            "Epoch 3, Sample 13874: Loss: 0.0000\n",
            "Epoch 3, Sample 13875: Loss: 0.0001\n",
            "Epoch 3, Sample 13876: Loss: 0.1091\n",
            "Epoch 3, Sample 13877: Loss: 0.0018\n",
            "Epoch 3, Sample 13878: Loss: 0.0824\n",
            "Epoch 3, Sample 13879: Loss: 0.0000\n",
            "Epoch 3, Sample 13880: Loss: 0.0026\n",
            "Epoch 3, Sample 13881: Loss: 0.1307\n",
            "Epoch 3, Sample 13882: Loss: 1.2926\n",
            "Epoch 3, Sample 13883: Loss: 0.5089\n",
            "Epoch 3, Sample 13884: Loss: 0.1252\n",
            "Epoch 3, Sample 13885: Loss: 0.6092\n",
            "Epoch 3, Sample 13886: Loss: 3.0665\n",
            "Epoch 3, Sample 13887: Loss: 0.7083\n",
            "Epoch 3, Sample 13888: Loss: 0.2036\n",
            "Epoch 3, Sample 13889: Loss: 0.9635\n",
            "Epoch 3, Sample 13890: Loss: 0.0025\n",
            "Epoch 3, Sample 13891: Loss: 0.2112\n",
            "Epoch 3, Sample 13892: Loss: 0.1482\n",
            "Epoch 3, Sample 13893: Loss: 0.7036\n",
            "Epoch 3, Sample 13894: Loss: 1.1122\n",
            "Epoch 3, Sample 13895: Loss: 0.6092\n",
            "Epoch 3, Sample 13896: Loss: 0.0630\n",
            "Epoch 3, Sample 13897: Loss: 0.0744\n",
            "Epoch 3, Sample 13898: Loss: 0.3947\n",
            "Epoch 3, Sample 13899: Loss: 0.2032\n",
            "Epoch 3, Sample 13900: Loss: 1.0155\n",
            "Epoch 3, Sample 13901: Loss: 2.5965\n",
            "Epoch 3, Sample 13902: Loss: 0.0013\n",
            "Epoch 3, Sample 13903: Loss: 0.7036\n",
            "Epoch 3, Sample 13904: Loss: 2.5454\n",
            "Epoch 3, Sample 13905: Loss: 0.3627\n",
            "Epoch 3, Sample 13906: Loss: 0.7986\n",
            "Epoch 3, Sample 13907: Loss: 0.4799\n",
            "Epoch 3, Sample 13908: Loss: 0.3399\n",
            "Epoch 3, Sample 13909: Loss: 0.0039\n",
            "Epoch 3, Sample 13910: Loss: 0.9892\n",
            "Epoch 3, Sample 13911: Loss: 0.1250\n",
            "Epoch 3, Sample 13912: Loss: 0.3598\n",
            "Epoch 3, Sample 13913: Loss: 0.2034\n",
            "Epoch 3, Sample 13914: Loss: 0.1337\n",
            "Epoch 3, Sample 13915: Loss: 0.0234\n",
            "Epoch 3, Sample 13916: Loss: 0.3640\n",
            "Epoch 3, Sample 13917: Loss: 0.0093\n",
            "Epoch 3, Sample 13918: Loss: 0.4930\n",
            "Epoch 3, Sample 13919: Loss: 0.2044\n",
            "Epoch 3, Sample 13920: Loss: 0.0028\n",
            "Epoch 3, Sample 13921: Loss: 0.7036\n",
            "Epoch 3, Sample 13922: Loss: 0.1627\n",
            "Epoch 3, Sample 13923: Loss: 0.0915\n",
            "Epoch 3, Sample 13924: Loss: 0.5500\n",
            "Epoch 3, Sample 13925: Loss: 0.3399\n",
            "Epoch 3, Sample 13926: Loss: 1.0524\n",
            "Epoch 3, Sample 13927: Loss: 0.0016\n",
            "Epoch 3, Sample 13928: Loss: 0.3399\n",
            "Epoch 3, Sample 13929: Loss: 0.0102\n",
            "Epoch 3, Sample 13930: Loss: 0.2034\n",
            "Epoch 3, Sample 13931: Loss: 1.0155\n",
            "Epoch 3, Sample 13932: Loss: 0.0018\n",
            "Epoch 3, Sample 13933: Loss: 0.3066\n",
            "Epoch 3, Sample 13934: Loss: 0.0026\n",
            "Epoch 3, Sample 13935: Loss: 0.1555\n",
            "Epoch 3, Sample 13936: Loss: 0.8773\n",
            "Epoch 3, Sample 13937: Loss: 0.1336\n",
            "Epoch 3, Sample 13938: Loss: 0.2034\n",
            "Epoch 3, Sample 13939: Loss: 0.2759\n",
            "Epoch 3, Sample 13940: Loss: 0.4611\n",
            "Epoch 3, Sample 13941: Loss: 0.0630\n",
            "Epoch 3, Sample 13942: Loss: 0.1250\n",
            "Epoch 3, Sample 13943: Loss: 0.3949\n",
            "Epoch 3, Sample 13944: Loss: 1.0155\n",
            "Epoch 3, Sample 13945: Loss: 0.1559\n",
            "Epoch 3, Sample 13946: Loss: 1.0524\n",
            "Epoch 3, Sample 13947: Loss: 0.2044\n",
            "Epoch 3, Sample 13948: Loss: 0.3568\n",
            "Epoch 3, Sample 13949: Loss: 0.4588\n",
            "Epoch 3, Sample 13950: Loss: 0.5003\n",
            "Epoch 3, Sample 13951: Loss: 0.2032\n",
            "Epoch 3, Sample 13952: Loss: 1.3394\n",
            "Epoch 3, Sample 13953: Loss: 0.0127\n",
            "Epoch 3, Sample 13954: Loss: 0.2032\n",
            "Epoch 3, Sample 13955: Loss: 1.7693\n",
            "Epoch 3, Sample 13956: Loss: 0.6867\n",
            "Epoch 3, Sample 13957: Loss: 0.3949\n",
            "Epoch 3, Sample 13958: Loss: 0.9401\n",
            "Epoch 3, Sample 13959: Loss: 0.7453\n",
            "Epoch 3, Sample 13960: Loss: 1.0155\n",
            "Epoch 3, Sample 13961: Loss: 0.3399\n",
            "Epoch 3, Sample 13962: Loss: 1.1967\n",
            "Epoch 3, Sample 13963: Loss: 0.5972\n",
            "Epoch 3, Sample 13964: Loss: 0.0000\n",
            "Epoch 3, Sample 13965: Loss: 0.4607\n",
            "Epoch 3, Sample 13966: Loss: 0.3441\n",
            "Epoch 3, Sample 13967: Loss: 0.2639\n",
            "Epoch 3, Sample 13968: Loss: 0.0595\n",
            "Epoch 3, Sample 13969: Loss: 1.1569\n",
            "Epoch 3, Sample 13970: Loss: 0.7453\n",
            "Epoch 3, Sample 13971: Loss: 0.2044\n",
            "Epoch 3, Sample 13972: Loss: 0.5078\n",
            "Epoch 3, Sample 13973: Loss: 7.2463\n",
            "Epoch 3, Sample 13974: Loss: 0.9367\n",
            "Epoch 3, Sample 13975: Loss: 0.3160\n",
            "Epoch 3, Sample 13976: Loss: 0.3399\n",
            "Epoch 3, Sample 13977: Loss: 0.2044\n",
            "Epoch 3, Sample 13978: Loss: 0.0303\n",
            "Epoch 3, Sample 13979: Loss: 0.0026\n",
            "Epoch 3, Sample 13980: Loss: 0.9367\n",
            "Epoch 3, Sample 13981: Loss: 0.5972\n",
            "Epoch 3, Sample 13982: Loss: 0.1250\n",
            "Epoch 3, Sample 13983: Loss: 0.0630\n",
            "Epoch 3, Sample 13984: Loss: 0.2157\n",
            "Epoch 3, Sample 13985: Loss: 0.0630\n",
            "Epoch 3, Sample 13986: Loss: 0.1185\n",
            "Epoch 3, Sample 13987: Loss: 0.1838\n",
            "Epoch 3, Sample 13988: Loss: 4.0265\n",
            "Epoch 3, Sample 13989: Loss: 1.3026\n",
            "Epoch 3, Sample 13990: Loss: 0.3332\n",
            "Epoch 3, Sample 13991: Loss: 0.2032\n",
            "Epoch 3, Sample 13992: Loss: 0.3402\n",
            "Epoch 3, Sample 13993: Loss: 0.2034\n",
            "Epoch 3, Sample 13994: Loss: 1.0524\n",
            "Epoch 3, Sample 13995: Loss: 0.4032\n",
            "Epoch 3, Sample 13996: Loss: 0.0488\n",
            "Epoch 3, Sample 13997: Loss: 0.6990\n",
            "Epoch 3, Sample 13998: Loss: 0.0026\n",
            "Epoch 3, Sample 13999: Loss: 0.0364\n",
            "Epoch 3, Sample 14000: Loss: 1.0155\n",
            "Epoch 3, Sample 14001: Loss: 0.0838\n",
            "Epoch 3, Sample 14002: Loss: 0.2945\n",
            "Epoch 3, Sample 14003: Loss: 0.0000\n",
            "Epoch 3, Sample 14004: Loss: 0.0001\n",
            "Epoch 3, Sample 14005: Loss: 0.0693\n",
            "Epoch 3, Sample 14006: Loss: 0.2036\n",
            "Epoch 3, Sample 14007: Loss: 0.0026\n",
            "Epoch 3, Sample 14008: Loss: 0.0084\n",
            "Epoch 3, Sample 14009: Loss: 0.1399\n",
            "Epoch 3, Sample 14010: Loss: 0.7036\n",
            "Epoch 3, Sample 14011: Loss: 0.4849\n",
            "Epoch 3, Sample 14012: Loss: 0.6194\n",
            "Epoch 3, Sample 14013: Loss: 0.3441\n",
            "Epoch 3, Sample 14014: Loss: 0.4799\n",
            "Epoch 3, Sample 14015: Loss: 2.7888\n",
            "Epoch 3, Sample 14016: Loss: 1.0155\n",
            "Epoch 3, Sample 14017: Loss: 0.2814\n",
            "Epoch 3, Sample 14018: Loss: 0.0526\n",
            "Epoch 3, Sample 14019: Loss: 4.2873\n",
            "Epoch 3, Sample 14020: Loss: 9.2435\n",
            "Epoch 3, Sample 14021: Loss: 0.3399\n",
            "Epoch 3, Sample 14022: Loss: 1.0524\n",
            "Epoch 3, Sample 14023: Loss: 1.0524\n",
            "Epoch 3, Sample 14024: Loss: 0.0915\n",
            "Epoch 3, Sample 14025: Loss: 0.3399\n",
            "Epoch 3, Sample 14026: Loss: 0.0466\n",
            "Epoch 3, Sample 14027: Loss: 0.3418\n",
            "Epoch 3, Sample 14028: Loss: 0.1559\n",
            "Epoch 3, Sample 14029: Loss: 0.5278\n",
            "Epoch 3, Sample 14030: Loss: 0.9785\n",
            "Epoch 3, Sample 14031: Loss: 0.9367\n",
            "Epoch 3, Sample 14032: Loss: 0.4032\n",
            "Epoch 3, Sample 14033: Loss: 0.2992\n",
            "Epoch 3, Sample 14034: Loss: 0.5003\n",
            "Epoch 3, Sample 14035: Loss: 0.0915\n",
            "Epoch 3, Sample 14036: Loss: 1.0070\n",
            "Epoch 3, Sample 14037: Loss: 0.8951\n",
            "Epoch 3, Sample 14038: Loss: 0.4382\n",
            "Epoch 3, Sample 14039: Loss: 0.1246\n",
            "Epoch 3, Sample 14040: Loss: 0.2494\n",
            "Epoch 3, Sample 14041: Loss: 0.3851\n",
            "Epoch 3, Sample 14042: Loss: 0.0801\n",
            "Epoch 3, Sample 14043: Loss: 0.1559\n",
            "Epoch 3, Sample 14044: Loss: 0.8577\n",
            "Epoch 3, Sample 14045: Loss: 0.1250\n",
            "Epoch 3, Sample 14046: Loss: 0.0102\n",
            "Epoch 3, Sample 14047: Loss: 0.6990\n",
            "Epoch 3, Sample 14048: Loss: 0.3598\n",
            "Epoch 3, Sample 14049: Loss: 0.2044\n",
            "Epoch 3, Sample 14050: Loss: 0.0062\n",
            "Epoch 3, Sample 14051: Loss: 0.4841\n",
            "Epoch 3, Sample 14052: Loss: 0.3288\n",
            "Epoch 3, Sample 14053: Loss: 0.9367\n",
            "Epoch 3, Sample 14054: Loss: 0.1989\n",
            "Epoch 3, Sample 14055: Loss: 0.2036\n",
            "Epoch 3, Sample 14056: Loss: 1.0524\n",
            "Epoch 3, Sample 14057: Loss: 0.2036\n",
            "Epoch 3, Sample 14058: Loss: 1.0524\n",
            "Epoch 3, Sample 14059: Loss: 1.1156\n",
            "Epoch 3, Sample 14060: Loss: 0.2044\n",
            "Epoch 3, Sample 14061: Loss: 0.4611\n",
            "Epoch 3, Sample 14062: Loss: 0.3539\n",
            "Epoch 3, Sample 14063: Loss: 1.0530\n",
            "Epoch 3, Sample 14064: Loss: 0.0176\n",
            "Epoch 3, Sample 14065: Loss: 0.0018\n",
            "Epoch 3, Sample 14066: Loss: 0.1170\n",
            "Epoch 3, Sample 14067: Loss: 0.0915\n",
            "Epoch 3, Sample 14068: Loss: 0.2219\n",
            "Epoch 3, Sample 14069: Loss: 0.0063\n",
            "Epoch 3, Sample 14070: Loss: 0.0630\n",
            "Epoch 3, Sample 14071: Loss: 0.2271\n",
            "Epoch 3, Sample 14072: Loss: 0.7036\n",
            "Epoch 3, Sample 14073: Loss: 0.1177\n",
            "Epoch 3, Sample 14074: Loss: 0.0625\n",
            "Epoch 3, Sample 14075: Loss: 0.8951\n",
            "Epoch 3, Sample 14076: Loss: 0.8951\n",
            "Epoch 3, Sample 14077: Loss: 0.6092\n",
            "Epoch 3, Sample 14078: Loss: 1.2011\n",
            "Epoch 3, Sample 14079: Loss: 0.9361\n",
            "Epoch 3, Sample 14080: Loss: 0.1672\n",
            "Epoch 3, Sample 14081: Loss: 0.0299\n",
            "Epoch 3, Sample 14082: Loss: 3.7215\n",
            "Epoch 3, Sample 14083: Loss: 0.2750\n",
            "Epoch 3, Sample 14084: Loss: 0.0915\n",
            "Epoch 3, Sample 14085: Loss: 1.5134\n",
            "Epoch 3, Sample 14086: Loss: 8.2169\n",
            "Epoch 3, Sample 14087: Loss: 0.3399\n",
            "Epoch 3, Sample 14088: Loss: 0.0168\n",
            "Epoch 3, Sample 14089: Loss: 0.3441\n",
            "Epoch 3, Sample 14090: Loss: 0.2044\n",
            "Epoch 3, Sample 14091: Loss: 0.1225\n",
            "Epoch 3, Sample 14092: Loss: 0.0915\n",
            "Epoch 3, Sample 14093: Loss: 0.0000\n",
            "Epoch 3, Sample 14094: Loss: 2.5873\n",
            "Epoch 3, Sample 14095: Loss: 0.3402\n",
            "Epoch 3, Sample 14096: Loss: 1.0530\n",
            "Epoch 3, Sample 14097: Loss: 0.1170\n",
            "Epoch 3, Sample 14098: Loss: 0.1091\n",
            "Epoch 3, Sample 14099: Loss: 0.5704\n",
            "Epoch 3, Sample 14100: Loss: 0.2034\n",
            "Epoch 3, Sample 14101: Loss: 0.2044\n",
            "Epoch 3, Sample 14102: Loss: 1.0524\n",
            "Epoch 3, Sample 14103: Loss: 0.3399\n",
            "Epoch 3, Sample 14104: Loss: 2.4573\n",
            "Epoch 3, Sample 14105: Loss: 0.7036\n",
            "Epoch 3, Sample 14106: Loss: 1.0524\n",
            "Epoch 3, Sample 14107: Loss: 0.2759\n",
            "Epoch 3, Sample 14108: Loss: 0.8951\n",
            "Epoch 3, Sample 14109: Loss: 0.1092\n",
            "Epoch 3, Sample 14110: Loss: 0.6110\n",
            "Epoch 3, Sample 14111: Loss: 0.2219\n",
            "Epoch 3, Sample 14112: Loss: 0.2846\n",
            "Epoch 3, Sample 14113: Loss: 0.1248\n",
            "Epoch 3, Sample 14114: Loss: 0.3949\n",
            "Epoch 3, Sample 14115: Loss: 0.0819\n",
            "Epoch 3, Sample 14116: Loss: 0.1364\n",
            "Epoch 3, Sample 14117: Loss: 0.0229\n",
            "Epoch 3, Sample 14118: Loss: 5.5835\n",
            "Epoch 3, Sample 14119: Loss: 0.0016\n",
            "Epoch 3, Sample 14120: Loss: 0.3399\n",
            "Epoch 3, Sample 14121: Loss: 1.0511\n",
            "Epoch 3, Sample 14122: Loss: 0.0463\n",
            "Epoch 3, Sample 14123: Loss: 0.3402\n",
            "Epoch 3, Sample 14124: Loss: 2.2481\n",
            "Epoch 3, Sample 14125: Loss: 0.2832\n",
            "Epoch 3, Sample 14126: Loss: 0.3741\n",
            "Epoch 3, Sample 14127: Loss: 0.3441\n",
            "Epoch 3, Sample 14128: Loss: 0.2044\n",
            "Epoch 3, Sample 14129: Loss: 0.2938\n",
            "Epoch 3, Sample 14130: Loss: 0.0303\n",
            "Epoch 3, Sample 14131: Loss: 1.1789\n",
            "Epoch 3, Sample 14132: Loss: 0.0002\n",
            "Epoch 3, Sample 14133: Loss: 0.1248\n",
            "Epoch 3, Sample 14134: Loss: 0.0363\n",
            "Epoch 3, Sample 14135: Loss: 0.5972\n",
            "Epoch 3, Sample 14136: Loss: 0.0915\n",
            "Epoch 3, Sample 14137: Loss: 0.1646\n",
            "Epoch 3, Sample 14138: Loss: 1.2026\n",
            "Epoch 3, Sample 14139: Loss: 1.0530\n",
            "Epoch 3, Sample 14140: Loss: 0.4841\n",
            "Epoch 3, Sample 14141: Loss: 0.8164\n",
            "Epoch 3, Sample 14142: Loss: 0.1250\n",
            "Epoch 3, Sample 14143: Loss: 0.3247\n",
            "Epoch 3, Sample 14144: Loss: 0.3055\n",
            "Epoch 3, Sample 14145: Loss: 0.3949\n",
            "Epoch 3, Sample 14146: Loss: 0.5858\n",
            "Epoch 3, Sample 14147: Loss: 0.2759\n",
            "Epoch 3, Sample 14148: Loss: 0.4032\n",
            "Epoch 3, Sample 14149: Loss: 0.3399\n",
            "Epoch 3, Sample 14150: Loss: 0.6092\n",
            "Epoch 3, Sample 14151: Loss: 0.1250\n",
            "Epoch 3, Sample 14152: Loss: 0.0144\n",
            "Epoch 3, Sample 14153: Loss: 0.1773\n",
            "Epoch 3, Sample 14154: Loss: 0.4930\n",
            "Epoch 3, Sample 14155: Loss: 0.1047\n",
            "Epoch 3, Sample 14156: Loss: 0.0306\n",
            "Epoch 3, Sample 14157: Loss: 0.0108\n",
            "Epoch 3, Sample 14158: Loss: 1.3126\n",
            "Epoch 3, Sample 14159: Loss: 0.0026\n",
            "Epoch 3, Sample 14160: Loss: 0.2687\n",
            "Epoch 3, Sample 14161: Loss: 0.4799\n",
            "Epoch 3, Sample 14162: Loss: 0.0129\n",
            "Epoch 3, Sample 14163: Loss: 0.0558\n",
            "Epoch 3, Sample 14164: Loss: 0.2044\n",
            "Epoch 3, Sample 14165: Loss: 0.1031\n",
            "Epoch 3, Sample 14166: Loss: 0.2032\n",
            "Epoch 3, Sample 14167: Loss: 0.0018\n",
            "Epoch 3, Sample 14168: Loss: 1.0524\n",
            "Epoch 3, Sample 14169: Loss: 0.0103\n",
            "Epoch 3, Sample 14170: Loss: 0.5375\n",
            "Epoch 3, Sample 14171: Loss: 0.0001\n",
            "Epoch 3, Sample 14172: Loss: 1.3647\n",
            "Epoch 3, Sample 14173: Loss: 0.4799\n",
            "Epoch 3, Sample 14174: Loss: 3.1597\n",
            "Epoch 3, Sample 14175: Loss: 0.4424\n",
            "Epoch 3, Sample 14176: Loss: 0.4032\n",
            "Epoch 3, Sample 14177: Loss: 0.2832\n",
            "Epoch 3, Sample 14178: Loss: 0.2044\n",
            "Epoch 3, Sample 14179: Loss: 0.2034\n",
            "Epoch 3, Sample 14180: Loss: 0.2290\n",
            "Epoch 3, Sample 14181: Loss: 0.5858\n",
            "Epoch 3, Sample 14182: Loss: 0.5972\n",
            "Epoch 3, Sample 14183: Loss: 0.0088\n",
            "Epoch 3, Sample 14184: Loss: 0.3441\n",
            "Epoch 3, Sample 14185: Loss: 0.1372\n",
            "Epoch 3, Sample 14186: Loss: 0.2832\n",
            "Epoch 3, Sample 14187: Loss: 0.1489\n",
            "Epoch 3, Sample 14188: Loss: 0.1559\n",
            "Epoch 3, Sample 14189: Loss: 0.2699\n",
            "Epoch 3, Sample 14190: Loss: 0.3450\n",
            "Epoch 3, Sample 14191: Loss: 0.0292\n",
            "Epoch 3, Sample 14192: Loss: 0.0026\n",
            "Epoch 3, Sample 14193: Loss: 0.3584\n",
            "Epoch 3, Sample 14194: Loss: 0.1170\n",
            "Epoch 3, Sample 14195: Loss: 0.6092\n",
            "Epoch 3, Sample 14196: Loss: 0.6139\n",
            "Epoch 3, Sample 14197: Loss: 1.0524\n",
            "Epoch 3, Sample 14198: Loss: 0.5877\n",
            "Epoch 3, Sample 14199: Loss: 0.0808\n",
            "Epoch 3, Sample 14200: Loss: 0.0168\n",
            "Epoch 3, Sample 14201: Loss: 0.0590\n",
            "Epoch 3, Sample 14202: Loss: 0.0026\n",
            "Epoch 3, Sample 14203: Loss: 0.2044\n",
            "Epoch 3, Sample 14204: Loss: 0.7036\n",
            "Epoch 3, Sample 14205: Loss: 2.2893\n",
            "Epoch 3, Sample 14206: Loss: 0.1113\n",
            "Epoch 3, Sample 14207: Loss: 0.0025\n",
            "Epoch 3, Sample 14208: Loss: 1.0524\n",
            "Epoch 3, Sample 14209: Loss: 0.0785\n",
            "Epoch 3, Sample 14210: Loss: 0.0000\n",
            "Epoch 3, Sample 14211: Loss: 0.4474\n",
            "Epoch 3, Sample 14212: Loss: 1.0524\n",
            "Epoch 3, Sample 14213: Loss: 0.3949\n",
            "Epoch 3, Sample 14214: Loss: 0.4611\n",
            "Epoch 3, Sample 14215: Loss: 0.5089\n",
            "Epoch 3, Sample 14216: Loss: 1.0524\n",
            "Epoch 3, Sample 14217: Loss: 0.0306\n",
            "Epoch 3, Sample 14218: Loss: 1.4187\n",
            "Epoch 3, Sample 14219: Loss: 0.2034\n",
            "Epoch 3, Sample 14220: Loss: 0.0026\n",
            "Epoch 3, Sample 14221: Loss: 0.0026\n",
            "Epoch 3, Sample 14222: Loss: 0.1211\n",
            "Epoch 3, Sample 14223: Loss: 0.1995\n",
            "Epoch 3, Sample 14224: Loss: 0.0520\n",
            "Epoch 3, Sample 14225: Loss: 0.3949\n",
            "Epoch 3, Sample 14226: Loss: 0.2639\n",
            "Epoch 3, Sample 14227: Loss: 0.2879\n",
            "Epoch 3, Sample 14228: Loss: 0.4663\n",
            "Epoch 3, Sample 14229: Loss: 0.2340\n",
            "Epoch 3, Sample 14230: Loss: 1.0530\n",
            "Epoch 3, Sample 14231: Loss: 0.0915\n",
            "Epoch 3, Sample 14232: Loss: 0.4799\n",
            "Epoch 3, Sample 14233: Loss: 1.0524\n",
            "Epoch 3, Sample 14234: Loss: 0.3399\n",
            "Epoch 3, Sample 14235: Loss: 0.2044\n",
            "Epoch 3, Sample 14236: Loss: 0.8951\n",
            "Epoch 3, Sample 14237: Loss: 0.3399\n",
            "Epoch 3, Sample 14238: Loss: 0.7501\n",
            "Epoch 3, Sample 14239: Loss: 0.1364\n",
            "Epoch 3, Sample 14240: Loss: 0.1091\n",
            "Epoch 3, Sample 14241: Loss: 0.0838\n",
            "Epoch 3, Sample 14242: Loss: 0.0604\n",
            "Epoch 3, Sample 14243: Loss: 0.0604\n",
            "Epoch 3, Sample 14244: Loss: 0.6600\n",
            "Epoch 3, Sample 14245: Loss: 0.2112\n",
            "Epoch 3, Sample 14246: Loss: 0.1238\n",
            "Epoch 3, Sample 14247: Loss: 0.2034\n",
            "Epoch 3, Sample 14248: Loss: 0.4611\n",
            "Epoch 3, Sample 14249: Loss: 0.0318\n",
            "Epoch 3, Sample 14250: Loss: 0.0915\n",
            "Epoch 3, Sample 14251: Loss: 0.4588\n",
            "Epoch 3, Sample 14252: Loss: 0.4930\n",
            "Epoch 3, Sample 14253: Loss: 0.0135\n",
            "Epoch 3, Sample 14254: Loss: 1.4607\n",
            "Epoch 3, Sample 14255: Loss: 0.2759\n",
            "Epoch 3, Sample 14256: Loss: 0.0026\n",
            "Epoch 3, Sample 14257: Loss: 0.3568\n",
            "Epoch 3, Sample 14258: Loss: 0.0022\n",
            "Epoch 3, Sample 14259: Loss: 0.0105\n",
            "Epoch 3, Sample 14260: Loss: 0.0018\n",
            "Epoch 3, Sample 14261: Loss: 0.6990\n",
            "Epoch 3, Sample 14262: Loss: 1.0266\n",
            "Epoch 3, Sample 14263: Loss: 0.2836\n",
            "Epoch 3, Sample 14264: Loss: 0.4382\n",
            "Epoch 3, Sample 14265: Loss: 0.7931\n",
            "Epoch 3, Sample 14266: Loss: 0.1559\n",
            "Epoch 3, Sample 14267: Loss: 0.3973\n",
            "Epoch 3, Sample 14268: Loss: 12.0464\n",
            "Epoch 3, Sample 14269: Loss: 0.0018\n",
            "Epoch 3, Sample 14270: Loss: 0.9618\n",
            "Epoch 3, Sample 14271: Loss: 0.3399\n",
            "Epoch 3, Sample 14272: Loss: 0.2639\n",
            "Epoch 3, Sample 14273: Loss: 0.5266\n",
            "Epoch 3, Sample 14274: Loss: 0.0424\n",
            "Epoch 3, Sample 14275: Loss: 0.0084\n",
            "Epoch 3, Sample 14276: Loss: 0.0170\n",
            "Epoch 3, Sample 14277: Loss: 0.0001\n",
            "Epoch 3, Sample 14278: Loss: 0.0303\n",
            "Epoch 3, Sample 14279: Loss: 0.0114\n",
            "Epoch 3, Sample 14280: Loss: 0.6990\n",
            "Epoch 3, Sample 14281: Loss: 0.5799\n",
            "Epoch 3, Sample 14282: Loss: 0.0121\n",
            "Epoch 3, Sample 14283: Loss: 1.2782\n",
            "Epoch 3, Sample 14284: Loss: 0.0938\n",
            "Epoch 3, Sample 14285: Loss: 0.5003\n",
            "Epoch 3, Sample 14286: Loss: 0.2032\n",
            "Epoch 3, Sample 14287: Loss: 0.4055\n",
            "Epoch 3, Sample 14288: Loss: 0.7453\n",
            "Epoch 3, Sample 14289: Loss: 0.2182\n",
            "Epoch 3, Sample 14290: Loss: 0.2132\n",
            "Epoch 3, Sample 14291: Loss: 0.0026\n",
            "Epoch 3, Sample 14292: Loss: 1.0530\n",
            "Epoch 3, Sample 14293: Loss: 0.0001\n",
            "Epoch 3, Sample 14294: Loss: 0.2034\n",
            "Epoch 3, Sample 14295: Loss: 0.0622\n",
            "Epoch 3, Sample 14296: Loss: 0.4799\n",
            "Epoch 3, Sample 14297: Loss: 0.2044\n",
            "Epoch 3, Sample 14298: Loss: 0.0063\n",
            "Epoch 3, Sample 14299: Loss: 0.0018\n",
            "Epoch 3, Sample 14300: Loss: 0.1170\n",
            "Epoch 3, Sample 14301: Loss: 1.0524\n",
            "Epoch 3, Sample 14302: Loss: 0.5858\n",
            "Epoch 3, Sample 14303: Loss: 1.0524\n",
            "Epoch 3, Sample 14304: Loss: 0.3402\n",
            "Epoch 3, Sample 14305: Loss: 1.0633\n",
            "Epoch 3, Sample 14306: Loss: 1.0524\n",
            "Epoch 3, Sample 14307: Loss: 0.1250\n",
            "Epoch 3, Sample 14308: Loss: 0.5871\n",
            "Epoch 3, Sample 14309: Loss: 0.0469\n",
            "Epoch 3, Sample 14310: Loss: 0.0415\n",
            "Epoch 3, Sample 14311: Loss: 0.3399\n",
            "Epoch 3, Sample 14312: Loss: 0.7036\n",
            "Epoch 3, Sample 14313: Loss: 0.2098\n",
            "Epoch 3, Sample 14314: Loss: 0.8951\n",
            "Epoch 3, Sample 14315: Loss: 0.6502\n",
            "Epoch 3, Sample 14316: Loss: 0.3399\n",
            "Epoch 3, Sample 14317: Loss: 0.4930\n",
            "Epoch 3, Sample 14318: Loss: 0.7036\n",
            "Epoch 3, Sample 14319: Loss: 0.2034\n",
            "Epoch 3, Sample 14320: Loss: 0.0640\n",
            "Epoch 3, Sample 14321: Loss: 0.6304\n",
            "Epoch 3, Sample 14322: Loss: 0.0838\n",
            "Epoch 3, Sample 14323: Loss: 0.0039\n",
            "Epoch 3, Sample 14324: Loss: 0.5858\n",
            "Epoch 3, Sample 14325: Loss: 0.2032\n",
            "Epoch 3, Sample 14326: Loss: 0.1250\n",
            "Epoch 3, Sample 14327: Loss: 0.2639\n",
            "Epoch 3, Sample 14328: Loss: 0.2044\n",
            "Epoch 3, Sample 14329: Loss: 0.5972\n",
            "Epoch 3, Sample 14330: Loss: 0.1204\n",
            "Epoch 3, Sample 14331: Loss: 1.0530\n",
            "Epoch 3, Sample 14332: Loss: 0.0001\n",
            "Epoch 3, Sample 14333: Loss: 0.0024\n",
            "Epoch 3, Sample 14334: Loss: 1.0530\n",
            "Epoch 3, Sample 14335: Loss: 0.0001\n",
            "Epoch 3, Sample 14336: Loss: 0.0456\n",
            "Epoch 3, Sample 14337: Loss: 0.0826\n",
            "Epoch 3, Sample 14338: Loss: 0.2832\n",
            "Epoch 3, Sample 14339: Loss: 1.0524\n",
            "Epoch 3, Sample 14340: Loss: 0.3758\n",
            "Epoch 3, Sample 14341: Loss: 0.0907\n",
            "Epoch 3, Sample 14342: Loss: 0.6304\n",
            "Epoch 3, Sample 14343: Loss: 0.0101\n",
            "Epoch 3, Sample 14344: Loss: 0.0063\n",
            "Epoch 3, Sample 14345: Loss: 0.3921\n",
            "Epoch 3, Sample 14346: Loss: 0.0006\n",
            "Epoch 3, Sample 14347: Loss: 1.0530\n",
            "Epoch 3, Sample 14348: Loss: 0.2639\n",
            "Epoch 3, Sample 14349: Loss: 0.7036\n",
            "Epoch 3, Sample 14350: Loss: 0.0163\n",
            "Epoch 3, Sample 14351: Loss: 0.1508\n",
            "Epoch 3, Sample 14352: Loss: 0.6990\n",
            "Epoch 3, Sample 14353: Loss: 0.1684\n",
            "Epoch 3, Sample 14354: Loss: 1.3333\n",
            "Epoch 3, Sample 14355: Loss: 0.0838\n",
            "Epoch 3, Sample 14356: Loss: 0.3241\n",
            "Epoch 3, Sample 14357: Loss: 1.0524\n",
            "Epoch 3, Sample 14358: Loss: 0.0018\n",
            "Epoch 3, Sample 14359: Loss: 0.4474\n",
            "Epoch 3, Sample 14360: Loss: 0.2430\n",
            "Epoch 3, Sample 14361: Loss: 0.2651\n",
            "Epoch 3, Sample 14362: Loss: 0.7453\n",
            "Epoch 3, Sample 14363: Loss: 0.6304\n",
            "Epoch 3, Sample 14364: Loss: 0.0712\n",
            "Epoch 3, Sample 14365: Loss: 0.0744\n",
            "Epoch 3, Sample 14366: Loss: 1.2133\n",
            "Epoch 3, Sample 14367: Loss: 0.5003\n",
            "Epoch 3, Sample 14368: Loss: 1.3198\n",
            "Epoch 3, Sample 14369: Loss: 0.4466\n",
            "Epoch 3, Sample 14370: Loss: 0.2032\n",
            "Epoch 3, Sample 14371: Loss: 0.0690\n",
            "Epoch 3, Sample 14372: Loss: 0.2044\n",
            "Epoch 3, Sample 14373: Loss: 0.5636\n",
            "Epoch 3, Sample 14374: Loss: 0.5000\n",
            "Epoch 3, Sample 14375: Loss: 0.8808\n",
            "Epoch 3, Sample 14376: Loss: 0.8484\n",
            "Epoch 3, Sample 14377: Loss: 1.1569\n",
            "Epoch 3, Sample 14378: Loss: 0.7036\n",
            "Epoch 3, Sample 14379: Loss: 0.0060\n",
            "Epoch 3, Sample 14380: Loss: 2.1588\n",
            "Epoch 3, Sample 14381: Loss: 0.0630\n",
            "Epoch 3, Sample 14382: Loss: 0.0270\n",
            "Epoch 3, Sample 14383: Loss: 0.2044\n",
            "Epoch 3, Sample 14384: Loss: 1.2838\n",
            "Epoch 3, Sample 14385: Loss: 0.0363\n",
            "Epoch 3, Sample 14386: Loss: 1.0070\n",
            "Epoch 3, Sample 14387: Loss: 0.3332\n",
            "Epoch 3, Sample 14388: Loss: 0.4382\n",
            "Epoch 3, Sample 14389: Loss: 0.3805\n",
            "Epoch 3, Sample 14390: Loss: 0.7036\n",
            "Epoch 3, Sample 14391: Loss: 1.6829\n",
            "Epoch 3, Sample 14392: Loss: 0.1559\n",
            "Epoch 3, Sample 14393: Loss: 0.0736\n",
            "Epoch 3, Sample 14394: Loss: 0.5858\n",
            "Epoch 3, Sample 14395: Loss: 0.2615\n",
            "Epoch 3, Sample 14396: Loss: 0.0959\n",
            "Epoch 3, Sample 14397: Loss: 1.0530\n",
            "Epoch 3, Sample 14398: Loss: 1.0524\n",
            "Epoch 3, Sample 14399: Loss: 0.7430\n",
            "Epoch 3, Sample 14400: Loss: 0.0013\n",
            "Epoch 3, Sample 14401: Loss: 0.4774\n",
            "Epoch 3, Sample 14402: Loss: 0.0026\n",
            "Epoch 3, Sample 14403: Loss: 0.6446\n",
            "Epoch 3, Sample 14404: Loss: 1.6685\n",
            "Epoch 3, Sample 14405: Loss: 1.0524\n",
            "Epoch 3, Sample 14406: Loss: 1.6694\n",
            "Epoch 3, Sample 14407: Loss: 1.0524\n",
            "Epoch 3, Sample 14408: Loss: 0.3399\n",
            "Epoch 3, Sample 14409: Loss: 1.5024\n",
            "Epoch 3, Sample 14410: Loss: 0.0018\n",
            "Epoch 3, Sample 14411: Loss: 0.2585\n",
            "Epoch 3, Sample 14412: Loss: 0.0026\n",
            "Epoch 3, Sample 14413: Loss: 0.2032\n",
            "Epoch 3, Sample 14414: Loss: 0.0026\n",
            "Epoch 3, Sample 14415: Loss: 0.5310\n",
            "Epoch 3, Sample 14416: Loss: 0.3924\n",
            "Epoch 3, Sample 14417: Loss: 2.8487\n",
            "Epoch 3, Sample 14418: Loss: 0.2044\n",
            "Epoch 3, Sample 14419: Loss: 0.0019\n",
            "Epoch 3, Sample 14420: Loss: 0.0001\n",
            "Epoch 3, Sample 14421: Loss: 0.0760\n",
            "Epoch 3, Sample 14422: Loss: 0.3238\n",
            "Epoch 3, Sample 14423: Loss: 0.3332\n",
            "Epoch 3, Sample 14424: Loss: 0.1396\n",
            "Epoch 3, Sample 14425: Loss: 0.4799\n",
            "Epoch 3, Sample 14426: Loss: 0.4474\n",
            "Epoch 3, Sample 14427: Loss: 0.3114\n",
            "Epoch 3, Sample 14428: Loss: 0.4841\n",
            "Epoch 3, Sample 14429: Loss: 0.6452\n",
            "Epoch 3, Sample 14430: Loss: 0.6028\n",
            "Epoch 3, Sample 14431: Loss: 0.0727\n",
            "Epoch 3, Sample 14432: Loss: 0.0707\n",
            "Epoch 3, Sample 14433: Loss: 0.0271\n",
            "Epoch 3, Sample 14434: Loss: 0.0018\n",
            "Epoch 3, Sample 14435: Loss: 1.0530\n",
            "Epoch 3, Sample 14436: Loss: 0.1170\n",
            "Epoch 3, Sample 14437: Loss: 0.2832\n",
            "Epoch 3, Sample 14438: Loss: 0.2034\n",
            "Epoch 3, Sample 14439: Loss: 0.3441\n",
            "Epoch 3, Sample 14440: Loss: 0.0026\n",
            "Epoch 3, Sample 14441: Loss: 0.7453\n",
            "Epoch 3, Sample 14442: Loss: 0.2962\n",
            "Epoch 3, Sample 14443: Loss: 0.1523\n",
            "Epoch 3, Sample 14444: Loss: 0.6304\n",
            "Epoch 3, Sample 14445: Loss: 1.0155\n",
            "Epoch 3, Sample 14446: Loss: 1.1884\n",
            "Epoch 3, Sample 14447: Loss: 0.0841\n",
            "Epoch 3, Sample 14448: Loss: 0.2044\n",
            "Epoch 3, Sample 14449: Loss: 0.7036\n",
            "Epoch 3, Sample 14450: Loss: 0.1559\n",
            "Epoch 3, Sample 14451: Loss: 0.4471\n",
            "Epoch 3, Sample 14452: Loss: 0.1170\n",
            "Epoch 3, Sample 14453: Loss: 0.2032\n",
            "Epoch 3, Sample 14454: Loss: 1.0524\n",
            "Epoch 3, Sample 14455: Loss: 0.2639\n",
            "Epoch 3, Sample 14456: Loss: 0.1559\n",
            "Epoch 3, Sample 14457: Loss: 0.7036\n",
            "Epoch 3, Sample 14458: Loss: 0.2112\n",
            "Epoch 3, Sample 14459: Loss: 6.4687\n",
            "Epoch 3, Sample 14460: Loss: 0.2032\n",
            "Epoch 3, Sample 14461: Loss: 0.2970\n",
            "Epoch 3, Sample 14462: Loss: 0.2930\n",
            "Epoch 3, Sample 14463: Loss: 0.2032\n",
            "Epoch 3, Sample 14464: Loss: 1.0524\n",
            "Epoch 3, Sample 14465: Loss: 1.6361\n",
            "Epoch 3, Sample 14466: Loss: 0.5000\n",
            "Epoch 3, Sample 14467: Loss: 0.4549\n",
            "Epoch 3, Sample 14468: Loss: 0.0026\n",
            "Epoch 3, Sample 14469: Loss: 0.2765\n",
            "Epoch 3, Sample 14470: Loss: 0.2832\n",
            "Epoch 3, Sample 14471: Loss: 0.0707\n",
            "Epoch 3, Sample 14472: Loss: 0.2036\n",
            "Epoch 3, Sample 14473: Loss: 0.5000\n",
            "Epoch 3, Sample 14474: Loss: 0.0149\n",
            "Epoch 3, Sample 14475: Loss: 0.2868\n",
            "Epoch 3, Sample 14476: Loss: 0.0877\n",
            "Epoch 3, Sample 14477: Loss: 0.0554\n",
            "Epoch 3, Sample 14478: Loss: 0.7036\n",
            "Epoch 3, Sample 14479: Loss: 0.0919\n",
            "Epoch 3, Sample 14480: Loss: 0.5139\n",
            "Epoch 3, Sample 14481: Loss: 0.2459\n",
            "Epoch 3, Sample 14482: Loss: 0.0180\n",
            "Epoch 3, Sample 14483: Loss: 0.1959\n",
            "Epoch 3, Sample 14484: Loss: 1.0155\n",
            "Epoch 3, Sample 14485: Loss: 0.0062\n",
            "Epoch 3, Sample 14486: Loss: 0.4799\n",
            "Epoch 3, Sample 14487: Loss: 0.0055\n",
            "Epoch 3, Sample 14488: Loss: 0.0865\n",
            "Epoch 3, Sample 14489: Loss: 0.2014\n",
            "Epoch 3, Sample 14490: Loss: 2.0413\n",
            "Epoch 3, Sample 14491: Loss: 0.3090\n",
            "Epoch 3, Sample 14492: Loss: 0.4032\n",
            "Epoch 3, Sample 14493: Loss: 1.0524\n",
            "Epoch 3, Sample 14494: Loss: 0.0915\n",
            "Epoch 3, Sample 14495: Loss: 0.4092\n",
            "Epoch 3, Sample 14496: Loss: 0.2855\n",
            "Epoch 3, Sample 14497: Loss: 0.5003\n",
            "Epoch 3, Sample 14498: Loss: 0.0026\n",
            "Epoch 3, Sample 14499: Loss: 0.2034\n",
            "Epoch 3, Sample 14500: Loss: 0.1225\n",
            "Epoch 3, Sample 14501: Loss: 0.4799\n",
            "Epoch 3, Sample 14502: Loss: 0.3399\n",
            "Epoch 3, Sample 14503: Loss: 0.0067\n",
            "Epoch 3, Sample 14504: Loss: 2.5957\n",
            "Epoch 3, Sample 14505: Loss: 0.1401\n",
            "Epoch 3, Sample 14506: Loss: 0.2034\n",
            "Epoch 3, Sample 14507: Loss: 1.6501\n",
            "Epoch 3, Sample 14508: Loss: 0.2832\n",
            "Epoch 3, Sample 14509: Loss: 0.1241\n",
            "Epoch 3, Sample 14510: Loss: 0.0001\n",
            "Epoch 3, Sample 14511: Loss: 0.0557\n",
            "Epoch 3, Sample 14512: Loss: 0.5858\n",
            "Epoch 3, Sample 14513: Loss: 0.7036\n",
            "Epoch 3, Sample 14514: Loss: 0.2036\n",
            "Epoch 3, Sample 14515: Loss: 0.4973\n",
            "Epoch 3, Sample 14516: Loss: 0.4799\n",
            "Epoch 3, Sample 14517: Loss: 0.0429\n",
            "Epoch 3, Sample 14518: Loss: 0.1170\n",
            "Epoch 3, Sample 14519: Loss: 0.0000\n",
            "Epoch 3, Sample 14520: Loss: 0.0625\n",
            "Epoch 3, Sample 14521: Loss: 0.8951\n",
            "Epoch 3, Sample 14522: Loss: 0.3506\n",
            "Epoch 3, Sample 14523: Loss: 0.4611\n",
            "Epoch 3, Sample 14524: Loss: 1.0524\n",
            "Epoch 3, Sample 14525: Loss: 0.2639\n",
            "Epoch 3, Sample 14526: Loss: 0.2759\n",
            "Epoch 3, Sample 14527: Loss: 0.7036\n",
            "Epoch 3, Sample 14528: Loss: 0.3714\n",
            "Epoch 3, Sample 14529: Loss: 0.0030\n",
            "Epoch 3, Sample 14530: Loss: 0.4611\n",
            "Epoch 3, Sample 14531: Loss: 0.0258\n",
            "Epoch 3, Sample 14532: Loss: 0.2621\n",
            "Epoch 3, Sample 14533: Loss: 0.3399\n",
            "Epoch 3, Sample 14534: Loss: 0.7036\n",
            "Epoch 3, Sample 14535: Loss: 0.0018\n",
            "Epoch 3, Sample 14536: Loss: 0.0258\n",
            "Epoch 3, Sample 14537: Loss: 1.0530\n",
            "Epoch 3, Sample 14538: Loss: 0.5000\n",
            "Epoch 3, Sample 14539: Loss: 0.1806\n",
            "Epoch 3, Sample 14540: Loss: 0.2044\n",
            "Epoch 3, Sample 14541: Loss: 0.2032\n",
            "Epoch 3, Sample 14542: Loss: 0.3441\n",
            "Epoch 3, Sample 14543: Loss: 1.0524\n",
            "Epoch 3, Sample 14544: Loss: 0.3399\n",
            "Epoch 3, Sample 14545: Loss: 0.2036\n",
            "Epoch 3, Sample 14546: Loss: 0.0018\n",
            "Epoch 3, Sample 14547: Loss: 0.3436\n",
            "Epoch 3, Sample 14548: Loss: 0.3441\n",
            "Epoch 3, Sample 14549: Loss: 0.0000\n",
            "Epoch 3, Sample 14550: Loss: 0.0320\n",
            "Epoch 3, Sample 14551: Loss: 0.1170\n",
            "Epoch 3, Sample 14552: Loss: 0.3598\n",
            "Epoch 3, Sample 14553: Loss: 0.0292\n",
            "Epoch 3, Sample 14554: Loss: 0.2494\n",
            "Epoch 3, Sample 14555: Loss: 0.1250\n",
            "Epoch 3, Sample 14556: Loss: 0.0915\n",
            "Epoch 3, Sample 14557: Loss: 0.0630\n",
            "Epoch 3, Sample 14558: Loss: 0.3758\n",
            "Epoch 3, Sample 14559: Loss: 0.4841\n",
            "Epoch 3, Sample 14560: Loss: 0.0145\n",
            "Epoch 3, Sample 14561: Loss: 0.1989\n",
            "Epoch 3, Sample 14562: Loss: 0.2036\n",
            "Epoch 3, Sample 14563: Loss: 1.0524\n",
            "Epoch 3, Sample 14564: Loss: 0.0018\n",
            "Epoch 3, Sample 14565: Loss: 1.0524\n",
            "Epoch 3, Sample 14566: Loss: 0.3568\n",
            "Epoch 3, Sample 14567: Loss: 1.0530\n",
            "Epoch 3, Sample 14568: Loss: 0.7036\n",
            "Epoch 3, Sample 14569: Loss: 0.0001\n",
            "Epoch 3, Sample 14570: Loss: 0.2523\n",
            "Epoch 3, Sample 14571: Loss: 0.2044\n",
            "Epoch 3, Sample 14572: Loss: 0.2044\n",
            "Epoch 3, Sample 14573: Loss: 0.2044\n",
            "Epoch 3, Sample 14574: Loss: 1.0524\n",
            "Epoch 3, Sample 14575: Loss: 0.0067\n",
            "Epoch 3, Sample 14576: Loss: 0.2970\n",
            "Epoch 3, Sample 14577: Loss: 0.2487\n",
            "Epoch 3, Sample 14578: Loss: 0.7036\n",
            "Epoch 3, Sample 14579: Loss: 0.0385\n",
            "Epoch 3, Sample 14580: Loss: 0.0036\n",
            "Epoch 3, Sample 14581: Loss: 0.0025\n",
            "Epoch 3, Sample 14582: Loss: 0.3949\n",
            "Epoch 3, Sample 14583: Loss: 0.0026\n",
            "Epoch 3, Sample 14584: Loss: 0.2112\n",
            "Epoch 3, Sample 14585: Loss: 0.2044\n",
            "Epoch 3, Sample 14586: Loss: 1.0524\n",
            "Epoch 3, Sample 14587: Loss: 3.6155\n",
            "Epoch 3, Sample 14588: Loss: 0.0212\n",
            "Epoch 3, Sample 14589: Loss: 12.6118\n",
            "Epoch 3, Sample 14590: Loss: 0.3683\n",
            "Epoch 3, Sample 14591: Loss: 0.5207\n",
            "Epoch 3, Sample 14592: Loss: 0.1523\n",
            "Epoch 3, Sample 14593: Loss: 0.8944\n",
            "Epoch 3, Sample 14594: Loss: 0.7036\n",
            "Epoch 3, Sample 14595: Loss: 0.0145\n",
            "Epoch 3, Sample 14596: Loss: 0.0594\n",
            "Epoch 3, Sample 14597: Loss: 0.2712\n",
            "Epoch 3, Sample 14598: Loss: 0.0630\n",
            "Epoch 3, Sample 14599: Loss: 0.2664\n",
            "Epoch 3, Sample 14600: Loss: 0.2339\n",
            "Epoch 3, Sample 14601: Loss: 0.0625\n",
            "Epoch 3, Sample 14602: Loss: 0.3399\n",
            "Epoch 3, Sample 14603: Loss: 1.7063\n",
            "Epoch 3, Sample 14604: Loss: 1.2205\n",
            "Epoch 3, Sample 14605: Loss: 0.0001\n",
            "Epoch 3, Sample 14606: Loss: 0.2352\n",
            "Epoch 3, Sample 14607: Loss: 0.0001\n",
            "Epoch 3, Sample 14608: Loss: 0.1419\n",
            "Epoch 3, Sample 14609: Loss: 0.4930\n",
            "Epoch 3, Sample 14610: Loss: 0.2724\n",
            "Epoch 3, Sample 14611: Loss: 0.0000\n",
            "Epoch 3, Sample 14612: Loss: 0.3036\n",
            "Epoch 3, Sample 14613: Loss: 0.0630\n",
            "Epoch 3, Sample 14614: Loss: 0.0027\n",
            "Epoch 3, Sample 14615: Loss: 0.2034\n",
            "Epoch 3, Sample 14616: Loss: 0.1660\n",
            "Epoch 3, Sample 14617: Loss: 0.0630\n",
            "Epoch 3, Sample 14618: Loss: 0.0018\n",
            "Epoch 3, Sample 14619: Loss: 0.0205\n",
            "Epoch 3, Sample 14620: Loss: 0.2759\n",
            "Epoch 3, Sample 14621: Loss: 0.3441\n",
            "Epoch 3, Sample 14622: Loss: 1.0227\n",
            "Epoch 3, Sample 14623: Loss: 0.2036\n",
            "Epoch 3, Sample 14624: Loss: 0.2032\n",
            "Epoch 3, Sample 14625: Loss: 0.4930\n",
            "Epoch 3, Sample 14626: Loss: 1.0524\n",
            "Epoch 3, Sample 14627: Loss: 0.2032\n",
            "Epoch 3, Sample 14628: Loss: 0.7036\n",
            "Epoch 3, Sample 14629: Loss: 0.1337\n",
            "Epoch 3, Sample 14630: Loss: 0.0026\n",
            "Epoch 3, Sample 14631: Loss: 0.0026\n",
            "Epoch 3, Sample 14632: Loss: 2.1043\n",
            "Epoch 3, Sample 14633: Loss: 0.2034\n",
            "Epoch 3, Sample 14634: Loss: 0.6990\n",
            "Epoch 3, Sample 14635: Loss: 0.0431\n",
            "Epoch 3, Sample 14636: Loss: 0.3399\n",
            "Epoch 3, Sample 14637: Loss: 0.0138\n",
            "Epoch 3, Sample 14638: Loss: 0.0630\n",
            "Epoch 3, Sample 14639: Loss: 0.1164\n",
            "Epoch 3, Sample 14640: Loss: 0.0915\n",
            "Epoch 3, Sample 14641: Loss: 0.2759\n",
            "Epoch 3, Sample 14642: Loss: 0.1559\n",
            "Epoch 3, Sample 14643: Loss: 0.1485\n",
            "Epoch 3, Sample 14644: Loss: 0.0026\n",
            "Epoch 3, Sample 14645: Loss: 0.2340\n",
            "Epoch 3, Sample 14646: Loss: 3.7596\n",
            "Epoch 3, Sample 14647: Loss: 0.0001\n",
            "Epoch 3, Sample 14648: Loss: 0.2032\n",
            "Epoch 3, Sample 14649: Loss: 1.1569\n",
            "Epoch 3, Sample 14650: Loss: 0.0013\n",
            "Epoch 3, Sample 14651: Loss: 0.0018\n",
            "Epoch 3, Sample 14652: Loss: 0.0775\n",
            "Epoch 3, Sample 14653: Loss: 1.0155\n",
            "Epoch 3, Sample 14654: Loss: 0.0819\n",
            "Epoch 3, Sample 14655: Loss: 0.7036\n",
            "Epoch 3, Sample 14656: Loss: 0.1092\n",
            "Epoch 3, Sample 14657: Loss: 0.2034\n",
            "Epoch 3, Sample 14658: Loss: 0.1817\n",
            "Epoch 3, Sample 14659: Loss: 0.8484\n",
            "Epoch 3, Sample 14660: Loss: 0.2032\n",
            "Epoch 3, Sample 14661: Loss: 0.2044\n",
            "Epoch 3, Sample 14662: Loss: 0.0871\n",
            "Epoch 3, Sample 14663: Loss: 0.1213\n",
            "Epoch 3, Sample 14664: Loss: 1.3452\n",
            "Epoch 3, Sample 14665: Loss: 0.0260\n",
            "Epoch 3, Sample 14666: Loss: 0.1588\n",
            "Epoch 3, Sample 14667: Loss: 0.2044\n",
            "Epoch 3, Sample 14668: Loss: 0.7036\n",
            "Epoch 3, Sample 14669: Loss: 1.0682\n",
            "Epoch 3, Sample 14670: Loss: 0.4996\n",
            "Epoch 3, Sample 14671: Loss: 0.0026\n",
            "Epoch 3, Sample 14672: Loss: 0.8951\n",
            "Epoch 3, Sample 14673: Loss: 0.1250\n",
            "Epoch 3, Sample 14674: Loss: 0.1960\n",
            "Epoch 3, Sample 14675: Loss: 0.2112\n",
            "Epoch 3, Sample 14676: Loss: 0.0000\n",
            "Epoch 3, Sample 14677: Loss: 0.2639\n",
            "Epoch 3, Sample 14678: Loss: 0.1555\n",
            "Epoch 3, Sample 14679: Loss: 0.0838\n",
            "Epoch 3, Sample 14680: Loss: 0.0938\n",
            "Epoch 3, Sample 14681: Loss: 0.3399\n",
            "Epoch 3, Sample 14682: Loss: 1.0524\n",
            "Epoch 3, Sample 14683: Loss: 1.7904\n",
            "Epoch 3, Sample 14684: Loss: 0.0947\n",
            "Epoch 3, Sample 14685: Loss: 0.1588\n",
            "Epoch 3, Sample 14686: Loss: 0.0108\n",
            "Epoch 3, Sample 14687: Loss: 0.2494\n",
            "Epoch 3, Sample 14688: Loss: 0.1559\n",
            "Epoch 3, Sample 14689: Loss: 0.0001\n",
            "Epoch 3, Sample 14690: Loss: 2.7331\n",
            "Epoch 3, Sample 14691: Loss: 0.0630\n",
            "Epoch 3, Sample 14692: Loss: 0.9726\n",
            "Epoch 3, Sample 14693: Loss: 1.0155\n",
            "Epoch 3, Sample 14694: Loss: 0.5871\n",
            "Epoch 3, Sample 14695: Loss: 0.5000\n",
            "Epoch 3, Sample 14696: Loss: 0.0018\n",
            "Epoch 3, Sample 14697: Loss: 0.4742\n",
            "Epoch 3, Sample 14698: Loss: 0.0630\n",
            "Epoch 3, Sample 14699: Loss: 0.2044\n",
            "Epoch 3, Sample 14700: Loss: 0.1696\n",
            "Epoch 3, Sample 14701: Loss: 0.2044\n",
            "Epoch 3, Sample 14702: Loss: 0.2639\n",
            "Epoch 3, Sample 14703: Loss: 0.1170\n",
            "Epoch 3, Sample 14704: Loss: 0.1250\n",
            "Epoch 3, Sample 14705: Loss: 0.7036\n",
            "Epoch 3, Sample 14706: Loss: 2.7560\n",
            "Epoch 3, Sample 14707: Loss: 1.0524\n",
            "Epoch 3, Sample 14708: Loss: 0.1250\n",
            "Epoch 3, Sample 14709: Loss: 0.0000\n",
            "Epoch 3, Sample 14710: Loss: 1.0227\n",
            "Epoch 3, Sample 14711: Loss: 1.0524\n",
            "Epoch 3, Sample 14712: Loss: 0.2704\n",
            "Epoch 3, Sample 14713: Loss: 0.1337\n",
            "Epoch 3, Sample 14714: Loss: 0.1250\n",
            "Epoch 3, Sample 14715: Loss: 0.2044\n",
            "Epoch 3, Sample 14716: Loss: 0.2660\n",
            "Epoch 3, Sample 14717: Loss: 0.4930\n",
            "Epoch 3, Sample 14718: Loss: 1.0275\n",
            "Epoch 3, Sample 14719: Loss: 0.0022\n",
            "Epoch 3, Sample 14720: Loss: 0.0630\n",
            "Epoch 3, Sample 14721: Loss: 0.2851\n",
            "Epoch 3, Sample 14722: Loss: 0.2044\n",
            "Epoch 3, Sample 14723: Loss: 0.0000\n",
            "Epoch 3, Sample 14724: Loss: 0.1252\n",
            "Epoch 3, Sample 14725: Loss: 0.7036\n",
            "Epoch 3, Sample 14726: Loss: 0.6092\n",
            "Epoch 3, Sample 14727: Loss: 0.2759\n",
            "Epoch 3, Sample 14728: Loss: 1.0524\n",
            "Epoch 3, Sample 14729: Loss: 0.1100\n",
            "Epoch 3, Sample 14730: Loss: 0.0103\n",
            "Epoch 3, Sample 14731: Loss: 0.3633\n",
            "Epoch 3, Sample 14732: Loss: 0.1378\n",
            "Epoch 3, Sample 14733: Loss: 0.0915\n",
            "Epoch 3, Sample 14734: Loss: 0.0009\n",
            "Epoch 3, Sample 14735: Loss: 0.7036\n",
            "Epoch 3, Sample 14736: Loss: 0.5858\n",
            "Epoch 3, Sample 14737: Loss: 0.0212\n",
            "Epoch 3, Sample 14738: Loss: 0.1523\n",
            "Epoch 3, Sample 14739: Loss: 0.0026\n",
            "Epoch 3, Sample 14740: Loss: 0.4032\n",
            "Epoch 3, Sample 14741: Loss: 0.4159\n",
            "Epoch 3, Sample 14742: Loss: 0.0838\n",
            "Epoch 3, Sample 14743: Loss: 0.7036\n",
            "Epoch 3, Sample 14744: Loss: 1.3030\n",
            "Epoch 3, Sample 14745: Loss: 0.2759\n",
            "Epoch 3, Sample 14746: Loss: 0.3441\n",
            "Epoch 3, Sample 14747: Loss: 2.7407\n",
            "Epoch 3, Sample 14748: Loss: 0.1337\n",
            "Epoch 3, Sample 14749: Loss: 0.5871\n",
            "Epoch 3, Sample 14750: Loss: 0.7453\n",
            "Epoch 3, Sample 14751: Loss: 0.3831\n",
            "Epoch 3, Sample 14752: Loss: 0.3399\n",
            "Epoch 3, Sample 14753: Loss: 0.0270\n",
            "Epoch 3, Sample 14754: Loss: 0.2639\n",
            "Epoch 3, Sample 14755: Loss: 0.0263\n",
            "Epoch 3, Sample 14756: Loss: 0.0073\n",
            "Epoch 3, Sample 14757: Loss: 0.0069\n",
            "Epoch 3, Sample 14758: Loss: 0.0045\n",
            "Epoch 3, Sample 14759: Loss: 3.4424\n",
            "Epoch 3, Sample 14760: Loss: 0.1048\n",
            "Epoch 3, Sample 14761: Loss: 0.0363\n",
            "Epoch 3, Sample 14762: Loss: 0.5196\n",
            "Epoch 3, Sample 14763: Loss: 0.2034\n",
            "Epoch 3, Sample 14764: Loss: 1.0266\n",
            "Epoch 3, Sample 14765: Loss: 0.0303\n",
            "Epoch 3, Sample 14766: Loss: 0.0015\n",
            "Epoch 3, Sample 14767: Loss: 0.0306\n",
            "Epoch 3, Sample 14768: Loss: 0.0181\n",
            "Epoch 3, Sample 14769: Loss: 1.0360\n",
            "Epoch 3, Sample 14770: Loss: 0.2962\n",
            "Epoch 3, Sample 14771: Loss: 0.7036\n",
            "Epoch 3, Sample 14772: Loss: 0.1250\n",
            "Epoch 3, Sample 14773: Loss: 0.3399\n",
            "Epoch 3, Sample 14774: Loss: 1.0155\n",
            "Epoch 3, Sample 14775: Loss: 0.0031\n",
            "Epoch 3, Sample 14776: Loss: 1.0524\n",
            "Epoch 3, Sample 14777: Loss: 0.2219\n",
            "Epoch 3, Sample 14778: Loss: 0.7036\n",
            "Epoch 3, Sample 14779: Loss: 0.1170\n",
            "Epoch 3, Sample 14780: Loss: 0.1765\n",
            "Epoch 3, Sample 14781: Loss: 0.6076\n",
            "Epoch 3, Sample 14782: Loss: 0.0025\n",
            "Epoch 3, Sample 14783: Loss: 0.1248\n",
            "Epoch 3, Sample 14784: Loss: 0.2044\n",
            "Epoch 3, Sample 14785: Loss: 0.0084\n",
            "Epoch 3, Sample 14786: Loss: 0.1170\n",
            "Epoch 3, Sample 14787: Loss: 0.0205\n",
            "Epoch 3, Sample 14788: Loss: 0.0915\n",
            "Epoch 3, Sample 14789: Loss: 0.5858\n",
            "Epoch 3, Sample 14790: Loss: 0.1250\n",
            "Epoch 3, Sample 14791: Loss: 0.0206\n",
            "Epoch 3, Sample 14792: Loss: 1.0530\n",
            "Epoch 3, Sample 14793: Loss: 0.2086\n",
            "Epoch 3, Sample 14794: Loss: 0.0415\n",
            "Epoch 3, Sample 14795: Loss: 0.5972\n",
            "Epoch 3, Sample 14796: Loss: 0.3399\n",
            "Epoch 3, Sample 14797: Loss: 0.2558\n",
            "Epoch 3, Sample 14798: Loss: 0.0006\n",
            "Epoch 3, Sample 14799: Loss: 1.0155\n",
            "Epoch 3, Sample 14800: Loss: 0.0026\n",
            "Epoch 3, Sample 14801: Loss: 0.2044\n",
            "Epoch 3, Sample 14802: Loss: 0.6990\n",
            "Epoch 3, Sample 14803: Loss: 0.0018\n",
            "Epoch 3, Sample 14804: Loss: 0.0630\n",
            "Epoch 3, Sample 14805: Loss: 0.0088\n",
            "Epoch 3, Sample 14806: Loss: 0.8484\n",
            "Epoch 3, Sample 14807: Loss: 0.2034\n",
            "Epoch 3, Sample 14808: Loss: 0.2032\n",
            "Epoch 3, Sample 14809: Loss: 0.2759\n",
            "Epoch 3, Sample 14810: Loss: 0.1250\n",
            "Epoch 3, Sample 14811: Loss: 1.0524\n",
            "Epoch 3, Sample 14812: Loss: 1.0155\n",
            "Epoch 3, Sample 14813: Loss: 0.7561\n",
            "Epoch 3, Sample 14814: Loss: 0.1590\n",
            "Epoch 3, Sample 14815: Loss: 0.2989\n",
            "Epoch 3, Sample 14816: Loss: 0.0099\n",
            "Epoch 3, Sample 14817: Loss: 1.0266\n",
            "Epoch 3, Sample 14818: Loss: 0.0838\n",
            "Epoch 3, Sample 14819: Loss: 0.2219\n",
            "Epoch 3, Sample 14820: Loss: 0.3402\n",
            "Epoch 3, Sample 14821: Loss: 0.0128\n",
            "Epoch 3, Sample 14822: Loss: 0.2759\n",
            "Epoch 3, Sample 14823: Loss: 1.0524\n",
            "Epoch 3, Sample 14824: Loss: 0.3949\n",
            "Epoch 3, Sample 14825: Loss: 0.3816\n",
            "Epoch 3, Sample 14826: Loss: 0.6055\n",
            "Epoch 3, Sample 14827: Loss: 0.0069\n",
            "Epoch 3, Sample 14828: Loss: 0.0907\n",
            "Epoch 3, Sample 14829: Loss: 0.7036\n",
            "Epoch 3, Sample 14830: Loss: 0.1018\n",
            "Epoch 3, Sample 14831: Loss: 5.5067\n",
            "Epoch 3, Sample 14832: Loss: 0.0133\n",
            "Epoch 3, Sample 14833: Loss: 0.7453\n",
            "Epoch 3, Sample 14834: Loss: 0.3441\n",
            "Epoch 3, Sample 14835: Loss: 0.1674\n",
            "Epoch 3, Sample 14836: Loss: 0.0554\n",
            "Epoch 3, Sample 14837: Loss: 0.4382\n",
            "Epoch 3, Sample 14838: Loss: 0.2044\n",
            "Epoch 3, Sample 14839: Loss: 0.3399\n",
            "Epoch 3, Sample 14840: Loss: 0.6139\n",
            "Epoch 3, Sample 14841: Loss: 1.0524\n",
            "Epoch 3, Sample 14842: Loss: 0.3441\n",
            "Epoch 3, Sample 14843: Loss: 0.1191\n",
            "Epoch 3, Sample 14844: Loss: 19.9570\n",
            "Epoch 3, Sample 14845: Loss: 0.0313\n",
            "Epoch 3, Sample 14846: Loss: 0.2639\n",
            "Epoch 3, Sample 14847: Loss: 0.0001\n",
            "Epoch 3, Sample 14848: Loss: 0.1974\n",
            "Epoch 3, Sample 14849: Loss: 0.0793\n",
            "Epoch 3, Sample 14850: Loss: 1.0155\n",
            "Epoch 3, Sample 14851: Loss: 0.0026\n",
            "Epoch 3, Sample 14852: Loss: 0.2036\n",
            "Epoch 3, Sample 14853: Loss: 0.0026\n",
            "Epoch 3, Sample 14854: Loss: 0.1012\n",
            "Epoch 3, Sample 14855: Loss: 0.0018\n",
            "Epoch 3, Sample 14856: Loss: 0.3659\n",
            "Epoch 3, Sample 14857: Loss: 0.2832\n",
            "Epoch 3, Sample 14858: Loss: 0.1451\n",
            "Epoch 3, Sample 14859: Loss: 0.0108\n",
            "Epoch 3, Sample 14860: Loss: 0.0371\n",
            "Epoch 3, Sample 14861: Loss: 0.0002\n",
            "Epoch 3, Sample 14862: Loss: 0.3399\n",
            "Epoch 3, Sample 14863: Loss: 0.9000\n",
            "Epoch 3, Sample 14864: Loss: 0.3441\n",
            "Epoch 3, Sample 14865: Loss: 0.0391\n",
            "Epoch 3, Sample 14866: Loss: 0.0477\n",
            "Epoch 3, Sample 14867: Loss: 1.0530\n",
            "Epoch 3, Sample 14868: Loss: 0.0380\n",
            "Epoch 3, Sample 14869: Loss: 1.9656\n",
            "Epoch 3, Sample 14870: Loss: 0.0005\n",
            "Epoch 3, Sample 14871: Loss: 0.6166\n",
            "Epoch 3, Sample 14872: Loss: 0.8951\n",
            "Epoch 3, Sample 14873: Loss: 0.0013\n",
            "Epoch 3, Sample 14874: Loss: 0.0919\n",
            "Epoch 3, Sample 14875: Loss: 0.4607\n",
            "Epoch 3, Sample 14876: Loss: 0.1559\n",
            "Epoch 3, Sample 14877: Loss: 0.0018\n",
            "Epoch 3, Sample 14878: Loss: 0.9367\n",
            "Epoch 3, Sample 14879: Loss: 0.0626\n",
            "Epoch 3, Sample 14880: Loss: 0.7453\n",
            "Epoch 3, Sample 14881: Loss: 0.1248\n",
            "Epoch 3, Sample 14882: Loss: 0.3126\n",
            "Epoch 3, Sample 14883: Loss: 0.5000\n",
            "Epoch 3, Sample 14884: Loss: 0.2036\n",
            "Epoch 3, Sample 14885: Loss: 1.0530\n",
            "Epoch 3, Sample 14886: Loss: 0.1170\n",
            "Epoch 3, Sample 14887: Loss: 0.2044\n",
            "Epoch 3, Sample 14888: Loss: 0.4032\n",
            "Epoch 3, Sample 14889: Loss: 0.3441\n",
            "Epoch 3, Sample 14890: Loss: 0.3399\n",
            "Epoch 3, Sample 14891: Loss: 0.0938\n",
            "Epoch 3, Sample 14892: Loss: 0.7036\n",
            "Epoch 3, Sample 14893: Loss: 3.6656\n",
            "Epoch 3, Sample 14894: Loss: 0.1248\n",
            "Epoch 3, Sample 14895: Loss: 0.0286\n",
            "Epoch 3, Sample 14896: Loss: 0.0034\n",
            "Epoch 3, Sample 14897: Loss: 0.6092\n",
            "Epoch 3, Sample 14898: Loss: 1.0524\n",
            "Epoch 3, Sample 14899: Loss: 1.4187\n",
            "Epoch 3, Sample 14900: Loss: 0.3949\n",
            "Epoch 3, Sample 14901: Loss: 0.6867\n",
            "Epoch 3, Sample 14902: Loss: 0.1056\n",
            "Epoch 3, Sample 14903: Loss: 0.0026\n",
            "Epoch 3, Sample 14904: Loss: 0.3758\n",
            "Epoch 3, Sample 14905: Loss: 1.0524\n",
            "Epoch 3, Sample 14906: Loss: 0.2674\n",
            "Epoch 3, Sample 14907: Loss: 2.4626\n",
            "Epoch 3, Sample 14908: Loss: 0.4644\n",
            "Epoch 3, Sample 14909: Loss: 1.0155\n",
            "Epoch 3, Sample 14910: Loss: 0.0018\n",
            "Epoch 3, Sample 14911: Loss: 0.2044\n",
            "Epoch 3, Sample 14912: Loss: 0.0026\n",
            "Epoch 3, Sample 14913: Loss: 0.0205\n",
            "Epoch 3, Sample 14914: Loss: 0.0138\n",
            "Epoch 3, Sample 14915: Loss: 0.5003\n",
            "Epoch 3, Sample 14916: Loss: 0.0363\n",
            "Epoch 3, Sample 14917: Loss: 0.6990\n",
            "Epoch 3, Sample 14918: Loss: 0.3441\n",
            "Epoch 3, Sample 14919: Loss: 3.3534\n",
            "Epoch 3, Sample 14920: Loss: 0.2032\n",
            "Epoch 3, Sample 14921: Loss: 0.0150\n",
            "Epoch 3, Sample 14922: Loss: 0.1170\n",
            "Epoch 3, Sample 14923: Loss: 0.0062\n",
            "Epoch 3, Sample 14924: Loss: 0.0329\n",
            "Epoch 3, Sample 14925: Loss: 0.0626\n",
            "Epoch 3, Sample 14926: Loss: 0.0001\n",
            "Epoch 3, Sample 14927: Loss: 0.6304\n",
            "Epoch 3, Sample 14928: Loss: 0.0025\n",
            "Epoch 3, Sample 14929: Loss: 1.6612\n",
            "Epoch 3, Sample 14930: Loss: 0.0018\n",
            "Epoch 3, Sample 14931: Loss: 0.0802\n",
            "Epoch 3, Sample 14932: Loss: 0.3399\n",
            "Epoch 3, Sample 14933: Loss: 0.0108\n",
            "Epoch 3, Sample 14934: Loss: 0.7754\n",
            "Epoch 3, Sample 14935: Loss: 0.0564\n",
            "Epoch 3, Sample 14936: Loss: 0.3441\n",
            "Epoch 3, Sample 14937: Loss: 0.2182\n",
            "Epoch 3, Sample 14938: Loss: 0.0013\n",
            "Epoch 3, Sample 14939: Loss: 0.3399\n",
            "Epoch 3, Sample 14940: Loss: 0.6304\n",
            "Epoch 3, Sample 14941: Loss: 1.5690\n",
            "Epoch 3, Sample 14942: Loss: 0.1170\n",
            "Epoch 3, Sample 14943: Loss: 1.0530\n",
            "Epoch 3, Sample 14944: Loss: 0.2523\n",
            "Epoch 3, Sample 14945: Loss: 0.3399\n",
            "Epoch 3, Sample 14946: Loss: 0.4607\n",
            "Epoch 3, Sample 14947: Loss: 0.0630\n",
            "Epoch 3, Sample 14948: Loss: 0.2639\n",
            "Epoch 3, Sample 14949: Loss: 0.0062\n",
            "Epoch 3, Sample 14950: Loss: 0.5858\n",
            "Epoch 3, Sample 14951: Loss: 0.0084\n",
            "Epoch 3, Sample 14952: Loss: 0.0258\n",
            "Epoch 3, Sample 14953: Loss: 0.1397\n",
            "Epoch 3, Sample 14954: Loss: 0.0458\n",
            "Epoch 3, Sample 14955: Loss: 0.1559\n",
            "Epoch 3, Sample 14956: Loss: 0.2032\n",
            "Epoch 3, Sample 14957: Loss: 0.7130\n",
            "Epoch 3, Sample 14958: Loss: 0.3399\n",
            "Epoch 3, Sample 14959: Loss: 0.0012\n",
            "Epoch 3, Sample 14960: Loss: 0.5722\n",
            "Epoch 3, Sample 14961: Loss: 0.2219\n",
            "Epoch 3, Sample 14962: Loss: 0.2211\n",
            "Epoch 3, Sample 14963: Loss: 0.2044\n",
            "Epoch 3, Sample 14964: Loss: 0.0030\n",
            "Epoch 3, Sample 14965: Loss: 0.7036\n",
            "Epoch 3, Sample 14966: Loss: 0.0712\n",
            "Epoch 3, Sample 14967: Loss: 0.1252\n",
            "Epoch 3, Sample 14968: Loss: 0.0026\n",
            "Epoch 3, Sample 14969: Loss: 2.0108\n",
            "Epoch 3, Sample 14970: Loss: 0.0405\n",
            "Epoch 3, Sample 14971: Loss: 0.5003\n",
            "Epoch 3, Sample 14972: Loss: 0.0466\n",
            "Epoch 3, Sample 14973: Loss: 0.1246\n",
            "Epoch 3, Sample 14974: Loss: 1.0524\n",
            "Epoch 3, Sample 14975: Loss: 0.1463\n",
            "Epoch 3, Sample 14976: Loss: 0.0466\n",
            "Epoch 3, Sample 14977: Loss: 1.0524\n",
            "Epoch 3, Sample 14978: Loss: 0.2931\n",
            "Epoch 3, Sample 14979: Loss: 0.0026\n",
            "Epoch 3, Sample 14980: Loss: 0.0026\n",
            "Epoch 3, Sample 14981: Loss: 0.4799\n",
            "Epoch 3, Sample 14982: Loss: 0.8484\n",
            "Epoch 3, Sample 14983: Loss: 0.4930\n",
            "Epoch 3, Sample 14984: Loss: 1.0155\n",
            "Epoch 3, Sample 14985: Loss: 0.0026\n",
            "Epoch 3, Sample 14986: Loss: 0.0026\n",
            "Epoch 3, Sample 14987: Loss: 1.6667\n",
            "Epoch 3, Sample 14988: Loss: 1.0688\n",
            "Epoch 3, Sample 14989: Loss: 0.0178\n",
            "Epoch 3, Sample 14990: Loss: 0.0004\n",
            "Epoch 3, Sample 14991: Loss: 0.1225\n",
            "Epoch 3, Sample 14992: Loss: 1.0524\n",
            "Epoch 3, Sample 14993: Loss: 0.9785\n",
            "Epoch 3, Sample 14994: Loss: 0.4611\n",
            "Epoch 3, Sample 14995: Loss: 0.6990\n",
            "Epoch 3, Sample 14996: Loss: 0.4641\n",
            "Epoch 3, Sample 14997: Loss: 0.6990\n",
            "Epoch 3, Sample 14998: Loss: 0.6867\n",
            "Epoch 3, Sample 14999: Loss: 0.0038\n",
            "Epoch 3, Sample 15000: Loss: 0.3949\n",
            "Epoch 3, Sample 15001: Loss: 0.0018\n",
            "Epoch 3, Sample 15002: Loss: 0.6170\n",
            "Epoch 3, Sample 15003: Loss: 0.1364\n",
            "Epoch 3, Sample 15004: Loss: 0.2182\n",
            "Epoch 3, Sample 15005: Loss: 0.0688\n",
            "Epoch 3, Sample 15006: Loss: 0.1964\n",
            "Epoch 3, Sample 15007: Loss: 0.2032\n",
            "Epoch 3, Sample 15008: Loss: 0.2044\n",
            "Epoch 3, Sample 15009: Loss: 0.2219\n",
            "Epoch 3, Sample 15010: Loss: 0.3949\n",
            "Epoch 3, Sample 15011: Loss: 0.4930\n",
            "Epoch 3, Sample 15012: Loss: 0.2044\n",
            "Epoch 3, Sample 15013: Loss: 0.0006\n",
            "Epoch 3, Sample 15014: Loss: 1.0524\n",
            "Epoch 3, Sample 15015: Loss: 0.3399\n",
            "Epoch 3, Sample 15016: Loss: 0.0018\n",
            "Epoch 3, Sample 15017: Loss: 1.0524\n",
            "Epoch 3, Sample 15018: Loss: 0.7702\n",
            "Epoch 3, Sample 15019: Loss: 0.0040\n",
            "Epoch 3, Sample 15020: Loss: 3.7338\n",
            "Epoch 3, Sample 15021: Loss: 0.3402\n",
            "Epoch 3, Sample 15022: Loss: 0.7702\n",
            "Epoch 3, Sample 15023: Loss: 0.2044\n",
            "Epoch 3, Sample 15024: Loss: 0.0726\n",
            "Epoch 3, Sample 15025: Loss: 1.0155\n",
            "Epoch 3, Sample 15026: Loss: 0.0303\n",
            "Epoch 3, Sample 15027: Loss: 0.0563\n",
            "Epoch 3, Sample 15028: Loss: 0.0089\n",
            "Epoch 3, Sample 15029: Loss: 0.1039\n",
            "Epoch 3, Sample 15030: Loss: 1.0155\n",
            "Epoch 3, Sample 15031: Loss: 3.0847\n",
            "Epoch 3, Sample 15032: Loss: 0.4505\n",
            "Epoch 3, Sample 15033: Loss: 0.3332\n",
            "Epoch 3, Sample 15034: Loss: 0.0026\n",
            "Epoch 3, Sample 15035: Loss: 0.6990\n",
            "Epoch 3, Sample 15036: Loss: 0.1225\n",
            "Epoch 3, Sample 15037: Loss: 0.0000\n",
            "Epoch 3, Sample 15038: Loss: 0.0019\n",
            "Epoch 3, Sample 15039: Loss: 0.2034\n",
            "Epoch 3, Sample 15040: Loss: 0.5858\n",
            "Epoch 3, Sample 15041: Loss: 0.8951\n",
            "Epoch 3, Sample 15042: Loss: 1.0524\n",
            "Epoch 3, Sample 15043: Loss: 0.2728\n",
            "Epoch 3, Sample 15044: Loss: 0.0034\n",
            "Epoch 3, Sample 15045: Loss: 9.4646\n",
            "Epoch 3, Sample 15046: Loss: 1.0524\n",
            "Epoch 3, Sample 15047: Loss: 0.0026\n",
            "Epoch 3, Sample 15048: Loss: 1.5113\n",
            "Epoch 3, Sample 15049: Loss: 0.2558\n",
            "Epoch 3, Sample 15050: Loss: 0.7036\n",
            "Epoch 3, Sample 15051: Loss: 1.0524\n",
            "Epoch 3, Sample 15052: Loss: 0.1040\n",
            "Epoch 3, Sample 15053: Loss: 0.1296\n",
            "Epoch 3, Sample 15054: Loss: 0.2034\n",
            "Epoch 3, Sample 15055: Loss: 0.3399\n",
            "Epoch 3, Sample 15056: Loss: 0.4728\n",
            "Epoch 3, Sample 15057: Loss: 0.3984\n",
            "Epoch 3, Sample 15058: Loss: 10.8397\n",
            "Epoch 3, Sample 15059: Loss: 0.2044\n",
            "Epoch 3, Sample 15060: Loss: 0.1592\n",
            "Epoch 3, Sample 15061: Loss: 0.5424\n",
            "Epoch 3, Sample 15062: Loss: 0.3399\n",
            "Epoch 3, Sample 15063: Loss: 0.0888\n",
            "Epoch 3, Sample 15064: Loss: 0.1364\n",
            "Epoch 3, Sample 15065: Loss: 0.0001\n",
            "Epoch 3, Sample 15066: Loss: 0.3441\n",
            "Epoch 3, Sample 15067: Loss: 0.2032\n",
            "Epoch 3, Sample 15068: Loss: 0.2036\n",
            "Epoch 3, Sample 15069: Loss: 0.1250\n",
            "Epoch 3, Sample 15070: Loss: 1.0530\n",
            "Epoch 3, Sample 15071: Loss: 0.0026\n",
            "Epoch 3, Sample 15072: Loss: 0.0839\n",
            "Epoch 3, Sample 15073: Loss: 0.6625\n",
            "Epoch 3, Sample 15074: Loss: 0.4032\n",
            "Epoch 3, Sample 15075: Loss: 0.8688\n",
            "Epoch 3, Sample 15076: Loss: 0.4799\n",
            "Epoch 3, Sample 15077: Loss: 0.7036\n",
            "Epoch 3, Sample 15078: Loss: 0.2855\n",
            "Epoch 3, Sample 15079: Loss: 0.0000\n",
            "Epoch 3, Sample 15080: Loss: 0.2832\n",
            "Epoch 3, Sample 15081: Loss: 0.1170\n",
            "Epoch 3, Sample 15082: Loss: 1.1160\n",
            "Epoch 3, Sample 15083: Loss: 0.0000\n",
            "Epoch 3, Sample 15084: Loss: 0.0025\n",
            "Epoch 3, Sample 15085: Loss: 0.1055\n",
            "Epoch 3, Sample 15086: Loss: 0.3332\n",
            "Epoch 3, Sample 15087: Loss: 0.1252\n",
            "Epoch 3, Sample 15088: Loss: 0.3441\n",
            "Epoch 3, Sample 15089: Loss: 0.2032\n",
            "Epoch 3, Sample 15090: Loss: 0.0001\n",
            "Epoch 3, Sample 15091: Loss: 0.0637\n",
            "Epoch 3, Sample 15092: Loss: 0.6072\n",
            "Epoch 3, Sample 15093: Loss: 0.6990\n",
            "Epoch 3, Sample 15094: Loss: 0.0026\n",
            "Epoch 3, Sample 15095: Loss: 0.5000\n",
            "Epoch 3, Sample 15096: Loss: 0.0001\n",
            "Epoch 3, Sample 15097: Loss: 0.0026\n",
            "Epoch 3, Sample 15098: Loss: 0.5200\n",
            "Epoch 3, Sample 15099: Loss: 0.0306\n",
            "Epoch 3, Sample 15100: Loss: 0.0026\n",
            "Epoch 3, Sample 15101: Loss: 0.0026\n",
            "Epoch 3, Sample 15102: Loss: 0.7702\n",
            "Epoch 3, Sample 15103: Loss: 0.3949\n",
            "Epoch 3, Sample 15104: Loss: 1.0524\n",
            "Epoch 3, Sample 15105: Loss: 0.5003\n",
            "Epoch 3, Sample 15106: Loss: 0.2044\n",
            "Epoch 3, Sample 15107: Loss: 1.0155\n",
            "Epoch 3, Sample 15108: Loss: 0.0153\n",
            "Epoch 3, Sample 15109: Loss: 0.1248\n",
            "Epoch 3, Sample 15110: Loss: 1.0524\n",
            "Epoch 3, Sample 15111: Loss: 0.1397\n",
            "Epoch 3, Sample 15112: Loss: 0.0005\n",
            "Epoch 3, Sample 15113: Loss: 0.6076\n",
            "Epoch 3, Sample 15114: Loss: 0.1872\n",
            "Epoch 3, Sample 15115: Loss: 1.8189\n",
            "Epoch 3, Sample 15116: Loss: 0.5636\n",
            "Epoch 3, Sample 15117: Loss: 0.3441\n",
            "Epoch 3, Sample 15118: Loss: 1.0688\n",
            "Epoch 3, Sample 15119: Loss: 0.1170\n",
            "Epoch 3, Sample 15120: Loss: 1.0524\n",
            "Epoch 3, Sample 15121: Loss: 1.0524\n",
            "Epoch 3, Sample 15122: Loss: 0.0018\n",
            "Epoch 3, Sample 15123: Loss: 0.1627\n",
            "Epoch 3, Sample 15124: Loss: 0.5591\n",
            "Epoch 3, Sample 15125: Loss: 0.0630\n",
            "Epoch 3, Sample 15126: Loss: 0.0466\n",
            "Epoch 3, Sample 15127: Loss: 0.0241\n",
            "Epoch 3, Sample 15128: Loss: 0.2044\n",
            "Epoch 3, Sample 15129: Loss: 0.2034\n",
            "Epoch 3, Sample 15130: Loss: 0.4799\n",
            "Epoch 3, Sample 15131: Loss: 0.2759\n",
            "Epoch 3, Sample 15132: Loss: 0.1225\n",
            "Epoch 3, Sample 15133: Loss: 1.4482\n",
            "Epoch 3, Sample 15134: Loss: 0.0001\n",
            "Epoch 3, Sample 15135: Loss: 0.2086\n",
            "Epoch 3, Sample 15136: Loss: 0.2962\n",
            "Epoch 3, Sample 15137: Loss: 0.3872\n",
            "Epoch 3, Sample 15138: Loss: 0.1250\n",
            "Epoch 3, Sample 15139: Loss: 1.0524\n",
            "Epoch 3, Sample 15140: Loss: 0.3568\n",
            "Epoch 3, Sample 15141: Loss: 0.2044\n",
            "Epoch 3, Sample 15142: Loss: 1.0524\n",
            "Epoch 3, Sample 15143: Loss: 0.0023\n",
            "Epoch 3, Sample 15144: Loss: 0.0001\n",
            "Epoch 3, Sample 15145: Loss: 0.0026\n",
            "Epoch 3, Sample 15146: Loss: 1.0524\n",
            "Epoch 3, Sample 15147: Loss: 0.0026\n",
            "Epoch 3, Sample 15148: Loss: 0.6092\n",
            "Epoch 3, Sample 15149: Loss: 2.4873\n",
            "Epoch 3, Sample 15150: Loss: 0.3608\n",
            "Epoch 3, Sample 15151: Loss: 0.7036\n",
            "Epoch 3, Sample 15152: Loss: 0.5078\n",
            "Epoch 3, Sample 15153: Loss: 0.0625\n",
            "Epoch 3, Sample 15154: Loss: 0.1258\n",
            "Epoch 3, Sample 15155: Loss: 0.7036\n",
            "Epoch 3, Sample 15156: Loss: 0.0062\n",
            "Epoch 3, Sample 15157: Loss: 0.1252\n",
            "Epoch 3, Sample 15158: Loss: 0.0150\n",
            "Epoch 3, Sample 15159: Loss: 0.0476\n",
            "Epoch 3, Sample 15160: Loss: 2.1721\n",
            "Epoch 3, Sample 15161: Loss: 0.0258\n",
            "Epoch 3, Sample 15162: Loss: 0.4930\n",
            "Epoch 3, Sample 15163: Loss: 1.0524\n",
            "Epoch 3, Sample 15164: Loss: 1.9213\n",
            "Epoch 3, Sample 15165: Loss: 0.4588\n",
            "Epoch 3, Sample 15166: Loss: 0.1246\n",
            "Epoch 3, Sample 15167: Loss: 0.2759\n",
            "Epoch 3, Sample 15168: Loss: 0.7274\n",
            "Epoch 3, Sample 15169: Loss: 0.1924\n",
            "Epoch 3, Sample 15170: Loss: 0.5858\n",
            "Epoch 3, Sample 15171: Loss: 0.0000\n",
            "Epoch 3, Sample 15172: Loss: 0.0298\n",
            "Epoch 3, Sample 15173: Loss: 0.3265\n",
            "Epoch 3, Sample 15174: Loss: 0.0001\n",
            "Epoch 3, Sample 15175: Loss: 0.1523\n",
            "Epoch 3, Sample 15176: Loss: 0.3367\n",
            "Epoch 3, Sample 15177: Loss: 1.0524\n",
            "Epoch 3, Sample 15178: Loss: 0.3399\n",
            "Epoch 3, Sample 15179: Loss: 0.4032\n",
            "Epoch 3, Sample 15180: Loss: 0.1238\n",
            "Epoch 3, Sample 15181: Loss: 0.2034\n",
            "Epoch 3, Sample 15182: Loss: 0.1170\n",
            "Epoch 3, Sample 15183: Loss: 0.0018\n",
            "Epoch 3, Sample 15184: Loss: 0.6990\n",
            "Epoch 3, Sample 15185: Loss: 0.0328\n",
            "Epoch 3, Sample 15186: Loss: 0.4799\n",
            "Epoch 3, Sample 15187: Loss: 0.2494\n",
            "Epoch 3, Sample 15188: Loss: 0.2985\n",
            "Epoch 3, Sample 15189: Loss: 0.2095\n",
            "Epoch 3, Sample 15190: Loss: 1.0530\n",
            "Epoch 3, Sample 15191: Loss: 0.2806\n",
            "Epoch 3, Sample 15192: Loss: 0.2032\n",
            "Epoch 3, Sample 15193: Loss: 0.2032\n",
            "Epoch 3, Sample 15194: Loss: 0.2219\n",
            "Epoch 3, Sample 15195: Loss: 12.8361\n",
            "Epoch 3, Sample 15196: Loss: 0.4996\n",
            "Epoch 3, Sample 15197: Loss: 0.6304\n",
            "Epoch 3, Sample 15198: Loss: 0.0915\n",
            "Epoch 3, Sample 15199: Loss: 0.1170\n",
            "Epoch 3, Sample 15200: Loss: 1.0530\n",
            "Epoch 3, Sample 15201: Loss: 0.0049\n",
            "Epoch 3, Sample 15202: Loss: 0.0018\n",
            "Epoch 3, Sample 15203: Loss: 0.2132\n",
            "Epoch 3, Sample 15204: Loss: 0.2034\n",
            "Epoch 3, Sample 15205: Loss: 2.1765\n",
            "Epoch 3, Sample 15206: Loss: 0.4816\n",
            "Epoch 3, Sample 15207: Loss: 0.2219\n",
            "Epoch 3, Sample 15208: Loss: 0.0951\n",
            "Epoch 3, Sample 15209: Loss: 0.0077\n",
            "Epoch 3, Sample 15210: Loss: 0.0084\n",
            "Epoch 3, Sample 15211: Loss: 0.3949\n",
            "Epoch 3, Sample 15212: Loss: 0.1016\n",
            "Epoch 3, Sample 15213: Loss: 0.2112\n",
            "Epoch 3, Sample 15214: Loss: 0.3399\n",
            "Epoch 3, Sample 15215: Loss: 1.0524\n",
            "Epoch 3, Sample 15216: Loss: 0.3477\n",
            "Epoch 3, Sample 15217: Loss: 0.0415\n",
            "Epoch 3, Sample 15218: Loss: 0.3698\n",
            "Epoch 3, Sample 15219: Loss: 0.5573\n",
            "Epoch 3, Sample 15220: Loss: 0.2046\n",
            "Epoch 3, Sample 15221: Loss: 0.2759\n",
            "Epoch 3, Sample 15222: Loss: 0.3399\n",
            "Epoch 3, Sample 15223: Loss: 0.7108\n",
            "Epoch 3, Sample 15224: Loss: 0.2034\n",
            "Epoch 3, Sample 15225: Loss: 0.0630\n",
            "Epoch 3, Sample 15226: Loss: 0.0212\n",
            "Epoch 3, Sample 15227: Loss: 0.0059\n",
            "Epoch 3, Sample 15228: Loss: 1.0524\n",
            "Epoch 3, Sample 15229: Loss: 0.7036\n",
            "Epoch 3, Sample 15230: Loss: 0.2034\n",
            "Epoch 3, Sample 15231: Loss: 0.1559\n",
            "Epoch 3, Sample 15232: Loss: 0.0802\n",
            "Epoch 3, Sample 15233: Loss: 0.0938\n",
            "Epoch 3, Sample 15234: Loss: 0.1817\n",
            "Epoch 3, Sample 15235: Loss: 1.0524\n",
            "Epoch 3, Sample 15236: Loss: 0.2452\n",
            "Epoch 3, Sample 15237: Loss: 0.6203\n",
            "Epoch 3, Sample 15238: Loss: 1.0524\n",
            "Epoch 3, Sample 15239: Loss: 0.3949\n",
            "Epoch 3, Sample 15240: Loss: 0.0751\n",
            "Epoch 3, Sample 15241: Loss: 0.4607\n",
            "Epoch 3, Sample 15242: Loss: 0.3441\n",
            "Epoch 3, Sample 15243: Loss: 1.0524\n",
            "Epoch 3, Sample 15244: Loss: 0.1472\n",
            "Epoch 3, Sample 15245: Loss: 0.1170\n",
            "Epoch 3, Sample 15246: Loss: 0.7036\n",
            "Epoch 3, Sample 15247: Loss: 0.8226\n",
            "Epoch 3, Sample 15248: Loss: 0.2032\n",
            "Epoch 3, Sample 15249: Loss: 0.8951\n",
            "Epoch 3, Sample 15250: Loss: 1.0524\n",
            "Epoch 3, Sample 15251: Loss: 0.2034\n",
            "Epoch 3, Sample 15252: Loss: 0.0042\n",
            "Epoch 3, Sample 15253: Loss: 0.0026\n",
            "Epoch 3, Sample 15254: Loss: 0.6139\n",
            "Epoch 3, Sample 15255: Loss: 1.9820\n",
            "Epoch 3, Sample 15256: Loss: 1.0155\n",
            "Epoch 3, Sample 15257: Loss: 0.0067\n",
            "Epoch 3, Sample 15258: Loss: 0.1039\n",
            "Epoch 3, Sample 15259: Loss: 0.2759\n",
            "Epoch 3, Sample 15260: Loss: 0.5858\n",
            "Epoch 3, Sample 15261: Loss: 0.3441\n",
            "Epoch 3, Sample 15262: Loss: 1.0524\n",
            "Epoch 3, Sample 15263: Loss: 1.0530\n",
            "Epoch 3, Sample 15264: Loss: 0.4611\n",
            "Epoch 3, Sample 15265: Loss: 0.2759\n",
            "Epoch 3, Sample 15266: Loss: 0.0337\n",
            "Epoch 3, Sample 15267: Loss: 0.5636\n",
            "Epoch 3, Sample 15268: Loss: 0.2032\n",
            "Epoch 3, Sample 15269: Loss: 0.0682\n",
            "Epoch 3, Sample 15270: Loss: 0.0249\n",
            "Epoch 3, Sample 15271: Loss: 0.0026\n",
            "Epoch 3, Sample 15272: Loss: 1.0524\n",
            "Epoch 3, Sample 15273: Loss: 0.0000\n",
            "Epoch 3, Sample 15274: Loss: 0.2032\n",
            "Epoch 3, Sample 15275: Loss: 0.0012\n",
            "Epoch 3, Sample 15276: Loss: 0.1170\n",
            "Epoch 3, Sample 15277: Loss: 0.0203\n",
            "Epoch 3, Sample 15278: Loss: 0.1968\n",
            "Epoch 3, Sample 15279: Loss: 0.1264\n",
            "Epoch 3, Sample 15280: Loss: 0.9785\n",
            "Epoch 3, Sample 15281: Loss: 1.1569\n",
            "Epoch 3, Sample 15282: Loss: 0.0945\n",
            "Epoch 3, Sample 15283: Loss: 0.3418\n",
            "Epoch 3, Sample 15284: Loss: 0.6697\n",
            "Epoch 3, Sample 15285: Loss: 0.4682\n",
            "Epoch 3, Sample 15286: Loss: 0.0270\n",
            "Epoch 3, Sample 15287: Loss: 0.2598\n",
            "Epoch 3, Sample 15288: Loss: 0.3441\n",
            "Epoch 3, Sample 15289: Loss: 0.2044\n",
            "Epoch 3, Sample 15290: Loss: 0.3262\n",
            "Epoch 3, Sample 15291: Loss: 0.2034\n",
            "Epoch 3, Sample 15292: Loss: 0.2034\n",
            "Epoch 3, Sample 15293: Loss: 0.4799\n",
            "Epoch 3, Sample 15294: Loss: 0.1036\n",
            "Epoch 3, Sample 15295: Loss: 0.0025\n",
            "Epoch 3, Sample 15296: Loss: 0.2036\n",
            "Epoch 3, Sample 15297: Loss: 0.1397\n",
            "Epoch 3, Sample 15298: Loss: 0.1170\n",
            "Epoch 3, Sample 15299: Loss: 0.9785\n",
            "Epoch 3, Sample 15300: Loss: 0.2812\n",
            "Epoch 3, Sample 15301: Loss: 0.5845\n",
            "Epoch 3, Sample 15302: Loss: 0.0170\n",
            "Epoch 3, Sample 15303: Loss: 0.0001\n",
            "Epoch 3, Sample 15304: Loss: 0.2393\n",
            "Epoch 3, Sample 15305: Loss: 0.1040\n",
            "Epoch 3, Sample 15306: Loss: 0.3399\n",
            "Epoch 3, Sample 15307: Loss: 0.0626\n",
            "Epoch 3, Sample 15308: Loss: 0.1465\n",
            "Epoch 3, Sample 15309: Loss: 0.9044\n",
            "Epoch 3, Sample 15310: Loss: 10.3220\n",
            "Epoch 3, Sample 15311: Loss: 0.0466\n",
            "Epoch 3, Sample 15312: Loss: 1.0524\n",
            "Epoch 3, Sample 15313: Loss: 0.2639\n",
            "Epoch 3, Sample 15314: Loss: 0.3288\n",
            "Epoch 3, Sample 15315: Loss: 0.3477\n",
            "Epoch 3, Sample 15316: Loss: 0.6990\n",
            "Epoch 3, Sample 15317: Loss: 0.2044\n",
            "Epoch 3, Sample 15318: Loss: 0.0057\n",
            "Epoch 3, Sample 15319: Loss: 0.3228\n",
            "Epoch 3, Sample 15320: Loss: 1.0524\n",
            "Epoch 3, Sample 15321: Loss: 0.5799\n",
            "Epoch 3, Sample 15322: Loss: 0.4996\n",
            "Epoch 3, Sample 15323: Loss: 1.0155\n",
            "Epoch 3, Sample 15324: Loss: 0.0802\n",
            "Epoch 3, Sample 15325: Loss: 1.0524\n",
            "Epoch 3, Sample 15326: Loss: 0.0082\n",
            "Epoch 3, Sample 15327: Loss: 0.2032\n",
            "Epoch 3, Sample 15328: Loss: 0.3399\n",
            "Epoch 3, Sample 15329: Loss: 1.0524\n",
            "Epoch 3, Sample 15330: Loss: 1.0524\n",
            "Epoch 3, Sample 15331: Loss: 0.2034\n",
            "Epoch 3, Sample 15332: Loss: 0.1581\n",
            "Epoch 3, Sample 15333: Loss: 0.1546\n",
            "Epoch 3, Sample 15334: Loss: 0.1005\n",
            "Epoch 3, Sample 15335: Loss: 0.0018\n",
            "Epoch 3, Sample 15336: Loss: 0.0001\n",
            "Epoch 3, Sample 15337: Loss: 4.6584\n",
            "Epoch 3, Sample 15338: Loss: 0.0630\n",
            "Epoch 3, Sample 15339: Loss: 0.1039\n",
            "Epoch 3, Sample 15340: Loss: 0.0460\n",
            "Epoch 3, Sample 15341: Loss: 0.0270\n",
            "Epoch 3, Sample 15342: Loss: 0.7203\n",
            "Epoch 3, Sample 15343: Loss: 0.0640\n",
            "Epoch 3, Sample 15344: Loss: 0.7036\n",
            "Epoch 3, Sample 15345: Loss: 1.0524\n",
            "Epoch 3, Sample 15346: Loss: 1.0359\n",
            "Epoch 3, Sample 15347: Loss: 0.0426\n",
            "Epoch 3, Sample 15348: Loss: 0.4213\n",
            "Epoch 3, Sample 15349: Loss: 1.4969\n",
            "Epoch 3, Sample 15350: Loss: 0.2219\n",
            "Epoch 3, Sample 15351: Loss: 0.2036\n",
            "Epoch 3, Sample 15352: Loss: 0.6925\n",
            "Epoch 3, Sample 15353: Loss: 0.1559\n",
            "Epoch 3, Sample 15354: Loss: 1.0524\n",
            "Epoch 3, Sample 15355: Loss: 0.3949\n",
            "Epoch 3, Sample 15356: Loss: 0.1170\n",
            "Epoch 3, Sample 15357: Loss: 0.2270\n",
            "Epoch 3, Sample 15358: Loss: 0.0286\n",
            "Epoch 3, Sample 15359: Loss: 0.3399\n",
            "Epoch 3, Sample 15360: Loss: 2.6215\n",
            "Epoch 3, Sample 15361: Loss: 0.0001\n",
            "Epoch 3, Sample 15362: Loss: 0.3399\n",
            "Epoch 3, Sample 15363: Loss: 4.2335\n",
            "Epoch 3, Sample 15364: Loss: 1.5542\n",
            "Epoch 3, Sample 15365: Loss: 0.6990\n",
            "Epoch 3, Sample 15366: Loss: 0.9428\n",
            "Epoch 3, Sample 15367: Loss: 0.2759\n",
            "Epoch 3, Sample 15368: Loss: 0.3598\n",
            "Epoch 3, Sample 15369: Loss: 0.0915\n",
            "Epoch 3, Sample 15370: Loss: 0.7036\n",
            "Epoch 3, Sample 15371: Loss: 0.1246\n",
            "Epoch 3, Sample 15372: Loss: 0.2614\n",
            "Epoch 3, Sample 15373: Loss: 1.0530\n",
            "Epoch 3, Sample 15374: Loss: 0.2044\n",
            "Epoch 3, Sample 15375: Loss: 0.4087\n",
            "Epoch 3, Sample 15376: Loss: 0.0532\n",
            "Epoch 3, Sample 15377: Loss: 9.1280\n",
            "Epoch 3, Sample 15378: Loss: 0.6990\n",
            "Epoch 3, Sample 15379: Loss: 0.2044\n",
            "Epoch 3, Sample 15380: Loss: 0.1989\n",
            "Epoch 3, Sample 15381: Loss: 1.0524\n",
            "Epoch 3, Sample 15382: Loss: 0.5058\n",
            "Epoch 3, Sample 15383: Loss: 0.0005\n",
            "Epoch 3, Sample 15384: Loss: 0.3367\n",
            "Epoch 3, Sample 15385: Loss: 0.5000\n",
            "Epoch 3, Sample 15386: Loss: 0.9367\n",
            "Epoch 3, Sample 15387: Loss: 0.0026\n",
            "Epoch 3, Sample 15388: Loss: 0.6581\n",
            "Epoch 3, Sample 15389: Loss: 0.0063\n",
            "Epoch 3, Sample 15390: Loss: 1.0524\n",
            "Epoch 3, Sample 15391: Loss: 0.1814\n",
            "Epoch 3, Sample 15392: Loss: 0.4799\n",
            "Epoch 3, Sample 15393: Loss: 0.2778\n",
            "Epoch 3, Sample 15394: Loss: 0.0630\n",
            "Epoch 3, Sample 15395: Loss: 0.0063\n",
            "Epoch 3, Sample 15396: Loss: 0.0230\n",
            "Epoch 3, Sample 15397: Loss: 0.6092\n",
            "Epoch 3, Sample 15398: Loss: 0.1343\n",
            "Epoch 3, Sample 15399: Loss: 0.4996\n",
            "Epoch 3, Sample 15400: Loss: 0.5636\n",
            "Epoch 3, Sample 15401: Loss: 0.8046\n",
            "Epoch 3, Sample 15402: Loss: 1.0530\n",
            "Epoch 3, Sample 15403: Loss: 0.0001\n",
            "Epoch 3, Sample 15404: Loss: 0.0026\n",
            "Epoch 3, Sample 15405: Loss: 0.3577\n",
            "Epoch 3, Sample 15406: Loss: 0.5000\n",
            "Epoch 3, Sample 15407: Loss: 0.0838\n",
            "Epoch 3, Sample 15408: Loss: 0.0460\n",
            "Epoch 3, Sample 15409: Loss: 0.0001\n",
            "Epoch 3, Sample 15410: Loss: 0.0220\n",
            "Epoch 3, Sample 15411: Loss: 0.0152\n",
            "Epoch 3, Sample 15412: Loss: 0.7036\n",
            "Epoch 3, Sample 15413: Loss: 0.7453\n",
            "Epoch 3, Sample 15414: Loss: 0.2032\n",
            "Epoch 3, Sample 15415: Loss: 1.0524\n",
            "Epoch 3, Sample 15416: Loss: 0.7486\n",
            "Epoch 3, Sample 15417: Loss: 0.1170\n",
            "Epoch 3, Sample 15418: Loss: 0.5799\n",
            "Epoch 3, Sample 15419: Loss: 0.0026\n",
            "Epoch 3, Sample 15420: Loss: 0.5078\n",
            "Epoch 3, Sample 15421: Loss: 0.0749\n",
            "Epoch 3, Sample 15422: Loss: 1.0524\n",
            "Epoch 3, Sample 15423: Loss: 0.3062\n",
            "Epoch 3, Sample 15424: Loss: 0.0270\n",
            "Epoch 3, Sample 15425: Loss: 0.2032\n",
            "Epoch 3, Sample 15426: Loss: 0.0018\n",
            "Epoch 3, Sample 15427: Loss: 0.7091\n",
            "Epoch 3, Sample 15428: Loss: 0.4733\n",
            "Epoch 3, Sample 15429: Loss: 0.2150\n",
            "Epoch 3, Sample 15430: Loss: 1.1636\n",
            "Epoch 3, Sample 15431: Loss: 0.0013\n",
            "Epoch 3, Sample 15432: Loss: 0.4032\n",
            "Epoch 3, Sample 15433: Loss: 0.0915\n",
            "Epoch 3, Sample 15434: Loss: 0.2639\n",
            "Epoch 3, Sample 15435: Loss: 0.0306\n",
            "Epoch 3, Sample 15436: Loss: 0.0286\n",
            "Epoch 3, Sample 15437: Loss: 0.0145\n",
            "Epoch 3, Sample 15438: Loss: 0.8951\n",
            "Epoch 3, Sample 15439: Loss: 0.1588\n",
            "Epoch 3, Sample 15440: Loss: 0.1326\n",
            "Epoch 3, Sample 15441: Loss: 1.0524\n",
            "Epoch 3, Sample 15442: Loss: 0.5858\n",
            "Epoch 3, Sample 15443: Loss: 0.0177\n",
            "Epoch 3, Sample 15444: Loss: 0.2639\n",
            "Epoch 3, Sample 15445: Loss: 0.1057\n",
            "Epoch 3, Sample 15446: Loss: 1.0530\n",
            "Epoch 3, Sample 15447: Loss: 4.5910\n",
            "Epoch 3, Sample 15448: Loss: 0.2044\n",
            "Epoch 3, Sample 15449: Loss: 0.1170\n",
            "Epoch 3, Sample 15450: Loss: 0.0026\n",
            "Epoch 3, Sample 15451: Loss: 0.3399\n",
            "Epoch 3, Sample 15452: Loss: 0.3332\n",
            "Epoch 3, Sample 15453: Loss: 0.0625\n",
            "Epoch 3, Sample 15454: Loss: 0.7036\n",
            "Epoch 3, Sample 15455: Loss: 0.0415\n",
            "Epoch 3, Sample 15456: Loss: 0.1208\n",
            "Epoch 3, Sample 15457: Loss: 0.0077\n",
            "Epoch 3, Sample 15458: Loss: 0.0663\n",
            "Epoch 3, Sample 15459: Loss: 0.7036\n",
            "Epoch 3, Sample 15460: Loss: 0.8562\n",
            "Epoch 3, Sample 15461: Loss: 0.0630\n",
            "Epoch 3, Sample 15462: Loss: 0.0062\n",
            "Epoch 3, Sample 15463: Loss: 0.0126\n",
            "Epoch 3, Sample 15464: Loss: 0.3450\n",
            "Epoch 3, Sample 15465: Loss: 1.2553\n",
            "Epoch 3, Sample 15466: Loss: 0.0630\n",
            "Epoch 3, Sample 15467: Loss: 0.2044\n",
            "Epoch 3, Sample 15468: Loss: 0.5058\n",
            "Epoch 3, Sample 15469: Loss: 0.1248\n",
            "Epoch 3, Sample 15470: Loss: 0.2034\n",
            "Epoch 3, Sample 15471: Loss: 0.1417\n",
            "Epoch 3, Sample 15472: Loss: 0.4930\n",
            "Epoch 3, Sample 15473: Loss: 0.1559\n",
            "Epoch 3, Sample 15474: Loss: 2.0437\n",
            "Epoch 3, Sample 15475: Loss: 0.8951\n",
            "Epoch 3, Sample 15476: Loss: 0.1741\n",
            "Epoch 3, Sample 15477: Loss: 0.3584\n",
            "Epoch 3, Sample 15478: Loss: 1.0155\n",
            "Epoch 3, Sample 15479: Loss: 0.0220\n",
            "Epoch 3, Sample 15480: Loss: 0.5003\n",
            "Epoch 3, Sample 15481: Loss: 1.0155\n",
            "Epoch 3, Sample 15482: Loss: 0.7036\n",
            "Epoch 3, Sample 15483: Loss: 0.0313\n",
            "Epoch 3, Sample 15484: Loss: 0.6867\n",
            "Epoch 3, Sample 15485: Loss: 0.1399\n",
            "Epoch 3, Sample 15486: Loss: 0.3332\n",
            "Epoch 3, Sample 15487: Loss: 0.0640\n",
            "Epoch 3, Sample 15488: Loss: 0.5721\n",
            "Epoch 3, Sample 15489: Loss: 0.3418\n",
            "Epoch 3, Sample 15490: Loss: 1.0002\n",
            "Epoch 3, Sample 15491: Loss: 1.0524\n",
            "Epoch 3, Sample 15492: Loss: 1.0227\n",
            "Epoch 3, Sample 15493: Loss: 0.5000\n",
            "Epoch 3, Sample 15494: Loss: 0.5871\n",
            "Epoch 3, Sample 15495: Loss: 0.1225\n",
            "Epoch 3, Sample 15496: Loss: 0.0022\n",
            "Epoch 3, Sample 15497: Loss: 0.2355\n",
            "Epoch 3, Sample 15498: Loss: 0.1401\n",
            "Epoch 3, Sample 15499: Loss: 0.0018\n",
            "Epoch 3, Sample 15500: Loss: 1.0524\n",
            "Epoch 3, Sample 15501: Loss: 0.0001\n",
            "Epoch 3, Sample 15502: Loss: 0.7453\n",
            "Epoch 3, Sample 15503: Loss: 0.4486\n",
            "Epoch 3, Sample 15504: Loss: 0.2759\n",
            "Epoch 3, Sample 15505: Loss: 0.1006\n",
            "Epoch 3, Sample 15506: Loss: 7.1345\n",
            "Epoch 3, Sample 15507: Loss: 0.0270\n",
            "Epoch 3, Sample 15508: Loss: 0.5519\n",
            "Epoch 3, Sample 15509: Loss: 0.9367\n",
            "Epoch 3, Sample 15510: Loss: 1.0524\n",
            "Epoch 3, Sample 15511: Loss: 0.0018\n",
            "Epoch 3, Sample 15512: Loss: 0.2832\n",
            "Epoch 3, Sample 15513: Loss: 0.7036\n",
            "Epoch 3, Sample 15514: Loss: 2.1979\n",
            "Epoch 3, Sample 15515: Loss: 0.0364\n",
            "Epoch 3, Sample 15516: Loss: 0.0018\n",
            "Epoch 3, Sample 15517: Loss: 0.3441\n",
            "Epoch 3, Sample 15518: Loss: 0.2832\n",
            "Epoch 3, Sample 15519: Loss: 0.2175\n",
            "Epoch 3, Sample 15520: Loss: 0.2032\n",
            "Epoch 3, Sample 15521: Loss: 0.0240\n",
            "Epoch 3, Sample 15522: Loss: 0.0519\n",
            "Epoch 3, Sample 15523: Loss: 0.7036\n",
            "Epoch 3, Sample 15524: Loss: 0.3441\n",
            "Epoch 3, Sample 15525: Loss: 0.0212\n",
            "Epoch 3, Sample 15526: Loss: 1.0530\n",
            "Epoch 3, Sample 15527: Loss: 0.0212\n",
            "Epoch 3, Sample 15528: Loss: 0.1248\n",
            "Epoch 3, Sample 15529: Loss: 0.7036\n",
            "Epoch 3, Sample 15530: Loss: 0.3433\n",
            "Epoch 3, Sample 15531: Loss: 0.2704\n",
            "Epoch 3, Sample 15532: Loss: 0.0015\n",
            "Epoch 3, Sample 15533: Loss: 0.1588\n",
            "Epoch 3, Sample 15534: Loss: 0.3949\n",
            "Epoch 3, Sample 15535: Loss: 0.5283\n",
            "Epoch 3, Sample 15536: Loss: 0.1397\n",
            "Epoch 3, Sample 15537: Loss: 0.0026\n",
            "Epoch 3, Sample 15538: Loss: 1.0524\n",
            "Epoch 3, Sample 15539: Loss: 0.1546\n",
            "Epoch 3, Sample 15540: Loss: 0.0501\n",
            "Epoch 3, Sample 15541: Loss: 0.2851\n",
            "Epoch 3, Sample 15542: Loss: 0.3402\n",
            "Epoch 3, Sample 15543: Loss: 0.2759\n",
            "Epoch 3, Sample 15544: Loss: 0.2044\n",
            "Epoch 3, Sample 15545: Loss: 0.9367\n",
            "Epoch 3, Sample 15546: Loss: 0.2639\n",
            "Epoch 3, Sample 15547: Loss: 1.0524\n",
            "Epoch 3, Sample 15548: Loss: 0.1250\n",
            "Epoch 3, Sample 15549: Loss: 1.3444\n",
            "Epoch 3, Sample 15550: Loss: 0.0270\n",
            "Epoch 3, Sample 15551: Loss: 0.2962\n",
            "Epoch 3, Sample 15552: Loss: 0.5893\n",
            "Epoch 3, Sample 15553: Loss: 0.0200\n",
            "Epoch 3, Sample 15554: Loss: 0.8951\n",
            "Epoch 3, Sample 15555: Loss: 0.2759\n",
            "Epoch 3, Sample 15556: Loss: 2.0175\n",
            "Epoch 3, Sample 15557: Loss: 1.0266\n",
            "Epoch 3, Sample 15558: Loss: 1.8409\n",
            "Epoch 3, Sample 15559: Loss: 0.0340\n",
            "Epoch 3, Sample 15560: Loss: 1.0524\n",
            "Epoch 3, Sample 15561: Loss: 0.0145\n",
            "Epoch 3, Sample 15562: Loss: 0.3441\n",
            "Epoch 3, Sample 15563: Loss: 0.0026\n",
            "Epoch 3, Sample 15564: Loss: 0.0135\n",
            "Epoch 3, Sample 15565: Loss: 1.0524\n",
            "Epoch 3, Sample 15566: Loss: 0.1559\n",
            "Epoch 3, Sample 15567: Loss: 1.8266\n",
            "Epoch 3, Sample 15568: Loss: 0.2032\n",
            "Epoch 3, Sample 15569: Loss: 0.0915\n",
            "Epoch 3, Sample 15570: Loss: 0.2759\n",
            "Epoch 3, Sample 15571: Loss: 1.0524\n",
            "Epoch 3, Sample 15572: Loss: 0.3758\n",
            "Epoch 3, Sample 15573: Loss: 0.6139\n",
            "Epoch 3, Sample 15574: Loss: 1.0524\n",
            "Epoch 3, Sample 15575: Loss: 0.0018\n",
            "Epoch 3, Sample 15576: Loss: 1.1789\n",
            "Epoch 3, Sample 15577: Loss: 0.0254\n",
            "Epoch 3, Sample 15578: Loss: 0.0642\n",
            "Epoch 3, Sample 15579: Loss: 1.0524\n",
            "Epoch 3, Sample 15580: Loss: 0.2044\n",
            "Epoch 3, Sample 15581: Loss: 0.0978\n",
            "Epoch 3, Sample 15582: Loss: 0.2759\n",
            "Epoch 3, Sample 15583: Loss: 0.0630\n",
            "Epoch 3, Sample 15584: Loss: 0.1170\n",
            "Epoch 3, Sample 15585: Loss: 0.0001\n",
            "Epoch 3, Sample 15586: Loss: 0.2036\n",
            "Epoch 3, Sample 15587: Loss: 0.0018\n",
            "Epoch 3, Sample 15588: Loss: 1.0530\n",
            "Epoch 3, Sample 15589: Loss: 1.0524\n",
            "Epoch 3, Sample 15590: Loss: 1.7060\n",
            "Epoch 3, Sample 15591: Loss: 0.0550\n",
            "Epoch 3, Sample 15592: Loss: 0.0505\n",
            "Epoch 3, Sample 15593: Loss: 1.4662\n",
            "Epoch 3, Sample 15594: Loss: 0.4611\n",
            "Epoch 3, Sample 15595: Loss: 0.0630\n",
            "Epoch 3, Sample 15596: Loss: 1.0524\n",
            "Epoch 3, Sample 15597: Loss: 0.4879\n",
            "Epoch 3, Sample 15598: Loss: 0.4454\n",
            "Epoch 3, Sample 15599: Loss: 0.0195\n",
            "Epoch 3, Sample 15600: Loss: 0.3275\n",
            "Epoch 3, Sample 15601: Loss: 0.2832\n",
            "Epoch 3, Sample 15602: Loss: 0.1482\n",
            "Epoch 3, Sample 15603: Loss: 0.1250\n",
            "Epoch 3, Sample 15604: Loss: 0.9651\n",
            "Epoch 3, Sample 15605: Loss: 0.3247\n",
            "Epoch 3, Sample 15606: Loss: 1.0524\n",
            "Epoch 3, Sample 15607: Loss: 0.1924\n",
            "Epoch 3, Sample 15608: Loss: 2.5350\n",
            "Epoch 3, Sample 15609: Loss: 0.0026\n",
            "Epoch 3, Sample 15610: Loss: 0.4466\n",
            "Epoch 3, Sample 15611: Loss: 1.0524\n",
            "Epoch 3, Sample 15612: Loss: 0.7036\n",
            "Epoch 3, Sample 15613: Loss: 0.2044\n",
            "Epoch 3, Sample 15614: Loss: 0.4996\n",
            "Epoch 3, Sample 15615: Loss: 0.2034\n",
            "Epoch 3, Sample 15616: Loss: 0.0273\n",
            "Epoch 3, Sample 15617: Loss: 0.2639\n",
            "Epoch 3, Sample 15618: Loss: 0.6092\n",
            "Epoch 3, Sample 15619: Loss: 0.2044\n",
            "Epoch 3, Sample 15620: Loss: 0.2032\n",
            "Epoch 3, Sample 15621: Loss: 0.0838\n",
            "Epoch 3, Sample 15622: Loss: 0.1627\n",
            "Epoch 3, Sample 15623: Loss: 0.2639\n",
            "Epoch 3, Sample 15624: Loss: 0.5871\n",
            "Epoch 3, Sample 15625: Loss: 0.0232\n",
            "Epoch 3, Sample 15626: Loss: 0.3399\n",
            "Epoch 3, Sample 15627: Loss: 1.0524\n",
            "Epoch 3, Sample 15628: Loss: 0.0026\n",
            "Epoch 3, Sample 15629: Loss: 0.0026\n",
            "Epoch 3, Sample 15630: Loss: 0.1170\n",
            "Epoch 3, Sample 15631: Loss: 0.1989\n",
            "Epoch 3, Sample 15632: Loss: 0.1559\n",
            "Epoch 3, Sample 15633: Loss: 0.4611\n",
            "Epoch 3, Sample 15634: Loss: 0.4663\n",
            "Epoch 3, Sample 15635: Loss: 0.2032\n",
            "Epoch 3, Sample 15636: Loss: 0.2759\n",
            "Epoch 3, Sample 15637: Loss: 0.1337\n",
            "Epoch 3, Sample 15638: Loss: 0.5989\n",
            "Epoch 3, Sample 15639: Loss: 0.4930\n",
            "Epoch 3, Sample 15640: Loss: 0.2034\n",
            "Epoch 3, Sample 15641: Loss: 1.0524\n",
            "Epoch 3, Sample 15642: Loss: 0.1559\n",
            "Epoch 3, Sample 15643: Loss: 0.5019\n",
            "Epoch 3, Sample 15644: Loss: 1.0155\n",
            "Epoch 3, Sample 15645: Loss: 0.0145\n",
            "Epoch 3, Sample 15646: Loss: 0.3399\n",
            "Epoch 3, Sample 15647: Loss: 0.0938\n",
            "Epoch 3, Sample 15648: Loss: 0.0034\n",
            "Epoch 3, Sample 15649: Loss: 0.1170\n",
            "Epoch 3, Sample 15650: Loss: 0.7036\n",
            "Epoch 3, Sample 15651: Loss: 0.4134\n",
            "Epoch 3, Sample 15652: Loss: 0.7036\n",
            "Epoch 3, Sample 15653: Loss: 0.1170\n",
            "Epoch 3, Sample 15654: Loss: 0.5858\n",
            "Epoch 3, Sample 15655: Loss: 0.8238\n",
            "Epoch 3, Sample 15656: Loss: 0.7036\n",
            "Epoch 3, Sample 15657: Loss: 0.1336\n",
            "Epoch 3, Sample 15658: Loss: 0.0915\n",
            "Epoch 3, Sample 15659: Loss: 0.5000\n",
            "Epoch 3, Sample 15660: Loss: 0.2044\n",
            "Epoch 3, Sample 15661: Loss: 0.2114\n",
            "Epoch 3, Sample 15662: Loss: 0.3766\n",
            "Epoch 3, Sample 15663: Loss: 1.1075\n",
            "Epoch 3, Sample 15664: Loss: 0.4611\n",
            "Epoch 3, Sample 15665: Loss: 0.3130\n",
            "Epoch 3, Sample 15666: Loss: 0.7203\n",
            "Epoch 3, Sample 15667: Loss: 1.0155\n",
            "Epoch 3, Sample 15668: Loss: 1.0266\n",
            "Epoch 3, Sample 15669: Loss: 0.5528\n",
            "Epoch 3, Sample 15670: Loss: 0.0026\n",
            "Epoch 3, Sample 15671: Loss: 0.0972\n",
            "Epoch 3, Sample 15672: Loss: 0.1250\n",
            "Epoch 3, Sample 15673: Loss: 0.2989\n",
            "Epoch 3, Sample 15674: Loss: 0.0025\n",
            "Epoch 3, Sample 15675: Loss: 0.0038\n",
            "Epoch 3, Sample 15676: Loss: 0.4930\n",
            "Epoch 3, Sample 15677: Loss: 1.0524\n",
            "Epoch 3, Sample 15678: Loss: 0.3402\n",
            "Epoch 3, Sample 15679: Loss: 0.2112\n",
            "Epoch 3, Sample 15680: Loss: 1.0524\n",
            "Epoch 3, Sample 15681: Loss: 0.0025\n",
            "Epoch 3, Sample 15682: Loss: 0.3568\n",
            "Epoch 3, Sample 15683: Loss: 1.1352\n",
            "Epoch 3, Sample 15684: Loss: 0.1817\n",
            "Epoch 3, Sample 15685: Loss: 0.1036\n",
            "Epoch 3, Sample 15686: Loss: 0.6768\n",
            "Epoch 3, Sample 15687: Loss: 1.4314\n",
            "Epoch 3, Sample 15688: Loss: 0.0227\n",
            "Epoch 3, Sample 15689: Loss: 0.0052\n",
            "Epoch 3, Sample 15690: Loss: 0.2044\n",
            "Epoch 3, Sample 15691: Loss: 0.5850\n",
            "Epoch 3, Sample 15692: Loss: 0.2044\n",
            "Epoch 3, Sample 15693: Loss: 3.8664\n",
            "Epoch 3, Sample 15694: Loss: 1.0524\n",
            "Epoch 3, Sample 15695: Loss: 0.4550\n",
            "Epoch 3, Sample 15696: Loss: 1.5210\n",
            "Epoch 3, Sample 15697: Loss: 0.7453\n",
            "Epoch 3, Sample 15698: Loss: 0.3399\n",
            "Epoch 3, Sample 15699: Loss: 0.0026\n",
            "Epoch 3, Sample 15700: Loss: 0.0630\n",
            "Epoch 3, Sample 15701: Loss: 0.0026\n",
            "Epoch 3, Sample 15702: Loss: 0.0090\n",
            "Epoch 3, Sample 15703: Loss: 0.3247\n",
            "Epoch 3, Sample 15704: Loss: 0.0625\n",
            "Epoch 3, Sample 15705: Loss: 0.6990\n",
            "Epoch 3, Sample 15706: Loss: 0.3402\n",
            "Epoch 3, Sample 15707: Loss: 0.0104\n",
            "Epoch 3, Sample 15708: Loss: 0.0416\n",
            "Epoch 3, Sample 15709: Loss: 0.0358\n",
            "Epoch 3, Sample 15710: Loss: 0.3441\n",
            "Epoch 3, Sample 15711: Loss: 0.2759\n",
            "Epoch 3, Sample 15712: Loss: 0.5617\n",
            "Epoch 3, Sample 15713: Loss: 0.2899\n",
            "Epoch 3, Sample 15714: Loss: 0.6990\n",
            "Epoch 3, Sample 15715: Loss: 0.3399\n",
            "Epoch 3, Sample 15716: Loss: 0.0747\n",
            "Epoch 3, Sample 15717: Loss: 2.7331\n",
            "Epoch 3, Sample 15718: Loss: 0.1250\n",
            "Epoch 3, Sample 15719: Loss: 0.3805\n",
            "Epoch 3, Sample 15720: Loss: 0.1941\n",
            "Epoch 3, Sample 15721: Loss: 0.0377\n",
            "Epoch 3, Sample 15722: Loss: 0.0306\n",
            "Epoch 3, Sample 15723: Loss: 0.3949\n",
            "Epoch 3, Sample 15724: Loss: 2.9718\n",
            "Epoch 3, Sample 15725: Loss: 0.3573\n",
            "Epoch 3, Sample 15726: Loss: 0.2755\n",
            "Epoch 3, Sample 15727: Loss: 1.0397\n",
            "Epoch 3, Sample 15728: Loss: 1.0155\n",
            "Epoch 3, Sample 15729: Loss: 0.3949\n",
            "Epoch 3, Sample 15730: Loss: 0.6139\n",
            "Epoch 3, Sample 15731: Loss: 0.1559\n",
            "Epoch 3, Sample 15732: Loss: 2.2434\n",
            "Epoch 3, Sample 15733: Loss: 0.3332\n",
            "Epoch 3, Sample 15734: Loss: 0.1170\n",
            "Epoch 3, Sample 15735: Loss: 0.0505\n",
            "Epoch 3, Sample 15736: Loss: 0.2995\n",
            "Epoch 3, Sample 15737: Loss: 0.8951\n",
            "Epoch 3, Sample 15738: Loss: 0.4996\n",
            "Epoch 3, Sample 15739: Loss: 0.2219\n",
            "Epoch 3, Sample 15740: Loss: 0.2032\n",
            "Epoch 3, Sample 15741: Loss: 0.2044\n",
            "Epoch 3, Sample 15742: Loss: 0.4996\n",
            "Epoch 3, Sample 15743: Loss: 0.2219\n",
            "Epoch 3, Sample 15744: Loss: 0.3399\n",
            "Epoch 3, Sample 15745: Loss: 0.0460\n",
            "Epoch 3, Sample 15746: Loss: 0.1559\n",
            "Epoch 3, Sample 15747: Loss: 0.0630\n",
            "Epoch 3, Sample 15748: Loss: 0.1250\n",
            "Epoch 3, Sample 15749: Loss: 0.7486\n",
            "Epoch 3, Sample 15750: Loss: 0.0236\n",
            "Epoch 3, Sample 15751: Loss: 0.2044\n",
            "Epoch 3, Sample 15752: Loss: 0.1559\n",
            "Epoch 3, Sample 15753: Loss: 0.0018\n",
            "Epoch 3, Sample 15754: Loss: 0.0590\n",
            "Epoch 3, Sample 15755: Loss: 0.5000\n",
            "Epoch 3, Sample 15756: Loss: 0.0026\n",
            "Epoch 3, Sample 15757: Loss: 0.9780\n",
            "Epoch 3, Sample 15758: Loss: 0.1246\n",
            "Epoch 3, Sample 15759: Loss: 0.9367\n",
            "Epoch 3, Sample 15760: Loss: 0.1170\n",
            "Epoch 3, Sample 15761: Loss: 0.0639\n",
            "Epoch 3, Sample 15762: Loss: 0.4799\n",
            "Epoch 3, Sample 15763: Loss: 0.7453\n",
            "Epoch 3, Sample 15764: Loss: 0.6990\n",
            "Epoch 3, Sample 15765: Loss: 0.5003\n",
            "Epoch 3, Sample 15766: Loss: 1.0155\n",
            "Epoch 3, Sample 15767: Loss: 1.0524\n",
            "Epoch 3, Sample 15768: Loss: 0.3441\n",
            "Epoch 3, Sample 15769: Loss: 0.1219\n",
            "Epoch 3, Sample 15770: Loss: 0.0083\n",
            "Epoch 3, Sample 15771: Loss: 0.3539\n",
            "Epoch 3, Sample 15772: Loss: 0.6990\n",
            "Epoch 3, Sample 15773: Loss: 0.0042\n",
            "Epoch 3, Sample 15774: Loss: 0.7036\n",
            "Epoch 3, Sample 15775: Loss: 0.5871\n",
            "Epoch 3, Sample 15776: Loss: 0.3949\n",
            "Epoch 3, Sample 15777: Loss: 0.3441\n",
            "Epoch 3, Sample 15778: Loss: 0.0144\n",
            "Epoch 3, Sample 15779: Loss: 1.1569\n",
            "Epoch 3, Sample 15780: Loss: 0.1399\n",
            "Epoch 3, Sample 15781: Loss: 0.7036\n",
            "Epoch 3, Sample 15782: Loss: 0.1968\n",
            "Epoch 3, Sample 15783: Loss: 0.1397\n",
            "Epoch 3, Sample 15784: Loss: 0.6184\n",
            "Epoch 3, Sample 15785: Loss: 0.5003\n",
            "Epoch 3, Sample 15786: Loss: 0.6439\n",
            "Epoch 3, Sample 15787: Loss: 0.2034\n",
            "Epoch 3, Sample 15788: Loss: 1.0530\n",
            "Epoch 3, Sample 15789: Loss: 0.3441\n",
            "Epoch 3, Sample 15790: Loss: 0.1654\n",
            "Epoch 3, Sample 15791: Loss: 0.3399\n",
            "Epoch 3, Sample 15792: Loss: 0.4611\n",
            "Epoch 3, Sample 15793: Loss: 1.0524\n",
            "Epoch 3, Sample 15794: Loss: 1.0524\n",
            "Epoch 3, Sample 15795: Loss: 1.0524\n",
            "Epoch 3, Sample 15796: Loss: 0.0291\n",
            "Epoch 3, Sample 15797: Loss: 0.7486\n",
            "Epoch 3, Sample 15798: Loss: 0.0609\n",
            "Epoch 3, Sample 15799: Loss: 0.0026\n",
            "Epoch 3, Sample 15800: Loss: 1.0524\n",
            "Epoch 3, Sample 15801: Loss: 0.2034\n",
            "Epoch 3, Sample 15802: Loss: 0.3441\n",
            "Epoch 3, Sample 15803: Loss: 0.0838\n",
            "Epoch 3, Sample 15804: Loss: 0.4930\n",
            "Epoch 3, Sample 15805: Loss: 0.0038\n",
            "Epoch 3, Sample 15806: Loss: 0.2629\n",
            "Epoch 3, Sample 15807: Loss: 0.9022\n",
            "Epoch 3, Sample 15808: Loss: 1.0524\n",
            "Epoch 3, Sample 15809: Loss: 0.0542\n",
            "Epoch 3, Sample 15810: Loss: 0.0554\n",
            "Epoch 3, Sample 15811: Loss: 0.7036\n",
            "Epoch 3, Sample 15812: Loss: 0.1625\n",
            "Epoch 3, Sample 15813: Loss: 0.0145\n",
            "Epoch 3, Sample 15814: Loss: 0.2034\n",
            "Epoch 3, Sample 15815: Loss: 0.3441\n",
            "Epoch 3, Sample 15816: Loss: 0.3119\n",
            "Epoch 3, Sample 15817: Loss: 0.0018\n",
            "Epoch 3, Sample 15818: Loss: 0.0212\n",
            "Epoch 3, Sample 15819: Loss: 0.0115\n",
            "Epoch 3, Sample 15820: Loss: 0.0221\n",
            "Epoch 3, Sample 15821: Loss: 0.0014\n",
            "Epoch 3, Sample 15822: Loss: 0.4032\n",
            "Epoch 3, Sample 15823: Loss: 0.2989\n",
            "Epoch 3, Sample 15824: Loss: 0.2340\n",
            "Epoch 3, Sample 15825: Loss: 0.0026\n",
            "Epoch 3, Sample 15826: Loss: 0.0026\n",
            "Epoch 3, Sample 15827: Loss: 0.3851\n",
            "Epoch 3, Sample 15828: Loss: 3.4661\n",
            "Epoch 3, Sample 15829: Loss: 0.0256\n",
            "Epoch 3, Sample 15830: Loss: 0.9367\n",
            "Epoch 3, Sample 15831: Loss: 1.0524\n",
            "Epoch 3, Sample 15832: Loss: 0.2044\n",
            "Epoch 3, Sample 15833: Loss: 0.4176\n",
            "Epoch 3, Sample 15834: Loss: 0.0460\n",
            "Epoch 3, Sample 15835: Loss: 0.2935\n",
            "Epoch 3, Sample 15836: Loss: 0.1075\n",
            "Epoch 3, Sample 15837: Loss: 0.2044\n",
            "Epoch 3, Sample 15838: Loss: 0.2704\n",
            "Epoch 3, Sample 15839: Loss: 0.6139\n",
            "Epoch 3, Sample 15840: Loss: 2.6860\n",
            "Epoch 3, Sample 15841: Loss: 9.1697\n",
            "Epoch 3, Sample 15842: Loss: 0.1250\n",
            "Epoch 3, Sample 15843: Loss: 0.1170\n",
            "Epoch 3, Sample 15844: Loss: 0.0608\n",
            "Epoch 3, Sample 15845: Loss: 0.7036\n",
            "Epoch 3, Sample 15846: Loss: 0.4799\n",
            "Epoch 3, Sample 15847: Loss: 0.0026\n",
            "Epoch 3, Sample 15848: Loss: 0.2759\n",
            "Epoch 3, Sample 15849: Loss: 0.3949\n",
            "Epoch 3, Sample 15850: Loss: 0.6026\n",
            "Epoch 3, Sample 15851: Loss: 0.2751\n",
            "Epoch 3, Sample 15852: Loss: 0.0169\n",
            "Epoch 3, Sample 15853: Loss: 0.0018\n",
            "Epoch 3, Sample 15854: Loss: 0.8951\n",
            "Epoch 3, Sample 15855: Loss: 0.4382\n",
            "Epoch 3, Sample 15856: Loss: 0.3758\n",
            "Epoch 3, Sample 15857: Loss: 0.0018\n",
            "Epoch 3, Sample 15858: Loss: 0.0026\n",
            "Epoch 3, Sample 15859: Loss: 0.4902\n",
            "Epoch 3, Sample 15860: Loss: 0.2034\n",
            "Epoch 3, Sample 15861: Loss: 0.1250\n",
            "Epoch 3, Sample 15862: Loss: 0.3399\n",
            "Epoch 3, Sample 15863: Loss: 0.1535\n",
            "Epoch 3, Sample 15864: Loss: 0.2032\n",
            "Epoch 3, Sample 15865: Loss: 0.9367\n",
            "Epoch 3, Sample 15866: Loss: 0.2036\n",
            "Epoch 3, Sample 15867: Loss: 1.0202\n",
            "Epoch 3, Sample 15868: Loss: 2.1901\n",
            "Epoch 3, Sample 15869: Loss: 0.2032\n",
            "Epoch 3, Sample 15870: Loss: 0.8951\n",
            "Epoch 3, Sample 15871: Loss: 0.1250\n",
            "Epoch 3, Sample 15872: Loss: 0.7360\n",
            "Epoch 3, Sample 15873: Loss: 0.3441\n",
            "Epoch 3, Sample 15874: Loss: 0.1399\n",
            "Epoch 3, Sample 15875: Loss: 0.1807\n",
            "Epoch 3, Sample 15876: Loss: 0.1022\n",
            "Epoch 3, Sample 15877: Loss: 0.2759\n",
            "Epoch 3, Sample 15878: Loss: 0.0026\n",
            "Epoch 3, Sample 15879: Loss: 0.1559\n",
            "Epoch 3, Sample 15880: Loss: 0.1233\n",
            "Epoch 3, Sample 15881: Loss: 0.2034\n",
            "Epoch 3, Sample 15882: Loss: 0.1170\n",
            "Epoch 3, Sample 15883: Loss: 0.0044\n",
            "Epoch 3, Sample 15884: Loss: 0.8951\n",
            "Epoch 3, Sample 15885: Loss: 0.2759\n",
            "Epoch 3, Sample 15886: Loss: 0.1170\n",
            "Epoch 3, Sample 15887: Loss: 0.1170\n",
            "Epoch 3, Sample 15888: Loss: 0.2832\n",
            "Epoch 3, Sample 15889: Loss: 0.0052\n",
            "Epoch 3, Sample 15890: Loss: 0.0299\n",
            "Epoch 3, Sample 15891: Loss: 0.2340\n",
            "Epoch 3, Sample 15892: Loss: 0.3229\n",
            "Epoch 3, Sample 15893: Loss: 0.2044\n",
            "Epoch 3, Sample 15894: Loss: 0.2215\n",
            "Epoch 3, Sample 15895: Loss: 1.0155\n",
            "Epoch 3, Sample 15896: Loss: 0.4799\n",
            "Epoch 3, Sample 15897: Loss: 0.0026\n",
            "Epoch 3, Sample 15898: Loss: 0.0001\n",
            "Epoch 3, Sample 15899: Loss: 1.6484\n",
            "Epoch 3, Sample 15900: Loss: 0.3399\n",
            "Epoch 3, Sample 15901: Loss: 0.6304\n",
            "Epoch 3, Sample 15902: Loss: 0.3082\n",
            "Epoch 3, Sample 15903: Loss: 0.0446\n",
            "Epoch 3, Sample 15904: Loss: 0.5858\n",
            "Epoch 3, Sample 15905: Loss: 0.2034\n",
            "Epoch 3, Sample 15906: Loss: 0.0205\n",
            "Epoch 3, Sample 15907: Loss: 0.6990\n",
            "Epoch 3, Sample 15908: Loss: 0.5858\n",
            "Epoch 3, Sample 15909: Loss: 0.8951\n",
            "Epoch 3, Sample 15910: Loss: 0.2121\n",
            "Epoch 3, Sample 15911: Loss: 0.0625\n",
            "Epoch 3, Sample 15912: Loss: 1.2090\n",
            "Epoch 3, Sample 15913: Loss: 0.0001\n",
            "Epoch 3, Sample 15914: Loss: 8.4158\n",
            "Epoch 3, Sample 15915: Loss: 0.0630\n",
            "Epoch 3, Sample 15916: Loss: 0.0108\n",
            "Epoch 3, Sample 15917: Loss: 0.2032\n",
            "Epoch 3, Sample 15918: Loss: 0.2241\n",
            "Epoch 3, Sample 15919: Loss: 0.0001\n",
            "Epoch 3, Sample 15920: Loss: 0.5196\n",
            "Epoch 3, Sample 15921: Loss: 0.3126\n",
            "Epoch 3, Sample 15922: Loss: 0.7036\n",
            "Epoch 3, Sample 15923: Loss: 0.7036\n",
            "Epoch 3, Sample 15924: Loss: 0.4799\n",
            "Epoch 3, Sample 15925: Loss: 0.0026\n",
            "Epoch 3, Sample 15926: Loss: 0.0014\n",
            "Epoch 3, Sample 15927: Loss: 1.0530\n",
            "Epoch 3, Sample 15928: Loss: 0.0838\n",
            "Epoch 3, Sample 15929: Loss: 0.0920\n",
            "Epoch 3, Sample 15930: Loss: 0.3758\n",
            "Epoch 3, Sample 15931: Loss: 0.0306\n",
            "Epoch 3, Sample 15932: Loss: 0.3450\n",
            "Epoch 3, Sample 15933: Loss: 0.3189\n",
            "Epoch 3, Sample 15934: Loss: 0.0001\n",
            "Epoch 3, Sample 15935: Loss: 0.3221\n",
            "Epoch 3, Sample 15936: Loss: 1.4544\n",
            "Epoch 3, Sample 15937: Loss: 0.5089\n",
            "Epoch 3, Sample 15938: Loss: 0.1256\n",
            "Epoch 3, Sample 15939: Loss: 0.0626\n",
            "Epoch 3, Sample 15940: Loss: 0.6990\n",
            "Epoch 3, Sample 15941: Loss: 1.4336\n",
            "Epoch 3, Sample 15942: Loss: 0.1588\n",
            "Epoch 3, Sample 15943: Loss: 0.2935\n",
            "Epoch 3, Sample 15944: Loss: 0.3399\n",
            "Epoch 3, Sample 15945: Loss: 0.0397\n",
            "Epoch 3, Sample 15946: Loss: 0.1252\n",
            "Epoch 3, Sample 15947: Loss: 0.0020\n",
            "Epoch 3, Sample 15948: Loss: 0.0062\n",
            "Epoch 3, Sample 15949: Loss: 0.0303\n",
            "Epoch 3, Sample 15950: Loss: 0.0070\n",
            "Epoch 3, Sample 15951: Loss: 1.0524\n",
            "Epoch 3, Sample 15952: Loss: 0.2759\n",
            "Epoch 3, Sample 15953: Loss: 0.1627\n",
            "Epoch 3, Sample 15954: Loss: 0.1397\n",
            "Epoch 3, Sample 15955: Loss: 0.3399\n",
            "Epoch 3, Sample 15956: Loss: 0.6867\n",
            "Epoch 3, Sample 15957: Loss: 1.2496\n",
            "Epoch 3, Sample 15958: Loss: 0.0337\n",
            "Epoch 3, Sample 15959: Loss: 0.0601\n",
            "Epoch 3, Sample 15960: Loss: 0.2340\n",
            "Epoch 3, Sample 15961: Loss: 0.4303\n",
            "Epoch 3, Sample 15962: Loss: 0.2660\n",
            "Epoch 3, Sample 15963: Loss: 1.0530\n",
            "Epoch 3, Sample 15964: Loss: 0.5659\n",
            "Epoch 3, Sample 15965: Loss: 0.3332\n",
            "Epoch 3, Sample 15966: Loss: 0.6139\n",
            "Epoch 3, Sample 15967: Loss: 0.2962\n",
            "Epoch 3, Sample 15968: Loss: 0.1829\n",
            "Epoch 3, Sample 15969: Loss: 0.0064\n",
            "Epoch 3, Sample 15970: Loss: 0.1999\n",
            "Epoch 3, Sample 15971: Loss: 0.3517\n",
            "Epoch 3, Sample 15972: Loss: 0.0026\n",
            "Epoch 3, Sample 15973: Loss: 2.3537\n",
            "Epoch 3, Sample 15974: Loss: 0.3399\n",
            "Epoch 3, Sample 15975: Loss: 0.0001\n",
            "Epoch 3, Sample 15976: Loss: 1.0524\n",
            "Epoch 3, Sample 15977: Loss: 0.6867\n",
            "Epoch 3, Sample 15978: Loss: 0.2044\n",
            "Epoch 3, Sample 15979: Loss: 0.0630\n",
            "Epoch 3, Sample 15980: Loss: 0.8951\n",
            "Epoch 3, Sample 15981: Loss: 0.3441\n",
            "Epoch 3, Sample 15982: Loss: 0.3399\n",
            "Epoch 3, Sample 15983: Loss: 1.0524\n",
            "Epoch 3, Sample 15984: Loss: 0.0018\n",
            "Epoch 3, Sample 15985: Loss: 0.8951\n",
            "Epoch 3, Sample 15986: Loss: 0.0101\n",
            "Epoch 3, Sample 15987: Loss: 0.0026\n",
            "Epoch 3, Sample 15988: Loss: 0.0026\n",
            "Epoch 3, Sample 15989: Loss: 1.0155\n",
            "Epoch 3, Sample 15990: Loss: 0.4641\n",
            "Epoch 3, Sample 15991: Loss: 0.0051\n",
            "Epoch 3, Sample 15992: Loss: 0.1219\n",
            "Epoch 3, Sample 15993: Loss: 0.1263\n",
            "Epoch 3, Sample 15994: Loss: 0.1246\n",
            "Epoch 3, Sample 15995: Loss: 0.6139\n",
            "Epoch 3, Sample 15996: Loss: 2.9136\n",
            "Epoch 3, Sample 15997: Loss: 0.0171\n",
            "Epoch 3, Sample 15998: Loss: 0.5972\n",
            "Epoch 3, Sample 15999: Loss: 0.0225\n",
            "Epoch 3, Sample 16000: Loss: 0.6867\n",
            "\n",
            "Epoch 3 Average Loss: 0.5494\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 6th trial we chose these settings\n",
        "epochs = 3\n",
        "learning_rate = .005\n",
        "input_size = 20\n",
        "Neurons = 70\n",
        "activation_input = 70\n",
        "activation function = relu\n",
        "output = 1"
      ],
      "metadata": {
        "id": "hs6NJg3EdRBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "learning_rate = .005\n",
        "\n",
        "\n",
        "# Initializing Parameters\n",
        "w = 50\n",
        "\n",
        "loss_set = {}\n",
        "\n",
        "# 1. Creating a FeedForwardNetwork\n",
        "# 1.1 Structure (Architecture) of NN\n",
        "model_net6 = torch.nn.Sequential(torch.nn.Linear(20,70),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(0.33),\n",
        "\n",
        "                                 torch.nn.Linear(70,1),\n",
        "                                 torch.nn.ReLU(),\n",
        "\n",
        "                                 );\n",
        "\n",
        "# 1.2 Loss Function\n",
        "loss_mse = torch.nn.MSELoss()\n",
        "\n",
        "# 1.3 Optmization Approch\n",
        "optimizer = torch.optim.SGD(model_net6.parameters(), lr=learning_rate)\n",
        "\n",
        "w_his = []\n",
        "w_his.append(w)\n",
        "# Loop over the number of epochs\n",
        "for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over each sample in the dataset\n",
        "    for i in range(tensor_data_X.size(0)):\n",
        "\n",
        "      # 2. Forward Pass\n",
        "      output = model_net6.forward(tensor_data_X[i].reshape(-1))\n",
        "\n",
        "      # 3. FeedForward Evaluation\n",
        "      loss = loss_mse(output, tensor_data_Y[i].reshape(-1))\n",
        "      optimizer.zero_grad();\n",
        "\n",
        "      # 4. Backward Pass / Gradient Calculation\n",
        "      loss.backward()\n",
        "\n",
        "      # Store the loss for each epoch\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # 5. Back Propagation / Update Weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store the weight value for each sample of data\n",
        "      w_his.append(float(model_net6[0].weight.data[0][0]))\n",
        "\n",
        "      # Display the loss for the current sample\n",
        "      print(f\"Epoch {epoch+1}, Sample {i+1}: Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # Calculate and display average loss for the epoch\n",
        "    epoch_loss /= tensor_data_X.size(0)\n",
        "\n",
        "    # Store the loss for each sample of data\n",
        "    loss_set[epoch] = epoch_loss\n",
        "    print(f\"\\nEpoch {epoch+1} Average Loss: {epoch_loss:.4f}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8ed153701408472baa87ed1d1bafff8e",
            "de12b941d23841a7840d020bbe20e089",
            "37ec6e1e99194356b9d310de9824a6d5",
            "ff15079743b5498b9a88dece8fec0912",
            "bf650b2ffd804aa88dd47285cb36f6ee",
            "9eb8a4f227d1464a9a23174d7792a88a",
            "4b9effe01d64464bad6e771f6d8249f8",
            "ab9f784d802e43acaf31027b03dca824",
            "006e3c145aa24c88aeed60b0a476ed2a",
            "fa8cd96f7d2e49ad8cfbc63e01c6c6a2",
            "b16867b1e68b4d6f9f5af725d5bcc76b"
          ]
        },
        "id": "YKcJOUz7c1pp",
        "outputId": "0afe305d-2b78-49cd-a34c-134d424fa111"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-283-6ab5608572ae>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ed153701408472baa87ed1d1bafff8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 11005: Loss: 0.2832\n",
            "Epoch 3, Sample 11006: Loss: 0.0213\n",
            "Epoch 3, Sample 11007: Loss: 0.0031\n",
            "Epoch 3, Sample 11008: Loss: 0.7036\n",
            "Epoch 3, Sample 11009: Loss: 0.2831\n",
            "Epoch 3, Sample 11010: Loss: 0.0008\n",
            "Epoch 3, Sample 11011: Loss: 0.0026\n",
            "Epoch 3, Sample 11012: Loss: 0.7453\n",
            "Epoch 3, Sample 11013: Loss: 0.4243\n",
            "Epoch 3, Sample 11014: Loss: 0.2032\n",
            "Epoch 3, Sample 11015: Loss: 0.1677\n",
            "Epoch 3, Sample 11016: Loss: 0.3399\n",
            "Epoch 3, Sample 11017: Loss: 0.2339\n",
            "Epoch 3, Sample 11018: Loss: 1.4611\n",
            "Epoch 3, Sample 11019: Loss: 0.0505\n",
            "Epoch 3, Sample 11020: Loss: 0.1170\n",
            "Epoch 3, Sample 11021: Loss: 0.4663\n",
            "Epoch 3, Sample 11022: Loss: 1.6418\n",
            "Epoch 3, Sample 11023: Loss: 0.2750\n",
            "Epoch 3, Sample 11024: Loss: 0.9367\n",
            "Epoch 3, Sample 11025: Loss: 0.0025\n",
            "Epoch 3, Sample 11026: Loss: 1.1265\n",
            "Epoch 3, Sample 11027: Loss: 1.0155\n",
            "Epoch 3, Sample 11028: Loss: 0.7036\n",
            "Epoch 3, Sample 11029: Loss: 0.5871\n",
            "Epoch 3, Sample 11030: Loss: 0.0212\n",
            "Epoch 3, Sample 11031: Loss: 0.0505\n",
            "Epoch 3, Sample 11032: Loss: 1.0524\n",
            "Epoch 3, Sample 11033: Loss: 1.1168\n",
            "Epoch 3, Sample 11034: Loss: 0.1838\n",
            "Epoch 3, Sample 11035: Loss: 0.0189\n",
            "Epoch 3, Sample 11036: Loss: 0.3506\n",
            "Epoch 3, Sample 11037: Loss: 0.2098\n",
            "Epoch 3, Sample 11038: Loss: 0.3399\n",
            "Epoch 3, Sample 11039: Loss: 1.0155\n",
            "Epoch 3, Sample 11040: Loss: 1.0524\n",
            "Epoch 3, Sample 11041: Loss: 0.0391\n",
            "Epoch 3, Sample 11042: Loss: 1.9825\n",
            "Epoch 3, Sample 11043: Loss: 0.0287\n",
            "Epoch 3, Sample 11044: Loss: 0.2639\n",
            "Epoch 3, Sample 11045: Loss: 0.0630\n",
            "Epoch 3, Sample 11046: Loss: 0.3441\n",
            "Epoch 3, Sample 11047: Loss: 0.0130\n",
            "Epoch 3, Sample 11048: Loss: 0.9367\n",
            "Epoch 3, Sample 11049: Loss: 0.2759\n",
            "Epoch 3, Sample 11050: Loss: 0.0084\n",
            "Epoch 3, Sample 11051: Loss: 0.0001\n",
            "Epoch 3, Sample 11052: Loss: 3.1834\n",
            "Epoch 3, Sample 11053: Loss: 0.2032\n",
            "Epoch 3, Sample 11054: Loss: 0.0554\n",
            "Epoch 3, Sample 11055: Loss: 0.0406\n",
            "Epoch 3, Sample 11056: Loss: 0.0018\n",
            "Epoch 3, Sample 11057: Loss: 0.0099\n",
            "Epoch 3, Sample 11058: Loss: 1.7512\n",
            "Epoch 3, Sample 11059: Loss: 0.5972\n",
            "Epoch 3, Sample 11060: Loss: 0.3610\n",
            "Epoch 3, Sample 11061: Loss: 2.2871\n",
            "Epoch 3, Sample 11062: Loss: 0.0234\n",
            "Epoch 3, Sample 11063: Loss: 0.2044\n",
            "Epoch 3, Sample 11064: Loss: 0.9017\n",
            "Epoch 3, Sample 11065: Loss: 0.7036\n",
            "Epoch 3, Sample 11066: Loss: 0.1799\n",
            "Epoch 3, Sample 11067: Loss: 0.1868\n",
            "Epoch 3, Sample 11068: Loss: 1.0530\n",
            "Epoch 3, Sample 11069: Loss: 0.7036\n",
            "Epoch 3, Sample 11070: Loss: 0.2639\n",
            "Epoch 3, Sample 11071: Loss: 0.7036\n",
            "Epoch 3, Sample 11072: Loss: 0.5858\n",
            "Epoch 3, Sample 11073: Loss: 0.0013\n",
            "Epoch 3, Sample 11074: Loss: 0.0061\n",
            "Epoch 3, Sample 11075: Loss: 0.0026\n",
            "Epoch 3, Sample 11076: Loss: 0.0328\n",
            "Epoch 3, Sample 11077: Loss: 1.2265\n",
            "Epoch 3, Sample 11078: Loss: 0.2412\n",
            "Epoch 3, Sample 11079: Loss: 0.3399\n",
            "Epoch 3, Sample 11080: Loss: 0.0446\n",
            "Epoch 3, Sample 11081: Loss: 0.0145\n",
            "Epoch 3, Sample 11082: Loss: 0.0026\n",
            "Epoch 3, Sample 11083: Loss: 0.2639\n",
            "Epoch 3, Sample 11084: Loss: 0.0205\n",
            "Epoch 3, Sample 11085: Loss: 1.0524\n",
            "Epoch 3, Sample 11086: Loss: 0.3399\n",
            "Epoch 3, Sample 11087: Loss: 0.1559\n",
            "Epoch 3, Sample 11088: Loss: 1.0155\n",
            "Epoch 3, Sample 11089: Loss: 0.0022\n",
            "Epoch 3, Sample 11090: Loss: 0.0630\n",
            "Epoch 3, Sample 11091: Loss: 0.2044\n",
            "Epoch 3, Sample 11092: Loss: 0.0018\n",
            "Epoch 3, Sample 11093: Loss: 0.0368\n",
            "Epoch 3, Sample 11094: Loss: 0.0026\n",
            "Epoch 3, Sample 11095: Loss: 1.0524\n",
            "Epoch 3, Sample 11096: Loss: 0.2340\n",
            "Epoch 3, Sample 11097: Loss: 0.5078\n",
            "Epoch 3, Sample 11098: Loss: 0.0108\n",
            "Epoch 3, Sample 11099: Loss: 0.2295\n",
            "Epoch 3, Sample 11100: Loss: 0.5708\n",
            "Epoch 3, Sample 11101: Loss: 0.1170\n",
            "Epoch 3, Sample 11102: Loss: 0.2036\n",
            "Epoch 3, Sample 11103: Loss: 0.5858\n",
            "Epoch 3, Sample 11104: Loss: 0.2034\n",
            "Epoch 3, Sample 11105: Loss: 0.4246\n",
            "Epoch 3, Sample 11106: Loss: 0.2032\n",
            "Epoch 3, Sample 11107: Loss: 0.0248\n",
            "Epoch 3, Sample 11108: Loss: 0.0630\n",
            "Epoch 3, Sample 11109: Loss: 0.2340\n",
            "Epoch 3, Sample 11110: Loss: 1.0524\n",
            "Epoch 3, Sample 11111: Loss: 0.2032\n",
            "Epoch 3, Sample 11112: Loss: 0.4382\n",
            "Epoch 3, Sample 11113: Loss: 1.0524\n",
            "Epoch 3, Sample 11114: Loss: 1.0155\n",
            "Epoch 3, Sample 11115: Loss: 0.1250\n",
            "Epoch 3, Sample 11116: Loss: 0.4607\n",
            "Epoch 3, Sample 11117: Loss: 1.0524\n",
            "Epoch 3, Sample 11118: Loss: 0.0034\n",
            "Epoch 3, Sample 11119: Loss: 1.0524\n",
            "Epoch 3, Sample 11120: Loss: 0.7036\n",
            "Epoch 3, Sample 11121: Loss: 0.2044\n",
            "Epoch 3, Sample 11122: Loss: 0.1170\n",
            "Epoch 3, Sample 11123: Loss: 0.5278\n",
            "Epoch 3, Sample 11124: Loss: 0.2759\n",
            "Epoch 3, Sample 11125: Loss: 0.0630\n",
            "Epoch 3, Sample 11126: Loss: 0.7036\n",
            "Epoch 3, Sample 11127: Loss: 2.4374\n",
            "Epoch 3, Sample 11128: Loss: 0.4930\n",
            "Epoch 3, Sample 11129: Loss: 0.9367\n",
            "Epoch 3, Sample 11130: Loss: 0.0666\n",
            "Epoch 3, Sample 11131: Loss: 0.1804\n",
            "Epoch 3, Sample 11132: Loss: 1.0524\n",
            "Epoch 3, Sample 11133: Loss: 0.3183\n",
            "Epoch 3, Sample 11134: Loss: 0.0460\n",
            "Epoch 3, Sample 11135: Loss: 0.2036\n",
            "Epoch 3, Sample 11136: Loss: 0.0018\n",
            "Epoch 3, Sample 11137: Loss: 0.2148\n",
            "Epoch 3, Sample 11138: Loss: 0.1281\n",
            "Epoch 3, Sample 11139: Loss: 0.0001\n",
            "Epoch 3, Sample 11140: Loss: 0.1219\n",
            "Epoch 3, Sample 11141: Loss: 0.2759\n",
            "Epoch 3, Sample 11142: Loss: 0.4611\n",
            "Epoch 3, Sample 11143: Loss: 0.2032\n",
            "Epoch 3, Sample 11144: Loss: 0.2219\n",
            "Epoch 3, Sample 11145: Loss: 0.7036\n",
            "Epoch 3, Sample 11146: Loss: 0.0062\n",
            "Epoch 3, Sample 11147: Loss: 4.8243\n",
            "Epoch 3, Sample 11148: Loss: 0.5750\n",
            "Epoch 3, Sample 11149: Loss: 0.7036\n",
            "Epoch 3, Sample 11150: Loss: 0.5120\n",
            "Epoch 3, Sample 11151: Loss: 0.2036\n",
            "Epoch 3, Sample 11152: Loss: 0.0044\n",
            "Epoch 3, Sample 11153: Loss: 0.6990\n",
            "Epoch 3, Sample 11154: Loss: 0.0802\n",
            "Epoch 3, Sample 11155: Loss: 0.1250\n",
            "Epoch 3, Sample 11156: Loss: 0.6304\n",
            "Epoch 3, Sample 11157: Loss: 0.9785\n",
            "Epoch 3, Sample 11158: Loss: 0.8951\n",
            "Epoch 3, Sample 11159: Loss: 0.2044\n",
            "Epoch 3, Sample 11160: Loss: 0.4719\n",
            "Epoch 3, Sample 11161: Loss: 0.1154\n",
            "Epoch 3, Sample 11162: Loss: 0.0026\n",
            "Epoch 3, Sample 11163: Loss: 0.3003\n",
            "Epoch 3, Sample 11164: Loss: 0.0460\n",
            "Epoch 3, Sample 11165: Loss: 0.0144\n",
            "Epoch 3, Sample 11166: Loss: 0.2032\n",
            "Epoch 3, Sample 11167: Loss: 0.7036\n",
            "Epoch 3, Sample 11168: Loss: 0.3873\n",
            "Epoch 3, Sample 11169: Loss: 0.8188\n",
            "Epoch 3, Sample 11170: Loss: 0.3132\n",
            "Epoch 3, Sample 11171: Loss: 1.0530\n",
            "Epoch 3, Sample 11172: Loss: 0.0026\n",
            "Epoch 3, Sample 11173: Loss: 0.2036\n",
            "Epoch 3, Sample 11174: Loss: 0.1523\n",
            "Epoch 3, Sample 11175: Loss: 0.2759\n",
            "Epoch 3, Sample 11176: Loss: 0.0637\n",
            "Epoch 3, Sample 11177: Loss: 0.9511\n",
            "Epoch 3, Sample 11178: Loss: 0.8951\n",
            "Epoch 3, Sample 11179: Loss: 0.6689\n",
            "Epoch 3, Sample 11180: Loss: 0.5000\n",
            "Epoch 3, Sample 11181: Loss: 0.1218\n",
            "Epoch 3, Sample 11182: Loss: 1.0155\n",
            "Epoch 3, Sample 11183: Loss: 0.0254\n",
            "Epoch 3, Sample 11184: Loss: 1.0524\n",
            "Epoch 3, Sample 11185: Loss: 0.0639\n",
            "Epoch 3, Sample 11186: Loss: 0.4611\n",
            "Epoch 3, Sample 11187: Loss: 0.4924\n",
            "Epoch 3, Sample 11188: Loss: 0.2032\n",
            "Epoch 3, Sample 11189: Loss: 1.0155\n",
            "Epoch 3, Sample 11190: Loss: 1.1602\n",
            "Epoch 3, Sample 11191: Loss: 0.3399\n",
            "Epoch 3, Sample 11192: Loss: 0.7036\n",
            "Epoch 3, Sample 11193: Loss: 0.2639\n",
            "Epoch 3, Sample 11194: Loss: 0.2034\n",
            "Epoch 3, Sample 11195: Loss: 0.7036\n",
            "Epoch 3, Sample 11196: Loss: 0.2036\n",
            "Epoch 3, Sample 11197: Loss: 1.0524\n",
            "Epoch 3, Sample 11198: Loss: 0.0626\n",
            "Epoch 3, Sample 11199: Loss: 1.0530\n",
            "Epoch 3, Sample 11200: Loss: 1.9205\n",
            "Epoch 3, Sample 11201: Loss: 1.1356\n",
            "Epoch 3, Sample 11202: Loss: 0.0027\n",
            "Epoch 3, Sample 11203: Loss: 0.2034\n",
            "Epoch 3, Sample 11204: Loss: 0.0026\n",
            "Epoch 3, Sample 11205: Loss: 0.4611\n",
            "Epoch 3, Sample 11206: Loss: 1.0524\n",
            "Epoch 3, Sample 11207: Loss: 1.0524\n",
            "Epoch 3, Sample 11208: Loss: 0.2795\n",
            "Epoch 3, Sample 11209: Loss: 0.0630\n",
            "Epoch 3, Sample 11210: Loss: 0.0026\n",
            "Epoch 3, Sample 11211: Loss: 0.2044\n",
            "Epoch 3, Sample 11212: Loss: 0.2832\n",
            "Epoch 3, Sample 11213: Loss: 0.3441\n",
            "Epoch 3, Sample 11214: Loss: 0.4996\n",
            "Epoch 3, Sample 11215: Loss: 0.5375\n",
            "Epoch 3, Sample 11216: Loss: 0.0460\n",
            "Epoch 3, Sample 11217: Loss: 1.1163\n",
            "Epoch 3, Sample 11218: Loss: 0.3992\n",
            "Epoch 3, Sample 11219: Loss: 1.0524\n",
            "Epoch 3, Sample 11220: Loss: 0.0027\n",
            "Epoch 3, Sample 11221: Loss: 0.0108\n",
            "Epoch 3, Sample 11222: Loss: 1.0155\n",
            "Epoch 3, Sample 11223: Loss: 0.0026\n",
            "Epoch 3, Sample 11224: Loss: 0.1170\n",
            "Epoch 3, Sample 11225: Loss: 0.0018\n",
            "Epoch 3, Sample 11226: Loss: 0.2034\n",
            "Epoch 3, Sample 11227: Loss: 0.2340\n",
            "Epoch 3, Sample 11228: Loss: 2.0108\n",
            "Epoch 3, Sample 11229: Loss: 0.1225\n",
            "Epoch 3, Sample 11230: Loss: 0.1674\n",
            "Epoch 3, Sample 11231: Loss: 1.0155\n",
            "Epoch 3, Sample 11232: Loss: 0.3402\n",
            "Epoch 3, Sample 11233: Loss: 0.2340\n",
            "Epoch 3, Sample 11234: Loss: 0.0026\n",
            "Epoch 3, Sample 11235: Loss: 0.1463\n",
            "Epoch 3, Sample 11236: Loss: 0.8951\n",
            "Epoch 3, Sample 11237: Loss: 0.2044\n",
            "Epoch 3, Sample 11238: Loss: 0.4032\n",
            "Epoch 3, Sample 11239: Loss: 0.8584\n",
            "Epoch 3, Sample 11240: Loss: 0.4032\n",
            "Epoch 3, Sample 11241: Loss: 0.0234\n",
            "Epoch 3, Sample 11242: Loss: 0.6990\n",
            "Epoch 3, Sample 11243: Loss: 0.0363\n",
            "Epoch 3, Sample 11244: Loss: 0.0729\n",
            "Epoch 3, Sample 11245: Loss: 0.0625\n",
            "Epoch 3, Sample 11246: Loss: 1.0254\n",
            "Epoch 3, Sample 11247: Loss: 0.1546\n",
            "Epoch 3, Sample 11248: Loss: 0.1751\n",
            "Epoch 3, Sample 11249: Loss: 0.2098\n",
            "Epoch 3, Sample 11250: Loss: 1.0155\n",
            "Epoch 3, Sample 11251: Loss: 0.0915\n",
            "Epoch 3, Sample 11252: Loss: 0.9367\n",
            "Epoch 3, Sample 11253: Loss: 2.6823\n",
            "Epoch 3, Sample 11254: Loss: 0.1559\n",
            "Epoch 3, Sample 11255: Loss: 0.3399\n",
            "Epoch 3, Sample 11256: Loss: 0.3402\n",
            "Epoch 3, Sample 11257: Loss: 0.0240\n",
            "Epoch 3, Sample 11258: Loss: 0.8271\n",
            "Epoch 3, Sample 11259: Loss: 0.6990\n",
            "Epoch 3, Sample 11260: Loss: 1.0524\n",
            "Epoch 3, Sample 11261: Loss: 0.3168\n",
            "Epoch 3, Sample 11262: Loss: 0.0026\n",
            "Epoch 3, Sample 11263: Loss: 0.0391\n",
            "Epoch 3, Sample 11264: Loss: 0.3441\n",
            "Epoch 3, Sample 11265: Loss: 0.8951\n",
            "Epoch 3, Sample 11266: Loss: 0.3742\n",
            "Epoch 3, Sample 11267: Loss: 0.0001\n",
            "Epoch 3, Sample 11268: Loss: 0.2759\n",
            "Epoch 3, Sample 11269: Loss: 0.6304\n",
            "Epoch 3, Sample 11270: Loss: 0.2759\n",
            "Epoch 3, Sample 11271: Loss: 0.2034\n",
            "Epoch 3, Sample 11272: Loss: 0.5858\n",
            "Epoch 3, Sample 11273: Loss: 0.0018\n",
            "Epoch 3, Sample 11274: Loss: 0.3399\n",
            "Epoch 3, Sample 11275: Loss: 1.0266\n",
            "Epoch 3, Sample 11276: Loss: 1.3297\n",
            "Epoch 3, Sample 11277: Loss: 0.0915\n",
            "Epoch 3, Sample 11278: Loss: 0.2044\n",
            "Epoch 3, Sample 11279: Loss: 0.7036\n",
            "Epoch 3, Sample 11280: Loss: 0.3399\n",
            "Epoch 3, Sample 11281: Loss: 2.2434\n",
            "Epoch 3, Sample 11282: Loss: 0.0000\n",
            "Epoch 3, Sample 11283: Loss: 1.2123\n",
            "Epoch 3, Sample 11284: Loss: 0.0018\n",
            "Epoch 3, Sample 11285: Loss: 0.4930\n",
            "Epoch 3, Sample 11286: Loss: 1.4884\n",
            "Epoch 3, Sample 11287: Loss: 0.1943\n",
            "Epoch 3, Sample 11288: Loss: 0.4032\n",
            "Epoch 3, Sample 11289: Loss: 0.2759\n",
            "Epoch 3, Sample 11290: Loss: 1.0177\n",
            "Epoch 3, Sample 11291: Loss: 0.4032\n",
            "Epoch 3, Sample 11292: Loss: 1.0967\n",
            "Epoch 3, Sample 11293: Loss: 0.5871\n",
            "Epoch 3, Sample 11294: Loss: 0.3399\n",
            "Epoch 3, Sample 11295: Loss: 0.4218\n",
            "Epoch 3, Sample 11296: Loss: 0.0630\n",
            "Epoch 3, Sample 11297: Loss: 0.4032\n",
            "Epoch 3, Sample 11298: Loss: 0.2044\n",
            "Epoch 3, Sample 11299: Loss: 0.4867\n",
            "Epoch 3, Sample 11300: Loss: 0.0320\n",
            "Epoch 3, Sample 11301: Loss: 1.1865\n",
            "Epoch 3, Sample 11302: Loss: 0.2044\n",
            "Epoch 3, Sample 11303: Loss: 0.1559\n",
            "Epoch 3, Sample 11304: Loss: 0.2659\n",
            "Epoch 3, Sample 11305: Loss: 5.7274\n",
            "Epoch 3, Sample 11306: Loss: 0.0212\n",
            "Epoch 3, Sample 11307: Loss: 0.9589\n",
            "Epoch 3, Sample 11308: Loss: 1.1434\n",
            "Epoch 3, Sample 11309: Loss: 0.6990\n",
            "Epoch 3, Sample 11310: Loss: 0.2396\n",
            "Epoch 3, Sample 11311: Loss: 0.8393\n",
            "Epoch 3, Sample 11312: Loss: 0.0212\n",
            "Epoch 3, Sample 11313: Loss: 0.2182\n",
            "Epoch 3, Sample 11314: Loss: 0.3399\n",
            "Epoch 3, Sample 11315: Loss: 0.3399\n",
            "Epoch 3, Sample 11316: Loss: 0.0915\n",
            "Epoch 3, Sample 11317: Loss: 0.7036\n",
            "Epoch 3, Sample 11318: Loss: 0.0576\n",
            "Epoch 3, Sample 11319: Loss: 0.4611\n",
            "Epoch 3, Sample 11320: Loss: 0.6092\n",
            "Epoch 3, Sample 11321: Loss: 0.1523\n",
            "Epoch 3, Sample 11322: Loss: 0.3949\n",
            "Epoch 3, Sample 11323: Loss: 0.2738\n",
            "Epoch 3, Sample 11324: Loss: 0.9367\n",
            "Epoch 3, Sample 11325: Loss: 0.1040\n",
            "Epoch 3, Sample 11326: Loss: 1.0524\n",
            "Epoch 3, Sample 11327: Loss: 0.3949\n",
            "Epoch 3, Sample 11328: Loss: 0.1264\n",
            "Epoch 3, Sample 11329: Loss: 0.0013\n",
            "Epoch 3, Sample 11330: Loss: 0.2044\n",
            "Epoch 3, Sample 11331: Loss: 0.0455\n",
            "Epoch 3, Sample 11332: Loss: 0.3399\n",
            "Epoch 3, Sample 11333: Loss: 0.3427\n",
            "Epoch 3, Sample 11334: Loss: 0.0918\n",
            "Epoch 3, Sample 11335: Loss: 0.2532\n",
            "Epoch 3, Sample 11336: Loss: 0.5799\n",
            "Epoch 3, Sample 11337: Loss: 0.2729\n",
            "Epoch 3, Sample 11338: Loss: 0.4761\n",
            "Epoch 3, Sample 11339: Loss: 0.0466\n",
            "Epoch 3, Sample 11340: Loss: 0.3332\n",
            "Epoch 3, Sample 11341: Loss: 0.2044\n",
            "Epoch 3, Sample 11342: Loss: 0.7036\n",
            "Epoch 3, Sample 11343: Loss: 0.2079\n",
            "Epoch 3, Sample 11344: Loss: 0.1250\n",
            "Epoch 3, Sample 11345: Loss: 0.2014\n",
            "Epoch 3, Sample 11346: Loss: 3.5742\n",
            "Epoch 3, Sample 11347: Loss: 0.2832\n",
            "Epoch 3, Sample 11348: Loss: 0.5019\n",
            "Epoch 3, Sample 11349: Loss: 0.2124\n",
            "Epoch 3, Sample 11350: Loss: 0.3399\n",
            "Epoch 3, Sample 11351: Loss: 0.2329\n",
            "Epoch 3, Sample 11352: Loss: 0.9651\n",
            "Epoch 3, Sample 11353: Loss: 0.8951\n",
            "Epoch 3, Sample 11354: Loss: 0.3367\n",
            "Epoch 3, Sample 11355: Loss: 0.4808\n",
            "Epoch 3, Sample 11356: Loss: 0.0009\n",
            "Epoch 3, Sample 11357: Loss: 0.5972\n",
            "Epoch 3, Sample 11358: Loss: 0.2044\n",
            "Epoch 3, Sample 11359: Loss: 0.1627\n",
            "Epoch 3, Sample 11360: Loss: 0.4082\n",
            "Epoch 3, Sample 11361: Loss: 0.8086\n",
            "Epoch 3, Sample 11362: Loss: 0.3805\n",
            "Epoch 3, Sample 11363: Loss: 0.0026\n",
            "Epoch 3, Sample 11364: Loss: 0.0068\n",
            "Epoch 3, Sample 11365: Loss: 2.5542\n",
            "Epoch 3, Sample 11366: Loss: 0.2034\n",
            "Epoch 3, Sample 11367: Loss: 0.4032\n",
            "Epoch 3, Sample 11368: Loss: 0.5858\n",
            "Epoch 3, Sample 11369: Loss: 0.1282\n",
            "Epoch 3, Sample 11370: Loss: 0.1250\n",
            "Epoch 3, Sample 11371: Loss: 0.0161\n",
            "Epoch 3, Sample 11372: Loss: 0.0144\n",
            "Epoch 3, Sample 11373: Loss: 0.0113\n",
            "Epoch 3, Sample 11374: Loss: 1.0524\n",
            "Epoch 3, Sample 11375: Loss: 0.2759\n",
            "Epoch 3, Sample 11376: Loss: 0.2084\n",
            "Epoch 3, Sample 11377: Loss: 0.0824\n",
            "Epoch 3, Sample 11378: Loss: 0.2091\n",
            "Epoch 3, Sample 11379: Loss: 0.2962\n",
            "Epoch 3, Sample 11380: Loss: 0.0460\n",
            "Epoch 3, Sample 11381: Loss: 1.0524\n",
            "Epoch 3, Sample 11382: Loss: 0.0838\n",
            "Epoch 3, Sample 11383: Loss: 0.7036\n",
            "Epoch 3, Sample 11384: Loss: 2.9900\n",
            "Epoch 3, Sample 11385: Loss: 0.2079\n",
            "Epoch 3, Sample 11386: Loss: 0.1250\n",
            "Epoch 3, Sample 11387: Loss: 0.0834\n",
            "Epoch 3, Sample 11388: Loss: 0.2414\n",
            "Epoch 3, Sample 11389: Loss: 0.0495\n",
            "Epoch 3, Sample 11390: Loss: 0.5871\n",
            "Epoch 3, Sample 11391: Loss: 1.0266\n",
            "Epoch 3, Sample 11392: Loss: 0.6099\n",
            "Epoch 3, Sample 11393: Loss: 0.0700\n",
            "Epoch 3, Sample 11394: Loss: 0.3441\n",
            "Epoch 3, Sample 11395: Loss: 0.0851\n",
            "Epoch 3, Sample 11396: Loss: 1.0524\n",
            "Epoch 3, Sample 11397: Loss: 0.0567\n",
            "Epoch 3, Sample 11398: Loss: 0.1403\n",
            "Epoch 3, Sample 11399: Loss: 0.4792\n",
            "Epoch 3, Sample 11400: Loss: 0.1219\n",
            "Epoch 3, Sample 11401: Loss: 0.2064\n",
            "Epoch 3, Sample 11402: Loss: 0.4495\n",
            "Epoch 3, Sample 11403: Loss: 0.0626\n",
            "Epoch 3, Sample 11404: Loss: 0.2759\n",
            "Epoch 3, Sample 11405: Loss: 1.0524\n",
            "Epoch 3, Sample 11406: Loss: 1.0524\n",
            "Epoch 3, Sample 11407: Loss: 1.0155\n",
            "Epoch 3, Sample 11408: Loss: 1.2189\n",
            "Epoch 3, Sample 11409: Loss: 0.0018\n",
            "Epoch 3, Sample 11410: Loss: 0.0018\n",
            "Epoch 3, Sample 11411: Loss: 0.2044\n",
            "Epoch 3, Sample 11412: Loss: 0.8951\n",
            "Epoch 3, Sample 11413: Loss: 0.0101\n",
            "Epoch 3, Sample 11414: Loss: 0.2832\n",
            "Epoch 3, Sample 11415: Loss: 0.0777\n",
            "Epoch 3, Sample 11416: Loss: 0.3402\n",
            "Epoch 3, Sample 11417: Loss: 0.0158\n",
            "Epoch 3, Sample 11418: Loss: 0.0001\n",
            "Epoch 3, Sample 11419: Loss: 0.2044\n",
            "Epoch 3, Sample 11420: Loss: 0.9024\n",
            "Epoch 3, Sample 11421: Loss: 0.7453\n",
            "Epoch 3, Sample 11422: Loss: 0.2759\n",
            "Epoch 3, Sample 11423: Loss: 0.7036\n",
            "Epoch 3, Sample 11424: Loss: 0.0286\n",
            "Epoch 3, Sample 11425: Loss: 0.2034\n",
            "Epoch 3, Sample 11426: Loss: 0.2044\n",
            "Epoch 3, Sample 11427: Loss: 0.5858\n",
            "Epoch 3, Sample 11428: Loss: 1.0524\n",
            "Epoch 3, Sample 11429: Loss: 0.0018\n",
            "Epoch 3, Sample 11430: Loss: 0.5871\n",
            "Epoch 3, Sample 11431: Loss: 0.5753\n",
            "Epoch 3, Sample 11432: Loss: 0.2044\n",
            "Epoch 3, Sample 11433: Loss: 0.0026\n",
            "Epoch 3, Sample 11434: Loss: 0.0867\n",
            "Epoch 3, Sample 11435: Loss: 0.0838\n",
            "Epoch 3, Sample 11436: Loss: 1.9938\n",
            "Epoch 3, Sample 11437: Loss: 0.4500\n",
            "Epoch 3, Sample 11438: Loss: 0.2044\n",
            "Epoch 3, Sample 11439: Loss: 0.0640\n",
            "Epoch 3, Sample 11440: Loss: 0.8625\n",
            "Epoch 3, Sample 11441: Loss: 0.0655\n",
            "Epoch 3, Sample 11442: Loss: 1.2248\n",
            "Epoch 3, Sample 11443: Loss: 0.0087\n",
            "Epoch 3, Sample 11444: Loss: 1.0524\n",
            "Epoch 3, Sample 11445: Loss: 1.5214\n",
            "Epoch 3, Sample 11446: Loss: 0.3441\n",
            "Epoch 3, Sample 11447: Loss: 0.8951\n",
            "Epoch 3, Sample 11448: Loss: 0.5078\n",
            "Epoch 3, Sample 11449: Loss: 1.0524\n",
            "Epoch 3, Sample 11450: Loss: 0.9780\n",
            "Epoch 3, Sample 11451: Loss: 0.0517\n",
            "Epoch 3, Sample 11452: Loss: 0.2340\n",
            "Epoch 3, Sample 11453: Loss: 0.2832\n",
            "Epoch 3, Sample 11454: Loss: 4.1125\n",
            "Epoch 3, Sample 11455: Loss: 0.0018\n",
            "Epoch 3, Sample 11456: Loss: 0.1510\n",
            "Epoch 3, Sample 11457: Loss: 0.1210\n",
            "Epoch 3, Sample 11458: Loss: 1.0155\n",
            "Epoch 3, Sample 11459: Loss: 0.3949\n",
            "Epoch 3, Sample 11460: Loss: 0.4644\n",
            "Epoch 3, Sample 11461: Loss: 0.8484\n",
            "Epoch 3, Sample 11462: Loss: 0.1170\n",
            "Epoch 3, Sample 11463: Loss: 0.9367\n",
            "Epoch 3, Sample 11464: Loss: 0.2032\n",
            "Epoch 3, Sample 11465: Loss: 0.0022\n",
            "Epoch 3, Sample 11466: Loss: 1.1405\n",
            "Epoch 3, Sample 11467: Loss: 0.0143\n",
            "Epoch 3, Sample 11468: Loss: 0.0001\n",
            "Epoch 3, Sample 11469: Loss: 0.2639\n",
            "Epoch 3, Sample 11470: Loss: 0.5858\n",
            "Epoch 3, Sample 11471: Loss: 1.0530\n",
            "Epoch 3, Sample 11472: Loss: 0.5972\n",
            "Epoch 3, Sample 11473: Loss: 0.0000\n",
            "Epoch 3, Sample 11474: Loss: 0.2106\n",
            "Epoch 3, Sample 11475: Loss: 0.7528\n",
            "Epoch 3, Sample 11476: Loss: 0.0630\n",
            "Epoch 3, Sample 11477: Loss: 0.8951\n",
            "Epoch 3, Sample 11478: Loss: 0.7036\n",
            "Epoch 3, Sample 11479: Loss: 0.0108\n",
            "Epoch 3, Sample 11480: Loss: 0.0625\n",
            "Epoch 3, Sample 11481: Loss: 0.3441\n",
            "Epoch 3, Sample 11482: Loss: 0.0063\n",
            "Epoch 3, Sample 11483: Loss: 6.6551\n",
            "Epoch 3, Sample 11484: Loss: 0.2759\n",
            "Epoch 3, Sample 11485: Loss: 0.5972\n",
            "Epoch 3, Sample 11486: Loss: 0.0954\n",
            "Epoch 3, Sample 11487: Loss: 0.0466\n",
            "Epoch 3, Sample 11488: Loss: 0.0026\n",
            "Epoch 3, Sample 11489: Loss: 0.2034\n",
            "Epoch 3, Sample 11490: Loss: 0.0706\n",
            "Epoch 3, Sample 11491: Loss: 0.1822\n",
            "Epoch 3, Sample 11492: Loss: 0.1559\n",
            "Epoch 3, Sample 11493: Loss: 1.4133\n",
            "Epoch 3, Sample 11494: Loss: 0.4930\n",
            "Epoch 3, Sample 11495: Loss: 0.0116\n",
            "Epoch 3, Sample 11496: Loss: 0.7036\n",
            "Epoch 3, Sample 11497: Loss: 0.7036\n",
            "Epoch 3, Sample 11498: Loss: 0.2036\n",
            "Epoch 3, Sample 11499: Loss: 1.5597\n",
            "Epoch 3, Sample 11500: Loss: 0.2699\n",
            "Epoch 3, Sample 11501: Loss: 0.0110\n",
            "Epoch 3, Sample 11502: Loss: 0.3007\n",
            "Epoch 3, Sample 11503: Loss: 1.0524\n",
            "Epoch 3, Sample 11504: Loss: 0.3598\n",
            "Epoch 3, Sample 11505: Loss: 0.7036\n",
            "Epoch 3, Sample 11506: Loss: 0.0026\n",
            "Epoch 3, Sample 11507: Loss: 0.0013\n",
            "Epoch 3, Sample 11508: Loss: 0.3399\n",
            "Epoch 3, Sample 11509: Loss: 0.3441\n",
            "Epoch 3, Sample 11510: Loss: 0.0026\n",
            "Epoch 3, Sample 11511: Loss: 0.9367\n",
            "Epoch 3, Sample 11512: Loss: 2.4540\n",
            "Epoch 3, Sample 11513: Loss: 0.5630\n",
            "Epoch 3, Sample 11514: Loss: 0.0258\n",
            "Epoch 3, Sample 11515: Loss: 0.2044\n",
            "Epoch 3, Sample 11516: Loss: 4.1214\n",
            "Epoch 3, Sample 11517: Loss: 0.1588\n",
            "Epoch 3, Sample 11518: Loss: 0.0212\n",
            "Epoch 3, Sample 11519: Loss: 0.2832\n",
            "Epoch 3, Sample 11520: Loss: 0.2329\n",
            "Epoch 3, Sample 11521: Loss: 0.3399\n",
            "Epoch 3, Sample 11522: Loss: 2.1684\n",
            "Epoch 3, Sample 11523: Loss: 0.3701\n",
            "Epoch 3, Sample 11524: Loss: 0.2112\n",
            "Epoch 3, Sample 11525: Loss: 0.0897\n",
            "Epoch 3, Sample 11526: Loss: 1.2304\n",
            "Epoch 3, Sample 11527: Loss: 0.2036\n",
            "Epoch 3, Sample 11528: Loss: 0.8951\n",
            "Epoch 3, Sample 11529: Loss: 1.0155\n",
            "Epoch 3, Sample 11530: Loss: 1.0524\n",
            "Epoch 3, Sample 11531: Loss: 0.3399\n",
            "Epoch 3, Sample 11532: Loss: 0.8257\n",
            "Epoch 3, Sample 11533: Loss: 0.0084\n",
            "Epoch 3, Sample 11534: Loss: 0.0630\n",
            "Epoch 3, Sample 11535: Loss: 1.2758\n",
            "Epoch 3, Sample 11536: Loss: 0.7071\n",
            "Epoch 3, Sample 11537: Loss: 0.2558\n",
            "Epoch 3, Sample 11538: Loss: 1.0524\n",
            "Epoch 3, Sample 11539: Loss: 0.0010\n",
            "Epoch 3, Sample 11540: Loss: 0.2590\n",
            "Epoch 3, Sample 11541: Loss: 0.0018\n",
            "Epoch 3, Sample 11542: Loss: 0.7036\n",
            "Epoch 3, Sample 11543: Loss: 0.2034\n",
            "Epoch 3, Sample 11544: Loss: 0.0258\n",
            "Epoch 3, Sample 11545: Loss: 0.6150\n",
            "Epoch 3, Sample 11546: Loss: 0.1559\n",
            "Epoch 3, Sample 11547: Loss: 1.0524\n",
            "Epoch 3, Sample 11548: Loss: 1.0524\n",
            "Epoch 3, Sample 11549: Loss: 1.0155\n",
            "Epoch 3, Sample 11550: Loss: 0.6990\n",
            "Epoch 3, Sample 11551: Loss: 0.1724\n",
            "Epoch 3, Sample 11552: Loss: 0.3441\n",
            "Epoch 3, Sample 11553: Loss: 1.7801\n",
            "Epoch 3, Sample 11554: Loss: 0.7036\n",
            "Epoch 3, Sample 11555: Loss: 0.0018\n",
            "Epoch 3, Sample 11556: Loss: 0.5003\n",
            "Epoch 3, Sample 11557: Loss: 1.0155\n",
            "Epoch 3, Sample 11558: Loss: 0.2044\n",
            "Epoch 3, Sample 11559: Loss: 0.1838\n",
            "Epoch 3, Sample 11560: Loss: 0.0626\n",
            "Epoch 3, Sample 11561: Loss: 1.4121\n",
            "Epoch 3, Sample 11562: Loss: 0.5310\n",
            "Epoch 3, Sample 11563: Loss: 0.0039\n",
            "Epoch 3, Sample 11564: Loss: 0.1474\n",
            "Epoch 3, Sample 11565: Loss: 0.2112\n",
            "Epoch 3, Sample 11566: Loss: 0.2989\n",
            "Epoch 3, Sample 11567: Loss: 0.0000\n",
            "Epoch 3, Sample 11568: Loss: 0.2699\n",
            "Epoch 3, Sample 11569: Loss: 1.0524\n",
            "Epoch 3, Sample 11570: Loss: 0.2044\n",
            "Epoch 3, Sample 11571: Loss: 0.5858\n",
            "Epoch 3, Sample 11572: Loss: 0.0466\n",
            "Epoch 3, Sample 11573: Loss: 0.1817\n",
            "Epoch 3, Sample 11574: Loss: 0.1559\n",
            "Epoch 3, Sample 11575: Loss: 0.2032\n",
            "Epoch 3, Sample 11576: Loss: 0.6893\n",
            "Epoch 3, Sample 11577: Loss: 1.0524\n",
            "Epoch 3, Sample 11578: Loss: 0.2044\n",
            "Epoch 3, Sample 11579: Loss: 0.0300\n",
            "Epoch 3, Sample 11580: Loss: 0.7036\n",
            "Epoch 3, Sample 11581: Loss: 0.0407\n",
            "Epoch 3, Sample 11582: Loss: 1.0530\n",
            "Epoch 3, Sample 11583: Loss: 0.1523\n",
            "Epoch 3, Sample 11584: Loss: 1.0155\n",
            "Epoch 3, Sample 11585: Loss: 0.1654\n",
            "Epoch 3, Sample 11586: Loss: 0.5858\n",
            "Epoch 3, Sample 11587: Loss: 0.5858\n",
            "Epoch 3, Sample 11588: Loss: 0.0212\n",
            "Epoch 3, Sample 11589: Loss: 0.0501\n",
            "Epoch 3, Sample 11590: Loss: 0.0630\n",
            "Epoch 3, Sample 11591: Loss: 0.1248\n",
            "Epoch 3, Sample 11592: Loss: 0.2032\n",
            "Epoch 3, Sample 11593: Loss: 0.0018\n",
            "Epoch 3, Sample 11594: Loss: 0.2340\n",
            "Epoch 3, Sample 11595: Loss: 0.6360\n",
            "Epoch 3, Sample 11596: Loss: 0.3399\n",
            "Epoch 3, Sample 11597: Loss: 0.2034\n",
            "Epoch 3, Sample 11598: Loss: 0.1657\n",
            "Epoch 3, Sample 11599: Loss: 0.1986\n",
            "Epoch 3, Sample 11600: Loss: 0.0436\n",
            "Epoch 3, Sample 11601: Loss: 0.2044\n",
            "Epoch 3, Sample 11602: Loss: 0.9428\n",
            "Epoch 3, Sample 11603: Loss: 1.0155\n",
            "Epoch 3, Sample 11604: Loss: 0.0466\n",
            "Epoch 3, Sample 11605: Loss: 0.9547\n",
            "Epoch 3, Sample 11606: Loss: 0.3568\n",
            "Epoch 3, Sample 11607: Loss: 0.2361\n",
            "Epoch 3, Sample 11608: Loss: 0.0026\n",
            "Epoch 3, Sample 11609: Loss: 0.6092\n",
            "Epoch 3, Sample 11610: Loss: 0.3062\n",
            "Epoch 3, Sample 11611: Loss: 0.4996\n",
            "Epoch 3, Sample 11612: Loss: 1.0530\n",
            "Epoch 3, Sample 11613: Loss: 0.1271\n",
            "Epoch 3, Sample 11614: Loss: 1.0155\n",
            "Epoch 3, Sample 11615: Loss: 0.0477\n",
            "Epoch 3, Sample 11616: Loss: 6.7172\n",
            "Epoch 3, Sample 11617: Loss: 0.2044\n",
            "Epoch 3, Sample 11618: Loss: 0.2459\n",
            "Epoch 3, Sample 11619: Loss: 0.7036\n",
            "Epoch 3, Sample 11620: Loss: 0.7702\n",
            "Epoch 3, Sample 11621: Loss: 0.4996\n",
            "Epoch 3, Sample 11622: Loss: 0.2032\n",
            "Epoch 3, Sample 11623: Loss: 0.5000\n",
            "Epoch 3, Sample 11624: Loss: 0.1170\n",
            "Epoch 3, Sample 11625: Loss: 0.0460\n",
            "Epoch 3, Sample 11626: Loss: 0.2363\n",
            "Epoch 3, Sample 11627: Loss: 7.6726\n",
            "Epoch 3, Sample 11628: Loss: 0.2044\n",
            "Epoch 3, Sample 11629: Loss: 2.1482\n",
            "Epoch 3, Sample 11630: Loss: 1.0155\n",
            "Epoch 3, Sample 11631: Loss: 1.0155\n",
            "Epoch 3, Sample 11632: Loss: 0.1250\n",
            "Epoch 3, Sample 11633: Loss: 0.6139\n",
            "Epoch 3, Sample 11634: Loss: 0.0630\n",
            "Epoch 3, Sample 11635: Loss: 0.0034\n",
            "Epoch 3, Sample 11636: Loss: 0.7036\n",
            "Epoch 3, Sample 11637: Loss: 0.2032\n",
            "Epoch 3, Sample 11638: Loss: 0.2339\n",
            "Epoch 3, Sample 11639: Loss: 0.2044\n",
            "Epoch 3, Sample 11640: Loss: 0.3399\n",
            "Epoch 3, Sample 11641: Loss: 0.3399\n",
            "Epoch 3, Sample 11642: Loss: 0.0018\n",
            "Epoch 3, Sample 11643: Loss: 0.1669\n",
            "Epoch 3, Sample 11644: Loss: 0.3214\n",
            "Epoch 3, Sample 11645: Loss: 0.7036\n",
            "Epoch 3, Sample 11646: Loss: 0.1745\n",
            "Epoch 3, Sample 11647: Loss: 0.0026\n",
            "Epoch 3, Sample 11648: Loss: 0.7036\n",
            "Epoch 3, Sample 11649: Loss: 0.0018\n",
            "Epoch 3, Sample 11650: Loss: 0.5858\n",
            "Epoch 3, Sample 11651: Loss: 0.5858\n",
            "Epoch 3, Sample 11652: Loss: 0.0026\n",
            "Epoch 3, Sample 11653: Loss: 0.7036\n",
            "Epoch 3, Sample 11654: Loss: 0.6700\n",
            "Epoch 3, Sample 11655: Loss: 0.0018\n",
            "Epoch 3, Sample 11656: Loss: 0.3399\n",
            "Epoch 3, Sample 11657: Loss: 0.4032\n",
            "Epoch 3, Sample 11658: Loss: 0.0026\n",
            "Epoch 3, Sample 11659: Loss: 0.0150\n",
            "Epoch 3, Sample 11660: Loss: 0.2639\n",
            "Epoch 3, Sample 11661: Loss: 0.1682\n",
            "Epoch 3, Sample 11662: Loss: 0.5196\n",
            "Epoch 3, Sample 11663: Loss: 0.3441\n",
            "Epoch 3, Sample 11664: Loss: 1.0155\n",
            "Epoch 3, Sample 11665: Loss: 0.1170\n",
            "Epoch 3, Sample 11666: Loss: 0.2036\n",
            "Epoch 3, Sample 11667: Loss: 0.5078\n",
            "Epoch 3, Sample 11668: Loss: 0.4032\n",
            "Epoch 3, Sample 11669: Loss: 0.2832\n",
            "Epoch 3, Sample 11670: Loss: 0.2044\n",
            "Epoch 3, Sample 11671: Loss: 0.2722\n",
            "Epoch 3, Sample 11672: Loss: 0.2709\n",
            "Epoch 3, Sample 11673: Loss: 0.0001\n",
            "Epoch 3, Sample 11674: Loss: 0.5319\n",
            "Epoch 3, Sample 11675: Loss: 0.5078\n",
            "Epoch 3, Sample 11676: Loss: 0.0460\n",
            "Epoch 3, Sample 11677: Loss: 2.6384\n",
            "Epoch 3, Sample 11678: Loss: 0.2973\n",
            "Epoch 3, Sample 11679: Loss: 0.2044\n",
            "Epoch 3, Sample 11680: Loss: 0.0671\n",
            "Epoch 3, Sample 11681: Loss: 1.0524\n",
            "Epoch 3, Sample 11682: Loss: 0.5078\n",
            "Epoch 3, Sample 11683: Loss: 0.4799\n",
            "Epoch 3, Sample 11684: Loss: 1.2926\n",
            "Epoch 3, Sample 11685: Loss: 0.1170\n",
            "Epoch 3, Sample 11686: Loss: 1.1093\n",
            "Epoch 3, Sample 11687: Loss: 0.0018\n",
            "Epoch 3, Sample 11688: Loss: 0.2219\n",
            "Epoch 3, Sample 11689: Loss: 0.0022\n",
            "Epoch 3, Sample 11690: Loss: 0.0006\n",
            "Epoch 3, Sample 11691: Loss: 0.2044\n",
            "Epoch 3, Sample 11692: Loss: 0.0026\n",
            "Epoch 3, Sample 11693: Loss: 0.0498\n",
            "Epoch 3, Sample 11694: Loss: 0.5000\n",
            "Epoch 3, Sample 11695: Loss: 0.3399\n",
            "Epoch 3, Sample 11696: Loss: 1.5269\n",
            "Epoch 3, Sample 11697: Loss: 0.1791\n",
            "Epoch 3, Sample 11698: Loss: 0.7092\n",
            "Epoch 3, Sample 11699: Loss: 0.0219\n",
            "Epoch 3, Sample 11700: Loss: 0.2036\n",
            "Epoch 3, Sample 11701: Loss: 0.1874\n",
            "Epoch 3, Sample 11702: Loss: 0.0651\n",
            "Epoch 3, Sample 11703: Loss: 0.0554\n",
            "Epoch 3, Sample 11704: Loss: 0.1250\n",
            "Epoch 3, Sample 11705: Loss: 0.0063\n",
            "Epoch 3, Sample 11706: Loss: 5.2253\n",
            "Epoch 3, Sample 11707: Loss: 0.0133\n",
            "Epoch 3, Sample 11708: Loss: 2.9652\n",
            "Epoch 3, Sample 11709: Loss: 0.1446\n",
            "Epoch 3, Sample 11710: Loss: 0.1773\n",
            "Epoch 3, Sample 11711: Loss: 0.3094\n",
            "Epoch 3, Sample 11712: Loss: 0.0188\n",
            "Epoch 3, Sample 11713: Loss: 0.2759\n",
            "Epoch 3, Sample 11714: Loss: 0.2759\n",
            "Epoch 3, Sample 11715: Loss: 0.5858\n",
            "Epoch 3, Sample 11716: Loss: 1.0524\n",
            "Epoch 3, Sample 11717: Loss: 0.0630\n",
            "Epoch 3, Sample 11718: Loss: 0.5000\n",
            "Epoch 3, Sample 11719: Loss: 0.3450\n",
            "Epoch 3, Sample 11720: Loss: 1.0155\n",
            "Epoch 3, Sample 11721: Loss: 0.1250\n",
            "Epoch 3, Sample 11722: Loss: 0.2112\n",
            "Epoch 3, Sample 11723: Loss: 1.0070\n",
            "Epoch 3, Sample 11724: Loss: 0.3326\n",
            "Epoch 3, Sample 11725: Loss: 0.2112\n",
            "Epoch 3, Sample 11726: Loss: 0.2044\n",
            "Epoch 3, Sample 11727: Loss: 0.2759\n",
            "Epoch 3, Sample 11728: Loss: 0.4841\n",
            "Epoch 3, Sample 11729: Loss: 0.0529\n",
            "Epoch 3, Sample 11730: Loss: 0.3007\n",
            "Epoch 3, Sample 11731: Loss: 0.0018\n",
            "Epoch 3, Sample 11732: Loss: 0.0507\n",
            "Epoch 3, Sample 11733: Loss: 0.2816\n",
            "Epoch 3, Sample 11734: Loss: 0.3399\n",
            "Epoch 3, Sample 11735: Loss: 0.1689\n",
            "Epoch 3, Sample 11736: Loss: 0.5992\n",
            "Epoch 3, Sample 11737: Loss: 0.0026\n",
            "Epoch 3, Sample 11738: Loss: 0.0013\n",
            "Epoch 3, Sample 11739: Loss: 0.7453\n",
            "Epoch 3, Sample 11740: Loss: 0.0027\n",
            "Epoch 3, Sample 11741: Loss: 0.0793\n",
            "Epoch 3, Sample 11742: Loss: 0.4358\n",
            "Epoch 3, Sample 11743: Loss: 0.9367\n",
            "Epoch 3, Sample 11744: Loss: 0.1170\n",
            "Epoch 3, Sample 11745: Loss: 0.3441\n",
            "Epoch 3, Sample 11746: Loss: 0.5196\n",
            "Epoch 3, Sample 11747: Loss: 0.1163\n",
            "Epoch 3, Sample 11748: Loss: 0.0072\n",
            "Epoch 3, Sample 11749: Loss: 0.0630\n",
            "Epoch 3, Sample 11750: Loss: 0.1250\n",
            "Epoch 3, Sample 11751: Loss: 0.1326\n",
            "Epoch 3, Sample 11752: Loss: 0.0468\n",
            "Epoch 3, Sample 11753: Loss: 0.2832\n",
            "Epoch 3, Sample 11754: Loss: 0.0443\n",
            "Epoch 3, Sample 11755: Loss: 0.0084\n",
            "Epoch 3, Sample 11756: Loss: 0.8424\n",
            "Epoch 3, Sample 11757: Loss: 0.2036\n",
            "Epoch 3, Sample 11758: Loss: 0.4644\n",
            "Epoch 3, Sample 11759: Loss: 0.2032\n",
            "Epoch 3, Sample 11760: Loss: 0.6990\n",
            "Epoch 3, Sample 11761: Loss: 0.2109\n",
            "Epoch 3, Sample 11762: Loss: 0.0775\n",
            "Epoch 3, Sample 11763: Loss: 0.1250\n",
            "Epoch 3, Sample 11764: Loss: 0.0306\n",
            "Epoch 3, Sample 11765: Loss: 0.2018\n",
            "Epoch 3, Sample 11766: Loss: 0.0018\n",
            "Epoch 3, Sample 11767: Loss: 0.0744\n",
            "Epoch 3, Sample 11768: Loss: 0.1523\n",
            "Epoch 3, Sample 11769: Loss: 1.0155\n",
            "Epoch 3, Sample 11770: Loss: 0.5989\n",
            "Epoch 3, Sample 11771: Loss: 0.3399\n",
            "Epoch 3, Sample 11772: Loss: 1.0155\n",
            "Epoch 3, Sample 11773: Loss: 0.6181\n",
            "Epoch 3, Sample 11774: Loss: 0.1250\n",
            "Epoch 3, Sample 11775: Loss: 0.0007\n",
            "Epoch 3, Sample 11776: Loss: 1.0524\n",
            "Epoch 3, Sample 11777: Loss: 0.3168\n",
            "Epoch 3, Sample 11778: Loss: 0.2044\n",
            "Epoch 3, Sample 11779: Loss: 0.2759\n",
            "Epoch 3, Sample 11780: Loss: 0.0626\n",
            "Epoch 3, Sample 11781: Loss: 0.5000\n",
            "Epoch 3, Sample 11782: Loss: 1.0227\n",
            "Epoch 3, Sample 11783: Loss: 0.2032\n",
            "Epoch 3, Sample 11784: Loss: 0.6304\n",
            "Epoch 3, Sample 11785: Loss: 0.4841\n",
            "Epoch 3, Sample 11786: Loss: 1.0155\n",
            "Epoch 3, Sample 11787: Loss: 0.2941\n",
            "Epoch 3, Sample 11788: Loss: 0.8819\n",
            "Epoch 3, Sample 11789: Loss: 0.3949\n",
            "Epoch 3, Sample 11790: Loss: 0.0039\n",
            "Epoch 3, Sample 11791: Loss: 0.0026\n",
            "Epoch 3, Sample 11792: Loss: 0.0630\n",
            "Epoch 3, Sample 11793: Loss: 1.0155\n",
            "Epoch 3, Sample 11794: Loss: 0.0018\n",
            "Epoch 3, Sample 11795: Loss: 0.0000\n",
            "Epoch 3, Sample 11796: Loss: 0.2044\n",
            "Epoch 3, Sample 11797: Loss: 0.7453\n",
            "Epoch 3, Sample 11798: Loss: 2.9160\n",
            "Epoch 3, Sample 11799: Loss: 0.2832\n",
            "Epoch 3, Sample 11800: Loss: 0.2034\n",
            "Epoch 3, Sample 11801: Loss: 0.0630\n",
            "Epoch 3, Sample 11802: Loss: 0.0027\n",
            "Epoch 3, Sample 11803: Loss: 1.8267\n",
            "Epoch 3, Sample 11804: Loss: 0.5003\n",
            "Epoch 3, Sample 11805: Loss: 0.3341\n",
            "Epoch 3, Sample 11806: Loss: 0.0212\n",
            "Epoch 3, Sample 11807: Loss: 0.0189\n",
            "Epoch 3, Sample 11808: Loss: 0.0168\n",
            "Epoch 3, Sample 11809: Loss: 2.0302\n",
            "Epoch 3, Sample 11810: Loss: 0.0026\n",
            "Epoch 3, Sample 11811: Loss: 0.0026\n",
            "Epoch 3, Sample 11812: Loss: 0.2044\n",
            "Epoch 3, Sample 11813: Loss: 0.5311\n",
            "Epoch 3, Sample 11814: Loss: 0.2941\n",
            "Epoch 3, Sample 11815: Loss: 0.1546\n",
            "Epoch 3, Sample 11816: Loss: 0.1559\n",
            "Epoch 3, Sample 11817: Loss: 0.5858\n",
            "Epoch 3, Sample 11818: Loss: 0.3399\n",
            "Epoch 3, Sample 11819: Loss: 0.4032\n",
            "Epoch 3, Sample 11820: Loss: 0.2036\n",
            "Epoch 3, Sample 11821: Loss: 0.2639\n",
            "Epoch 3, Sample 11822: Loss: 1.0530\n",
            "Epoch 3, Sample 11823: Loss: 0.2256\n",
            "Epoch 3, Sample 11824: Loss: 0.2639\n",
            "Epoch 3, Sample 11825: Loss: 0.7036\n",
            "Epoch 3, Sample 11826: Loss: 0.2724\n",
            "Epoch 3, Sample 11827: Loss: 0.0509\n",
            "Epoch 3, Sample 11828: Loss: 1.4056\n",
            "Epoch 3, Sample 11829: Loss: 1.0530\n",
            "Epoch 3, Sample 11830: Loss: 0.2044\n",
            "Epoch 3, Sample 11831: Loss: 0.0240\n",
            "Epoch 3, Sample 11832: Loss: 0.3039\n",
            "Epoch 3, Sample 11833: Loss: 0.2044\n",
            "Epoch 3, Sample 11834: Loss: 0.2044\n",
            "Epoch 3, Sample 11835: Loss: 0.3399\n",
            "Epoch 3, Sample 11836: Loss: 0.0875\n",
            "Epoch 3, Sample 11837: Loss: 0.0025\n",
            "Epoch 3, Sample 11838: Loss: 0.0001\n",
            "Epoch 3, Sample 11839: Loss: 0.3441\n",
            "Epoch 3, Sample 11840: Loss: 0.5382\n",
            "Epoch 3, Sample 11841: Loss: 3.4433\n",
            "Epoch 3, Sample 11842: Loss: 0.7036\n",
            "Epoch 3, Sample 11843: Loss: 0.7036\n",
            "Epoch 3, Sample 11844: Loss: 0.0268\n",
            "Epoch 3, Sample 11845: Loss: 0.3584\n",
            "Epoch 3, Sample 11846: Loss: 0.3949\n",
            "Epoch 3, Sample 11847: Loss: 0.1517\n",
            "Epoch 3, Sample 11848: Loss: 0.2759\n",
            "Epoch 3, Sample 11849: Loss: 0.2759\n",
            "Epoch 3, Sample 11850: Loss: 0.2759\n",
            "Epoch 3, Sample 11851: Loss: 0.0278\n",
            "Epoch 3, Sample 11852: Loss: 0.0002\n",
            "Epoch 3, Sample 11853: Loss: 2.0912\n",
            "Epoch 3, Sample 11854: Loss: 0.8951\n",
            "Epoch 3, Sample 11855: Loss: 0.2375\n",
            "Epoch 3, Sample 11856: Loss: 0.0938\n",
            "Epoch 3, Sample 11857: Loss: 0.0018\n",
            "Epoch 3, Sample 11858: Loss: 0.0455\n",
            "Epoch 3, Sample 11859: Loss: 0.1627\n",
            "Epoch 3, Sample 11860: Loss: 0.7679\n",
            "Epoch 3, Sample 11861: Loss: 0.5375\n",
            "Epoch 3, Sample 11862: Loss: 1.0511\n",
            "Epoch 3, Sample 11863: Loss: 0.2044\n",
            "Epoch 3, Sample 11864: Loss: 0.0030\n",
            "Epoch 3, Sample 11865: Loss: 5.2268\n",
            "Epoch 3, Sample 11866: Loss: 0.7036\n",
            "Epoch 3, Sample 11867: Loss: 0.1007\n",
            "Epoch 3, Sample 11868: Loss: 0.3092\n",
            "Epoch 3, Sample 11869: Loss: 0.2112\n",
            "Epoch 3, Sample 11870: Loss: 0.0026\n",
            "Epoch 3, Sample 11871: Loss: 0.4588\n",
            "Epoch 3, Sample 11872: Loss: 0.0938\n",
            "Epoch 3, Sample 11873: Loss: 0.0466\n",
            "Epoch 3, Sample 11874: Loss: 0.0050\n",
            "Epoch 3, Sample 11875: Loss: 0.0205\n",
            "Epoch 3, Sample 11876: Loss: 1.0227\n",
            "Epoch 3, Sample 11877: Loss: 0.3399\n",
            "Epoch 3, Sample 11878: Loss: 1.0688\n",
            "Epoch 3, Sample 11879: Loss: 0.5972\n",
            "Epoch 3, Sample 11880: Loss: 0.1590\n",
            "Epoch 3, Sample 11881: Loss: 9.8546\n",
            "Epoch 3, Sample 11882: Loss: 0.5858\n",
            "Epoch 3, Sample 11883: Loss: 0.0505\n",
            "Epoch 3, Sample 11884: Loss: 0.0013\n",
            "Epoch 3, Sample 11885: Loss: 0.7036\n",
            "Epoch 3, Sample 11886: Loss: 1.0155\n",
            "Epoch 3, Sample 11887: Loss: 0.2034\n",
            "Epoch 3, Sample 11888: Loss: 0.5141\n",
            "Epoch 3, Sample 11889: Loss: 0.7036\n",
            "Epoch 3, Sample 11890: Loss: 0.2686\n",
            "Epoch 3, Sample 11891: Loss: 0.6990\n",
            "Epoch 3, Sample 11892: Loss: 0.1170\n",
            "Epoch 3, Sample 11893: Loss: 0.0026\n",
            "Epoch 3, Sample 11894: Loss: 0.2032\n",
            "Epoch 3, Sample 11895: Loss: 0.5858\n",
            "Epoch 3, Sample 11896: Loss: 0.1539\n",
            "Epoch 3, Sample 11897: Loss: 0.2639\n",
            "Epoch 3, Sample 11898: Loss: 0.3194\n",
            "Epoch 3, Sample 11899: Loss: 0.3399\n",
            "Epoch 3, Sample 11900: Loss: 8.7194\n",
            "Epoch 3, Sample 11901: Loss: 0.5003\n",
            "Epoch 3, Sample 11902: Loss: 0.3092\n",
            "Epoch 3, Sample 11903: Loss: 0.1250\n",
            "Epoch 3, Sample 11904: Loss: 0.1246\n",
            "Epoch 3, Sample 11905: Loss: 0.2832\n",
            "Epoch 3, Sample 11906: Loss: 0.3441\n",
            "Epoch 3, Sample 11907: Loss: 0.0205\n",
            "Epoch 3, Sample 11908: Loss: 0.1860\n",
            "Epoch 3, Sample 11909: Loss: 0.0026\n",
            "Epoch 3, Sample 11910: Loss: 0.3399\n",
            "Epoch 3, Sample 11911: Loss: 0.4007\n",
            "Epoch 3, Sample 11912: Loss: 0.1399\n",
            "Epoch 3, Sample 11913: Loss: 0.0625\n",
            "Epoch 3, Sample 11914: Loss: 0.2639\n",
            "Epoch 3, Sample 11915: Loss: 0.2034\n",
            "Epoch 3, Sample 11916: Loss: 0.0220\n",
            "Epoch 3, Sample 11917: Loss: 0.0832\n",
            "Epoch 3, Sample 11918: Loss: 0.0026\n",
            "Epoch 3, Sample 11919: Loss: 0.0630\n",
            "Epoch 3, Sample 11920: Loss: 0.0184\n",
            "Epoch 3, Sample 11921: Loss: 0.6990\n",
            "Epoch 3, Sample 11922: Loss: 0.3441\n",
            "Epoch 3, Sample 11923: Loss: 0.3399\n",
            "Epoch 3, Sample 11924: Loss: 0.5000\n",
            "Epoch 3, Sample 11925: Loss: 0.0630\n",
            "Epoch 3, Sample 11926: Loss: 0.4574\n",
            "Epoch 3, Sample 11927: Loss: 0.2340\n",
            "Epoch 3, Sample 11928: Loss: 0.3624\n",
            "Epoch 3, Sample 11929: Loss: 0.0220\n",
            "Epoch 3, Sample 11930: Loss: 0.4367\n",
            "Epoch 3, Sample 11931: Loss: 0.0060\n",
            "Epoch 3, Sample 11932: Loss: 0.9011\n",
            "Epoch 3, Sample 11933: Loss: 0.0554\n",
            "Epoch 3, Sample 11934: Loss: 0.9651\n",
            "Epoch 3, Sample 11935: Loss: 0.4930\n",
            "Epoch 3, Sample 11936: Loss: 0.1043\n",
            "Epoch 3, Sample 11937: Loss: 0.0006\n",
            "Epoch 3, Sample 11938: Loss: 0.1372\n",
            "Epoch 3, Sample 11939: Loss: 0.2044\n",
            "Epoch 3, Sample 11940: Loss: 1.0524\n",
            "Epoch 3, Sample 11941: Loss: 0.2044\n",
            "Epoch 3, Sample 11942: Loss: 0.0004\n",
            "Epoch 3, Sample 11943: Loss: 0.7702\n",
            "Epoch 3, Sample 11944: Loss: 0.0025\n",
            "Epoch 3, Sample 11945: Loss: 0.5858\n",
            "Epoch 3, Sample 11946: Loss: 1.0524\n",
            "Epoch 3, Sample 11947: Loss: 0.1170\n",
            "Epoch 3, Sample 11948: Loss: 0.0212\n",
            "Epoch 3, Sample 11949: Loss: 0.2036\n",
            "Epoch 3, Sample 11950: Loss: 1.6275\n",
            "Epoch 3, Sample 11951: Loss: 0.8217\n",
            "Epoch 3, Sample 11952: Loss: 0.5000\n",
            "Epoch 3, Sample 11953: Loss: 0.0838\n",
            "Epoch 3, Sample 11954: Loss: 0.2783\n",
            "Epoch 3, Sample 11955: Loss: 0.1337\n",
            "Epoch 3, Sample 11956: Loss: 0.4799\n",
            "Epoch 3, Sample 11957: Loss: 0.7623\n",
            "Epoch 3, Sample 11958: Loss: 0.4155\n",
            "Epoch 3, Sample 11959: Loss: 0.9721\n",
            "Epoch 3, Sample 11960: Loss: 0.3007\n",
            "Epoch 3, Sample 11961: Loss: 0.2759\n",
            "Epoch 3, Sample 11962: Loss: 0.0578\n",
            "Epoch 3, Sample 11963: Loss: 0.0083\n",
            "Epoch 3, Sample 11964: Loss: 0.7702\n",
            "Epoch 3, Sample 11965: Loss: 0.0018\n",
            "Epoch 3, Sample 11966: Loss: 0.2034\n",
            "Epoch 3, Sample 11967: Loss: 0.0640\n",
            "Epoch 3, Sample 11968: Loss: 6.7582\n",
            "Epoch 3, Sample 11969: Loss: 0.6990\n",
            "Epoch 3, Sample 11970: Loss: 0.2044\n",
            "Epoch 3, Sample 11971: Loss: 0.3399\n",
            "Epoch 3, Sample 11972: Loss: 0.0062\n",
            "Epoch 3, Sample 11973: Loss: 2.3530\n",
            "Epoch 3, Sample 11974: Loss: 0.4611\n",
            "Epoch 3, Sample 11975: Loss: 1.0524\n",
            "Epoch 3, Sample 11976: Loss: 0.5871\n",
            "Epoch 3, Sample 11977: Loss: 1.0524\n",
            "Epoch 3, Sample 11978: Loss: 0.2044\n",
            "Epoch 3, Sample 11979: Loss: 0.4697\n",
            "Epoch 3, Sample 11980: Loss: 0.6867\n",
            "Epoch 3, Sample 11981: Loss: 0.0000\n",
            "Epoch 3, Sample 11982: Loss: 0.5000\n",
            "Epoch 3, Sample 11983: Loss: 0.0018\n",
            "Epoch 3, Sample 11984: Loss: 0.1508\n",
            "Epoch 3, Sample 11985: Loss: 0.3506\n",
            "Epoch 3, Sample 11986: Loss: 1.0545\n",
            "Epoch 3, Sample 11987: Loss: 0.9959\n",
            "Epoch 3, Sample 11988: Loss: 0.0000\n",
            "Epoch 3, Sample 11989: Loss: 0.1619\n",
            "Epoch 3, Sample 11990: Loss: 0.2034\n",
            "Epoch 3, Sample 11991: Loss: 0.2034\n",
            "Epoch 3, Sample 11992: Loss: 0.5003\n",
            "Epoch 3, Sample 11993: Loss: 0.3598\n",
            "Epoch 3, Sample 11994: Loss: 0.0358\n",
            "Epoch 3, Sample 11995: Loss: 1.0524\n",
            "Epoch 3, Sample 11996: Loss: 0.1091\n",
            "Epoch 3, Sample 11997: Loss: 0.2036\n",
            "Epoch 3, Sample 11998: Loss: 0.1254\n",
            "Epoch 3, Sample 11999: Loss: 8.7405\n",
            "Epoch 3, Sample 12000: Loss: 0.0018\n",
            "Epoch 3, Sample 12001: Loss: 0.9988\n",
            "Epoch 3, Sample 12002: Loss: 0.0306\n",
            "Epoch 3, Sample 12003: Loss: 0.0001\n",
            "Epoch 3, Sample 12004: Loss: 0.0005\n",
            "Epoch 3, Sample 12005: Loss: 0.7344\n",
            "Epoch 3, Sample 12006: Loss: 0.1890\n",
            "Epoch 3, Sample 12007: Loss: 0.0805\n",
            "Epoch 3, Sample 12008: Loss: 0.0001\n",
            "Epoch 3, Sample 12009: Loss: 0.2993\n",
            "Epoch 3, Sample 12010: Loss: 0.0476\n",
            "Epoch 3, Sample 12011: Loss: 0.4607\n",
            "Epoch 3, Sample 12012: Loss: 0.0000\n",
            "Epoch 3, Sample 12013: Loss: 0.4930\n",
            "Epoch 3, Sample 12014: Loss: 0.1114\n",
            "Epoch 3, Sample 12015: Loss: 0.3598\n",
            "Epoch 3, Sample 12016: Loss: 0.5806\n",
            "Epoch 3, Sample 12017: Loss: 0.3017\n",
            "Epoch 3, Sample 12018: Loss: 0.0626\n",
            "Epoch 3, Sample 12019: Loss: 0.2044\n",
            "Epoch 3, Sample 12020: Loss: 0.5011\n",
            "Epoch 3, Sample 12021: Loss: 0.3949\n",
            "Epoch 3, Sample 12022: Loss: 0.3949\n",
            "Epoch 3, Sample 12023: Loss: 0.1250\n",
            "Epoch 3, Sample 12024: Loss: 1.0524\n",
            "Epoch 3, Sample 12025: Loss: 1.0524\n",
            "Epoch 3, Sample 12026: Loss: 0.2759\n",
            "Epoch 3, Sample 12027: Loss: 0.0060\n",
            "Epoch 3, Sample 12028: Loss: 0.5019\n",
            "Epoch 3, Sample 12029: Loss: 0.2219\n",
            "Epoch 3, Sample 12030: Loss: 0.4382\n",
            "Epoch 3, Sample 12031: Loss: 0.0006\n",
            "Epoch 3, Sample 12032: Loss: 0.3441\n",
            "Epoch 3, Sample 12033: Loss: 6.9198\n",
            "Epoch 3, Sample 12034: Loss: 0.3441\n",
            "Epoch 3, Sample 12035: Loss: 0.2459\n",
            "Epoch 3, Sample 12036: Loss: 0.1039\n",
            "Epoch 3, Sample 12037: Loss: 0.0018\n",
            "Epoch 3, Sample 12038: Loss: 1.3792\n",
            "Epoch 3, Sample 12039: Loss: 0.4663\n",
            "Epoch 3, Sample 12040: Loss: 0.2177\n",
            "Epoch 3, Sample 12041: Loss: 0.3367\n",
            "Epoch 3, Sample 12042: Loss: 0.0558\n",
            "Epoch 3, Sample 12043: Loss: 0.0247\n",
            "Epoch 3, Sample 12044: Loss: 0.7036\n",
            "Epoch 3, Sample 12045: Loss: 0.0026\n",
            "Epoch 3, Sample 12046: Loss: 0.2034\n",
            "Epoch 3, Sample 12047: Loss: 0.0009\n",
            "Epoch 3, Sample 12048: Loss: 0.6139\n",
            "Epoch 3, Sample 12049: Loss: 0.1559\n",
            "Epoch 3, Sample 12050: Loss: 0.5003\n",
            "Epoch 3, Sample 12051: Loss: 0.0019\n",
            "Epoch 3, Sample 12052: Loss: 0.0026\n",
            "Epoch 3, Sample 12053: Loss: 0.3584\n",
            "Epoch 3, Sample 12054: Loss: 0.1250\n",
            "Epoch 3, Sample 12055: Loss: 0.0700\n",
            "Epoch 3, Sample 12056: Loss: 0.5019\n",
            "Epoch 3, Sample 12057: Loss: 0.0470\n",
            "Epoch 3, Sample 12058: Loss: 0.0289\n",
            "Epoch 3, Sample 12059: Loss: 0.2034\n",
            "Epoch 3, Sample 12060: Loss: 0.6990\n",
            "Epoch 3, Sample 12061: Loss: 0.1451\n",
            "Epoch 3, Sample 12062: Loss: 0.0018\n",
            "Epoch 3, Sample 12063: Loss: 0.3441\n",
            "Epoch 3, Sample 12064: Loss: 0.3399\n",
            "Epoch 3, Sample 12065: Loss: 0.0201\n",
            "Epoch 3, Sample 12066: Loss: 0.0505\n",
            "Epoch 3, Sample 12067: Loss: 0.0002\n",
            "Epoch 3, Sample 12068: Loss: 0.0025\n",
            "Epoch 3, Sample 12069: Loss: 0.2032\n",
            "Epoch 3, Sample 12070: Loss: 0.6388\n",
            "Epoch 3, Sample 12071: Loss: 0.1748\n",
            "Epoch 3, Sample 12072: Loss: 5.2690\n",
            "Epoch 3, Sample 12073: Loss: 1.0155\n",
            "Epoch 3, Sample 12074: Loss: 0.7036\n",
            "Epoch 3, Sample 12075: Loss: 0.1170\n",
            "Epoch 3, Sample 12076: Loss: 0.1387\n",
            "Epoch 3, Sample 12077: Loss: 0.2044\n",
            "Epoch 3, Sample 12078: Loss: 0.0026\n",
            "Epoch 3, Sample 12079: Loss: 1.6282\n",
            "Epoch 3, Sample 12080: Loss: 0.7453\n",
            "Epoch 3, Sample 12081: Loss: 0.6867\n",
            "Epoch 3, Sample 12082: Loss: 0.7036\n",
            "Epoch 3, Sample 12083: Loss: 0.6304\n",
            "Epoch 3, Sample 12084: Loss: 0.1399\n",
            "Epoch 3, Sample 12085: Loss: 0.2759\n",
            "Epoch 3, Sample 12086: Loss: 0.8951\n",
            "Epoch 3, Sample 12087: Loss: 0.7036\n",
            "Epoch 3, Sample 12088: Loss: 1.0524\n",
            "Epoch 3, Sample 12089: Loss: 0.2044\n",
            "Epoch 3, Sample 12090: Loss: 4.1541\n",
            "Epoch 3, Sample 12091: Loss: 0.2639\n",
            "Epoch 3, Sample 12092: Loss: 0.2044\n",
            "Epoch 3, Sample 12093: Loss: 0.3055\n",
            "Epoch 3, Sample 12094: Loss: 0.0018\n",
            "Epoch 3, Sample 12095: Loss: 0.7036\n",
            "Epoch 3, Sample 12096: Loss: 0.6990\n",
            "Epoch 3, Sample 12097: Loss: 0.7036\n",
            "Epoch 3, Sample 12098: Loss: 0.0108\n",
            "Epoch 3, Sample 12099: Loss: 0.0815\n",
            "Epoch 3, Sample 12100: Loss: 0.0087\n",
            "Epoch 3, Sample 12101: Loss: 0.2036\n",
            "Epoch 3, Sample 12102: Loss: 0.2044\n",
            "Epoch 3, Sample 12103: Loss: 0.3441\n",
            "Epoch 3, Sample 12104: Loss: 0.2032\n",
            "Epoch 3, Sample 12105: Loss: 0.4362\n",
            "Epoch 3, Sample 12106: Loss: 1.0530\n",
            "Epoch 3, Sample 12107: Loss: 0.0063\n",
            "Epoch 3, Sample 12108: Loss: 0.1397\n",
            "Epoch 3, Sample 12109: Loss: 0.0116\n",
            "Epoch 3, Sample 12110: Loss: 0.3024\n",
            "Epoch 3, Sample 12111: Loss: 0.1559\n",
            "Epoch 3, Sample 12112: Loss: 0.4767\n",
            "Epoch 3, Sample 12113: Loss: 1.0524\n",
            "Epoch 3, Sample 12114: Loss: 0.7036\n",
            "Epoch 3, Sample 12115: Loss: 2.0233\n",
            "Epoch 3, Sample 12116: Loss: 0.6050\n",
            "Epoch 3, Sample 12117: Loss: 0.5972\n",
            "Epoch 3, Sample 12118: Loss: 3.7333\n",
            "Epoch 3, Sample 12119: Loss: 0.6995\n",
            "Epoch 3, Sample 12120: Loss: 0.3399\n",
            "Epoch 3, Sample 12121: Loss: 0.5196\n",
            "Epoch 3, Sample 12122: Loss: 0.2832\n",
            "Epoch 3, Sample 12123: Loss: 0.6990\n",
            "Epoch 3, Sample 12124: Loss: 0.1056\n",
            "Epoch 3, Sample 12125: Loss: 0.0145\n",
            "Epoch 3, Sample 12126: Loss: 0.0018\n",
            "Epoch 3, Sample 12127: Loss: 0.1250\n",
            "Epoch 3, Sample 12128: Loss: 0.2044\n",
            "Epoch 3, Sample 12129: Loss: 1.0530\n",
            "Epoch 3, Sample 12130: Loss: 0.0630\n",
            "Epoch 3, Sample 12131: Loss: 0.8951\n",
            "Epoch 3, Sample 12132: Loss: 0.0097\n",
            "Epoch 3, Sample 12133: Loss: 1.8256\n",
            "Epoch 3, Sample 12134: Loss: 0.2034\n",
            "Epoch 3, Sample 12135: Loss: 0.2044\n",
            "Epoch 3, Sample 12136: Loss: 0.2269\n",
            "Epoch 3, Sample 12137: Loss: 0.2759\n",
            "Epoch 3, Sample 12138: Loss: 0.1822\n",
            "Epoch 3, Sample 12139: Loss: 0.2759\n",
            "Epoch 3, Sample 12140: Loss: 0.2044\n",
            "Epoch 3, Sample 12141: Loss: 0.0144\n",
            "Epoch 3, Sample 12142: Loss: 0.1010\n",
            "Epoch 3, Sample 12143: Loss: 1.0155\n",
            "Epoch 3, Sample 12144: Loss: 0.2759\n",
            "Epoch 3, Sample 12145: Loss: 0.3402\n",
            "Epoch 3, Sample 12146: Loss: 0.5062\n",
            "Epoch 3, Sample 12147: Loss: 0.1170\n",
            "Epoch 3, Sample 12148: Loss: 0.3556\n",
            "Epoch 3, Sample 12149: Loss: 0.0626\n",
            "Epoch 3, Sample 12150: Loss: 0.1559\n",
            "Epoch 3, Sample 12151: Loss: 0.0843\n",
            "Epoch 3, Sample 12152: Loss: 0.1835\n",
            "Epoch 3, Sample 12153: Loss: 0.1250\n",
            "Epoch 3, Sample 12154: Loss: 0.5701\n",
            "Epoch 3, Sample 12155: Loss: 0.2044\n",
            "Epoch 3, Sample 12156: Loss: 0.1170\n",
            "Epoch 3, Sample 12157: Loss: 1.0530\n",
            "Epoch 3, Sample 12158: Loss: 0.0819\n",
            "Epoch 3, Sample 12159: Loss: 0.2044\n",
            "Epoch 3, Sample 12160: Loss: 0.2044\n",
            "Epoch 3, Sample 12161: Loss: 0.3399\n",
            "Epoch 3, Sample 12162: Loss: 0.0206\n",
            "Epoch 3, Sample 12163: Loss: 0.0018\n",
            "Epoch 3, Sample 12164: Loss: 0.3399\n",
            "Epoch 3, Sample 12165: Loss: 0.0104\n",
            "Epoch 3, Sample 12166: Loss: 0.5039\n",
            "Epoch 3, Sample 12167: Loss: 0.3948\n",
            "Epoch 3, Sample 12168: Loss: 1.9627\n",
            "Epoch 3, Sample 12169: Loss: 0.0212\n",
            "Epoch 3, Sample 12170: Loss: 0.7036\n",
            "Epoch 3, Sample 12171: Loss: 0.3399\n",
            "Epoch 3, Sample 12172: Loss: 0.2044\n",
            "Epoch 3, Sample 12173: Loss: 0.0013\n",
            "Epoch 3, Sample 12174: Loss: 0.1170\n",
            "Epoch 3, Sample 12175: Loss: 0.7036\n",
            "Epoch 3, Sample 12176: Loss: 0.0830\n",
            "Epoch 3, Sample 12177: Loss: 1.0524\n",
            "Epoch 3, Sample 12178: Loss: 0.0026\n",
            "Epoch 3, Sample 12179: Loss: 0.9492\n",
            "Epoch 3, Sample 12180: Loss: 0.7036\n",
            "Epoch 3, Sample 12181: Loss: 1.0524\n",
            "Epoch 3, Sample 12182: Loss: 0.0838\n",
            "Epoch 3, Sample 12183: Loss: 0.7036\n",
            "Epoch 3, Sample 12184: Loss: 0.7036\n",
            "Epoch 3, Sample 12185: Loss: 0.0034\n",
            "Epoch 3, Sample 12186: Loss: 0.4514\n",
            "Epoch 3, Sample 12187: Loss: 0.0126\n",
            "Epoch 3, Sample 12188: Loss: 0.2036\n",
            "Epoch 3, Sample 12189: Loss: 1.0524\n",
            "Epoch 3, Sample 12190: Loss: 0.0838\n",
            "Epoch 3, Sample 12191: Loss: 0.1662\n",
            "Epoch 3, Sample 12192: Loss: 0.2962\n",
            "Epoch 3, Sample 12193: Loss: 0.0744\n",
            "Epoch 3, Sample 12194: Loss: 0.0026\n",
            "Epoch 3, Sample 12195: Loss: 0.3399\n",
            "Epoch 3, Sample 12196: Loss: 0.3402\n",
            "Epoch 3, Sample 12197: Loss: 0.3441\n",
            "Epoch 3, Sample 12198: Loss: 2.1965\n",
            "Epoch 3, Sample 12199: Loss: 0.0018\n",
            "Epoch 3, Sample 12200: Loss: 0.1150\n",
            "Epoch 3, Sample 12201: Loss: 2.1057\n",
            "Epoch 3, Sample 12202: Loss: 0.1559\n",
            "Epoch 3, Sample 12203: Loss: 0.2219\n",
            "Epoch 3, Sample 12204: Loss: 0.2044\n",
            "Epoch 3, Sample 12205: Loss: 0.2759\n",
            "Epoch 3, Sample 12206: Loss: 0.5858\n",
            "Epoch 3, Sample 12207: Loss: 1.8643\n",
            "Epoch 3, Sample 12208: Loss: 0.0026\n",
            "Epoch 3, Sample 12209: Loss: 0.3075\n",
            "Epoch 3, Sample 12210: Loss: 0.1248\n",
            "Epoch 3, Sample 12211: Loss: 0.0030\n",
            "Epoch 3, Sample 12212: Loss: 0.0108\n",
            "Epoch 3, Sample 12213: Loss: 0.9473\n",
            "Epoch 3, Sample 12214: Loss: 0.5858\n",
            "Epoch 3, Sample 12215: Loss: 0.3399\n",
            "Epoch 3, Sample 12216: Loss: 0.0108\n",
            "Epoch 3, Sample 12217: Loss: 0.0026\n",
            "Epoch 3, Sample 12218: Loss: 0.3441\n",
            "Epoch 3, Sample 12219: Loss: 1.0524\n",
            "Epoch 3, Sample 12220: Loss: 0.6990\n",
            "Epoch 3, Sample 12221: Loss: 0.2044\n",
            "Epoch 3, Sample 12222: Loss: 1.5924\n",
            "Epoch 3, Sample 12223: Loss: 0.0306\n",
            "Epoch 3, Sample 12224: Loss: 0.2340\n",
            "Epoch 3, Sample 12225: Loss: 0.2034\n",
            "Epoch 3, Sample 12226: Loss: 1.0551\n",
            "Epoch 3, Sample 12227: Loss: 0.3868\n",
            "Epoch 3, Sample 12228: Loss: 0.2219\n",
            "Epoch 3, Sample 12229: Loss: 0.7075\n",
            "Epoch 3, Sample 12230: Loss: 0.1774\n",
            "Epoch 3, Sample 12231: Loss: 0.4761\n",
            "Epoch 3, Sample 12232: Loss: 0.0505\n",
            "Epoch 3, Sample 12233: Loss: 0.0000\n",
            "Epoch 3, Sample 12234: Loss: 0.2832\n",
            "Epoch 3, Sample 12235: Loss: 0.9367\n",
            "Epoch 3, Sample 12236: Loss: 0.0934\n",
            "Epoch 3, Sample 12237: Loss: 0.1276\n",
            "Epoch 3, Sample 12238: Loss: 0.0238\n",
            "Epoch 3, Sample 12239: Loss: 0.3441\n",
            "Epoch 3, Sample 12240: Loss: 0.0390\n",
            "Epoch 3, Sample 12241: Loss: 3.9629\n",
            "Epoch 3, Sample 12242: Loss: 0.6867\n",
            "Epoch 3, Sample 12243: Loss: 0.2332\n",
            "Epoch 3, Sample 12244: Loss: 0.2044\n",
            "Epoch 3, Sample 12245: Loss: 1.0155\n",
            "Epoch 3, Sample 12246: Loss: 0.0075\n",
            "Epoch 3, Sample 12247: Loss: 0.6641\n",
            "Epoch 3, Sample 12248: Loss: 0.3441\n",
            "Epoch 3, Sample 12249: Loss: 0.2112\n",
            "Epoch 3, Sample 12250: Loss: 0.7036\n",
            "Epoch 3, Sample 12251: Loss: 0.0145\n",
            "Epoch 3, Sample 12252: Loss: 0.0067\n",
            "Epoch 3, Sample 12253: Loss: 1.0524\n",
            "Epoch 3, Sample 12254: Loss: 0.0303\n",
            "Epoch 3, Sample 12255: Loss: 0.2832\n",
            "Epoch 3, Sample 12256: Loss: 2.4541\n",
            "Epoch 3, Sample 12257: Loss: 0.2032\n",
            "Epoch 3, Sample 12258: Loss: 1.0524\n",
            "Epoch 3, Sample 12259: Loss: 0.2036\n",
            "Epoch 3, Sample 12260: Loss: 0.3621\n",
            "Epoch 3, Sample 12261: Loss: 0.8951\n",
            "Epoch 3, Sample 12262: Loss: 0.5972\n",
            "Epoch 3, Sample 12263: Loss: 0.0630\n",
            "Epoch 3, Sample 12264: Loss: 0.1252\n",
            "Epoch 3, Sample 12265: Loss: 1.0019\n",
            "Epoch 3, Sample 12266: Loss: 0.4930\n",
            "Epoch 3, Sample 12267: Loss: 3.9348\n",
            "Epoch 3, Sample 12268: Loss: 0.2044\n",
            "Epoch 3, Sample 12269: Loss: 0.1170\n",
            "Epoch 3, Sample 12270: Loss: 1.0524\n",
            "Epoch 3, Sample 12271: Loss: 1.1887\n",
            "Epoch 3, Sample 12272: Loss: 1.0524\n",
            "Epoch 3, Sample 12273: Loss: 0.1254\n",
            "Epoch 3, Sample 12274: Loss: 0.0955\n",
            "Epoch 3, Sample 12275: Loss: 0.0626\n",
            "Epoch 3, Sample 12276: Loss: 1.9821\n",
            "Epoch 3, Sample 12277: Loss: 0.8484\n",
            "Epoch 3, Sample 12278: Loss: 1.0524\n",
            "Epoch 3, Sample 12279: Loss: 2.4557\n",
            "Epoch 3, Sample 12280: Loss: 0.0270\n",
            "Epoch 3, Sample 12281: Loss: 0.2032\n",
            "Epoch 3, Sample 12282: Loss: 0.0076\n",
            "Epoch 3, Sample 12283: Loss: 0.3421\n",
            "Epoch 3, Sample 12284: Loss: 0.5972\n",
            "Epoch 3, Sample 12285: Loss: 1.0155\n",
            "Epoch 3, Sample 12286: Loss: 0.2729\n",
            "Epoch 3, Sample 12287: Loss: 0.2759\n",
            "Epoch 3, Sample 12288: Loss: 0.5647\n",
            "Epoch 3, Sample 12289: Loss: 0.0026\n",
            "Epoch 3, Sample 12290: Loss: 0.0082\n",
            "Epoch 3, Sample 12291: Loss: 0.3441\n",
            "Epoch 3, Sample 12292: Loss: 0.1273\n",
            "Epoch 3, Sample 12293: Loss: 0.7036\n",
            "Epoch 3, Sample 12294: Loss: 0.5582\n",
            "Epoch 3, Sample 12295: Loss: 0.0046\n",
            "Epoch 3, Sample 12296: Loss: 0.4952\n",
            "Epoch 3, Sample 12297: Loss: 0.0002\n",
            "Epoch 3, Sample 12298: Loss: 1.0524\n",
            "Epoch 3, Sample 12299: Loss: 0.1204\n",
            "Epoch 3, Sample 12300: Loss: 0.2682\n",
            "Epoch 3, Sample 12301: Loss: 0.1113\n",
            "Epoch 3, Sample 12302: Loss: 0.4799\n",
            "Epoch 3, Sample 12303: Loss: 0.5000\n",
            "Epoch 3, Sample 12304: Loss: 0.5858\n",
            "Epoch 3, Sample 12305: Loss: 0.2938\n",
            "Epoch 3, Sample 12306: Loss: 0.0630\n",
            "Epoch 3, Sample 12307: Loss: 0.0094\n",
            "Epoch 3, Sample 12308: Loss: 0.0194\n",
            "Epoch 3, Sample 12309: Loss: 1.0530\n",
            "Epoch 3, Sample 12310: Loss: 0.7036\n",
            "Epoch 3, Sample 12311: Loss: 0.1170\n",
            "Epoch 3, Sample 12312: Loss: 0.3339\n",
            "Epoch 3, Sample 12313: Loss: 0.3399\n",
            "Epoch 3, Sample 12314: Loss: 0.8220\n",
            "Epoch 3, Sample 12315: Loss: 0.1170\n",
            "Epoch 3, Sample 12316: Loss: 0.0591\n",
            "Epoch 3, Sample 12317: Loss: 0.2044\n",
            "Epoch 3, Sample 12318: Loss: 0.0675\n",
            "Epoch 3, Sample 12319: Loss: 0.6990\n",
            "Epoch 3, Sample 12320: Loss: 0.2032\n",
            "Epoch 3, Sample 12321: Loss: 0.5062\n",
            "Epoch 3, Sample 12322: Loss: 1.0524\n",
            "Epoch 3, Sample 12323: Loss: 0.2962\n",
            "Epoch 3, Sample 12324: Loss: 1.0524\n",
            "Epoch 3, Sample 12325: Loss: 1.0524\n",
            "Epoch 3, Sample 12326: Loss: 0.6565\n",
            "Epoch 3, Sample 12327: Loss: 1.0530\n",
            "Epoch 3, Sample 12328: Loss: 0.1372\n",
            "Epoch 3, Sample 12329: Loss: 0.1559\n",
            "Epoch 3, Sample 12330: Loss: 0.0005\n",
            "Epoch 3, Sample 12331: Loss: 0.0031\n",
            "Epoch 3, Sample 12332: Loss: 1.5612\n",
            "Epoch 3, Sample 12333: Loss: 0.9024\n",
            "Epoch 3, Sample 12334: Loss: 0.0751\n",
            "Epoch 3, Sample 12335: Loss: 0.1874\n",
            "Epoch 3, Sample 12336: Loss: 0.1039\n",
            "Epoch 3, Sample 12337: Loss: 0.5595\n",
            "Epoch 3, Sample 12338: Loss: 1.0307\n",
            "Epoch 3, Sample 12339: Loss: 0.6867\n",
            "Epoch 3, Sample 12340: Loss: 0.3949\n",
            "Epoch 3, Sample 12341: Loss: 0.0026\n",
            "Epoch 3, Sample 12342: Loss: 1.0155\n",
            "Epoch 3, Sample 12343: Loss: 15.0890\n",
            "Epoch 3, Sample 12344: Loss: 0.7036\n",
            "Epoch 3, Sample 12345: Loss: 0.0001\n",
            "Epoch 3, Sample 12346: Loss: 0.4930\n",
            "Epoch 3, Sample 12347: Loss: 0.7036\n",
            "Epoch 3, Sample 12348: Loss: 0.5196\n",
            "Epoch 3, Sample 12349: Loss: 0.2036\n",
            "Epoch 3, Sample 12350: Loss: 0.0487\n",
            "Epoch 3, Sample 12351: Loss: 1.0155\n",
            "Epoch 3, Sample 12352: Loss: 0.1463\n",
            "Epoch 3, Sample 12353: Loss: 0.6092\n",
            "Epoch 3, Sample 12354: Loss: 1.8764\n",
            "Epoch 3, Sample 12355: Loss: 0.0062\n",
            "Epoch 3, Sample 12356: Loss: 0.2832\n",
            "Epoch 3, Sample 12357: Loss: 0.5858\n",
            "Epoch 3, Sample 12358: Loss: 0.3949\n",
            "Epoch 3, Sample 12359: Loss: 0.0415\n",
            "Epoch 3, Sample 12360: Loss: 2.6540\n",
            "Epoch 3, Sample 12361: Loss: 0.1466\n",
            "Epoch 3, Sample 12362: Loss: 0.7036\n",
            "Epoch 3, Sample 12363: Loss: 0.0630\n",
            "Epoch 3, Sample 12364: Loss: 1.0266\n",
            "Epoch 3, Sample 12365: Loss: 0.5242\n",
            "Epoch 3, Sample 12366: Loss: 0.3402\n",
            "Epoch 3, Sample 12367: Loss: 0.6737\n",
            "Epoch 3, Sample 12368: Loss: 1.0954\n",
            "Epoch 3, Sample 12369: Loss: 1.0524\n",
            "Epoch 3, Sample 12370: Loss: 1.0155\n",
            "Epoch 3, Sample 12371: Loss: 0.1478\n",
            "Epoch 3, Sample 12372: Loss: 0.3399\n",
            "Epoch 3, Sample 12373: Loss: 0.4038\n",
            "Epoch 3, Sample 12374: Loss: 0.1508\n",
            "Epoch 3, Sample 12375: Loss: 0.0306\n",
            "Epoch 3, Sample 12376: Loss: 0.2034\n",
            "Epoch 3, Sample 12377: Loss: 0.2044\n",
            "Epoch 3, Sample 12378: Loss: 0.8484\n",
            "Epoch 3, Sample 12379: Loss: 7.6710\n",
            "Epoch 3, Sample 12380: Loss: 0.0026\n",
            "Epoch 3, Sample 12381: Loss: 0.2034\n",
            "Epoch 3, Sample 12382: Loss: 0.4606\n",
            "Epoch 3, Sample 12383: Loss: 0.0450\n",
            "Epoch 3, Sample 12384: Loss: 0.0013\n",
            "Epoch 3, Sample 12385: Loss: 1.7437\n",
            "Epoch 3, Sample 12386: Loss: 1.8542\n",
            "Epoch 3, Sample 12387: Loss: 0.7036\n",
            "Epoch 3, Sample 12388: Loss: 0.5972\n",
            "Epoch 3, Sample 12389: Loss: 0.4799\n",
            "Epoch 3, Sample 12390: Loss: 0.0018\n",
            "Epoch 3, Sample 12391: Loss: 0.3441\n",
            "Epoch 3, Sample 12392: Loss: 0.7036\n",
            "Epoch 3, Sample 12393: Loss: 0.4856\n",
            "Epoch 3, Sample 12394: Loss: 0.1955\n",
            "Epoch 3, Sample 12395: Loss: 1.0524\n",
            "Epoch 3, Sample 12396: Loss: 0.4841\n",
            "Epoch 3, Sample 12397: Loss: 0.2204\n",
            "Epoch 3, Sample 12398: Loss: 0.2759\n",
            "Epoch 3, Sample 12399: Loss: 0.0940\n",
            "Epoch 3, Sample 12400: Loss: 1.0155\n",
            "Epoch 3, Sample 12401: Loss: 0.2941\n",
            "Epoch 3, Sample 12402: Loss: 0.7702\n",
            "Epoch 3, Sample 12403: Loss: 0.0026\n",
            "Epoch 3, Sample 12404: Loss: 0.2989\n",
            "Epoch 3, Sample 12405: Loss: 0.1170\n",
            "Epoch 3, Sample 12406: Loss: 0.0860\n",
            "Epoch 3, Sample 12407: Loss: 1.0524\n",
            "Epoch 3, Sample 12408: Loss: 0.1588\n",
            "Epoch 3, Sample 12409: Loss: 0.0026\n",
            "Epoch 3, Sample 12410: Loss: 1.7195\n",
            "Epoch 3, Sample 12411: Loss: 0.0360\n",
            "Epoch 3, Sample 12412: Loss: 0.0009\n",
            "Epoch 3, Sample 12413: Loss: 1.0524\n",
            "Epoch 3, Sample 12414: Loss: 0.0018\n",
            "Epoch 3, Sample 12415: Loss: 1.0060\n",
            "Epoch 3, Sample 12416: Loss: 0.0629\n",
            "Epoch 3, Sample 12417: Loss: 0.5858\n",
            "Epoch 3, Sample 12418: Loss: 1.0530\n",
            "Epoch 3, Sample 12419: Loss: 0.4466\n",
            "Epoch 3, Sample 12420: Loss: 0.0915\n",
            "Epoch 3, Sample 12421: Loss: 1.2198\n",
            "Epoch 3, Sample 12422: Loss: 0.2699\n",
            "Epoch 3, Sample 12423: Loss: 0.1559\n",
            "Epoch 3, Sample 12424: Loss: 0.7036\n",
            "Epoch 3, Sample 12425: Loss: 0.1102\n",
            "Epoch 3, Sample 12426: Loss: 0.3555\n",
            "Epoch 3, Sample 12427: Loss: 0.0630\n",
            "Epoch 3, Sample 12428: Loss: 0.1372\n",
            "Epoch 3, Sample 12429: Loss: 0.2034\n",
            "Epoch 3, Sample 12430: Loss: 0.5972\n",
            "Epoch 3, Sample 12431: Loss: 0.0010\n",
            "Epoch 3, Sample 12432: Loss: 1.1925\n",
            "Epoch 3, Sample 12433: Loss: 0.8503\n",
            "Epoch 3, Sample 12434: Loss: 0.7036\n",
            "Epoch 3, Sample 12435: Loss: 0.4841\n",
            "Epoch 3, Sample 12436: Loss: 0.1559\n",
            "Epoch 3, Sample 12437: Loss: 0.2032\n",
            "Epoch 3, Sample 12438: Loss: 0.0026\n",
            "Epoch 3, Sample 12439: Loss: 0.0186\n",
            "Epoch 3, Sample 12440: Loss: 1.0155\n",
            "Epoch 3, Sample 12441: Loss: 1.0524\n",
            "Epoch 3, Sample 12442: Loss: 0.0011\n",
            "Epoch 3, Sample 12443: Loss: 0.0513\n",
            "Epoch 3, Sample 12444: Loss: 1.3389\n",
            "Epoch 3, Sample 12445: Loss: 0.3539\n",
            "Epoch 3, Sample 12446: Loss: 0.5003\n",
            "Epoch 3, Sample 12447: Loss: 0.7482\n",
            "Epoch 3, Sample 12448: Loss: 0.0147\n",
            "Epoch 3, Sample 12449: Loss: 1.0524\n",
            "Epoch 3, Sample 12450: Loss: 0.4032\n",
            "Epoch 3, Sample 12451: Loss: 0.0063\n",
            "Epoch 3, Sample 12452: Loss: 0.3949\n",
            "Epoch 3, Sample 12453: Loss: 0.8951\n",
            "Epoch 3, Sample 12454: Loss: 4.0002\n",
            "Epoch 3, Sample 12455: Loss: 0.5897\n",
            "Epoch 3, Sample 12456: Loss: 0.0005\n",
            "Epoch 3, Sample 12457: Loss: 0.0161\n",
            "Epoch 3, Sample 12458: Loss: 0.7036\n",
            "Epoch 3, Sample 12459: Loss: 0.8951\n",
            "Epoch 3, Sample 12460: Loss: 0.3949\n",
            "Epoch 3, Sample 12461: Loss: 0.3355\n",
            "Epoch 3, Sample 12462: Loss: 0.5972\n",
            "Epoch 3, Sample 12463: Loss: 0.5000\n",
            "Epoch 3, Sample 12464: Loss: 0.2438\n",
            "Epoch 3, Sample 12465: Loss: 0.6304\n",
            "Epoch 3, Sample 12466: Loss: 0.0205\n",
            "Epoch 3, Sample 12467: Loss: 0.2219\n",
            "Epoch 3, Sample 12468: Loss: 0.7147\n",
            "Epoch 3, Sample 12469: Loss: 0.0075\n",
            "Epoch 3, Sample 12470: Loss: 0.2034\n",
            "Epoch 3, Sample 12471: Loss: 0.6867\n",
            "Epoch 3, Sample 12472: Loss: 0.2044\n",
            "Epoch 3, Sample 12473: Loss: 0.2036\n",
            "Epoch 3, Sample 12474: Loss: 0.0041\n",
            "Epoch 3, Sample 12475: Loss: 0.9367\n",
            "Epoch 3, Sample 12476: Loss: 0.7453\n",
            "Epoch 3, Sample 12477: Loss: 0.0364\n",
            "Epoch 3, Sample 12478: Loss: 0.2255\n",
            "Epoch 3, Sample 12479: Loss: 0.0744\n",
            "Epoch 3, Sample 12480: Loss: 0.2112\n",
            "Epoch 3, Sample 12481: Loss: 4.0162\n",
            "Epoch 3, Sample 12482: Loss: 0.4367\n",
            "Epoch 3, Sample 12483: Loss: 0.2036\n",
            "Epoch 3, Sample 12484: Loss: 0.3402\n",
            "Epoch 3, Sample 12485: Loss: 0.0685\n",
            "Epoch 3, Sample 12486: Loss: 0.4906\n",
            "Epoch 3, Sample 12487: Loss: 0.5555\n",
            "Epoch 3, Sample 12488: Loss: 0.0560\n",
            "Epoch 3, Sample 12489: Loss: 0.0320\n",
            "Epoch 3, Sample 12490: Loss: 0.7036\n",
            "Epoch 3, Sample 12491: Loss: 0.0108\n",
            "Epoch 3, Sample 12492: Loss: 0.7036\n",
            "Epoch 3, Sample 12493: Loss: 0.2044\n",
            "Epoch 3, Sample 12494: Loss: 1.0530\n",
            "Epoch 3, Sample 12495: Loss: 0.2759\n",
            "Epoch 3, Sample 12496: Loss: 0.3357\n",
            "Epoch 3, Sample 12497: Loss: 0.1170\n",
            "Epoch 3, Sample 12498: Loss: 0.2034\n",
            "Epoch 3, Sample 12499: Loss: 0.7036\n",
            "Epoch 3, Sample 12500: Loss: 0.0026\n",
            "Epoch 3, Sample 12501: Loss: 0.0018\n",
            "Epoch 3, Sample 12502: Loss: 0.6957\n",
            "Epoch 3, Sample 12503: Loss: 0.1594\n",
            "Epoch 3, Sample 12504: Loss: 0.1937\n",
            "Epoch 3, Sample 12505: Loss: 0.0108\n",
            "Epoch 3, Sample 12506: Loss: 0.1219\n",
            "Epoch 3, Sample 12507: Loss: 0.0026\n",
            "Epoch 3, Sample 12508: Loss: 0.2941\n",
            "Epoch 3, Sample 12509: Loss: 0.2044\n",
            "Epoch 3, Sample 12510: Loss: 0.4611\n",
            "Epoch 3, Sample 12511: Loss: 0.2340\n",
            "Epoch 3, Sample 12512: Loss: 0.1114\n",
            "Epoch 3, Sample 12513: Loss: 0.1056\n",
            "Epoch 3, Sample 12514: Loss: 0.7036\n",
            "Epoch 3, Sample 12515: Loss: 1.0524\n",
            "Epoch 3, Sample 12516: Loss: 0.0026\n",
            "Epoch 3, Sample 12517: Loss: 0.0543\n",
            "Epoch 3, Sample 12518: Loss: 0.0471\n",
            "Epoch 3, Sample 12519: Loss: 0.1077\n",
            "Epoch 3, Sample 12520: Loss: 0.0497\n",
            "Epoch 3, Sample 12521: Loss: 0.0013\n",
            "Epoch 3, Sample 12522: Loss: 0.0031\n",
            "Epoch 3, Sample 12523: Loss: 0.0430\n",
            "Epoch 3, Sample 12524: Loss: 0.3399\n",
            "Epoch 3, Sample 12525: Loss: 0.9367\n",
            "Epoch 3, Sample 12526: Loss: 0.3212\n",
            "Epoch 3, Sample 12527: Loss: 1.0524\n",
            "Epoch 3, Sample 12528: Loss: 0.3399\n",
            "Epoch 3, Sample 12529: Loss: 8.2351\n",
            "Epoch 3, Sample 12530: Loss: 0.2363\n",
            "Epoch 3, Sample 12531: Loss: 0.3876\n",
            "Epoch 3, Sample 12532: Loss: 0.0212\n",
            "Epoch 3, Sample 12533: Loss: 0.0027\n",
            "Epoch 3, Sample 12534: Loss: 1.0155\n",
            "Epoch 3, Sample 12535: Loss: 0.8770\n",
            "Epoch 3, Sample 12536: Loss: 0.3539\n",
            "Epoch 3, Sample 12537: Loss: 0.3402\n",
            "Epoch 3, Sample 12538: Loss: 0.8951\n",
            "Epoch 3, Sample 12539: Loss: 0.7475\n",
            "Epoch 3, Sample 12540: Loss: 0.2855\n",
            "Epoch 3, Sample 12541: Loss: 0.2044\n",
            "Epoch 3, Sample 12542: Loss: 0.1250\n",
            "Epoch 3, Sample 12543: Loss: 0.0938\n",
            "Epoch 3, Sample 12544: Loss: 0.7036\n",
            "Epoch 3, Sample 12545: Loss: 1.0524\n",
            "Epoch 3, Sample 12546: Loss: 1.2926\n",
            "Epoch 3, Sample 12547: Loss: 0.0938\n",
            "Epoch 3, Sample 12548: Loss: 0.1355\n",
            "Epoch 3, Sample 12549: Loss: 0.1607\n",
            "Epoch 3, Sample 12550: Loss: 0.0000\n",
            "Epoch 3, Sample 12551: Loss: 2.0233\n",
            "Epoch 3, Sample 12552: Loss: 0.0013\n",
            "Epoch 3, Sample 12553: Loss: 0.2044\n",
            "Epoch 3, Sample 12554: Loss: 0.2325\n",
            "Epoch 3, Sample 12555: Loss: 0.0067\n",
            "Epoch 3, Sample 12556: Loss: 0.0026\n",
            "Epoch 3, Sample 12557: Loss: 0.1233\n",
            "Epoch 3, Sample 12558: Loss: 0.1250\n",
            "Epoch 3, Sample 12559: Loss: 0.6628\n",
            "Epoch 3, Sample 12560: Loss: 0.1826\n",
            "Epoch 3, Sample 12561: Loss: 0.1250\n",
            "Epoch 3, Sample 12562: Loss: 0.2457\n",
            "Epoch 3, Sample 12563: Loss: 1.6382\n",
            "Epoch 3, Sample 12564: Loss: 0.0484\n",
            "Epoch 3, Sample 12565: Loss: 0.1713\n",
            "Epoch 3, Sample 12566: Loss: 0.0274\n",
            "Epoch 3, Sample 12567: Loss: 0.1508\n",
            "Epoch 3, Sample 12568: Loss: 0.7036\n",
            "Epoch 3, Sample 12569: Loss: 0.2569\n",
            "Epoch 3, Sample 12570: Loss: 0.0108\n",
            "Epoch 3, Sample 12571: Loss: 0.0007\n",
            "Epoch 3, Sample 12572: Loss: 0.0106\n",
            "Epoch 3, Sample 12573: Loss: 0.0360\n",
            "Epoch 3, Sample 12574: Loss: 2.5325\n",
            "Epoch 3, Sample 12575: Loss: 0.2034\n",
            "Epoch 3, Sample 12576: Loss: 0.0709\n",
            "Epoch 3, Sample 12577: Loss: 0.0466\n",
            "Epoch 3, Sample 12578: Loss: 1.1405\n",
            "Epoch 3, Sample 12579: Loss: 0.0205\n",
            "Epoch 3, Sample 12580: Loss: 0.0108\n",
            "Epoch 3, Sample 12581: Loss: 0.2989\n",
            "Epoch 3, Sample 12582: Loss: 0.0063\n",
            "Epoch 3, Sample 12583: Loss: 1.0524\n",
            "Epoch 3, Sample 12584: Loss: 0.0026\n",
            "Epoch 3, Sample 12585: Loss: 0.5245\n",
            "Epoch 3, Sample 12586: Loss: 0.2711\n",
            "Epoch 3, Sample 12587: Loss: 0.6178\n",
            "Epoch 3, Sample 12588: Loss: 1.0524\n",
            "Epoch 3, Sample 12589: Loss: 0.0062\n",
            "Epoch 3, Sample 12590: Loss: 0.2327\n",
            "Epoch 3, Sample 12591: Loss: 0.0630\n",
            "Epoch 3, Sample 12592: Loss: 0.5946\n",
            "Epoch 3, Sample 12593: Loss: 0.1405\n",
            "Epoch 3, Sample 12594: Loss: 0.9367\n",
            "Epoch 3, Sample 12595: Loss: 0.1085\n",
            "Epoch 3, Sample 12596: Loss: 0.2034\n",
            "Epoch 3, Sample 12597: Loss: 2.4326\n",
            "Epoch 3, Sample 12598: Loss: 0.2759\n",
            "Epoch 3, Sample 12599: Loss: 0.7453\n",
            "Epoch 3, Sample 12600: Loss: 0.8259\n",
            "Epoch 3, Sample 12601: Loss: 0.0022\n",
            "Epoch 3, Sample 12602: Loss: 1.0524\n",
            "Epoch 3, Sample 12603: Loss: 11.6217\n",
            "Epoch 3, Sample 12604: Loss: 0.0026\n",
            "Epoch 3, Sample 12605: Loss: 0.7036\n",
            "Epoch 3, Sample 12606: Loss: 0.0370\n",
            "Epoch 3, Sample 12607: Loss: 0.1271\n",
            "Epoch 3, Sample 12608: Loss: 0.1225\n",
            "Epoch 3, Sample 12609: Loss: 0.9733\n",
            "Epoch 3, Sample 12610: Loss: 0.3699\n",
            "Epoch 3, Sample 12611: Loss: 0.0205\n",
            "Epoch 3, Sample 12612: Loss: 0.2034\n",
            "Epoch 3, Sample 12613: Loss: 0.0025\n",
            "Epoch 3, Sample 12614: Loss: 0.0604\n",
            "Epoch 3, Sample 12615: Loss: 0.0167\n",
            "Epoch 3, Sample 12616: Loss: 2.2949\n",
            "Epoch 3, Sample 12617: Loss: 0.2044\n",
            "Epoch 3, Sample 12618: Loss: 0.2811\n",
            "Epoch 3, Sample 12619: Loss: 0.1170\n",
            "Epoch 3, Sample 12620: Loss: 0.2759\n",
            "Epoch 3, Sample 12621: Loss: 0.2044\n",
            "Epoch 3, Sample 12622: Loss: 0.5858\n",
            "Epoch 3, Sample 12623: Loss: 0.0306\n",
            "Epoch 3, Sample 12624: Loss: 0.8323\n",
            "Epoch 3, Sample 12625: Loss: 0.2962\n",
            "Epoch 3, Sample 12626: Loss: 0.3441\n",
            "Epoch 3, Sample 12627: Loss: 0.0258\n",
            "Epoch 3, Sample 12628: Loss: 0.1549\n",
            "Epoch 3, Sample 12629: Loss: 0.5646\n",
            "Epoch 3, Sample 12630: Loss: 0.0001\n",
            "Epoch 3, Sample 12631: Loss: 0.9367\n",
            "Epoch 3, Sample 12632: Loss: 0.2034\n",
            "Epoch 3, Sample 12633: Loss: 0.0099\n",
            "Epoch 3, Sample 12634: Loss: 0.0363\n",
            "Epoch 3, Sample 12635: Loss: 0.1523\n",
            "Epoch 3, Sample 12636: Loss: 0.0513\n",
            "Epoch 3, Sample 12637: Loss: 0.1417\n",
            "Epoch 3, Sample 12638: Loss: 0.2044\n",
            "Epoch 3, Sample 12639: Loss: 0.0630\n",
            "Epoch 3, Sample 12640: Loss: 0.0063\n",
            "Epoch 3, Sample 12641: Loss: 0.0030\n",
            "Epoch 3, Sample 12642: Loss: 0.1777\n",
            "Epoch 3, Sample 12643: Loss: 0.2782\n",
            "Epoch 3, Sample 12644: Loss: 1.0524\n",
            "Epoch 3, Sample 12645: Loss: 0.3568\n",
            "Epoch 3, Sample 12646: Loss: 0.7453\n",
            "Epoch 3, Sample 12647: Loss: 0.0062\n",
            "Epoch 3, Sample 12648: Loss: 0.1798\n",
            "Epoch 3, Sample 12649: Loss: 0.0630\n",
            "Epoch 3, Sample 12650: Loss: 0.4611\n",
            "Epoch 3, Sample 12651: Loss: 0.1692\n",
            "Epoch 3, Sample 12652: Loss: 0.2044\n",
            "Epoch 3, Sample 12653: Loss: 0.1244\n",
            "Epoch 3, Sample 12654: Loss: 1.0155\n",
            "Epoch 3, Sample 12655: Loss: 2.7138\n",
            "Epoch 3, Sample 12656: Loss: 1.0504\n",
            "Epoch 3, Sample 12657: Loss: 0.3441\n",
            "Epoch 3, Sample 12658: Loss: 0.4841\n",
            "Epoch 3, Sample 12659: Loss: 0.1546\n",
            "Epoch 3, Sample 12660: Loss: 0.4930\n",
            "Epoch 3, Sample 12661: Loss: 0.0018\n",
            "Epoch 3, Sample 12662: Loss: 0.8931\n",
            "Epoch 3, Sample 12663: Loss: 0.0212\n",
            "Epoch 3, Sample 12664: Loss: 0.1546\n",
            "Epoch 3, Sample 12665: Loss: 0.3399\n",
            "Epoch 3, Sample 12666: Loss: 0.2044\n",
            "Epoch 3, Sample 12667: Loss: 1.0530\n",
            "Epoch 3, Sample 12668: Loss: 0.0084\n",
            "Epoch 3, Sample 12669: Loss: 0.0018\n",
            "Epoch 3, Sample 12670: Loss: 0.0028\n",
            "Epoch 3, Sample 12671: Loss: 0.5858\n",
            "Epoch 3, Sample 12672: Loss: 0.3177\n",
            "Epoch 3, Sample 12673: Loss: 0.7453\n",
            "Epoch 3, Sample 12674: Loss: 0.0001\n",
            "Epoch 3, Sample 12675: Loss: 0.5799\n",
            "Epoch 3, Sample 12676: Loss: 0.2118\n",
            "Epoch 3, Sample 12677: Loss: 1.0837\n",
            "Epoch 3, Sample 12678: Loss: 0.3399\n",
            "Epoch 3, Sample 12679: Loss: 0.2032\n",
            "Epoch 3, Sample 12680: Loss: 3.7306\n",
            "Epoch 3, Sample 12681: Loss: 1.0524\n",
            "Epoch 3, Sample 12682: Loss: 0.3441\n",
            "Epoch 3, Sample 12683: Loss: 0.1863\n",
            "Epoch 3, Sample 12684: Loss: 0.0840\n",
            "Epoch 3, Sample 12685: Loss: 0.1555\n",
            "Epoch 3, Sample 12686: Loss: 9.0373\n",
            "Epoch 3, Sample 12687: Loss: 0.1732\n",
            "Epoch 3, Sample 12688: Loss: 0.2032\n",
            "Epoch 3, Sample 12689: Loss: 1.0524\n",
            "Epoch 3, Sample 12690: Loss: 0.2032\n",
            "Epoch 3, Sample 12691: Loss: 0.0287\n",
            "Epoch 3, Sample 12692: Loss: 0.0234\n",
            "Epoch 3, Sample 12693: Loss: 0.2219\n",
            "Epoch 3, Sample 12694: Loss: 0.2962\n",
            "Epoch 3, Sample 12695: Loss: 0.9367\n",
            "Epoch 3, Sample 12696: Loss: 0.5858\n",
            "Epoch 3, Sample 12697: Loss: 0.2044\n",
            "Epoch 3, Sample 12698: Loss: 6.8938\n",
            "Epoch 3, Sample 12699: Loss: 0.4799\n",
            "Epoch 3, Sample 12700: Loss: 0.2036\n",
            "Epoch 3, Sample 12701: Loss: 0.1055\n",
            "Epoch 3, Sample 12702: Loss: 8.2156\n",
            "Epoch 3, Sample 12703: Loss: 2.2955\n",
            "Epoch 3, Sample 12704: Loss: 1.0530\n",
            "Epoch 3, Sample 12705: Loss: 0.0119\n",
            "Epoch 3, Sample 12706: Loss: 0.2832\n",
            "Epoch 3, Sample 12707: Loss: 0.8951\n",
            "Epoch 3, Sample 12708: Loss: 0.1890\n",
            "Epoch 3, Sample 12709: Loss: 0.1394\n",
            "Epoch 3, Sample 12710: Loss: 0.2034\n",
            "Epoch 3, Sample 12711: Loss: 0.0630\n",
            "Epoch 3, Sample 12712: Loss: 0.2935\n",
            "Epoch 3, Sample 12713: Loss: 0.1163\n",
            "Epoch 3, Sample 12714: Loss: 0.0018\n",
            "Epoch 3, Sample 12715: Loss: 0.2044\n",
            "Epoch 3, Sample 12716: Loss: 0.0026\n",
            "Epoch 3, Sample 12717: Loss: 0.6990\n",
            "Epoch 3, Sample 12718: Loss: 1.0524\n",
            "Epoch 3, Sample 12719: Loss: 0.7702\n",
            "Epoch 3, Sample 12720: Loss: 0.0002\n",
            "Epoch 3, Sample 12721: Loss: 1.9711\n",
            "Epoch 3, Sample 12722: Loss: 0.4220\n",
            "Epoch 3, Sample 12723: Loss: 0.2750\n",
            "Epoch 3, Sample 12724: Loss: 0.5019\n",
            "Epoch 3, Sample 12725: Loss: 0.7036\n",
            "Epoch 3, Sample 12726: Loss: 0.7453\n",
            "Epoch 3, Sample 12727: Loss: 0.0685\n",
            "Epoch 3, Sample 12728: Loss: 0.2173\n",
            "Epoch 3, Sample 12729: Loss: 1.0155\n",
            "Epoch 3, Sample 12730: Loss: 1.0155\n",
            "Epoch 3, Sample 12731: Loss: 0.3844\n",
            "Epoch 3, Sample 12732: Loss: 1.0276\n",
            "Epoch 3, Sample 12733: Loss: 0.0460\n",
            "Epoch 3, Sample 12734: Loss: 1.0214\n",
            "Epoch 3, Sample 12735: Loss: 0.0558\n",
            "Epoch 3, Sample 12736: Loss: 1.0956\n",
            "Epoch 3, Sample 12737: Loss: 0.4707\n",
            "Epoch 3, Sample 12738: Loss: 0.9432\n",
            "Epoch 3, Sample 12739: Loss: 0.2987\n",
            "Epoch 3, Sample 12740: Loss: 2.4176\n",
            "Epoch 3, Sample 12741: Loss: 0.2832\n",
            "Epoch 3, Sample 12742: Loss: 0.2639\n",
            "Epoch 3, Sample 12743: Loss: 0.0027\n",
            "Epoch 3, Sample 12744: Loss: 1.0524\n",
            "Epoch 3, Sample 12745: Loss: 0.0014\n",
            "Epoch 3, Sample 12746: Loss: 0.0026\n",
            "Epoch 3, Sample 12747: Loss: 0.7060\n",
            "Epoch 3, Sample 12748: Loss: 0.0731\n",
            "Epoch 3, Sample 12749: Loss: 0.0018\n",
            "Epoch 3, Sample 12750: Loss: 1.0155\n",
            "Epoch 3, Sample 12751: Loss: 0.5858\n",
            "Epoch 3, Sample 12752: Loss: 0.1079\n",
            "Epoch 3, Sample 12753: Loss: 1.3918\n",
            "Epoch 3, Sample 12754: Loss: 4.4025\n",
            "Epoch 3, Sample 12755: Loss: 0.3399\n",
            "Epoch 3, Sample 12756: Loss: 0.1040\n",
            "Epoch 3, Sample 12757: Loss: 0.0590\n",
            "Epoch 3, Sample 12758: Loss: 1.0511\n",
            "Epoch 3, Sample 12759: Loss: 0.1337\n",
            "Epoch 3, Sample 12760: Loss: 0.1170\n",
            "Epoch 3, Sample 12761: Loss: 0.2112\n",
            "Epoch 3, Sample 12762: Loss: 1.1003\n",
            "Epoch 3, Sample 12763: Loss: 0.2132\n",
            "Epoch 3, Sample 12764: Loss: 0.2034\n",
            "Epoch 3, Sample 12765: Loss: 1.9658\n",
            "Epoch 3, Sample 12766: Loss: 0.1499\n",
            "Epoch 3, Sample 12767: Loss: 7.1041\n",
            "Epoch 3, Sample 12768: Loss: 0.2044\n",
            "Epoch 3, Sample 12769: Loss: 0.0205\n",
            "Epoch 3, Sample 12770: Loss: 0.0274\n",
            "Epoch 3, Sample 12771: Loss: 1.0155\n",
            "Epoch 3, Sample 12772: Loss: 0.0008\n",
            "Epoch 3, Sample 12773: Loss: 0.3399\n",
            "Epoch 3, Sample 12774: Loss: 0.9755\n",
            "Epoch 3, Sample 12775: Loss: 0.2036\n",
            "Epoch 3, Sample 12776: Loss: 0.6304\n",
            "Epoch 3, Sample 12777: Loss: 1.0530\n",
            "Epoch 3, Sample 12778: Loss: 0.7508\n",
            "Epoch 3, Sample 12779: Loss: 2.0863\n",
            "Epoch 3, Sample 12780: Loss: 0.2382\n",
            "Epoch 3, Sample 12781: Loss: 0.0915\n",
            "Epoch 3, Sample 12782: Loss: 1.0155\n",
            "Epoch 3, Sample 12783: Loss: 0.3568\n",
            "Epoch 3, Sample 12784: Loss: 0.2303\n",
            "Epoch 3, Sample 12785: Loss: 0.2175\n",
            "Epoch 3, Sample 12786: Loss: 0.2832\n",
            "Epoch 3, Sample 12787: Loss: 0.1030\n",
            "Epoch 3, Sample 12788: Loss: 0.7036\n",
            "Epoch 3, Sample 12789: Loss: 0.7036\n",
            "Epoch 3, Sample 12790: Loss: 1.0530\n",
            "Epoch 3, Sample 12791: Loss: 0.2204\n",
            "Epoch 3, Sample 12792: Loss: 0.9367\n",
            "Epoch 3, Sample 12793: Loss: 0.5196\n",
            "Epoch 3, Sample 12794: Loss: 0.2759\n",
            "Epoch 3, Sample 12795: Loss: 0.7036\n",
            "Epoch 3, Sample 12796: Loss: 0.0018\n",
            "Epoch 3, Sample 12797: Loss: 0.1264\n",
            "Epoch 3, Sample 12798: Loss: 0.2044\n",
            "Epoch 3, Sample 12799: Loss: 0.7036\n",
            "Epoch 3, Sample 12800: Loss: 0.2036\n",
            "Epoch 3, Sample 12801: Loss: 0.3402\n",
            "Epoch 3, Sample 12802: Loss: 0.3367\n",
            "Epoch 3, Sample 12803: Loss: 0.0067\n",
            "Epoch 3, Sample 12804: Loss: 0.2639\n",
            "Epoch 3, Sample 12805: Loss: 0.0680\n",
            "Epoch 3, Sample 12806: Loss: 0.0092\n",
            "Epoch 3, Sample 12807: Loss: 0.2032\n",
            "Epoch 3, Sample 12808: Loss: 0.2219\n",
            "Epoch 3, Sample 12809: Loss: 0.0805\n",
            "Epoch 3, Sample 12810: Loss: 0.5187\n",
            "Epoch 3, Sample 12811: Loss: 0.2034\n",
            "Epoch 3, Sample 12812: Loss: 0.5858\n",
            "Epoch 3, Sample 12813: Loss: 0.0005\n",
            "Epoch 3, Sample 12814: Loss: 0.4353\n",
            "Epoch 3, Sample 12815: Loss: 0.8951\n",
            "Epoch 3, Sample 12816: Loss: 0.4032\n",
            "Epoch 3, Sample 12817: Loss: 1.0155\n",
            "Epoch 3, Sample 12818: Loss: 0.0205\n",
            "Epoch 3, Sample 12819: Loss: 0.0108\n",
            "Epoch 3, Sample 12820: Loss: 0.2074\n",
            "Epoch 3, Sample 12821: Loss: 0.0032\n",
            "Epoch 3, Sample 12822: Loss: 0.2032\n",
            "Epoch 3, Sample 12823: Loss: 0.1199\n",
            "Epoch 3, Sample 12824: Loss: 0.1508\n",
            "Epoch 3, Sample 12825: Loss: 0.2995\n",
            "Epoch 3, Sample 12826: Loss: 0.2340\n",
            "Epoch 3, Sample 12827: Loss: 0.2032\n",
            "Epoch 3, Sample 12828: Loss: 0.2832\n",
            "Epoch 3, Sample 12829: Loss: 0.5858\n",
            "Epoch 3, Sample 12830: Loss: 0.0026\n",
            "Epoch 3, Sample 12831: Loss: 0.5461\n",
            "Epoch 3, Sample 12832: Loss: 0.0182\n",
            "Epoch 3, Sample 12833: Loss: 0.0031\n",
            "Epoch 3, Sample 12834: Loss: 0.0026\n",
            "Epoch 3, Sample 12835: Loss: 0.2290\n",
            "Epoch 3, Sample 12836: Loss: 0.0918\n",
            "Epoch 3, Sample 12837: Loss: 1.9331\n",
            "Epoch 3, Sample 12838: Loss: 0.0874\n",
            "Epoch 3, Sample 12839: Loss: 0.3945\n",
            "Epoch 3, Sample 12840: Loss: 0.2935\n",
            "Epoch 3, Sample 12841: Loss: 0.8891\n",
            "Epoch 3, Sample 12842: Loss: 0.0306\n",
            "Epoch 3, Sample 12843: Loss: 0.2032\n",
            "Epoch 3, Sample 12844: Loss: 0.0026\n",
            "Epoch 3, Sample 12845: Loss: 0.7036\n",
            "Epoch 3, Sample 12846: Loss: 0.5972\n",
            "Epoch 3, Sample 12847: Loss: 0.1559\n",
            "Epoch 3, Sample 12848: Loss: 0.0391\n",
            "Epoch 3, Sample 12849: Loss: 0.0915\n",
            "Epoch 3, Sample 12850: Loss: 0.4032\n",
            "Epoch 3, Sample 12851: Loss: 0.0306\n",
            "Epoch 3, Sample 12852: Loss: 3.3415\n",
            "Epoch 3, Sample 12853: Loss: 1.1893\n",
            "Epoch 3, Sample 12854: Loss: 0.2044\n",
            "Epoch 3, Sample 12855: Loss: 0.3441\n",
            "Epoch 3, Sample 12856: Loss: 0.2873\n",
            "Epoch 3, Sample 12857: Loss: 0.2032\n",
            "Epoch 3, Sample 12858: Loss: 0.4996\n",
            "Epoch 3, Sample 12859: Loss: 0.1252\n",
            "Epoch 3, Sample 12860: Loss: 0.0383\n",
            "Epoch 3, Sample 12861: Loss: 0.0002\n",
            "Epoch 3, Sample 12862: Loss: 0.8951\n",
            "Epoch 3, Sample 12863: Loss: 0.1250\n",
            "Epoch 3, Sample 12864: Loss: 0.0212\n",
            "Epoch 3, Sample 12865: Loss: 0.0680\n",
            "Epoch 3, Sample 12866: Loss: 0.0013\n",
            "Epoch 3, Sample 12867: Loss: 0.0662\n",
            "Epoch 3, Sample 12868: Loss: 0.2935\n",
            "Epoch 3, Sample 12869: Loss: 0.4565\n",
            "Epoch 3, Sample 12870: Loss: 0.8951\n",
            "Epoch 3, Sample 12871: Loss: 0.0205\n",
            "Epoch 3, Sample 12872: Loss: 0.8951\n",
            "Epoch 3, Sample 12873: Loss: 0.2032\n",
            "Epoch 3, Sample 12874: Loss: 0.1709\n",
            "Epoch 3, Sample 12875: Loss: 0.0108\n",
            "Epoch 3, Sample 12876: Loss: 0.3949\n",
            "Epoch 3, Sample 12877: Loss: 1.0449\n",
            "Epoch 3, Sample 12878: Loss: 1.3421\n",
            "Epoch 3, Sample 12879: Loss: 4.3825\n",
            "Epoch 3, Sample 12880: Loss: 0.7453\n",
            "Epoch 3, Sample 12881: Loss: 0.0965\n",
            "Epoch 3, Sample 12882: Loss: 0.4032\n",
            "Epoch 3, Sample 12883: Loss: 0.2034\n",
            "Epoch 3, Sample 12884: Loss: 0.9367\n",
            "Epoch 3, Sample 12885: Loss: 0.1022\n",
            "Epoch 3, Sample 12886: Loss: 0.2044\n",
            "Epoch 3, Sample 12887: Loss: 0.3661\n",
            "Epoch 3, Sample 12888: Loss: 0.7453\n",
            "Epoch 3, Sample 12889: Loss: 0.2832\n",
            "Epoch 3, Sample 12890: Loss: 0.0201\n",
            "Epoch 3, Sample 12891: Loss: 0.5858\n",
            "Epoch 3, Sample 12892: Loss: 0.5989\n",
            "Epoch 3, Sample 12893: Loss: 1.0524\n",
            "Epoch 3, Sample 12894: Loss: 0.0838\n",
            "Epoch 3, Sample 12895: Loss: 0.0419\n",
            "Epoch 3, Sample 12896: Loss: 0.2832\n",
            "Epoch 3, Sample 12897: Loss: 0.0011\n",
            "Epoch 3, Sample 12898: Loss: 0.0052\n",
            "Epoch 3, Sample 12899: Loss: 0.1786\n",
            "Epoch 3, Sample 12900: Loss: 1.0524\n",
            "Epoch 3, Sample 12901: Loss: 0.2573\n",
            "Epoch 3, Sample 12902: Loss: 0.1768\n",
            "Epoch 3, Sample 12903: Loss: 0.0049\n",
            "Epoch 3, Sample 12904: Loss: 0.1482\n",
            "Epoch 3, Sample 12905: Loss: 0.5972\n",
            "Epoch 3, Sample 12906: Loss: 1.0266\n",
            "Epoch 3, Sample 12907: Loss: 0.2576\n",
            "Epoch 3, Sample 12908: Loss: 0.0045\n",
            "Epoch 3, Sample 12909: Loss: 0.0001\n",
            "Epoch 3, Sample 12910: Loss: 0.0026\n",
            "Epoch 3, Sample 12911: Loss: 0.3288\n",
            "Epoch 3, Sample 12912: Loss: 0.1349\n",
            "Epoch 3, Sample 12913: Loss: 0.0183\n",
            "Epoch 3, Sample 12914: Loss: 0.2094\n",
            "Epoch 3, Sample 12915: Loss: 0.1508\n",
            "Epoch 3, Sample 12916: Loss: 0.7036\n",
            "Epoch 3, Sample 12917: Loss: 0.0018\n",
            "Epoch 3, Sample 12918: Loss: 0.0498\n",
            "Epoch 3, Sample 12919: Loss: 0.3247\n",
            "Epoch 3, Sample 12920: Loss: 0.5972\n",
            "Epoch 3, Sample 12921: Loss: 0.2219\n",
            "Epoch 3, Sample 12922: Loss: 0.0105\n",
            "Epoch 3, Sample 12923: Loss: 0.0993\n",
            "Epoch 3, Sample 12924: Loss: 0.0027\n",
            "Epoch 3, Sample 12925: Loss: 1.2047\n",
            "Epoch 3, Sample 12926: Loss: 0.2759\n",
            "Epoch 3, Sample 12927: Loss: 0.6304\n",
            "Epoch 3, Sample 12928: Loss: 0.0287\n",
            "Epoch 3, Sample 12929: Loss: 0.1170\n",
            "Epoch 3, Sample 12930: Loss: 0.1559\n",
            "Epoch 3, Sample 12931: Loss: 0.0006\n",
            "Epoch 3, Sample 12932: Loss: 0.0165\n",
            "Epoch 3, Sample 12933: Loss: 0.2034\n",
            "Epoch 3, Sample 12934: Loss: 1.0155\n",
            "Epoch 3, Sample 12935: Loss: 0.1356\n",
            "Epoch 3, Sample 12936: Loss: 0.2884\n",
            "Epoch 3, Sample 12937: Loss: 0.4522\n",
            "Epoch 3, Sample 12938: Loss: 0.0626\n",
            "Epoch 3, Sample 12939: Loss: 0.1559\n",
            "Epoch 3, Sample 12940: Loss: 0.4607\n",
            "Epoch 3, Sample 12941: Loss: 0.1588\n",
            "Epoch 3, Sample 12942: Loss: 0.1523\n",
            "Epoch 3, Sample 12943: Loss: 0.4799\n",
            "Epoch 3, Sample 12944: Loss: 0.3067\n",
            "Epoch 3, Sample 12945: Loss: 0.0972\n",
            "Epoch 3, Sample 12946: Loss: 0.0326\n",
            "Epoch 3, Sample 12947: Loss: 0.2182\n",
            "Epoch 3, Sample 12948: Loss: 0.4611\n",
            "Epoch 3, Sample 12949: Loss: 0.0108\n",
            "Epoch 3, Sample 12950: Loss: 0.0018\n",
            "Epoch 3, Sample 12951: Loss: 0.0915\n",
            "Epoch 3, Sample 12952: Loss: 0.5858\n",
            "Epoch 3, Sample 12953: Loss: 1.2637\n",
            "Epoch 3, Sample 12954: Loss: 1.0155\n",
            "Epoch 3, Sample 12955: Loss: 0.4177\n",
            "Epoch 3, Sample 12956: Loss: 0.9078\n",
            "Epoch 3, Sample 12957: Loss: 0.0228\n",
            "Epoch 3, Sample 12958: Loss: 0.3441\n",
            "Epoch 3, Sample 12959: Loss: 0.0018\n",
            "Epoch 3, Sample 12960: Loss: 0.2032\n",
            "Epoch 3, Sample 12961: Loss: 0.8951\n",
            "Epoch 3, Sample 12962: Loss: 0.0270\n",
            "Epoch 3, Sample 12963: Loss: 8.1744\n",
            "Epoch 3, Sample 12964: Loss: 0.2142\n",
            "Epoch 3, Sample 12965: Loss: 0.2044\n",
            "Epoch 3, Sample 12966: Loss: 2.6860\n",
            "Epoch 3, Sample 12967: Loss: 0.1248\n",
            "Epoch 3, Sample 12968: Loss: 0.1250\n",
            "Epoch 3, Sample 12969: Loss: 0.0363\n",
            "Epoch 3, Sample 12970: Loss: 0.2032\n",
            "Epoch 3, Sample 12971: Loss: 1.5969\n",
            "Epoch 3, Sample 12972: Loss: 0.2044\n",
            "Epoch 3, Sample 12973: Loss: 0.5858\n",
            "Epoch 3, Sample 12974: Loss: 0.0598\n",
            "Epoch 3, Sample 12975: Loss: 0.4611\n",
            "Epoch 3, Sample 12976: Loss: 0.0287\n",
            "Epoch 3, Sample 12977: Loss: 1.0524\n",
            "Epoch 3, Sample 12978: Loss: 0.2750\n",
            "Epoch 3, Sample 12979: Loss: 0.1170\n",
            "Epoch 3, Sample 12980: Loss: 0.2044\n",
            "Epoch 3, Sample 12981: Loss: 0.6990\n",
            "Epoch 3, Sample 12982: Loss: 0.2778\n",
            "Epoch 3, Sample 12983: Loss: 0.5972\n",
            "Epoch 3, Sample 12984: Loss: 1.0524\n",
            "Epoch 3, Sample 12985: Loss: 0.1250\n",
            "Epoch 3, Sample 12986: Loss: 0.0076\n",
            "Epoch 3, Sample 12987: Loss: 0.0005\n",
            "Epoch 3, Sample 12988: Loss: 0.1687\n",
            "Epoch 3, Sample 12989: Loss: 0.2759\n",
            "Epoch 3, Sample 12990: Loss: 0.6720\n",
            "Epoch 3, Sample 12991: Loss: 0.1250\n",
            "Epoch 3, Sample 12992: Loss: 0.3399\n",
            "Epoch 3, Sample 12993: Loss: 0.0178\n",
            "Epoch 3, Sample 12994: Loss: 0.1764\n",
            "Epoch 3, Sample 12995: Loss: 0.0640\n",
            "Epoch 3, Sample 12996: Loss: 0.7036\n",
            "Epoch 3, Sample 12997: Loss: 0.0026\n",
            "Epoch 3, Sample 12998: Loss: 1.0524\n",
            "Epoch 3, Sample 12999: Loss: 0.0062\n",
            "Epoch 3, Sample 13000: Loss: 0.1559\n",
            "Epoch 3, Sample 13001: Loss: 0.2044\n",
            "Epoch 3, Sample 13002: Loss: 0.6536\n",
            "Epoch 3, Sample 13003: Loss: 1.0155\n",
            "Epoch 3, Sample 13004: Loss: 2.0123\n",
            "Epoch 3, Sample 13005: Loss: 0.0026\n",
            "Epoch 3, Sample 13006: Loss: 0.0026\n",
            "Epoch 3, Sample 13007: Loss: 0.2262\n",
            "Epoch 3, Sample 13008: Loss: 0.2686\n",
            "Epoch 3, Sample 13009: Loss: 1.0524\n",
            "Epoch 3, Sample 13010: Loss: 0.1523\n",
            "Epoch 3, Sample 13011: Loss: 0.0067\n",
            "Epoch 3, Sample 13012: Loss: 0.0069\n",
            "Epoch 3, Sample 13013: Loss: 1.0524\n",
            "Epoch 3, Sample 13014: Loss: 0.2034\n",
            "Epoch 3, Sample 13015: Loss: 0.3399\n",
            "Epoch 3, Sample 13016: Loss: 0.2036\n",
            "Epoch 3, Sample 13017: Loss: 0.0947\n",
            "Epoch 3, Sample 13018: Loss: 1.0524\n",
            "Epoch 3, Sample 13019: Loss: 2.0388\n",
            "Epoch 3, Sample 13020: Loss: 0.0921\n",
            "Epoch 3, Sample 13021: Loss: 2.0233\n",
            "Epoch 3, Sample 13022: Loss: 0.2044\n",
            "Epoch 3, Sample 13023: Loss: 0.2044\n",
            "Epoch 3, Sample 13024: Loss: 0.3477\n",
            "Epoch 3, Sample 13025: Loss: 0.4136\n",
            "Epoch 3, Sample 13026: Loss: 0.5871\n",
            "Epoch 3, Sample 13027: Loss: 1.0155\n",
            "Epoch 3, Sample 13028: Loss: 0.0455\n",
            "Epoch 3, Sample 13029: Loss: 1.0155\n",
            "Epoch 3, Sample 13030: Loss: 0.0455\n",
            "Epoch 3, Sample 13031: Loss: 1.0530\n",
            "Epoch 3, Sample 13032: Loss: 0.7910\n",
            "Epoch 3, Sample 13033: Loss: 1.3738\n",
            "Epoch 3, Sample 13034: Loss: 0.3399\n",
            "Epoch 3, Sample 13035: Loss: 0.3399\n",
            "Epoch 3, Sample 13036: Loss: 0.5858\n",
            "Epoch 3, Sample 13037: Loss: 0.3805\n",
            "Epoch 3, Sample 13038: Loss: 0.3949\n",
            "Epoch 3, Sample 13039: Loss: 0.7036\n",
            "Epoch 3, Sample 13040: Loss: 0.2034\n",
            "Epoch 3, Sample 13041: Loss: 0.4845\n",
            "Epoch 3, Sample 13042: Loss: 1.0524\n",
            "Epoch 3, Sample 13043: Loss: 0.7475\n",
            "Epoch 3, Sample 13044: Loss: 0.1210\n",
            "Epoch 3, Sample 13045: Loss: 0.5871\n",
            "Epoch 3, Sample 13046: Loss: 1.8614\n",
            "Epoch 3, Sample 13047: Loss: 0.0806\n",
            "Epoch 3, Sample 13048: Loss: 0.0630\n",
            "Epoch 3, Sample 13049: Loss: 0.0391\n",
            "Epoch 3, Sample 13050: Loss: 0.2036\n",
            "Epoch 3, Sample 13051: Loss: 0.0000\n",
            "Epoch 3, Sample 13052: Loss: 0.0002\n",
            "Epoch 3, Sample 13053: Loss: 0.2034\n",
            "Epoch 3, Sample 13054: Loss: 0.2832\n",
            "Epoch 3, Sample 13055: Loss: 0.0733\n",
            "Epoch 3, Sample 13056: Loss: 0.1170\n",
            "Epoch 3, Sample 13057: Loss: 0.3441\n",
            "Epoch 3, Sample 13058: Loss: 0.0454\n",
            "Epoch 3, Sample 13059: Loss: 0.7036\n",
            "Epoch 3, Sample 13060: Loss: 0.2759\n",
            "Epoch 3, Sample 13061: Loss: 0.5858\n",
            "Epoch 3, Sample 13062: Loss: 1.0155\n",
            "Epoch 3, Sample 13063: Loss: 0.3949\n",
            "Epoch 3, Sample 13064: Loss: 1.0524\n",
            "Epoch 3, Sample 13065: Loss: 0.5310\n",
            "Epoch 3, Sample 13066: Loss: 0.6058\n",
            "Epoch 3, Sample 13067: Loss: 0.0630\n",
            "Epoch 3, Sample 13068: Loss: 0.3949\n",
            "Epoch 3, Sample 13069: Loss: 0.7036\n",
            "Epoch 3, Sample 13070: Loss: 0.2034\n",
            "Epoch 3, Sample 13071: Loss: 0.0001\n",
            "Epoch 3, Sample 13072: Loss: 0.3399\n",
            "Epoch 3, Sample 13073: Loss: 0.0000\n",
            "Epoch 3, Sample 13074: Loss: 1.0524\n",
            "Epoch 3, Sample 13075: Loss: 0.0205\n",
            "Epoch 3, Sample 13076: Loss: 0.2034\n",
            "Epoch 3, Sample 13077: Loss: 0.7036\n",
            "Epoch 3, Sample 13078: Loss: 0.3450\n",
            "Epoch 3, Sample 13079: Loss: 0.5000\n",
            "Epoch 3, Sample 13080: Loss: 0.6092\n",
            "Epoch 3, Sample 13081: Loss: 1.1522\n",
            "Epoch 3, Sample 13082: Loss: 0.0013\n",
            "Epoch 3, Sample 13083: Loss: 0.6990\n",
            "Epoch 3, Sample 13084: Loss: 0.2044\n",
            "Epoch 3, Sample 13085: Loss: 0.2959\n",
            "Epoch 3, Sample 13086: Loss: 0.5062\n",
            "Epoch 3, Sample 13087: Loss: 0.9651\n",
            "Epoch 3, Sample 13088: Loss: 0.6990\n",
            "Epoch 3, Sample 13089: Loss: 0.7453\n",
            "Epoch 3, Sample 13090: Loss: 0.8636\n",
            "Epoch 3, Sample 13091: Loss: 0.2586\n",
            "Epoch 3, Sample 13092: Loss: 0.1250\n",
            "Epoch 3, Sample 13093: Loss: 0.3399\n",
            "Epoch 3, Sample 13094: Loss: 0.0630\n",
            "Epoch 3, Sample 13095: Loss: 0.2114\n",
            "Epoch 3, Sample 13096: Loss: 0.6867\n",
            "Epoch 3, Sample 13097: Loss: 0.0108\n",
            "Epoch 3, Sample 13098: Loss: 0.5871\n",
            "Epoch 3, Sample 13099: Loss: 0.5416\n",
            "Epoch 3, Sample 13100: Loss: 2.0986\n",
            "Epoch 3, Sample 13101: Loss: 0.3111\n",
            "Epoch 3, Sample 13102: Loss: 0.5871\n",
            "Epoch 3, Sample 13103: Loss: 1.0530\n",
            "Epoch 3, Sample 13104: Loss: 0.0108\n",
            "Epoch 3, Sample 13105: Loss: 0.2044\n",
            "Epoch 3, Sample 13106: Loss: 0.1250\n",
            "Epoch 3, Sample 13107: Loss: 0.2034\n",
            "Epoch 3, Sample 13108: Loss: 0.7036\n",
            "Epoch 3, Sample 13109: Loss: 0.1674\n",
            "Epoch 3, Sample 13110: Loss: 0.5754\n",
            "Epoch 3, Sample 13111: Loss: 0.8862\n",
            "Epoch 3, Sample 13112: Loss: 0.4930\n",
            "Epoch 3, Sample 13113: Loss: 0.0707\n",
            "Epoch 3, Sample 13114: Loss: 0.6981\n",
            "Epoch 3, Sample 13115: Loss: 0.0915\n",
            "Epoch 3, Sample 13116: Loss: 0.0234\n",
            "Epoch 3, Sample 13117: Loss: 0.6990\n",
            "Epoch 3, Sample 13118: Loss: 1.0530\n",
            "Epoch 3, Sample 13119: Loss: 1.6238\n",
            "Epoch 3, Sample 13120: Loss: 0.7989\n",
            "Epoch 3, Sample 13121: Loss: 0.2044\n",
            "Epoch 3, Sample 13122: Loss: 0.7075\n",
            "Epoch 3, Sample 13123: Loss: 0.7453\n",
            "Epoch 3, Sample 13124: Loss: 0.1588\n",
            "Epoch 3, Sample 13125: Loss: 0.1170\n",
            "Epoch 3, Sample 13126: Loss: 0.1114\n",
            "Epoch 3, Sample 13127: Loss: 0.4230\n",
            "Epoch 3, Sample 13128: Loss: 0.2034\n",
            "Epoch 3, Sample 13129: Loss: 0.2034\n",
            "Epoch 3, Sample 13130: Loss: 0.4032\n",
            "Epoch 3, Sample 13131: Loss: 1.0524\n",
            "Epoch 3, Sample 13132: Loss: 0.0270\n",
            "Epoch 3, Sample 13133: Loss: 0.0026\n",
            "Epoch 3, Sample 13134: Loss: 2.9895\n",
            "Epoch 3, Sample 13135: Loss: 0.1537\n",
            "Epoch 3, Sample 13136: Loss: 0.1222\n",
            "Epoch 3, Sample 13137: Loss: 0.2639\n",
            "Epoch 3, Sample 13138: Loss: 0.3399\n",
            "Epoch 3, Sample 13139: Loss: 0.0768\n",
            "Epoch 3, Sample 13140: Loss: 0.0498\n",
            "Epoch 3, Sample 13141: Loss: 0.7453\n",
            "Epoch 3, Sample 13142: Loss: 0.0117\n",
            "Epoch 3, Sample 13143: Loss: 0.0027\n",
            "Epoch 3, Sample 13144: Loss: 0.2494\n",
            "Epoch 3, Sample 13145: Loss: 0.2044\n",
            "Epoch 3, Sample 13146: Loss: 0.1372\n",
            "Epoch 3, Sample 13147: Loss: 0.0022\n",
            "Epoch 3, Sample 13148: Loss: 0.5858\n",
            "Epoch 3, Sample 13149: Loss: 1.0155\n",
            "Epoch 3, Sample 13150: Loss: 0.0018\n",
            "Epoch 3, Sample 13151: Loss: 0.3399\n",
            "Epoch 3, Sample 13152: Loss: 0.0001\n",
            "Epoch 3, Sample 13153: Loss: 0.0001\n",
            "Epoch 3, Sample 13154: Loss: 0.0000\n",
            "Epoch 3, Sample 13155: Loss: 0.8951\n",
            "Epoch 3, Sample 13156: Loss: 3.0370\n",
            "Epoch 3, Sample 13157: Loss: 0.1640\n",
            "Epoch 3, Sample 13158: Loss: 0.0063\n",
            "Epoch 3, Sample 13159: Loss: 0.0046\n",
            "Epoch 3, Sample 13160: Loss: 0.2759\n",
            "Epoch 3, Sample 13161: Loss: 0.0771\n",
            "Epoch 3, Sample 13162: Loss: 0.0110\n",
            "Epoch 3, Sample 13163: Loss: 1.8616\n",
            "Epoch 3, Sample 13164: Loss: 0.2036\n",
            "Epoch 3, Sample 13165: Loss: 0.0047\n",
            "Epoch 3, Sample 13166: Loss: 0.0303\n",
            "Epoch 3, Sample 13167: Loss: 0.1555\n",
            "Epoch 3, Sample 13168: Loss: 0.2126\n",
            "Epoch 3, Sample 13169: Loss: 0.1625\n",
            "Epoch 3, Sample 13170: Loss: 0.3539\n",
            "Epoch 3, Sample 13171: Loss: 0.7036\n",
            "Epoch 3, Sample 13172: Loss: 0.0031\n",
            "Epoch 3, Sample 13173: Loss: 0.0205\n",
            "Epoch 3, Sample 13174: Loss: 0.6141\n",
            "Epoch 3, Sample 13175: Loss: 0.1170\n",
            "Epoch 3, Sample 13176: Loss: 1.0155\n",
            "Epoch 3, Sample 13177: Loss: 0.3402\n",
            "Epoch 3, Sample 13178: Loss: 8.0265\n",
            "Epoch 3, Sample 13179: Loss: 0.0625\n",
            "Epoch 3, Sample 13180: Loss: 0.1170\n",
            "Epoch 3, Sample 13181: Loss: 0.0026\n",
            "Epoch 3, Sample 13182: Loss: 0.1838\n",
            "Epoch 3, Sample 13183: Loss: 0.6990\n",
            "Epoch 3, Sample 13184: Loss: 0.3441\n",
            "Epoch 3, Sample 13185: Loss: 0.0026\n",
            "Epoch 3, Sample 13186: Loss: 0.2160\n",
            "Epoch 3, Sample 13187: Loss: 0.9175\n",
            "Epoch 3, Sample 13188: Loss: 0.0438\n",
            "Epoch 3, Sample 13189: Loss: 0.7036\n",
            "Epoch 3, Sample 13190: Loss: 1.0524\n",
            "Epoch 3, Sample 13191: Loss: 0.0117\n",
            "Epoch 3, Sample 13192: Loss: 0.0006\n",
            "Epoch 3, Sample 13193: Loss: 1.0530\n",
            "Epoch 3, Sample 13194: Loss: 1.0530\n",
            "Epoch 3, Sample 13195: Loss: 0.5000\n",
            "Epoch 3, Sample 13196: Loss: 0.4523\n",
            "Epoch 3, Sample 13197: Loss: 0.4607\n",
            "Epoch 3, Sample 13198: Loss: 0.3591\n",
            "Epoch 3, Sample 13199: Loss: 1.0524\n",
            "Epoch 3, Sample 13200: Loss: 0.0062\n",
            "Epoch 3, Sample 13201: Loss: 1.0530\n",
            "Epoch 3, Sample 13202: Loss: 0.2832\n",
            "Epoch 3, Sample 13203: Loss: 0.0630\n",
            "Epoch 3, Sample 13204: Loss: 0.0912\n",
            "Epoch 3, Sample 13205: Loss: 0.1838\n",
            "Epoch 3, Sample 13206: Loss: 0.3568\n",
            "Epoch 3, Sample 13207: Loss: 0.0072\n",
            "Epoch 3, Sample 13208: Loss: 0.2044\n",
            "Epoch 3, Sample 13209: Loss: 0.2032\n",
            "Epoch 3, Sample 13210: Loss: 2.0532\n",
            "Epoch 3, Sample 13211: Loss: 0.1291\n",
            "Epoch 3, Sample 13212: Loss: 0.0582\n",
            "Epoch 3, Sample 13213: Loss: 0.2675\n",
            "Epoch 3, Sample 13214: Loss: 1.0155\n",
            "Epoch 3, Sample 13215: Loss: 1.3842\n",
            "Epoch 3, Sample 13216: Loss: 0.0387\n",
            "Epoch 3, Sample 13217: Loss: 0.2151\n",
            "Epoch 3, Sample 13218: Loss: 0.7453\n",
            "Epoch 3, Sample 13219: Loss: 0.0034\n",
            "Epoch 3, Sample 13220: Loss: 0.0026\n",
            "Epoch 3, Sample 13221: Loss: 1.0524\n",
            "Epoch 3, Sample 13222: Loss: 5.9530\n",
            "Epoch 3, Sample 13223: Loss: 0.2219\n",
            "Epoch 3, Sample 13224: Loss: 0.0026\n",
            "Epoch 3, Sample 13225: Loss: 0.0212\n",
            "Epoch 3, Sample 13226: Loss: 0.0026\n",
            "Epoch 3, Sample 13227: Loss: 0.7036\n",
            "Epoch 3, Sample 13228: Loss: 0.2012\n",
            "Epoch 3, Sample 13229: Loss: 0.3598\n",
            "Epoch 3, Sample 13230: Loss: 0.2109\n",
            "Epoch 3, Sample 13231: Loss: 0.2792\n",
            "Epoch 3, Sample 13232: Loss: 1.0155\n",
            "Epoch 3, Sample 13233: Loss: 0.0026\n",
            "Epoch 3, Sample 13234: Loss: 0.0001\n",
            "Epoch 3, Sample 13235: Loss: 0.2032\n",
            "Epoch 3, Sample 13236: Loss: 0.0915\n",
            "Epoch 3, Sample 13237: Loss: 0.6092\n",
            "Epoch 3, Sample 13238: Loss: 7.1546\n",
            "Epoch 3, Sample 13239: Loss: 0.1114\n",
            "Epoch 3, Sample 13240: Loss: 6.9441\n",
            "Epoch 3, Sample 13241: Loss: 0.0026\n",
            "Epoch 3, Sample 13242: Loss: 0.0018\n",
            "Epoch 3, Sample 13243: Loss: 0.2044\n",
            "Epoch 3, Sample 13244: Loss: 0.6238\n",
            "Epoch 3, Sample 13245: Loss: 0.3384\n",
            "Epoch 3, Sample 13246: Loss: 0.1559\n",
            "Epoch 3, Sample 13247: Loss: 0.1559\n",
            "Epoch 3, Sample 13248: Loss: 0.3332\n",
            "Epoch 3, Sample 13249: Loss: 0.1250\n",
            "Epoch 3, Sample 13250: Loss: 0.0001\n",
            "Epoch 3, Sample 13251: Loss: 1.0524\n",
            "Epoch 3, Sample 13252: Loss: 4.8352\n",
            "Epoch 3, Sample 13253: Loss: 0.4800\n",
            "Epoch 3, Sample 13254: Loss: 0.5463\n",
            "Epoch 3, Sample 13255: Loss: 0.3399\n",
            "Epoch 3, Sample 13256: Loss: 0.2483\n",
            "Epoch 3, Sample 13257: Loss: 0.2200\n",
            "Epoch 3, Sample 13258: Loss: 0.0915\n",
            "Epoch 3, Sample 13259: Loss: 0.4841\n",
            "Epoch 3, Sample 13260: Loss: 1.0524\n",
            "Epoch 3, Sample 13261: Loss: 0.0026\n",
            "Epoch 3, Sample 13262: Loss: 0.4032\n",
            "Epoch 3, Sample 13263: Loss: 0.3399\n",
            "Epoch 3, Sample 13264: Loss: 0.4611\n",
            "Epoch 3, Sample 13265: Loss: 0.0000\n",
            "Epoch 3, Sample 13266: Loss: 4.8523\n",
            "Epoch 3, Sample 13267: Loss: 0.1114\n",
            "Epoch 3, Sample 13268: Loss: 0.3450\n",
            "Epoch 3, Sample 13269: Loss: 0.5858\n",
            "Epoch 3, Sample 13270: Loss: 0.0000\n",
            "Epoch 3, Sample 13271: Loss: 0.2759\n",
            "Epoch 3, Sample 13272: Loss: 0.1404\n",
            "Epoch 3, Sample 13273: Loss: 0.2759\n",
            "Epoch 3, Sample 13274: Loss: 0.1559\n",
            "Epoch 3, Sample 13275: Loss: 1.0524\n",
            "Epoch 3, Sample 13276: Loss: 0.4867\n",
            "Epoch 3, Sample 13277: Loss: 0.0364\n",
            "Epoch 3, Sample 13278: Loss: 0.3450\n",
            "Epoch 3, Sample 13279: Loss: 1.1569\n",
            "Epoch 3, Sample 13280: Loss: 0.7051\n",
            "Epoch 3, Sample 13281: Loss: 1.0524\n",
            "Epoch 3, Sample 13282: Loss: 0.2759\n",
            "Epoch 3, Sample 13283: Loss: 0.3399\n",
            "Epoch 3, Sample 13284: Loss: 0.6139\n",
            "Epoch 3, Sample 13285: Loss: 1.0155\n",
            "Epoch 3, Sample 13286: Loss: 0.0486\n",
            "Epoch 3, Sample 13287: Loss: 0.3399\n",
            "Epoch 3, Sample 13288: Loss: 0.1687\n",
            "Epoch 3, Sample 13289: Loss: 0.0026\n",
            "Epoch 3, Sample 13290: Loss: 0.2219\n",
            "Epoch 3, Sample 13291: Loss: 1.0524\n",
            "Epoch 3, Sample 13292: Loss: 0.1250\n",
            "Epoch 3, Sample 13293: Loss: 0.2558\n",
            "Epoch 3, Sample 13294: Loss: 0.4906\n",
            "Epoch 3, Sample 13295: Loss: 0.5858\n",
            "Epoch 3, Sample 13296: Loss: 0.3399\n",
            "Epoch 3, Sample 13297: Loss: 0.0893\n",
            "Epoch 3, Sample 13298: Loss: 0.5858\n",
            "Epoch 3, Sample 13299: Loss: 0.0108\n",
            "Epoch 3, Sample 13300: Loss: 0.2639\n",
            "Epoch 3, Sample 13301: Loss: 0.2941\n",
            "Epoch 3, Sample 13302: Loss: 0.2044\n",
            "Epoch 3, Sample 13303: Loss: 0.0018\n",
            "Epoch 3, Sample 13304: Loss: 0.4799\n",
            "Epoch 3, Sample 13305: Loss: 0.1791\n",
            "Epoch 3, Sample 13306: Loss: 0.0936\n",
            "Epoch 3, Sample 13307: Loss: 0.0505\n",
            "Epoch 3, Sample 13308: Loss: 0.8951\n",
            "Epoch 3, Sample 13309: Loss: 1.2148\n",
            "Epoch 3, Sample 13310: Loss: 0.3267\n",
            "Epoch 3, Sample 13311: Loss: 1.0852\n",
            "Epoch 3, Sample 13312: Loss: 1.0070\n",
            "Epoch 3, Sample 13313: Loss: 0.2044\n",
            "Epoch 3, Sample 13314: Loss: 0.2044\n",
            "Epoch 3, Sample 13315: Loss: 0.2044\n",
            "Epoch 3, Sample 13316: Loss: 0.3166\n",
            "Epoch 3, Sample 13317: Loss: 2.6817\n",
            "Epoch 3, Sample 13318: Loss: 0.0001\n",
            "Epoch 3, Sample 13319: Loss: 0.4930\n",
            "Epoch 3, Sample 13320: Loss: 0.3040\n",
            "Epoch 3, Sample 13321: Loss: 0.3141\n",
            "Epoch 3, Sample 13322: Loss: 0.0630\n",
            "Epoch 3, Sample 13323: Loss: 9.0311\n",
            "Epoch 3, Sample 13324: Loss: 1.0524\n",
            "Epoch 3, Sample 13325: Loss: 0.7036\n",
            "Epoch 3, Sample 13326: Loss: 1.0857\n",
            "Epoch 3, Sample 13327: Loss: 0.3501\n",
            "Epoch 3, Sample 13328: Loss: 0.0205\n",
            "Epoch 3, Sample 13329: Loss: 0.2309\n",
            "Epoch 3, Sample 13330: Loss: 0.1035\n",
            "Epoch 3, Sample 13331: Loss: 6.5695\n",
            "Epoch 3, Sample 13332: Loss: 0.3949\n",
            "Epoch 3, Sample 13333: Loss: 0.2759\n",
            "Epoch 3, Sample 13334: Loss: 1.0530\n",
            "Epoch 3, Sample 13335: Loss: 0.0018\n",
            "Epoch 3, Sample 13336: Loss: 0.1246\n",
            "Epoch 3, Sample 13337: Loss: 0.8951\n",
            "Epoch 3, Sample 13338: Loss: 1.0155\n",
            "Epoch 3, Sample 13339: Loss: 0.0018\n",
            "Epoch 3, Sample 13340: Loss: 0.2034\n",
            "Epoch 3, Sample 13341: Loss: 0.2832\n",
            "Epoch 3, Sample 13342: Loss: 5.7645\n",
            "Epoch 3, Sample 13343: Loss: 0.6614\n",
            "Epoch 3, Sample 13344: Loss: 1.1034\n",
            "Epoch 3, Sample 13345: Loss: 1.0524\n",
            "Epoch 3, Sample 13346: Loss: 0.6990\n",
            "Epoch 3, Sample 13347: Loss: 5.0904\n",
            "Epoch 3, Sample 13348: Loss: 0.1692\n",
            "Epoch 3, Sample 13349: Loss: 0.4755\n",
            "Epoch 3, Sample 13350: Loss: 0.3441\n",
            "Epoch 3, Sample 13351: Loss: 0.3399\n",
            "Epoch 3, Sample 13352: Loss: 1.0530\n",
            "Epoch 3, Sample 13353: Loss: 0.2713\n",
            "Epoch 3, Sample 13354: Loss: 0.7917\n",
            "Epoch 3, Sample 13355: Loss: 2.9652\n",
            "Epoch 3, Sample 13356: Loss: 1.8545\n",
            "Epoch 3, Sample 13357: Loss: 0.0060\n",
            "Epoch 3, Sample 13358: Loss: 1.4172\n",
            "Epoch 3, Sample 13359: Loss: 0.2869\n",
            "Epoch 3, Sample 13360: Loss: 0.2036\n",
            "Epoch 3, Sample 13361: Loss: 0.5972\n",
            "Epoch 3, Sample 13362: Loss: 0.0018\n",
            "Epoch 3, Sample 13363: Loss: 0.0838\n",
            "Epoch 3, Sample 13364: Loss: 0.1170\n",
            "Epoch 3, Sample 13365: Loss: 0.5858\n",
            "Epoch 3, Sample 13366: Loss: 0.3441\n",
            "Epoch 3, Sample 13367: Loss: 1.0524\n",
            "Epoch 3, Sample 13368: Loss: 0.2759\n",
            "Epoch 3, Sample 13369: Loss: 0.0026\n",
            "Epoch 3, Sample 13370: Loss: 1.3250\n",
            "Epoch 3, Sample 13371: Loss: 1.6701\n",
            "Epoch 3, Sample 13372: Loss: 0.3441\n",
            "Epoch 3, Sample 13373: Loss: 0.0018\n",
            "Epoch 3, Sample 13374: Loss: 0.0630\n",
            "Epoch 3, Sample 13375: Loss: 0.2044\n",
            "Epoch 3, Sample 13376: Loss: 0.0212\n",
            "Epoch 3, Sample 13377: Loss: 0.0026\n",
            "Epoch 3, Sample 13378: Loss: 0.0539\n",
            "Epoch 3, Sample 13379: Loss: 0.3399\n",
            "Epoch 3, Sample 13380: Loss: 2.3213\n",
            "Epoch 3, Sample 13381: Loss: 0.4859\n",
            "Epoch 3, Sample 13382: Loss: 0.7036\n",
            "Epoch 3, Sample 13383: Loss: 0.2044\n",
            "Epoch 3, Sample 13384: Loss: 0.0168\n",
            "Epoch 3, Sample 13385: Loss: 0.4799\n",
            "Epoch 3, Sample 13386: Loss: 0.0132\n",
            "Epoch 3, Sample 13387: Loss: 0.0005\n",
            "Epoch 3, Sample 13388: Loss: 0.0025\n",
            "Epoch 3, Sample 13389: Loss: 0.0640\n",
            "Epoch 3, Sample 13390: Loss: 0.0148\n",
            "Epoch 3, Sample 13391: Loss: 0.3441\n",
            "Epoch 3, Sample 13392: Loss: 0.3399\n",
            "Epoch 3, Sample 13393: Loss: 0.7648\n",
            "Epoch 3, Sample 13394: Loss: 1.7932\n",
            "Epoch 3, Sample 13395: Loss: 0.3949\n",
            "Epoch 3, Sample 13396: Loss: 1.1783\n",
            "Epoch 3, Sample 13397: Loss: 0.3506\n",
            "Epoch 3, Sample 13398: Loss: 0.1241\n",
            "Epoch 3, Sample 13399: Loss: 1.1884\n",
            "Epoch 3, Sample 13400: Loss: 0.9367\n",
            "Epoch 3, Sample 13401: Loss: 0.3248\n",
            "Epoch 3, Sample 13402: Loss: 0.2759\n",
            "Epoch 3, Sample 13403: Loss: 0.3399\n",
            "Epoch 3, Sample 13404: Loss: 0.5053\n",
            "Epoch 3, Sample 13405: Loss: 1.0387\n",
            "Epoch 3, Sample 13406: Loss: 0.3467\n",
            "Epoch 3, Sample 13407: Loss: 0.7036\n",
            "Epoch 3, Sample 13408: Loss: 1.0530\n",
            "Epoch 3, Sample 13409: Loss: 0.3399\n",
            "Epoch 3, Sample 13410: Loss: 0.0303\n",
            "Epoch 3, Sample 13411: Loss: 0.0018\n",
            "Epoch 3, Sample 13412: Loss: 0.1523\n",
            "Epoch 3, Sample 13413: Loss: 0.2044\n",
            "Epoch 3, Sample 13414: Loss: 1.0530\n",
            "Epoch 3, Sample 13415: Loss: 0.2832\n",
            "Epoch 3, Sample 13416: Loss: 1.0530\n",
            "Epoch 3, Sample 13417: Loss: 0.3399\n",
            "Epoch 3, Sample 13418: Loss: 0.2962\n",
            "Epoch 3, Sample 13419: Loss: 0.8211\n",
            "Epoch 3, Sample 13420: Loss: 1.0093\n",
            "Epoch 3, Sample 13421: Loss: 0.1559\n",
            "Epoch 3, Sample 13422: Loss: 1.0155\n",
            "Epoch 3, Sample 13423: Loss: 0.3598\n",
            "Epoch 3, Sample 13424: Loss: 1.0524\n",
            "Epoch 3, Sample 13425: Loss: 0.2483\n",
            "Epoch 3, Sample 13426: Loss: 1.0155\n",
            "Epoch 3, Sample 13427: Loss: 0.0059\n",
            "Epoch 3, Sample 13428: Loss: 1.1473\n",
            "Epoch 3, Sample 13429: Loss: 1.5542\n",
            "Epoch 3, Sample 13430: Loss: 0.1372\n",
            "Epoch 3, Sample 13431: Loss: 0.0018\n",
            "Epoch 3, Sample 13432: Loss: 0.0018\n",
            "Epoch 3, Sample 13433: Loss: 0.2340\n",
            "Epoch 3, Sample 13434: Loss: 3.4424\n",
            "Epoch 3, Sample 13435: Loss: 0.0000\n",
            "Epoch 3, Sample 13436: Loss: 0.1091\n",
            "Epoch 3, Sample 13437: Loss: 0.2034\n",
            "Epoch 3, Sample 13438: Loss: 0.0203\n",
            "Epoch 3, Sample 13439: Loss: 0.0238\n",
            "Epoch 3, Sample 13440: Loss: 2.9895\n",
            "Epoch 3, Sample 13441: Loss: 0.7036\n",
            "Epoch 3, Sample 13442: Loss: 0.3399\n",
            "Epoch 3, Sample 13443: Loss: 1.0524\n",
            "Epoch 3, Sample 13444: Loss: 0.3399\n",
            "Epoch 3, Sample 13445: Loss: 0.0026\n",
            "Epoch 3, Sample 13446: Loss: 0.0326\n",
            "Epoch 3, Sample 13447: Loss: 0.6840\n",
            "Epoch 3, Sample 13448: Loss: 0.0062\n",
            "Epoch 3, Sample 13449: Loss: 0.0117\n",
            "Epoch 3, Sample 13450: Loss: 0.1326\n",
            "Epoch 3, Sample 13451: Loss: 0.2219\n",
            "Epoch 3, Sample 13452: Loss: 0.7036\n",
            "Epoch 3, Sample 13453: Loss: 1.8251\n",
            "Epoch 3, Sample 13454: Loss: 0.2639\n",
            "Epoch 3, Sample 13455: Loss: 0.0630\n",
            "Epoch 3, Sample 13456: Loss: 0.2981\n",
            "Epoch 3, Sample 13457: Loss: 0.0429\n",
            "Epoch 3, Sample 13458: Loss: 1.8261\n",
            "Epoch 3, Sample 13459: Loss: 0.0825\n",
            "Epoch 3, Sample 13460: Loss: 0.0205\n",
            "Epoch 3, Sample 13461: Loss: 1.1860\n",
            "Epoch 3, Sample 13462: Loss: 0.7036\n",
            "Epoch 3, Sample 13463: Loss: 4.5516\n",
            "Epoch 3, Sample 13464: Loss: 0.7036\n",
            "Epoch 3, Sample 13465: Loss: 0.1252\n",
            "Epoch 3, Sample 13466: Loss: 0.3770\n",
            "Epoch 3, Sample 13467: Loss: 0.0915\n",
            "Epoch 3, Sample 13468: Loss: 0.3399\n",
            "Epoch 3, Sample 13469: Loss: 0.0018\n",
            "Epoch 3, Sample 13470: Loss: 0.4101\n",
            "Epoch 3, Sample 13471: Loss: 0.1293\n",
            "Epoch 3, Sample 13472: Loss: 0.4930\n",
            "Epoch 3, Sample 13473: Loss: 0.0103\n",
            "Epoch 3, Sample 13474: Loss: 0.0000\n",
            "Epoch 3, Sample 13475: Loss: 0.0659\n",
            "Epoch 3, Sample 13476: Loss: 0.3126\n",
            "Epoch 3, Sample 13477: Loss: 0.3260\n",
            "Epoch 3, Sample 13478: Loss: 1.0524\n",
            "Epoch 3, Sample 13479: Loss: 0.6990\n",
            "Epoch 3, Sample 13480: Loss: 0.3399\n",
            "Epoch 3, Sample 13481: Loss: 0.7036\n",
            "Epoch 3, Sample 13482: Loss: 0.0306\n",
            "Epoch 3, Sample 13483: Loss: 0.3399\n",
            "Epoch 3, Sample 13484: Loss: 0.0838\n",
            "Epoch 3, Sample 13485: Loss: 0.7036\n",
            "Epoch 3, Sample 13486: Loss: 0.8932\n",
            "Epoch 3, Sample 13487: Loss: 0.1920\n",
            "Epoch 3, Sample 13488: Loss: 0.0099\n",
            "Epoch 3, Sample 13489: Loss: 0.1989\n",
            "Epoch 3, Sample 13490: Loss: 5.1824\n",
            "Epoch 3, Sample 13491: Loss: 1.0155\n",
            "Epoch 3, Sample 13492: Loss: 0.2044\n",
            "Epoch 3, Sample 13493: Loss: 0.2759\n",
            "Epoch 3, Sample 13494: Loss: 0.5853\n",
            "Epoch 3, Sample 13495: Loss: 0.2759\n",
            "Epoch 3, Sample 13496: Loss: 17.3509\n",
            "Epoch 3, Sample 13497: Loss: 0.1170\n",
            "Epoch 3, Sample 13498: Loss: 0.9367\n",
            "Epoch 3, Sample 13499: Loss: 0.0013\n",
            "Epoch 3, Sample 13500: Loss: 0.2044\n",
            "Epoch 3, Sample 13501: Loss: 0.2032\n",
            "Epoch 3, Sample 13502: Loss: 0.7667\n",
            "Epoch 3, Sample 13503: Loss: 0.2044\n",
            "Epoch 3, Sample 13504: Loss: 0.1337\n",
            "Epoch 3, Sample 13505: Loss: 0.2219\n",
            "Epoch 3, Sample 13506: Loss: 0.0730\n",
            "Epoch 3, Sample 13507: Loss: 0.1559\n",
            "Epoch 3, Sample 13508: Loss: 0.6990\n",
            "Epoch 3, Sample 13509: Loss: 0.3441\n",
            "Epoch 3, Sample 13510: Loss: 0.4663\n",
            "Epoch 3, Sample 13511: Loss: 0.2568\n",
            "Epoch 3, Sample 13512: Loss: 0.4799\n",
            "Epoch 3, Sample 13513: Loss: 1.0524\n",
            "Epoch 3, Sample 13514: Loss: 0.2034\n",
            "Epoch 3, Sample 13515: Loss: 0.4930\n",
            "Epoch 3, Sample 13516: Loss: 0.1250\n",
            "Epoch 3, Sample 13517: Loss: 0.4930\n",
            "Epoch 3, Sample 13518: Loss: 0.9290\n",
            "Epoch 3, Sample 13519: Loss: 0.0001\n",
            "Epoch 3, Sample 13520: Loss: 0.0630\n",
            "Epoch 3, Sample 13521: Loss: 0.3339\n",
            "Epoch 3, Sample 13522: Loss: 0.2704\n",
            "Epoch 3, Sample 13523: Loss: 0.5062\n",
            "Epoch 3, Sample 13524: Loss: 0.3250\n",
            "Epoch 3, Sample 13525: Loss: 0.0026\n",
            "Epoch 3, Sample 13526: Loss: 0.1636\n",
            "Epoch 3, Sample 13527: Loss: 0.3949\n",
            "Epoch 3, Sample 13528: Loss: 0.2044\n",
            "Epoch 3, Sample 13529: Loss: 0.3626\n",
            "Epoch 3, Sample 13530: Loss: 0.0018\n",
            "Epoch 3, Sample 13531: Loss: 0.7036\n",
            "Epoch 3, Sample 13532: Loss: 0.9365\n",
            "Epoch 3, Sample 13533: Loss: 0.1248\n",
            "Epoch 3, Sample 13534: Loss: 0.5858\n",
            "Epoch 3, Sample 13535: Loss: 0.0460\n",
            "Epoch 3, Sample 13536: Loss: 0.4799\n",
            "Epoch 3, Sample 13537: Loss: 0.6990\n",
            "Epoch 3, Sample 13538: Loss: 1.4836\n",
            "Epoch 3, Sample 13539: Loss: 0.5871\n",
            "Epoch 3, Sample 13540: Loss: 0.0234\n",
            "Epoch 3, Sample 13541: Loss: 0.0875\n",
            "Epoch 3, Sample 13542: Loss: 0.0258\n",
            "Epoch 3, Sample 13543: Loss: 0.2558\n",
            "Epoch 3, Sample 13544: Loss: 1.8469\n",
            "Epoch 3, Sample 13545: Loss: 1.0524\n",
            "Epoch 3, Sample 13546: Loss: 0.3758\n",
            "Epoch 3, Sample 13547: Loss: 1.0530\n",
            "Epoch 3, Sample 13548: Loss: 0.5000\n",
            "Epoch 3, Sample 13549: Loss: 0.0108\n",
            "Epoch 3, Sample 13550: Loss: 0.3441\n",
            "Epoch 3, Sample 13551: Loss: 0.6941\n",
            "Epoch 3, Sample 13552: Loss: 0.0701\n",
            "Epoch 3, Sample 13553: Loss: 0.3062\n",
            "Epoch 3, Sample 13554: Loss: 0.2044\n",
            "Epoch 3, Sample 13555: Loss: 0.0060\n",
            "Epoch 3, Sample 13556: Loss: 0.0059\n",
            "Epoch 3, Sample 13557: Loss: 1.2506\n",
            "Epoch 3, Sample 13558: Loss: 0.0018\n",
            "Epoch 3, Sample 13559: Loss: 1.0266\n",
            "Epoch 3, Sample 13560: Loss: 0.1250\n",
            "Epoch 3, Sample 13561: Loss: 0.1170\n",
            "Epoch 3, Sample 13562: Loss: 1.0524\n",
            "Epoch 3, Sample 13563: Loss: 0.3506\n",
            "Epoch 3, Sample 13564: Loss: 0.0838\n",
            "Epoch 3, Sample 13565: Loss: 1.6013\n",
            "Epoch 3, Sample 13566: Loss: 0.6152\n",
            "Epoch 3, Sample 13567: Loss: 0.5220\n",
            "Epoch 3, Sample 13568: Loss: 0.0915\n",
            "Epoch 3, Sample 13569: Loss: 0.2044\n",
            "Epoch 3, Sample 13570: Loss: 1.0266\n",
            "Epoch 3, Sample 13571: Loss: 0.1894\n",
            "Epoch 3, Sample 13572: Loss: 0.7107\n",
            "Epoch 3, Sample 13573: Loss: 1.7195\n",
            "Epoch 3, Sample 13574: Loss: 0.5196\n",
            "Epoch 3, Sample 13575: Loss: 0.8951\n",
            "Epoch 3, Sample 13576: Loss: 0.3247\n",
            "Epoch 3, Sample 13577: Loss: 0.0026\n",
            "Epoch 3, Sample 13578: Loss: 0.0000\n",
            "Epoch 3, Sample 13579: Loss: 0.2036\n",
            "Epoch 3, Sample 13580: Loss: 0.0205\n",
            "Epoch 3, Sample 13581: Loss: 0.3399\n",
            "Epoch 3, Sample 13582: Loss: 1.4933\n",
            "Epoch 3, Sample 13583: Loss: 0.2044\n",
            "Epoch 3, Sample 13584: Loss: 0.3399\n",
            "Epoch 3, Sample 13585: Loss: 0.3102\n",
            "Epoch 3, Sample 13586: Loss: 0.0972\n",
            "Epoch 3, Sample 13587: Loss: 0.8951\n",
            "Epoch 3, Sample 13588: Loss: 0.2851\n",
            "Epoch 3, Sample 13589: Loss: 0.2837\n",
            "Epoch 3, Sample 13590: Loss: 0.2759\n",
            "Epoch 3, Sample 13591: Loss: 1.7105\n",
            "Epoch 3, Sample 13592: Loss: 0.7486\n",
            "Epoch 3, Sample 13593: Loss: 1.4282\n",
            "Epoch 3, Sample 13594: Loss: 0.3441\n",
            "Epoch 3, Sample 13595: Loss: 0.2832\n",
            "Epoch 3, Sample 13596: Loss: 0.2034\n",
            "Epoch 3, Sample 13597: Loss: 0.2855\n",
            "Epoch 3, Sample 13598: Loss: 0.0327\n",
            "Epoch 3, Sample 13599: Loss: 0.0148\n",
            "Epoch 3, Sample 13600: Loss: 0.0026\n",
            "Epoch 3, Sample 13601: Loss: 0.4930\n",
            "Epoch 3, Sample 13602: Loss: 0.0001\n",
            "Epoch 3, Sample 13603: Loss: 0.1250\n",
            "Epoch 3, Sample 13604: Loss: 0.0303\n",
            "Epoch 3, Sample 13605: Loss: 0.0901\n",
            "Epoch 3, Sample 13606: Loss: 0.2044\n",
            "Epoch 3, Sample 13607: Loss: 0.0915\n",
            "Epoch 3, Sample 13608: Loss: 0.0084\n",
            "Epoch 3, Sample 13609: Loss: 0.0759\n",
            "Epoch 3, Sample 13610: Loss: 0.2340\n",
            "Epoch 3, Sample 13611: Loss: 0.0026\n",
            "Epoch 3, Sample 13612: Loss: 0.3938\n",
            "Epoch 3, Sample 13613: Loss: 0.0042\n",
            "Epoch 3, Sample 13614: Loss: 4.7564\n",
            "Epoch 3, Sample 13615: Loss: 0.1732\n",
            "Epoch 3, Sample 13616: Loss: 1.0524\n",
            "Epoch 3, Sample 13617: Loss: 0.0630\n",
            "Epoch 3, Sample 13618: Loss: 0.0026\n",
            "Epoch 3, Sample 13619: Loss: 0.2034\n",
            "Epoch 3, Sample 13620: Loss: 3.6558\n",
            "Epoch 3, Sample 13621: Loss: 0.0026\n",
            "Epoch 3, Sample 13622: Loss: 0.1250\n",
            "Epoch 3, Sample 13623: Loss: 0.0102\n",
            "Epoch 3, Sample 13624: Loss: 0.6990\n",
            "Epoch 3, Sample 13625: Loss: 0.4367\n",
            "Epoch 3, Sample 13626: Loss: 0.0076\n",
            "Epoch 3, Sample 13627: Loss: 0.0018\n",
            "Epoch 3, Sample 13628: Loss: 2.7331\n",
            "Epoch 3, Sample 13629: Loss: 0.1508\n",
            "Epoch 3, Sample 13630: Loss: 0.1372\n",
            "Epoch 3, Sample 13631: Loss: 4.7979\n",
            "Epoch 3, Sample 13632: Loss: 0.0002\n",
            "Epoch 3, Sample 13633: Loss: 0.3758\n",
            "Epoch 3, Sample 13634: Loss: 0.3441\n",
            "Epoch 3, Sample 13635: Loss: 0.1250\n",
            "Epoch 3, Sample 13636: Loss: 0.6444\n",
            "Epoch 3, Sample 13637: Loss: 0.1508\n",
            "Epoch 3, Sample 13638: Loss: 1.0524\n",
            "Epoch 3, Sample 13639: Loss: 0.9367\n",
            "Epoch 3, Sample 13640: Loss: 1.0266\n",
            "Epoch 3, Sample 13641: Loss: 1.0524\n",
            "Epoch 3, Sample 13642: Loss: 0.1523\n",
            "Epoch 3, Sample 13643: Loss: 0.3399\n",
            "Epoch 3, Sample 13644: Loss: 1.0524\n",
            "Epoch 3, Sample 13645: Loss: 1.2073\n",
            "Epoch 3, Sample 13646: Loss: 0.1636\n",
            "Epoch 3, Sample 13647: Loss: 0.3441\n",
            "Epoch 3, Sample 13648: Loss: 0.5858\n",
            "Epoch 3, Sample 13649: Loss: 0.0108\n",
            "Epoch 3, Sample 13650: Loss: 0.8951\n",
            "Epoch 3, Sample 13651: Loss: 0.7036\n",
            "Epoch 3, Sample 13652: Loss: 0.0026\n",
            "Epoch 3, Sample 13653: Loss: 0.5000\n",
            "Epoch 3, Sample 13654: Loss: 0.3030\n",
            "Epoch 3, Sample 13655: Loss: 0.0915\n",
            "Epoch 3, Sample 13656: Loss: 1.0524\n",
            "Epoch 3, Sample 13657: Loss: 0.5000\n",
            "Epoch 3, Sample 13658: Loss: 0.1588\n",
            "Epoch 3, Sample 13659: Loss: 0.3450\n",
            "Epoch 3, Sample 13660: Loss: 0.2759\n",
            "Epoch 3, Sample 13661: Loss: 0.0027\n",
            "Epoch 3, Sample 13662: Loss: 0.0026\n",
            "Epoch 3, Sample 13663: Loss: 0.2778\n",
            "Epoch 3, Sample 13664: Loss: 0.0962\n",
            "Epoch 3, Sample 13665: Loss: 0.0000\n",
            "Epoch 3, Sample 13666: Loss: 0.2759\n",
            "Epoch 3, Sample 13667: Loss: 0.4841\n",
            "Epoch 3, Sample 13668: Loss: 0.8951\n",
            "Epoch 3, Sample 13669: Loss: 1.0155\n",
            "Epoch 3, Sample 13670: Loss: 0.0026\n",
            "Epoch 3, Sample 13671: Loss: 0.4611\n",
            "Epoch 3, Sample 13672: Loss: 0.3438\n",
            "Epoch 3, Sample 13673: Loss: 0.6391\n",
            "Epoch 3, Sample 13674: Loss: 0.8110\n",
            "Epoch 3, Sample 13675: Loss: 14.7104\n",
            "Epoch 3, Sample 13676: Loss: 0.7036\n",
            "Epoch 3, Sample 13677: Loss: 0.2112\n",
            "Epoch 3, Sample 13678: Loss: 0.7036\n",
            "Epoch 3, Sample 13679: Loss: 0.4611\n",
            "Epoch 3, Sample 13680: Loss: 0.5196\n",
            "Epoch 3, Sample 13681: Loss: 0.0038\n",
            "Epoch 3, Sample 13682: Loss: 0.2759\n",
            "Epoch 3, Sample 13683: Loss: 6.4686\n",
            "Epoch 3, Sample 13684: Loss: 0.6233\n",
            "Epoch 3, Sample 13685: Loss: 2.5998\n",
            "Epoch 3, Sample 13686: Loss: 0.4799\n",
            "Epoch 3, Sample 13687: Loss: 0.5744\n",
            "Epoch 3, Sample 13688: Loss: 0.5972\n",
            "Epoch 3, Sample 13689: Loss: 0.0026\n",
            "Epoch 3, Sample 13690: Loss: 0.3758\n",
            "Epoch 3, Sample 13691: Loss: 0.3441\n",
            "Epoch 3, Sample 13692: Loss: 0.0026\n",
            "Epoch 3, Sample 13693: Loss: 0.7036\n",
            "Epoch 3, Sample 13694: Loss: 0.3568\n",
            "Epoch 3, Sample 13695: Loss: 0.1627\n",
            "Epoch 3, Sample 13696: Loss: 0.1246\n",
            "Epoch 3, Sample 13697: Loss: 0.2034\n",
            "Epoch 3, Sample 13698: Loss: 0.2219\n",
            "Epoch 3, Sample 13699: Loss: 0.8128\n",
            "Epoch 3, Sample 13700: Loss: 0.0915\n",
            "Epoch 3, Sample 13701: Loss: 0.5061\n",
            "Epoch 3, Sample 13702: Loss: 0.3402\n",
            "Epoch 3, Sample 13703: Loss: 0.7036\n",
            "Epoch 3, Sample 13704: Loss: 1.0247\n",
            "Epoch 3, Sample 13705: Loss: 0.2034\n",
            "Epoch 3, Sample 13706: Loss: 0.0006\n",
            "Epoch 3, Sample 13707: Loss: 0.0005\n",
            "Epoch 3, Sample 13708: Loss: 0.4902\n",
            "Epoch 3, Sample 13709: Loss: 0.7036\n",
            "Epoch 3, Sample 13710: Loss: 1.0524\n",
            "Epoch 3, Sample 13711: Loss: 0.6092\n",
            "Epoch 3, Sample 13712: Loss: 0.2044\n",
            "Epoch 3, Sample 13713: Loss: 0.3399\n",
            "Epoch 3, Sample 13714: Loss: 0.3441\n",
            "Epoch 3, Sample 13715: Loss: 0.2044\n",
            "Epoch 3, Sample 13716: Loss: 0.2832\n",
            "Epoch 3, Sample 13717: Loss: 0.1326\n",
            "Epoch 3, Sample 13718: Loss: 0.0640\n",
            "Epoch 3, Sample 13719: Loss: 0.2989\n",
            "Epoch 3, Sample 13720: Loss: 0.1740\n",
            "Epoch 3, Sample 13721: Loss: 1.0530\n",
            "Epoch 3, Sample 13722: Loss: 0.4996\n",
            "Epoch 3, Sample 13723: Loss: 0.2044\n",
            "Epoch 3, Sample 13724: Loss: 0.8717\n",
            "Epoch 3, Sample 13725: Loss: 1.0155\n",
            "Epoch 3, Sample 13726: Loss: 1.0155\n",
            "Epoch 3, Sample 13727: Loss: 0.0999\n",
            "Epoch 3, Sample 13728: Loss: 0.2851\n",
            "Epoch 3, Sample 13729: Loss: 0.2034\n",
            "Epoch 3, Sample 13730: Loss: 0.1091\n",
            "Epoch 3, Sample 13731: Loss: 0.2078\n",
            "Epoch 3, Sample 13732: Loss: 6.3970\n",
            "Epoch 3, Sample 13733: Loss: 0.1817\n",
            "Epoch 3, Sample 13734: Loss: 0.7036\n",
            "Epoch 3, Sample 13735: Loss: 0.0001\n",
            "Epoch 3, Sample 13736: Loss: 1.0155\n",
            "Epoch 3, Sample 13737: Loss: 0.1770\n",
            "Epoch 3, Sample 13738: Loss: 3.1238\n",
            "Epoch 3, Sample 13739: Loss: 0.2036\n",
            "Epoch 3, Sample 13740: Loss: 0.1465\n",
            "Epoch 3, Sample 13741: Loss: 0.0205\n",
            "Epoch 3, Sample 13742: Loss: 0.2989\n",
            "Epoch 3, Sample 13743: Loss: 1.0524\n",
            "Epoch 3, Sample 13744: Loss: 1.0155\n",
            "Epoch 3, Sample 13745: Loss: 0.8484\n",
            "Epoch 3, Sample 13746: Loss: 0.4032\n",
            "Epoch 3, Sample 13747: Loss: 0.2759\n",
            "Epoch 3, Sample 13748: Loss: 0.2851\n",
            "Epoch 3, Sample 13749: Loss: 0.2036\n",
            "Epoch 3, Sample 13750: Loss: 1.6190\n",
            "Epoch 3, Sample 13751: Loss: 0.0683\n",
            "Epoch 3, Sample 13752: Loss: 1.0524\n",
            "Epoch 3, Sample 13753: Loss: 0.6048\n",
            "Epoch 3, Sample 13754: Loss: 0.2044\n",
            "Epoch 3, Sample 13755: Loss: 0.0391\n",
            "Epoch 3, Sample 13756: Loss: 0.0744\n",
            "Epoch 3, Sample 13757: Loss: 3.3794\n",
            "Epoch 3, Sample 13758: Loss: 0.2044\n",
            "Epoch 3, Sample 13759: Loss: 0.0026\n",
            "Epoch 3, Sample 13760: Loss: 2.4990\n",
            "Epoch 3, Sample 13761: Loss: 0.3949\n",
            "Epoch 3, Sample 13762: Loss: 0.5000\n",
            "Epoch 3, Sample 13763: Loss: 0.0630\n",
            "Epoch 3, Sample 13764: Loss: 1.7578\n",
            "Epoch 3, Sample 13765: Loss: 0.8951\n",
            "Epoch 3, Sample 13766: Loss: 5.5795\n",
            "Epoch 3, Sample 13767: Loss: 0.2036\n",
            "Epoch 3, Sample 13768: Loss: 0.3399\n",
            "Epoch 3, Sample 13769: Loss: 0.0026\n",
            "Epoch 3, Sample 13770: Loss: 0.8951\n",
            "Epoch 3, Sample 13771: Loss: 0.5078\n",
            "Epoch 3, Sample 13772: Loss: 0.0915\n",
            "Epoch 3, Sample 13773: Loss: 0.0911\n",
            "Epoch 3, Sample 13774: Loss: 0.4611\n",
            "Epoch 3, Sample 13775: Loss: 0.7036\n",
            "Epoch 3, Sample 13776: Loss: 0.0180\n",
            "Epoch 3, Sample 13777: Loss: 0.2044\n",
            "Epoch 3, Sample 13778: Loss: 3.4977\n",
            "Epoch 3, Sample 13779: Loss: 4.9876\n",
            "Epoch 3, Sample 13780: Loss: 0.8135\n",
            "Epoch 3, Sample 13781: Loss: 0.0000\n",
            "Epoch 3, Sample 13782: Loss: 0.0064\n",
            "Epoch 3, Sample 13783: Loss: 0.0062\n",
            "Epoch 3, Sample 13784: Loss: 0.3399\n",
            "Epoch 3, Sample 13785: Loss: 0.0625\n",
            "Epoch 3, Sample 13786: Loss: 0.7036\n",
            "Epoch 3, Sample 13787: Loss: 0.0026\n",
            "Epoch 3, Sample 13788: Loss: 0.6126\n",
            "Epoch 3, Sample 13789: Loss: 0.0621\n",
            "Epoch 3, Sample 13790: Loss: 1.0680\n",
            "Epoch 3, Sample 13791: Loss: 0.6058\n",
            "Epoch 3, Sample 13792: Loss: 0.0145\n",
            "Epoch 3, Sample 13793: Loss: 0.3441\n",
            "Epoch 3, Sample 13794: Loss: 0.5604\n",
            "Epoch 3, Sample 13795: Loss: 0.3399\n",
            "Epoch 3, Sample 13796: Loss: 0.1516\n",
            "Epoch 3, Sample 13797: Loss: 0.0003\n",
            "Epoch 3, Sample 13798: Loss: 0.0202\n",
            "Epoch 3, Sample 13799: Loss: 1.0155\n",
            "Epoch 3, Sample 13800: Loss: 0.1676\n",
            "Epoch 3, Sample 13801: Loss: 0.0084\n",
            "Epoch 3, Sample 13802: Loss: 0.0067\n",
            "Epoch 3, Sample 13803: Loss: 0.7386\n",
            "Epoch 3, Sample 13804: Loss: 0.3399\n",
            "Epoch 3, Sample 13805: Loss: 1.0524\n",
            "Epoch 3, Sample 13806: Loss: 0.1250\n",
            "Epoch 3, Sample 13807: Loss: 0.0369\n",
            "Epoch 3, Sample 13808: Loss: 0.5858\n",
            "Epoch 3, Sample 13809: Loss: 0.2879\n",
            "Epoch 3, Sample 13810: Loss: 0.3441\n",
            "Epoch 3, Sample 13811: Loss: 0.5000\n",
            "Epoch 3, Sample 13812: Loss: 0.5102\n",
            "Epoch 3, Sample 13813: Loss: 0.1511\n",
            "Epoch 3, Sample 13814: Loss: 0.0018\n",
            "Epoch 3, Sample 13815: Loss: 1.0530\n",
            "Epoch 3, Sample 13816: Loss: 0.2044\n",
            "Epoch 3, Sample 13817: Loss: 0.2044\n",
            "Epoch 3, Sample 13818: Loss: 1.0524\n",
            "Epoch 3, Sample 13819: Loss: 0.4799\n",
            "Epoch 3, Sample 13820: Loss: 0.6058\n",
            "Epoch 3, Sample 13821: Loss: 0.9312\n",
            "Epoch 3, Sample 13822: Loss: 0.2034\n",
            "Epoch 3, Sample 13823: Loss: 0.0286\n",
            "Epoch 3, Sample 13824: Loss: 0.4851\n",
            "Epoch 3, Sample 13825: Loss: 0.0626\n",
            "Epoch 3, Sample 13826: Loss: 0.2832\n",
            "Epoch 3, Sample 13827: Loss: 0.2951\n",
            "Epoch 3, Sample 13828: Loss: 0.7861\n",
            "Epoch 3, Sample 13829: Loss: 0.1170\n",
            "Epoch 3, Sample 13830: Loss: 1.0524\n",
            "Epoch 3, Sample 13831: Loss: 0.2044\n",
            "Epoch 3, Sample 13832: Loss: 0.1170\n",
            "Epoch 3, Sample 13833: Loss: 0.1155\n",
            "Epoch 3, Sample 13834: Loss: 0.0774\n",
            "Epoch 3, Sample 13835: Loss: 0.7702\n",
            "Epoch 3, Sample 13836: Loss: 0.0267\n",
            "Epoch 3, Sample 13837: Loss: 1.0524\n",
            "Epoch 3, Sample 13838: Loss: 0.0432\n",
            "Epoch 3, Sample 13839: Loss: 2.6851\n",
            "Epoch 3, Sample 13840: Loss: 0.3024\n",
            "Epoch 3, Sample 13841: Loss: 0.1252\n",
            "Epoch 3, Sample 13842: Loss: 1.0524\n",
            "Epoch 3, Sample 13843: Loss: 1.8267\n",
            "Epoch 3, Sample 13844: Loss: 0.1170\n",
            "Epoch 3, Sample 13845: Loss: 0.5000\n",
            "Epoch 3, Sample 13846: Loss: 0.0060\n",
            "Epoch 3, Sample 13847: Loss: 0.2034\n",
            "Epoch 3, Sample 13848: Loss: 0.2832\n",
            "Epoch 3, Sample 13849: Loss: 0.2219\n",
            "Epoch 3, Sample 13850: Loss: 0.4841\n",
            "Epoch 3, Sample 13851: Loss: 0.5256\n",
            "Epoch 3, Sample 13852: Loss: 0.5871\n",
            "Epoch 3, Sample 13853: Loss: 1.0530\n",
            "Epoch 3, Sample 13854: Loss: 0.0026\n",
            "Epoch 3, Sample 13855: Loss: 0.2922\n",
            "Epoch 3, Sample 13856: Loss: 0.6304\n",
            "Epoch 3, Sample 13857: Loss: 0.1326\n",
            "Epoch 3, Sample 13858: Loss: 1.0524\n",
            "Epoch 3, Sample 13859: Loss: 0.0026\n",
            "Epoch 3, Sample 13860: Loss: 1.8943\n",
            "Epoch 3, Sample 13861: Loss: 0.0010\n",
            "Epoch 3, Sample 13862: Loss: 1.0524\n",
            "Epoch 3, Sample 13863: Loss: 0.0212\n",
            "Epoch 3, Sample 13864: Loss: 0.2472\n",
            "Epoch 3, Sample 13865: Loss: 0.2759\n",
            "Epoch 3, Sample 13866: Loss: 1.0155\n",
            "Epoch 3, Sample 13867: Loss: 0.0306\n",
            "Epoch 3, Sample 13868: Loss: 0.5871\n",
            "Epoch 3, Sample 13869: Loss: 0.0303\n",
            "Epoch 3, Sample 13870: Loss: 1.0524\n",
            "Epoch 3, Sample 13871: Loss: 0.2044\n",
            "Epoch 3, Sample 13872: Loss: 0.0630\n",
            "Epoch 3, Sample 13873: Loss: 0.9367\n",
            "Epoch 3, Sample 13874: Loss: 0.0000\n",
            "Epoch 3, Sample 13875: Loss: 0.0001\n",
            "Epoch 3, Sample 13876: Loss: 0.1091\n",
            "Epoch 3, Sample 13877: Loss: 0.0018\n",
            "Epoch 3, Sample 13878: Loss: 0.1037\n",
            "Epoch 3, Sample 13879: Loss: 0.0000\n",
            "Epoch 3, Sample 13880: Loss: 0.0026\n",
            "Epoch 3, Sample 13881: Loss: 0.0118\n",
            "Epoch 3, Sample 13882: Loss: 1.2926\n",
            "Epoch 3, Sample 13883: Loss: 0.5089\n",
            "Epoch 3, Sample 13884: Loss: 0.0602\n",
            "Epoch 3, Sample 13885: Loss: 0.6092\n",
            "Epoch 3, Sample 13886: Loss: 3.0924\n",
            "Epoch 3, Sample 13887: Loss: 0.9265\n",
            "Epoch 3, Sample 13888: Loss: 0.2036\n",
            "Epoch 3, Sample 13889: Loss: 0.6600\n",
            "Epoch 3, Sample 13890: Loss: 0.0025\n",
            "Epoch 3, Sample 13891: Loss: 0.2112\n",
            "Epoch 3, Sample 13892: Loss: 0.1482\n",
            "Epoch 3, Sample 13893: Loss: 0.7036\n",
            "Epoch 3, Sample 13894: Loss: 1.2095\n",
            "Epoch 3, Sample 13895: Loss: 0.6092\n",
            "Epoch 3, Sample 13896: Loss: 0.0630\n",
            "Epoch 3, Sample 13897: Loss: 0.0744\n",
            "Epoch 3, Sample 13898: Loss: 0.0220\n",
            "Epoch 3, Sample 13899: Loss: 0.2032\n",
            "Epoch 3, Sample 13900: Loss: 1.0155\n",
            "Epoch 3, Sample 13901: Loss: 4.2569\n",
            "Epoch 3, Sample 13902: Loss: 0.0013\n",
            "Epoch 3, Sample 13903: Loss: 0.7036\n",
            "Epoch 3, Sample 13904: Loss: 0.6451\n",
            "Epoch 3, Sample 13905: Loss: 0.3322\n",
            "Epoch 3, Sample 13906: Loss: 2.5912\n",
            "Epoch 3, Sample 13907: Loss: 0.4799\n",
            "Epoch 3, Sample 13908: Loss: 0.5480\n",
            "Epoch 3, Sample 13909: Loss: 0.0749\n",
            "Epoch 3, Sample 13910: Loss: 0.4421\n",
            "Epoch 3, Sample 13911: Loss: 0.1250\n",
            "Epoch 3, Sample 13912: Loss: 0.3598\n",
            "Epoch 3, Sample 13913: Loss: 0.2034\n",
            "Epoch 3, Sample 13914: Loss: 0.1337\n",
            "Epoch 3, Sample 13915: Loss: 0.0234\n",
            "Epoch 3, Sample 13916: Loss: 0.5369\n",
            "Epoch 3, Sample 13917: Loss: 0.0093\n",
            "Epoch 3, Sample 13918: Loss: 0.4930\n",
            "Epoch 3, Sample 13919: Loss: 0.2044\n",
            "Epoch 3, Sample 13920: Loss: 0.0052\n",
            "Epoch 3, Sample 13921: Loss: 0.7036\n",
            "Epoch 3, Sample 13922: Loss: 0.1627\n",
            "Epoch 3, Sample 13923: Loss: 0.0915\n",
            "Epoch 3, Sample 13924: Loss: 0.0026\n",
            "Epoch 3, Sample 13925: Loss: 0.3399\n",
            "Epoch 3, Sample 13926: Loss: 1.0524\n",
            "Epoch 3, Sample 13927: Loss: 0.0078\n",
            "Epoch 3, Sample 13928: Loss: 0.3399\n",
            "Epoch 3, Sample 13929: Loss: 0.0102\n",
            "Epoch 3, Sample 13930: Loss: 0.2034\n",
            "Epoch 3, Sample 13931: Loss: 1.0155\n",
            "Epoch 3, Sample 13932: Loss: 0.0018\n",
            "Epoch 3, Sample 13933: Loss: 0.0322\n",
            "Epoch 3, Sample 13934: Loss: 0.2165\n",
            "Epoch 3, Sample 13935: Loss: 0.1555\n",
            "Epoch 3, Sample 13936: Loss: 0.2098\n",
            "Epoch 3, Sample 13937: Loss: 0.1336\n",
            "Epoch 3, Sample 13938: Loss: 0.2034\n",
            "Epoch 3, Sample 13939: Loss: 0.2759\n",
            "Epoch 3, Sample 13940: Loss: 0.4611\n",
            "Epoch 3, Sample 13941: Loss: 0.0630\n",
            "Epoch 3, Sample 13942: Loss: 0.0811\n",
            "Epoch 3, Sample 13943: Loss: 0.3949\n",
            "Epoch 3, Sample 13944: Loss: 1.0155\n",
            "Epoch 3, Sample 13945: Loss: 0.1559\n",
            "Epoch 3, Sample 13946: Loss: 1.0524\n",
            "Epoch 3, Sample 13947: Loss: 0.2044\n",
            "Epoch 3, Sample 13948: Loss: 0.3568\n",
            "Epoch 3, Sample 13949: Loss: 0.4588\n",
            "Epoch 3, Sample 13950: Loss: 0.5003\n",
            "Epoch 3, Sample 13951: Loss: 0.2032\n",
            "Epoch 3, Sample 13952: Loss: 1.6293\n",
            "Epoch 3, Sample 13953: Loss: 0.1250\n",
            "Epoch 3, Sample 13954: Loss: 0.2032\n",
            "Epoch 3, Sample 13955: Loss: 0.6479\n",
            "Epoch 3, Sample 13956: Loss: 0.6867\n",
            "Epoch 3, Sample 13957: Loss: 0.3949\n",
            "Epoch 3, Sample 13958: Loss: 0.4984\n",
            "Epoch 3, Sample 13959: Loss: 0.7453\n",
            "Epoch 3, Sample 13960: Loss: 1.0155\n",
            "Epoch 3, Sample 13961: Loss: 0.3399\n",
            "Epoch 3, Sample 13962: Loss: 0.7036\n",
            "Epoch 3, Sample 13963: Loss: 0.5972\n",
            "Epoch 3, Sample 13964: Loss: 0.0000\n",
            "Epoch 3, Sample 13965: Loss: 0.4607\n",
            "Epoch 3, Sample 13966: Loss: 0.3441\n",
            "Epoch 3, Sample 13967: Loss: 0.2639\n",
            "Epoch 3, Sample 13968: Loss: 0.0595\n",
            "Epoch 3, Sample 13969: Loss: 1.1569\n",
            "Epoch 3, Sample 13970: Loss: 0.7453\n",
            "Epoch 3, Sample 13971: Loss: 0.2044\n",
            "Epoch 3, Sample 13972: Loss: 0.5078\n",
            "Epoch 3, Sample 13973: Loss: 9.4657\n",
            "Epoch 3, Sample 13974: Loss: 0.9367\n",
            "Epoch 3, Sample 13975: Loss: 0.0026\n",
            "Epoch 3, Sample 13976: Loss: 0.3399\n",
            "Epoch 3, Sample 13977: Loss: 0.2044\n",
            "Epoch 3, Sample 13978: Loss: 0.0303\n",
            "Epoch 3, Sample 13979: Loss: 0.0026\n",
            "Epoch 3, Sample 13980: Loss: 0.9367\n",
            "Epoch 3, Sample 13981: Loss: 0.5972\n",
            "Epoch 3, Sample 13982: Loss: 0.0090\n",
            "Epoch 3, Sample 13983: Loss: 0.0630\n",
            "Epoch 3, Sample 13984: Loss: 0.0897\n",
            "Epoch 3, Sample 13985: Loss: 0.0630\n",
            "Epoch 3, Sample 13986: Loss: 0.0328\n",
            "Epoch 3, Sample 13987: Loss: 0.1838\n",
            "Epoch 3, Sample 13988: Loss: 3.6305\n",
            "Epoch 3, Sample 13989: Loss: 0.0407\n",
            "Epoch 3, Sample 13990: Loss: 0.3332\n",
            "Epoch 3, Sample 13991: Loss: 0.2032\n",
            "Epoch 3, Sample 13992: Loss: 0.3402\n",
            "Epoch 3, Sample 13993: Loss: 0.2034\n",
            "Epoch 3, Sample 13994: Loss: 1.0524\n",
            "Epoch 3, Sample 13995: Loss: 0.4032\n",
            "Epoch 3, Sample 13996: Loss: 0.0173\n",
            "Epoch 3, Sample 13997: Loss: 0.6990\n",
            "Epoch 3, Sample 13998: Loss: 0.0026\n",
            "Epoch 3, Sample 13999: Loss: 0.0364\n",
            "Epoch 3, Sample 14000: Loss: 1.0155\n",
            "Epoch 3, Sample 14001: Loss: 0.0838\n",
            "Epoch 3, Sample 14002: Loss: 0.2347\n",
            "Epoch 3, Sample 14003: Loss: 0.0000\n",
            "Epoch 3, Sample 14004: Loss: 0.0001\n",
            "Epoch 3, Sample 14005: Loss: 0.4586\n",
            "Epoch 3, Sample 14006: Loss: 0.2036\n",
            "Epoch 3, Sample 14007: Loss: 0.0026\n",
            "Epoch 3, Sample 14008: Loss: 0.0084\n",
            "Epoch 3, Sample 14009: Loss: 0.1399\n",
            "Epoch 3, Sample 14010: Loss: 0.7036\n",
            "Epoch 3, Sample 14011: Loss: 0.4849\n",
            "Epoch 3, Sample 14012: Loss: 0.0277\n",
            "Epoch 3, Sample 14013: Loss: 0.3441\n",
            "Epoch 3, Sample 14014: Loss: 0.4799\n",
            "Epoch 3, Sample 14015: Loss: 0.8319\n",
            "Epoch 3, Sample 14016: Loss: 1.0155\n",
            "Epoch 3, Sample 14017: Loss: 0.1940\n",
            "Epoch 3, Sample 14018: Loss: 0.0203\n",
            "Epoch 3, Sample 14019: Loss: 2.0600\n",
            "Epoch 3, Sample 14020: Loss: 10.9900\n",
            "Epoch 3, Sample 14021: Loss: 0.3399\n",
            "Epoch 3, Sample 14022: Loss: 1.0524\n",
            "Epoch 3, Sample 14023: Loss: 1.0524\n",
            "Epoch 3, Sample 14024: Loss: 0.0915\n",
            "Epoch 3, Sample 14025: Loss: 0.3399\n",
            "Epoch 3, Sample 14026: Loss: 0.0466\n",
            "Epoch 3, Sample 14027: Loss: 0.3418\n",
            "Epoch 3, Sample 14028: Loss: 0.1559\n",
            "Epoch 3, Sample 14029: Loss: 0.2793\n",
            "Epoch 3, Sample 14030: Loss: 0.9785\n",
            "Epoch 3, Sample 14031: Loss: 0.9367\n",
            "Epoch 3, Sample 14032: Loss: 0.4032\n",
            "Epoch 3, Sample 14033: Loss: 1.0823\n",
            "Epoch 3, Sample 14034: Loss: 0.5003\n",
            "Epoch 3, Sample 14035: Loss: 0.0915\n",
            "Epoch 3, Sample 14036: Loss: 1.0070\n",
            "Epoch 3, Sample 14037: Loss: 0.8951\n",
            "Epoch 3, Sample 14038: Loss: 0.4382\n",
            "Epoch 3, Sample 14039: Loss: 0.0000\n",
            "Epoch 3, Sample 14040: Loss: 0.2494\n",
            "Epoch 3, Sample 14041: Loss: 1.2319\n",
            "Epoch 3, Sample 14042: Loss: 0.0019\n",
            "Epoch 3, Sample 14043: Loss: 0.1559\n",
            "Epoch 3, Sample 14044: Loss: 0.4003\n",
            "Epoch 3, Sample 14045: Loss: 0.1250\n",
            "Epoch 3, Sample 14046: Loss: 0.3915\n",
            "Epoch 3, Sample 14047: Loss: 0.6990\n",
            "Epoch 3, Sample 14048: Loss: 0.3598\n",
            "Epoch 3, Sample 14049: Loss: 0.2257\n",
            "Epoch 3, Sample 14050: Loss: 0.0062\n",
            "Epoch 3, Sample 14051: Loss: 0.4841\n",
            "Epoch 3, Sample 14052: Loss: 0.3288\n",
            "Epoch 3, Sample 14053: Loss: 0.9367\n",
            "Epoch 3, Sample 14054: Loss: 0.1989\n",
            "Epoch 3, Sample 14055: Loss: 0.2036\n",
            "Epoch 3, Sample 14056: Loss: 1.0524\n",
            "Epoch 3, Sample 14057: Loss: 0.2036\n",
            "Epoch 3, Sample 14058: Loss: 1.0524\n",
            "Epoch 3, Sample 14059: Loss: 0.8853\n",
            "Epoch 3, Sample 14060: Loss: 0.2044\n",
            "Epoch 3, Sample 14061: Loss: 0.4611\n",
            "Epoch 3, Sample 14062: Loss: 0.3539\n",
            "Epoch 3, Sample 14063: Loss: 1.0530\n",
            "Epoch 3, Sample 14064: Loss: 0.0176\n",
            "Epoch 3, Sample 14065: Loss: 0.0018\n",
            "Epoch 3, Sample 14066: Loss: 0.1170\n",
            "Epoch 3, Sample 14067: Loss: 0.0915\n",
            "Epoch 3, Sample 14068: Loss: 0.2219\n",
            "Epoch 3, Sample 14069: Loss: 0.0063\n",
            "Epoch 3, Sample 14070: Loss: 0.0630\n",
            "Epoch 3, Sample 14071: Loss: 0.2271\n",
            "Epoch 3, Sample 14072: Loss: 0.7036\n",
            "Epoch 3, Sample 14073: Loss: 0.1367\n",
            "Epoch 3, Sample 14074: Loss: 0.0625\n",
            "Epoch 3, Sample 14075: Loss: 0.8951\n",
            "Epoch 3, Sample 14076: Loss: 0.8951\n",
            "Epoch 3, Sample 14077: Loss: 0.6092\n",
            "Epoch 3, Sample 14078: Loss: 1.5105\n",
            "Epoch 3, Sample 14079: Loss: 1.4028\n",
            "Epoch 3, Sample 14080: Loss: 0.0691\n",
            "Epoch 3, Sample 14081: Loss: 0.5584\n",
            "Epoch 3, Sample 14082: Loss: 4.0051\n",
            "Epoch 3, Sample 14083: Loss: 0.2750\n",
            "Epoch 3, Sample 14084: Loss: 0.0915\n",
            "Epoch 3, Sample 14085: Loss: 2.0108\n",
            "Epoch 3, Sample 14086: Loss: 7.6417\n",
            "Epoch 3, Sample 14087: Loss: 0.3399\n",
            "Epoch 3, Sample 14088: Loss: 0.0168\n",
            "Epoch 3, Sample 14089: Loss: 0.3441\n",
            "Epoch 3, Sample 14090: Loss: 0.2044\n",
            "Epoch 3, Sample 14091: Loss: 0.1225\n",
            "Epoch 3, Sample 14092: Loss: 0.0915\n",
            "Epoch 3, Sample 14093: Loss: 0.1325\n",
            "Epoch 3, Sample 14094: Loss: 2.4773\n",
            "Epoch 3, Sample 14095: Loss: 0.3402\n",
            "Epoch 3, Sample 14096: Loss: 1.0530\n",
            "Epoch 3, Sample 14097: Loss: 0.1170\n",
            "Epoch 3, Sample 14098: Loss: 0.1091\n",
            "Epoch 3, Sample 14099: Loss: 0.1823\n",
            "Epoch 3, Sample 14100: Loss: 0.2034\n",
            "Epoch 3, Sample 14101: Loss: 0.2044\n",
            "Epoch 3, Sample 14102: Loss: 1.0524\n",
            "Epoch 3, Sample 14103: Loss: 0.3399\n",
            "Epoch 3, Sample 14104: Loss: 3.0907\n",
            "Epoch 3, Sample 14105: Loss: 0.7036\n",
            "Epoch 3, Sample 14106: Loss: 1.0524\n",
            "Epoch 3, Sample 14107: Loss: 0.2759\n",
            "Epoch 3, Sample 14108: Loss: 0.8951\n",
            "Epoch 3, Sample 14109: Loss: 0.1092\n",
            "Epoch 3, Sample 14110: Loss: 1.7258\n",
            "Epoch 3, Sample 14111: Loss: 0.2219\n",
            "Epoch 3, Sample 14112: Loss: 0.2846\n",
            "Epoch 3, Sample 14113: Loss: 0.0221\n",
            "Epoch 3, Sample 14114: Loss: 0.3949\n",
            "Epoch 3, Sample 14115: Loss: 0.1866\n",
            "Epoch 3, Sample 14116: Loss: 0.1364\n",
            "Epoch 3, Sample 14117: Loss: 0.0229\n",
            "Epoch 3, Sample 14118: Loss: 7.0089\n",
            "Epoch 3, Sample 14119: Loss: 0.0016\n",
            "Epoch 3, Sample 14120: Loss: 0.3399\n",
            "Epoch 3, Sample 14121: Loss: 1.0511\n",
            "Epoch 3, Sample 14122: Loss: 0.1694\n",
            "Epoch 3, Sample 14123: Loss: 0.3402\n",
            "Epoch 3, Sample 14124: Loss: 0.7136\n",
            "Epoch 3, Sample 14125: Loss: 0.2832\n",
            "Epoch 3, Sample 14126: Loss: 0.3830\n",
            "Epoch 3, Sample 14127: Loss: 0.3441\n",
            "Epoch 3, Sample 14128: Loss: 0.2044\n",
            "Epoch 3, Sample 14129: Loss: 0.2938\n",
            "Epoch 3, Sample 14130: Loss: 0.0303\n",
            "Epoch 3, Sample 14131: Loss: 1.1789\n",
            "Epoch 3, Sample 14132: Loss: 0.0002\n",
            "Epoch 3, Sample 14133: Loss: 0.1082\n",
            "Epoch 3, Sample 14134: Loss: 0.0363\n",
            "Epoch 3, Sample 14135: Loss: 0.5972\n",
            "Epoch 3, Sample 14136: Loss: 0.0915\n",
            "Epoch 3, Sample 14137: Loss: 0.1240\n",
            "Epoch 3, Sample 14138: Loss: 0.3399\n",
            "Epoch 3, Sample 14139: Loss: 1.0530\n",
            "Epoch 3, Sample 14140: Loss: 0.4841\n",
            "Epoch 3, Sample 14141: Loss: 0.2211\n",
            "Epoch 3, Sample 14142: Loss: 0.1250\n",
            "Epoch 3, Sample 14143: Loss: 0.3247\n",
            "Epoch 3, Sample 14144: Loss: 0.0938\n",
            "Epoch 3, Sample 14145: Loss: 0.3949\n",
            "Epoch 3, Sample 14146: Loss: 0.5858\n",
            "Epoch 3, Sample 14147: Loss: 0.2759\n",
            "Epoch 3, Sample 14148: Loss: 0.4032\n",
            "Epoch 3, Sample 14149: Loss: 0.3399\n",
            "Epoch 3, Sample 14150: Loss: 0.6092\n",
            "Epoch 3, Sample 14151: Loss: 0.1250\n",
            "Epoch 3, Sample 14152: Loss: 0.0144\n",
            "Epoch 3, Sample 14153: Loss: 0.1773\n",
            "Epoch 3, Sample 14154: Loss: 0.4930\n",
            "Epoch 3, Sample 14155: Loss: 0.3110\n",
            "Epoch 3, Sample 14156: Loss: 0.0306\n",
            "Epoch 3, Sample 14157: Loss: 0.0108\n",
            "Epoch 3, Sample 14158: Loss: 1.1189\n",
            "Epoch 3, Sample 14159: Loss: 0.0026\n",
            "Epoch 3, Sample 14160: Loss: 0.2687\n",
            "Epoch 3, Sample 14161: Loss: 0.4799\n",
            "Epoch 3, Sample 14162: Loss: 0.1403\n",
            "Epoch 3, Sample 14163: Loss: 0.0558\n",
            "Epoch 3, Sample 14164: Loss: 0.2044\n",
            "Epoch 3, Sample 14165: Loss: 0.1031\n",
            "Epoch 3, Sample 14166: Loss: 0.2032\n",
            "Epoch 3, Sample 14167: Loss: 0.0018\n",
            "Epoch 3, Sample 14168: Loss: 1.0524\n",
            "Epoch 3, Sample 14169: Loss: 0.0103\n",
            "Epoch 3, Sample 14170: Loss: 0.5375\n",
            "Epoch 3, Sample 14171: Loss: 0.0001\n",
            "Epoch 3, Sample 14172: Loss: 2.8356\n",
            "Epoch 3, Sample 14173: Loss: 0.4799\n",
            "Epoch 3, Sample 14174: Loss: 1.7923\n",
            "Epoch 3, Sample 14175: Loss: 0.2077\n",
            "Epoch 3, Sample 14176: Loss: 0.4032\n",
            "Epoch 3, Sample 14177: Loss: 0.2832\n",
            "Epoch 3, Sample 14178: Loss: 0.2044\n",
            "Epoch 3, Sample 14179: Loss: 0.2034\n",
            "Epoch 3, Sample 14180: Loss: 0.2290\n",
            "Epoch 3, Sample 14181: Loss: 0.5858\n",
            "Epoch 3, Sample 14182: Loss: 0.5972\n",
            "Epoch 3, Sample 14183: Loss: 0.0088\n",
            "Epoch 3, Sample 14184: Loss: 0.3441\n",
            "Epoch 3, Sample 14185: Loss: 0.1372\n",
            "Epoch 3, Sample 14186: Loss: 0.2832\n",
            "Epoch 3, Sample 14187: Loss: 0.0829\n",
            "Epoch 3, Sample 14188: Loss: 0.1559\n",
            "Epoch 3, Sample 14189: Loss: 0.2699\n",
            "Epoch 3, Sample 14190: Loss: 0.3450\n",
            "Epoch 3, Sample 14191: Loss: 0.0999\n",
            "Epoch 3, Sample 14192: Loss: 0.0026\n",
            "Epoch 3, Sample 14193: Loss: 0.3584\n",
            "Epoch 3, Sample 14194: Loss: 0.1170\n",
            "Epoch 3, Sample 14195: Loss: 0.6092\n",
            "Epoch 3, Sample 14196: Loss: 0.6139\n",
            "Epoch 3, Sample 14197: Loss: 1.0524\n",
            "Epoch 3, Sample 14198: Loss: 0.3449\n",
            "Epoch 3, Sample 14199: Loss: 0.0808\n",
            "Epoch 3, Sample 14200: Loss: 0.0168\n",
            "Epoch 3, Sample 14201: Loss: 0.0590\n",
            "Epoch 3, Sample 14202: Loss: 0.0026\n",
            "Epoch 3, Sample 14203: Loss: 0.2044\n",
            "Epoch 3, Sample 14204: Loss: 0.7036\n",
            "Epoch 3, Sample 14205: Loss: 0.7570\n",
            "Epoch 3, Sample 14206: Loss: 0.1113\n",
            "Epoch 3, Sample 14207: Loss: 0.0025\n",
            "Epoch 3, Sample 14208: Loss: 1.0524\n",
            "Epoch 3, Sample 14209: Loss: 0.0236\n",
            "Epoch 3, Sample 14210: Loss: 0.1826\n",
            "Epoch 3, Sample 14211: Loss: 0.4474\n",
            "Epoch 3, Sample 14212: Loss: 1.0524\n",
            "Epoch 3, Sample 14213: Loss: 0.3949\n",
            "Epoch 3, Sample 14214: Loss: 0.4611\n",
            "Epoch 3, Sample 14215: Loss: 0.5089\n",
            "Epoch 3, Sample 14216: Loss: 1.0524\n",
            "Epoch 3, Sample 14217: Loss: 0.0306\n",
            "Epoch 3, Sample 14218: Loss: 0.7509\n",
            "Epoch 3, Sample 14219: Loss: 0.2034\n",
            "Epoch 3, Sample 14220: Loss: 0.0026\n",
            "Epoch 3, Sample 14221: Loss: 0.0026\n",
            "Epoch 3, Sample 14222: Loss: 0.8893\n",
            "Epoch 3, Sample 14223: Loss: 0.2202\n",
            "Epoch 3, Sample 14224: Loss: 0.0384\n",
            "Epoch 3, Sample 14225: Loss: 0.3949\n",
            "Epoch 3, Sample 14226: Loss: 0.2639\n",
            "Epoch 3, Sample 14227: Loss: 0.2879\n",
            "Epoch 3, Sample 14228: Loss: 0.4663\n",
            "Epoch 3, Sample 14229: Loss: 0.2340\n",
            "Epoch 3, Sample 14230: Loss: 1.0530\n",
            "Epoch 3, Sample 14231: Loss: 0.0915\n",
            "Epoch 3, Sample 14232: Loss: 0.4799\n",
            "Epoch 3, Sample 14233: Loss: 1.0524\n",
            "Epoch 3, Sample 14234: Loss: 0.3399\n",
            "Epoch 3, Sample 14235: Loss: 0.2044\n",
            "Epoch 3, Sample 14236: Loss: 0.8951\n",
            "Epoch 3, Sample 14237: Loss: 0.3399\n",
            "Epoch 3, Sample 14238: Loss: 0.0013\n",
            "Epoch 3, Sample 14239: Loss: 0.1364\n",
            "Epoch 3, Sample 14240: Loss: 0.2591\n",
            "Epoch 3, Sample 14241: Loss: 0.0838\n",
            "Epoch 3, Sample 14242: Loss: 0.0604\n",
            "Epoch 3, Sample 14243: Loss: 0.0604\n",
            "Epoch 3, Sample 14244: Loss: 0.4071\n",
            "Epoch 3, Sample 14245: Loss: 0.2112\n",
            "Epoch 3, Sample 14246: Loss: 0.0234\n",
            "Epoch 3, Sample 14247: Loss: 0.2034\n",
            "Epoch 3, Sample 14248: Loss: 0.4611\n",
            "Epoch 3, Sample 14249: Loss: 0.0318\n",
            "Epoch 3, Sample 14250: Loss: 0.0915\n",
            "Epoch 3, Sample 14251: Loss: 0.6425\n",
            "Epoch 3, Sample 14252: Loss: 0.4930\n",
            "Epoch 3, Sample 14253: Loss: 0.0546\n",
            "Epoch 3, Sample 14254: Loss: 0.1278\n",
            "Epoch 3, Sample 14255: Loss: 0.2759\n",
            "Epoch 3, Sample 14256: Loss: 0.0122\n",
            "Epoch 3, Sample 14257: Loss: 0.3568\n",
            "Epoch 3, Sample 14258: Loss: 0.0006\n",
            "Epoch 3, Sample 14259: Loss: 0.1563\n",
            "Epoch 3, Sample 14260: Loss: 0.0018\n",
            "Epoch 3, Sample 14261: Loss: 0.6990\n",
            "Epoch 3, Sample 14262: Loss: 1.0266\n",
            "Epoch 3, Sample 14263: Loss: 0.3957\n",
            "Epoch 3, Sample 14264: Loss: 0.4382\n",
            "Epoch 3, Sample 14265: Loss: 0.2493\n",
            "Epoch 3, Sample 14266: Loss: 0.1559\n",
            "Epoch 3, Sample 14267: Loss: 0.0589\n",
            "Epoch 3, Sample 14268: Loss: 12.0464\n",
            "Epoch 3, Sample 14269: Loss: 0.0018\n",
            "Epoch 3, Sample 14270: Loss: 1.4062\n",
            "Epoch 3, Sample 14271: Loss: 0.3399\n",
            "Epoch 3, Sample 14272: Loss: 0.2639\n",
            "Epoch 3, Sample 14273: Loss: 0.0076\n",
            "Epoch 3, Sample 14274: Loss: 0.0083\n",
            "Epoch 3, Sample 14275: Loss: 0.0084\n",
            "Epoch 3, Sample 14276: Loss: 0.0177\n",
            "Epoch 3, Sample 14277: Loss: 0.0001\n",
            "Epoch 3, Sample 14278: Loss: 0.0303\n",
            "Epoch 3, Sample 14279: Loss: 0.0114\n",
            "Epoch 3, Sample 14280: Loss: 0.6990\n",
            "Epoch 3, Sample 14281: Loss: 0.5799\n",
            "Epoch 3, Sample 14282: Loss: 0.0054\n",
            "Epoch 3, Sample 14283: Loss: 0.9394\n",
            "Epoch 3, Sample 14284: Loss: 0.0938\n",
            "Epoch 3, Sample 14285: Loss: 0.5003\n",
            "Epoch 3, Sample 14286: Loss: 0.2032\n",
            "Epoch 3, Sample 14287: Loss: 0.0783\n",
            "Epoch 3, Sample 14288: Loss: 0.7453\n",
            "Epoch 3, Sample 14289: Loss: 0.2182\n",
            "Epoch 3, Sample 14290: Loss: 0.2132\n",
            "Epoch 3, Sample 14291: Loss: 0.0026\n",
            "Epoch 3, Sample 14292: Loss: 1.0530\n",
            "Epoch 3, Sample 14293: Loss: 0.0001\n",
            "Epoch 3, Sample 14294: Loss: 0.2034\n",
            "Epoch 3, Sample 14295: Loss: 0.1903\n",
            "Epoch 3, Sample 14296: Loss: 0.4799\n",
            "Epoch 3, Sample 14297: Loss: 0.2044\n",
            "Epoch 3, Sample 14298: Loss: 0.0063\n",
            "Epoch 3, Sample 14299: Loss: 0.0018\n",
            "Epoch 3, Sample 14300: Loss: 0.1170\n",
            "Epoch 3, Sample 14301: Loss: 1.0524\n",
            "Epoch 3, Sample 14302: Loss: 0.5858\n",
            "Epoch 3, Sample 14303: Loss: 1.0524\n",
            "Epoch 3, Sample 14304: Loss: 0.3402\n",
            "Epoch 3, Sample 14305: Loss: 0.1121\n",
            "Epoch 3, Sample 14306: Loss: 1.0524\n",
            "Epoch 3, Sample 14307: Loss: 0.1250\n",
            "Epoch 3, Sample 14308: Loss: 0.7135\n",
            "Epoch 3, Sample 14309: Loss: 0.0469\n",
            "Epoch 3, Sample 14310: Loss: 0.0415\n",
            "Epoch 3, Sample 14311: Loss: 0.3399\n",
            "Epoch 3, Sample 14312: Loss: 0.7036\n",
            "Epoch 3, Sample 14313: Loss: 0.2098\n",
            "Epoch 3, Sample 14314: Loss: 0.8951\n",
            "Epoch 3, Sample 14315: Loss: 0.0450\n",
            "Epoch 3, Sample 14316: Loss: 0.3399\n",
            "Epoch 3, Sample 14317: Loss: 0.4930\n",
            "Epoch 3, Sample 14318: Loss: 0.7036\n",
            "Epoch 3, Sample 14319: Loss: 0.2034\n",
            "Epoch 3, Sample 14320: Loss: 0.0640\n",
            "Epoch 3, Sample 14321: Loss: 0.6304\n",
            "Epoch 3, Sample 14322: Loss: 0.0838\n",
            "Epoch 3, Sample 14323: Loss: 0.0039\n",
            "Epoch 3, Sample 14324: Loss: 0.5858\n",
            "Epoch 3, Sample 14325: Loss: 0.2032\n",
            "Epoch 3, Sample 14326: Loss: 0.0364\n",
            "Epoch 3, Sample 14327: Loss: 0.2639\n",
            "Epoch 3, Sample 14328: Loss: 0.2044\n",
            "Epoch 3, Sample 14329: Loss: 0.5972\n",
            "Epoch 3, Sample 14330: Loss: 0.1316\n",
            "Epoch 3, Sample 14331: Loss: 1.0530\n",
            "Epoch 3, Sample 14332: Loss: 0.0001\n",
            "Epoch 3, Sample 14333: Loss: 0.0476\n",
            "Epoch 3, Sample 14334: Loss: 1.0530\n",
            "Epoch 3, Sample 14335: Loss: 0.0001\n",
            "Epoch 3, Sample 14336: Loss: 0.3480\n",
            "Epoch 3, Sample 14337: Loss: 0.2093\n",
            "Epoch 3, Sample 14338: Loss: 0.2832\n",
            "Epoch 3, Sample 14339: Loss: 1.0524\n",
            "Epoch 3, Sample 14340: Loss: 0.3758\n",
            "Epoch 3, Sample 14341: Loss: 1.2556\n",
            "Epoch 3, Sample 14342: Loss: 0.6304\n",
            "Epoch 3, Sample 14343: Loss: 0.0101\n",
            "Epoch 3, Sample 14344: Loss: 0.0063\n",
            "Epoch 3, Sample 14345: Loss: 0.1399\n",
            "Epoch 3, Sample 14346: Loss: 0.0006\n",
            "Epoch 3, Sample 14347: Loss: 1.0530\n",
            "Epoch 3, Sample 14348: Loss: 0.2639\n",
            "Epoch 3, Sample 14349: Loss: 0.7036\n",
            "Epoch 3, Sample 14350: Loss: 0.6070\n",
            "Epoch 3, Sample 14351: Loss: 0.1508\n",
            "Epoch 3, Sample 14352: Loss: 0.6990\n",
            "Epoch 3, Sample 14353: Loss: 0.3527\n",
            "Epoch 3, Sample 14354: Loss: 2.8910\n",
            "Epoch 3, Sample 14355: Loss: 0.0838\n",
            "Epoch 3, Sample 14356: Loss: 0.1007\n",
            "Epoch 3, Sample 14357: Loss: 1.0524\n",
            "Epoch 3, Sample 14358: Loss: 0.0018\n",
            "Epoch 3, Sample 14359: Loss: 0.4474\n",
            "Epoch 3, Sample 14360: Loss: 0.1374\n",
            "Epoch 3, Sample 14361: Loss: 0.0352\n",
            "Epoch 3, Sample 14362: Loss: 0.7453\n",
            "Epoch 3, Sample 14363: Loss: 0.6304\n",
            "Epoch 3, Sample 14364: Loss: 0.0238\n",
            "Epoch 3, Sample 14365: Loss: 0.0744\n",
            "Epoch 3, Sample 14366: Loss: 0.2879\n",
            "Epoch 3, Sample 14367: Loss: 0.5003\n",
            "Epoch 3, Sample 14368: Loss: 1.1586\n",
            "Epoch 3, Sample 14369: Loss: 0.4466\n",
            "Epoch 3, Sample 14370: Loss: 0.2032\n",
            "Epoch 3, Sample 14371: Loss: 0.7973\n",
            "Epoch 3, Sample 14372: Loss: 0.2044\n",
            "Epoch 3, Sample 14373: Loss: 0.5636\n",
            "Epoch 3, Sample 14374: Loss: 0.5000\n",
            "Epoch 3, Sample 14375: Loss: 0.2759\n",
            "Epoch 3, Sample 14376: Loss: 0.8484\n",
            "Epoch 3, Sample 14377: Loss: 1.1569\n",
            "Epoch 3, Sample 14378: Loss: 0.7036\n",
            "Epoch 3, Sample 14379: Loss: 0.0060\n",
            "Epoch 3, Sample 14380: Loss: 1.0530\n",
            "Epoch 3, Sample 14381: Loss: 0.0630\n",
            "Epoch 3, Sample 14382: Loss: 0.0270\n",
            "Epoch 3, Sample 14383: Loss: 0.2044\n",
            "Epoch 3, Sample 14384: Loss: 0.9336\n",
            "Epoch 3, Sample 14385: Loss: 0.0363\n",
            "Epoch 3, Sample 14386: Loss: 1.0070\n",
            "Epoch 3, Sample 14387: Loss: 0.3332\n",
            "Epoch 3, Sample 14388: Loss: 0.4382\n",
            "Epoch 3, Sample 14389: Loss: 0.3805\n",
            "Epoch 3, Sample 14390: Loss: 0.7036\n",
            "Epoch 3, Sample 14391: Loss: 0.4215\n",
            "Epoch 3, Sample 14392: Loss: 0.1559\n",
            "Epoch 3, Sample 14393: Loss: 0.9360\n",
            "Epoch 3, Sample 14394: Loss: 0.5858\n",
            "Epoch 3, Sample 14395: Loss: 0.2577\n",
            "Epoch 3, Sample 14396: Loss: 0.1093\n",
            "Epoch 3, Sample 14397: Loss: 1.0530\n",
            "Epoch 3, Sample 14398: Loss: 1.0524\n",
            "Epoch 3, Sample 14399: Loss: 0.4828\n",
            "Epoch 3, Sample 14400: Loss: 0.0013\n",
            "Epoch 3, Sample 14401: Loss: 0.6174\n",
            "Epoch 3, Sample 14402: Loss: 0.0026\n",
            "Epoch 3, Sample 14403: Loss: 0.5078\n",
            "Epoch 3, Sample 14404: Loss: 1.1662\n",
            "Epoch 3, Sample 14405: Loss: 1.0524\n",
            "Epoch 3, Sample 14406: Loss: 1.6694\n",
            "Epoch 3, Sample 14407: Loss: 1.0524\n",
            "Epoch 3, Sample 14408: Loss: 0.3399\n",
            "Epoch 3, Sample 14409: Loss: 1.9481\n",
            "Epoch 3, Sample 14410: Loss: 0.0018\n",
            "Epoch 3, Sample 14411: Loss: 0.0026\n",
            "Epoch 3, Sample 14412: Loss: 0.0026\n",
            "Epoch 3, Sample 14413: Loss: 0.2032\n",
            "Epoch 3, Sample 14414: Loss: 0.2836\n",
            "Epoch 3, Sample 14415: Loss: 0.5310\n",
            "Epoch 3, Sample 14416: Loss: 0.4002\n",
            "Epoch 3, Sample 14417: Loss: 2.3835\n",
            "Epoch 3, Sample 14418: Loss: 0.2044\n",
            "Epoch 3, Sample 14419: Loss: 0.0859\n",
            "Epoch 3, Sample 14420: Loss: 0.0001\n",
            "Epoch 3, Sample 14421: Loss: 0.1477\n",
            "Epoch 3, Sample 14422: Loss: 0.2759\n",
            "Epoch 3, Sample 14423: Loss: 1.3435\n",
            "Epoch 3, Sample 14424: Loss: 0.0421\n",
            "Epoch 3, Sample 14425: Loss: 0.4799\n",
            "Epoch 3, Sample 14426: Loss: 0.4474\n",
            "Epoch 3, Sample 14427: Loss: 0.1522\n",
            "Epoch 3, Sample 14428: Loss: 0.4841\n",
            "Epoch 3, Sample 14429: Loss: 0.6840\n",
            "Epoch 3, Sample 14430: Loss: 1.7209\n",
            "Epoch 3, Sample 14431: Loss: 0.0637\n",
            "Epoch 3, Sample 14432: Loss: 0.0707\n",
            "Epoch 3, Sample 14433: Loss: 0.4260\n",
            "Epoch 3, Sample 14434: Loss: 0.0018\n",
            "Epoch 3, Sample 14435: Loss: 1.0530\n",
            "Epoch 3, Sample 14436: Loss: 0.1170\n",
            "Epoch 3, Sample 14437: Loss: 0.2832\n",
            "Epoch 3, Sample 14438: Loss: 0.2034\n",
            "Epoch 3, Sample 14439: Loss: 0.3441\n",
            "Epoch 3, Sample 14440: Loss: 0.3186\n",
            "Epoch 3, Sample 14441: Loss: 0.7453\n",
            "Epoch 3, Sample 14442: Loss: 0.2962\n",
            "Epoch 3, Sample 14443: Loss: 0.1523\n",
            "Epoch 3, Sample 14444: Loss: 0.6304\n",
            "Epoch 3, Sample 14445: Loss: 1.0155\n",
            "Epoch 3, Sample 14446: Loss: 2.7340\n",
            "Epoch 3, Sample 14447: Loss: 0.0026\n",
            "Epoch 3, Sample 14448: Loss: 0.2044\n",
            "Epoch 3, Sample 14449: Loss: 0.7036\n",
            "Epoch 3, Sample 14450: Loss: 0.1559\n",
            "Epoch 3, Sample 14451: Loss: 0.5144\n",
            "Epoch 3, Sample 14452: Loss: 0.4381\n",
            "Epoch 3, Sample 14453: Loss: 0.2032\n",
            "Epoch 3, Sample 14454: Loss: 1.0524\n",
            "Epoch 3, Sample 14455: Loss: 1.1084\n",
            "Epoch 3, Sample 14456: Loss: 0.1559\n",
            "Epoch 3, Sample 14457: Loss: 0.7036\n",
            "Epoch 3, Sample 14458: Loss: 0.2112\n",
            "Epoch 3, Sample 14459: Loss: 8.6383\n",
            "Epoch 3, Sample 14460: Loss: 0.2032\n",
            "Epoch 3, Sample 14461: Loss: 0.2970\n",
            "Epoch 3, Sample 14462: Loss: 0.0985\n",
            "Epoch 3, Sample 14463: Loss: 0.2032\n",
            "Epoch 3, Sample 14464: Loss: 1.0524\n",
            "Epoch 3, Sample 14465: Loss: 2.9846\n",
            "Epoch 3, Sample 14466: Loss: 0.5000\n",
            "Epoch 3, Sample 14467: Loss: 0.1465\n",
            "Epoch 3, Sample 14468: Loss: 0.0026\n",
            "Epoch 3, Sample 14469: Loss: 0.4654\n",
            "Epoch 3, Sample 14470: Loss: 0.2832\n",
            "Epoch 3, Sample 14471: Loss: 0.0707\n",
            "Epoch 3, Sample 14472: Loss: 0.2036\n",
            "Epoch 3, Sample 14473: Loss: 0.5000\n",
            "Epoch 3, Sample 14474: Loss: 0.0713\n",
            "Epoch 3, Sample 14475: Loss: 0.0708\n",
            "Epoch 3, Sample 14476: Loss: 0.6436\n",
            "Epoch 3, Sample 14477: Loss: 0.0554\n",
            "Epoch 3, Sample 14478: Loss: 0.7036\n",
            "Epoch 3, Sample 14479: Loss: 0.0919\n",
            "Epoch 3, Sample 14480: Loss: 0.2704\n",
            "Epoch 3, Sample 14481: Loss: 0.2459\n",
            "Epoch 3, Sample 14482: Loss: 0.0042\n",
            "Epoch 3, Sample 14483: Loss: 0.1228\n",
            "Epoch 3, Sample 14484: Loss: 1.0155\n",
            "Epoch 3, Sample 14485: Loss: 0.0062\n",
            "Epoch 3, Sample 14486: Loss: 0.4799\n",
            "Epoch 3, Sample 14487: Loss: 0.2590\n",
            "Epoch 3, Sample 14488: Loss: 0.0077\n",
            "Epoch 3, Sample 14489: Loss: 0.2014\n",
            "Epoch 3, Sample 14490: Loss: 2.1015\n",
            "Epoch 3, Sample 14491: Loss: 0.2525\n",
            "Epoch 3, Sample 14492: Loss: 0.4032\n",
            "Epoch 3, Sample 14493: Loss: 1.0524\n",
            "Epoch 3, Sample 14494: Loss: 0.0915\n",
            "Epoch 3, Sample 14495: Loss: 2.4145\n",
            "Epoch 3, Sample 14496: Loss: 0.2855\n",
            "Epoch 3, Sample 14497: Loss: 0.5003\n",
            "Epoch 3, Sample 14498: Loss: 0.0026\n",
            "Epoch 3, Sample 14499: Loss: 0.2034\n",
            "Epoch 3, Sample 14500: Loss: 0.1225\n",
            "Epoch 3, Sample 14501: Loss: 0.4799\n",
            "Epoch 3, Sample 14502: Loss: 0.3399\n",
            "Epoch 3, Sample 14503: Loss: 0.0067\n",
            "Epoch 3, Sample 14504: Loss: 3.2060\n",
            "Epoch 3, Sample 14505: Loss: 0.5677\n",
            "Epoch 3, Sample 14506: Loss: 0.2034\n",
            "Epoch 3, Sample 14507: Loss: 1.2768\n",
            "Epoch 3, Sample 14508: Loss: 0.2832\n",
            "Epoch 3, Sample 14509: Loss: 0.3565\n",
            "Epoch 3, Sample 14510: Loss: 0.0001\n",
            "Epoch 3, Sample 14511: Loss: 0.1154\n",
            "Epoch 3, Sample 14512: Loss: 0.5858\n",
            "Epoch 3, Sample 14513: Loss: 0.7036\n",
            "Epoch 3, Sample 14514: Loss: 0.2036\n",
            "Epoch 3, Sample 14515: Loss: 0.2366\n",
            "Epoch 3, Sample 14516: Loss: 0.5693\n",
            "Epoch 3, Sample 14517: Loss: 0.0429\n",
            "Epoch 3, Sample 14518: Loss: 0.1170\n",
            "Epoch 3, Sample 14519: Loss: 0.0000\n",
            "Epoch 3, Sample 14520: Loss: 0.0625\n",
            "Epoch 3, Sample 14521: Loss: 0.8951\n",
            "Epoch 3, Sample 14522: Loss: 0.3506\n",
            "Epoch 3, Sample 14523: Loss: 0.4611\n",
            "Epoch 3, Sample 14524: Loss: 1.0524\n",
            "Epoch 3, Sample 14525: Loss: 0.2639\n",
            "Epoch 3, Sample 14526: Loss: 0.2759\n",
            "Epoch 3, Sample 14527: Loss: 0.7036\n",
            "Epoch 3, Sample 14528: Loss: 0.4174\n",
            "Epoch 3, Sample 14529: Loss: 0.0030\n",
            "Epoch 3, Sample 14530: Loss: 0.8655\n",
            "Epoch 3, Sample 14531: Loss: 0.0258\n",
            "Epoch 3, Sample 14532: Loss: 0.7779\n",
            "Epoch 3, Sample 14533: Loss: 0.3399\n",
            "Epoch 3, Sample 14534: Loss: 0.7036\n",
            "Epoch 3, Sample 14535: Loss: 0.0018\n",
            "Epoch 3, Sample 14536: Loss: 0.0258\n",
            "Epoch 3, Sample 14537: Loss: 1.0530\n",
            "Epoch 3, Sample 14538: Loss: 0.5000\n",
            "Epoch 3, Sample 14539: Loss: 0.1518\n",
            "Epoch 3, Sample 14540: Loss: 0.2044\n",
            "Epoch 3, Sample 14541: Loss: 0.2032\n",
            "Epoch 3, Sample 14542: Loss: 0.3441\n",
            "Epoch 3, Sample 14543: Loss: 1.0524\n",
            "Epoch 3, Sample 14544: Loss: 0.3399\n",
            "Epoch 3, Sample 14545: Loss: 0.2036\n",
            "Epoch 3, Sample 14546: Loss: 0.0018\n",
            "Epoch 3, Sample 14547: Loss: 1.1337\n",
            "Epoch 3, Sample 14548: Loss: 0.3441\n",
            "Epoch 3, Sample 14549: Loss: 0.0000\n",
            "Epoch 3, Sample 14550: Loss: 0.0024\n",
            "Epoch 3, Sample 14551: Loss: 0.1170\n",
            "Epoch 3, Sample 14552: Loss: 0.3598\n",
            "Epoch 3, Sample 14553: Loss: 0.0594\n",
            "Epoch 3, Sample 14554: Loss: 0.2494\n",
            "Epoch 3, Sample 14555: Loss: 0.1250\n",
            "Epoch 3, Sample 14556: Loss: 0.0915\n",
            "Epoch 3, Sample 14557: Loss: 0.0630\n",
            "Epoch 3, Sample 14558: Loss: 0.3758\n",
            "Epoch 3, Sample 14559: Loss: 0.4841\n",
            "Epoch 3, Sample 14560: Loss: 0.0145\n",
            "Epoch 3, Sample 14561: Loss: 0.1989\n",
            "Epoch 3, Sample 14562: Loss: 0.2036\n",
            "Epoch 3, Sample 14563: Loss: 1.0524\n",
            "Epoch 3, Sample 14564: Loss: 0.0018\n",
            "Epoch 3, Sample 14565: Loss: 1.0524\n",
            "Epoch 3, Sample 14566: Loss: 0.3568\n",
            "Epoch 3, Sample 14567: Loss: 1.0530\n",
            "Epoch 3, Sample 14568: Loss: 0.7036\n",
            "Epoch 3, Sample 14569: Loss: 0.0001\n",
            "Epoch 3, Sample 14570: Loss: 0.7073\n",
            "Epoch 3, Sample 14571: Loss: 0.2044\n",
            "Epoch 3, Sample 14572: Loss: 0.2044\n",
            "Epoch 3, Sample 14573: Loss: 0.2044\n",
            "Epoch 3, Sample 14574: Loss: 1.0524\n",
            "Epoch 3, Sample 14575: Loss: 0.0067\n",
            "Epoch 3, Sample 14576: Loss: 0.4281\n",
            "Epoch 3, Sample 14577: Loss: 0.2566\n",
            "Epoch 3, Sample 14578: Loss: 0.7036\n",
            "Epoch 3, Sample 14579: Loss: 0.2996\n",
            "Epoch 3, Sample 14580: Loss: 0.0036\n",
            "Epoch 3, Sample 14581: Loss: 0.0025\n",
            "Epoch 3, Sample 14582: Loss: 0.3949\n",
            "Epoch 3, Sample 14583: Loss: 0.0026\n",
            "Epoch 3, Sample 14584: Loss: 0.2112\n",
            "Epoch 3, Sample 14585: Loss: 0.2044\n",
            "Epoch 3, Sample 14586: Loss: 1.0524\n",
            "Epoch 3, Sample 14587: Loss: 2.0248\n",
            "Epoch 3, Sample 14588: Loss: 0.0212\n",
            "Epoch 3, Sample 14589: Loss: 11.6081\n",
            "Epoch 3, Sample 14590: Loss: 0.3301\n",
            "Epoch 3, Sample 14591: Loss: 0.0155\n",
            "Epoch 3, Sample 14592: Loss: 0.1523\n",
            "Epoch 3, Sample 14593: Loss: 0.8944\n",
            "Epoch 3, Sample 14594: Loss: 0.7036\n",
            "Epoch 3, Sample 14595: Loss: 0.0145\n",
            "Epoch 3, Sample 14596: Loss: 0.0522\n",
            "Epoch 3, Sample 14597: Loss: 0.8953\n",
            "Epoch 3, Sample 14598: Loss: 0.0630\n",
            "Epoch 3, Sample 14599: Loss: 0.2664\n",
            "Epoch 3, Sample 14600: Loss: 0.2339\n",
            "Epoch 3, Sample 14601: Loss: 0.0625\n",
            "Epoch 3, Sample 14602: Loss: 0.3399\n",
            "Epoch 3, Sample 14603: Loss: 2.3175\n",
            "Epoch 3, Sample 14604: Loss: 1.4239\n",
            "Epoch 3, Sample 14605: Loss: 0.0055\n",
            "Epoch 3, Sample 14606: Loss: 0.1195\n",
            "Epoch 3, Sample 14607: Loss: 0.0001\n",
            "Epoch 3, Sample 14608: Loss: 0.1419\n",
            "Epoch 3, Sample 14609: Loss: 0.4930\n",
            "Epoch 3, Sample 14610: Loss: 0.0208\n",
            "Epoch 3, Sample 14611: Loss: 0.3658\n",
            "Epoch 3, Sample 14612: Loss: 0.3036\n",
            "Epoch 3, Sample 14613: Loss: 0.0630\n",
            "Epoch 3, Sample 14614: Loss: 0.0027\n",
            "Epoch 3, Sample 14615: Loss: 0.2034\n",
            "Epoch 3, Sample 14616: Loss: 0.0002\n",
            "Epoch 3, Sample 14617: Loss: 0.0630\n",
            "Epoch 3, Sample 14618: Loss: 0.0018\n",
            "Epoch 3, Sample 14619: Loss: 0.0205\n",
            "Epoch 3, Sample 14620: Loss: 0.2759\n",
            "Epoch 3, Sample 14621: Loss: 0.3441\n",
            "Epoch 3, Sample 14622: Loss: 1.0227\n",
            "Epoch 3, Sample 14623: Loss: 0.2036\n",
            "Epoch 3, Sample 14624: Loss: 0.6202\n",
            "Epoch 3, Sample 14625: Loss: 0.4930\n",
            "Epoch 3, Sample 14626: Loss: 1.0524\n",
            "Epoch 3, Sample 14627: Loss: 0.2032\n",
            "Epoch 3, Sample 14628: Loss: 0.7036\n",
            "Epoch 3, Sample 14629: Loss: 0.1337\n",
            "Epoch 3, Sample 14630: Loss: 0.0425\n",
            "Epoch 3, Sample 14631: Loss: 0.2255\n",
            "Epoch 3, Sample 14632: Loss: 1.3034\n",
            "Epoch 3, Sample 14633: Loss: 0.2034\n",
            "Epoch 3, Sample 14634: Loss: 0.6990\n",
            "Epoch 3, Sample 14635: Loss: 0.0200\n",
            "Epoch 3, Sample 14636: Loss: 0.3399\n",
            "Epoch 3, Sample 14637: Loss: 0.5726\n",
            "Epoch 3, Sample 14638: Loss: 0.0630\n",
            "Epoch 3, Sample 14639: Loss: 0.0112\n",
            "Epoch 3, Sample 14640: Loss: 0.0915\n",
            "Epoch 3, Sample 14641: Loss: 0.5806\n",
            "Epoch 3, Sample 14642: Loss: 0.1559\n",
            "Epoch 3, Sample 14643: Loss: 0.8337\n",
            "Epoch 3, Sample 14644: Loss: 0.0026\n",
            "Epoch 3, Sample 14645: Loss: 0.2340\n",
            "Epoch 3, Sample 14646: Loss: 0.4632\n",
            "Epoch 3, Sample 14647: Loss: 0.0000\n",
            "Epoch 3, Sample 14648: Loss: 0.2032\n",
            "Epoch 3, Sample 14649: Loss: 1.1569\n",
            "Epoch 3, Sample 14650: Loss: 0.0013\n",
            "Epoch 3, Sample 14651: Loss: 0.0018\n",
            "Epoch 3, Sample 14652: Loss: 0.0370\n",
            "Epoch 3, Sample 14653: Loss: 1.0155\n",
            "Epoch 3, Sample 14654: Loss: 0.0819\n",
            "Epoch 3, Sample 14655: Loss: 0.7036\n",
            "Epoch 3, Sample 14656: Loss: 0.1092\n",
            "Epoch 3, Sample 14657: Loss: 0.2034\n",
            "Epoch 3, Sample 14658: Loss: 0.1817\n",
            "Epoch 3, Sample 14659: Loss: 0.8484\n",
            "Epoch 3, Sample 14660: Loss: 0.2032\n",
            "Epoch 3, Sample 14661: Loss: 0.2044\n",
            "Epoch 3, Sample 14662: Loss: 0.1486\n",
            "Epoch 3, Sample 14663: Loss: 0.9268\n",
            "Epoch 3, Sample 14664: Loss: 0.7464\n",
            "Epoch 3, Sample 14665: Loss: 0.0125\n",
            "Epoch 3, Sample 14666: Loss: 0.1588\n",
            "Epoch 3, Sample 14667: Loss: 0.2044\n",
            "Epoch 3, Sample 14668: Loss: 0.7036\n",
            "Epoch 3, Sample 14669: Loss: 0.0706\n",
            "Epoch 3, Sample 14670: Loss: 0.4996\n",
            "Epoch 3, Sample 14671: Loss: 0.0026\n",
            "Epoch 3, Sample 14672: Loss: 0.8951\n",
            "Epoch 3, Sample 14673: Loss: 0.1250\n",
            "Epoch 3, Sample 14674: Loss: 0.0343\n",
            "Epoch 3, Sample 14675: Loss: 0.2112\n",
            "Epoch 3, Sample 14676: Loss: 0.0040\n",
            "Epoch 3, Sample 14677: Loss: 0.2639\n",
            "Epoch 3, Sample 14678: Loss: 0.1555\n",
            "Epoch 3, Sample 14679: Loss: 0.0838\n",
            "Epoch 3, Sample 14680: Loss: 0.0938\n",
            "Epoch 3, Sample 14681: Loss: 0.3399\n",
            "Epoch 3, Sample 14682: Loss: 1.0524\n",
            "Epoch 3, Sample 14683: Loss: 0.7346\n",
            "Epoch 3, Sample 14684: Loss: 0.0947\n",
            "Epoch 3, Sample 14685: Loss: 0.1588\n",
            "Epoch 3, Sample 14686: Loss: 0.0108\n",
            "Epoch 3, Sample 14687: Loss: 0.2494\n",
            "Epoch 3, Sample 14688: Loss: 0.1559\n",
            "Epoch 3, Sample 14689: Loss: 0.0001\n",
            "Epoch 3, Sample 14690: Loss: 2.6205\n",
            "Epoch 3, Sample 14691: Loss: 0.0630\n",
            "Epoch 3, Sample 14692: Loss: 0.3551\n",
            "Epoch 3, Sample 14693: Loss: 1.0155\n",
            "Epoch 3, Sample 14694: Loss: 0.5871\n",
            "Epoch 3, Sample 14695: Loss: 0.5000\n",
            "Epoch 3, Sample 14696: Loss: 0.0018\n",
            "Epoch 3, Sample 14697: Loss: 0.2685\n",
            "Epoch 3, Sample 14698: Loss: 0.0630\n",
            "Epoch 3, Sample 14699: Loss: 0.2044\n",
            "Epoch 3, Sample 14700: Loss: 0.3707\n",
            "Epoch 3, Sample 14701: Loss: 0.2044\n",
            "Epoch 3, Sample 14702: Loss: 0.2639\n",
            "Epoch 3, Sample 14703: Loss: 0.1170\n",
            "Epoch 3, Sample 14704: Loss: 0.1250\n",
            "Epoch 3, Sample 14705: Loss: 0.7036\n",
            "Epoch 3, Sample 14706: Loss: 2.4892\n",
            "Epoch 3, Sample 14707: Loss: 1.0524\n",
            "Epoch 3, Sample 14708: Loss: 0.1250\n",
            "Epoch 3, Sample 14709: Loss: 0.0679\n",
            "Epoch 3, Sample 14710: Loss: 1.0227\n",
            "Epoch 3, Sample 14711: Loss: 1.0524\n",
            "Epoch 3, Sample 14712: Loss: 0.2704\n",
            "Epoch 3, Sample 14713: Loss: 0.1337\n",
            "Epoch 3, Sample 14714: Loss: 0.0322\n",
            "Epoch 3, Sample 14715: Loss: 0.2044\n",
            "Epoch 3, Sample 14716: Loss: 0.0019\n",
            "Epoch 3, Sample 14717: Loss: 1.1083\n",
            "Epoch 3, Sample 14718: Loss: 2.5382\n",
            "Epoch 3, Sample 14719: Loss: 0.0022\n",
            "Epoch 3, Sample 14720: Loss: 0.0630\n",
            "Epoch 3, Sample 14721: Loss: 0.2851\n",
            "Epoch 3, Sample 14722: Loss: 0.2044\n",
            "Epoch 3, Sample 14723: Loss: 0.0000\n",
            "Epoch 3, Sample 14724: Loss: 0.1252\n",
            "Epoch 3, Sample 14725: Loss: 0.7036\n",
            "Epoch 3, Sample 14726: Loss: 0.6092\n",
            "Epoch 3, Sample 14727: Loss: 0.2759\n",
            "Epoch 3, Sample 14728: Loss: 1.0524\n",
            "Epoch 3, Sample 14729: Loss: 0.1887\n",
            "Epoch 3, Sample 14730: Loss: 0.0005\n",
            "Epoch 3, Sample 14731: Loss: 0.0767\n",
            "Epoch 3, Sample 14732: Loss: 0.1378\n",
            "Epoch 3, Sample 14733: Loss: 0.0915\n",
            "Epoch 3, Sample 14734: Loss: 0.0009\n",
            "Epoch 3, Sample 14735: Loss: 0.7036\n",
            "Epoch 3, Sample 14736: Loss: 0.5858\n",
            "Epoch 3, Sample 14737: Loss: 0.0212\n",
            "Epoch 3, Sample 14738: Loss: 0.1523\n",
            "Epoch 3, Sample 14739: Loss: 0.0026\n",
            "Epoch 3, Sample 14740: Loss: 0.4032\n",
            "Epoch 3, Sample 14741: Loss: 2.1043\n",
            "Epoch 3, Sample 14742: Loss: 0.0838\n",
            "Epoch 3, Sample 14743: Loss: 0.7036\n",
            "Epoch 3, Sample 14744: Loss: 0.2841\n",
            "Epoch 3, Sample 14745: Loss: 0.2759\n",
            "Epoch 3, Sample 14746: Loss: 0.3441\n",
            "Epoch 3, Sample 14747: Loss: 2.4732\n",
            "Epoch 3, Sample 14748: Loss: 0.1337\n",
            "Epoch 3, Sample 14749: Loss: 0.5871\n",
            "Epoch 3, Sample 14750: Loss: 0.7453\n",
            "Epoch 3, Sample 14751: Loss: 0.5329\n",
            "Epoch 3, Sample 14752: Loss: 0.3399\n",
            "Epoch 3, Sample 14753: Loss: 0.0270\n",
            "Epoch 3, Sample 14754: Loss: 0.2639\n",
            "Epoch 3, Sample 14755: Loss: 0.2544\n",
            "Epoch 3, Sample 14756: Loss: 0.1851\n",
            "Epoch 3, Sample 14757: Loss: 0.0229\n",
            "Epoch 3, Sample 14758: Loss: 0.0853\n",
            "Epoch 3, Sample 14759: Loss: 3.4424\n",
            "Epoch 3, Sample 14760: Loss: 0.1334\n",
            "Epoch 3, Sample 14761: Loss: 0.0363\n",
            "Epoch 3, Sample 14762: Loss: 0.5196\n",
            "Epoch 3, Sample 14763: Loss: 0.2034\n",
            "Epoch 3, Sample 14764: Loss: 1.0266\n",
            "Epoch 3, Sample 14765: Loss: 0.0303\n",
            "Epoch 3, Sample 14766: Loss: 0.1774\n",
            "Epoch 3, Sample 14767: Loss: 0.0306\n",
            "Epoch 3, Sample 14768: Loss: 0.5602\n",
            "Epoch 3, Sample 14769: Loss: 0.9576\n",
            "Epoch 3, Sample 14770: Loss: 0.2962\n",
            "Epoch 3, Sample 14771: Loss: 0.7036\n",
            "Epoch 3, Sample 14772: Loss: 0.1250\n",
            "Epoch 3, Sample 14773: Loss: 0.3399\n",
            "Epoch 3, Sample 14774: Loss: 1.0155\n",
            "Epoch 3, Sample 14775: Loss: 0.0031\n",
            "Epoch 3, Sample 14776: Loss: 1.0524\n",
            "Epoch 3, Sample 14777: Loss: 0.2219\n",
            "Epoch 3, Sample 14778: Loss: 0.7036\n",
            "Epoch 3, Sample 14779: Loss: 0.2576\n",
            "Epoch 3, Sample 14780: Loss: 0.1199\n",
            "Epoch 3, Sample 14781: Loss: 0.8143\n",
            "Epoch 3, Sample 14782: Loss: 0.0025\n",
            "Epoch 3, Sample 14783: Loss: 0.0925\n",
            "Epoch 3, Sample 14784: Loss: 0.2044\n",
            "Epoch 3, Sample 14785: Loss: 0.0084\n",
            "Epoch 3, Sample 14786: Loss: 0.1170\n",
            "Epoch 3, Sample 14787: Loss: 0.0205\n",
            "Epoch 3, Sample 14788: Loss: 0.0915\n",
            "Epoch 3, Sample 14789: Loss: 0.5858\n",
            "Epoch 3, Sample 14790: Loss: 0.1250\n",
            "Epoch 3, Sample 14791: Loss: 0.0098\n",
            "Epoch 3, Sample 14792: Loss: 1.0530\n",
            "Epoch 3, Sample 14793: Loss: 0.2086\n",
            "Epoch 3, Sample 14794: Loss: 0.1605\n",
            "Epoch 3, Sample 14795: Loss: 0.5972\n",
            "Epoch 3, Sample 14796: Loss: 0.3399\n",
            "Epoch 3, Sample 14797: Loss: 0.2558\n",
            "Epoch 3, Sample 14798: Loss: 0.0011\n",
            "Epoch 3, Sample 14799: Loss: 1.0155\n",
            "Epoch 3, Sample 14800: Loss: 0.0026\n",
            "Epoch 3, Sample 14801: Loss: 0.2044\n",
            "Epoch 3, Sample 14802: Loss: 0.6990\n",
            "Epoch 3, Sample 14803: Loss: 0.0689\n",
            "Epoch 3, Sample 14804: Loss: 0.0630\n",
            "Epoch 3, Sample 14805: Loss: 0.0088\n",
            "Epoch 3, Sample 14806: Loss: 0.8484\n",
            "Epoch 3, Sample 14807: Loss: 0.2034\n",
            "Epoch 3, Sample 14808: Loss: 0.2032\n",
            "Epoch 3, Sample 14809: Loss: 0.2759\n",
            "Epoch 3, Sample 14810: Loss: 0.1250\n",
            "Epoch 3, Sample 14811: Loss: 1.0524\n",
            "Epoch 3, Sample 14812: Loss: 1.0155\n",
            "Epoch 3, Sample 14813: Loss: 0.7561\n",
            "Epoch 3, Sample 14814: Loss: 0.1673\n",
            "Epoch 3, Sample 14815: Loss: 0.2989\n",
            "Epoch 3, Sample 14816: Loss: 0.2719\n",
            "Epoch 3, Sample 14817: Loss: 1.0266\n",
            "Epoch 3, Sample 14818: Loss: 0.0838\n",
            "Epoch 3, Sample 14819: Loss: 0.2219\n",
            "Epoch 3, Sample 14820: Loss: 0.3402\n",
            "Epoch 3, Sample 14821: Loss: 0.1097\n",
            "Epoch 3, Sample 14822: Loss: 0.2759\n",
            "Epoch 3, Sample 14823: Loss: 1.0524\n",
            "Epoch 3, Sample 14824: Loss: 0.3949\n",
            "Epoch 3, Sample 14825: Loss: 0.5636\n",
            "Epoch 3, Sample 14826: Loss: 0.2057\n",
            "Epoch 3, Sample 14827: Loss: 0.0000\n",
            "Epoch 3, Sample 14828: Loss: 0.0658\n",
            "Epoch 3, Sample 14829: Loss: 0.7036\n",
            "Epoch 3, Sample 14830: Loss: 0.2099\n",
            "Epoch 3, Sample 14831: Loss: 5.5067\n",
            "Epoch 3, Sample 14832: Loss: 0.0133\n",
            "Epoch 3, Sample 14833: Loss: 0.7453\n",
            "Epoch 3, Sample 14834: Loss: 0.3441\n",
            "Epoch 3, Sample 14835: Loss: 0.1674\n",
            "Epoch 3, Sample 14836: Loss: 0.0554\n",
            "Epoch 3, Sample 14837: Loss: 0.4382\n",
            "Epoch 3, Sample 14838: Loss: 0.2044\n",
            "Epoch 3, Sample 14839: Loss: 0.3399\n",
            "Epoch 3, Sample 14840: Loss: 0.6139\n",
            "Epoch 3, Sample 14841: Loss: 1.0524\n",
            "Epoch 3, Sample 14842: Loss: 0.3441\n",
            "Epoch 3, Sample 14843: Loss: 0.0157\n",
            "Epoch 3, Sample 14844: Loss: 16.8849\n",
            "Epoch 3, Sample 14845: Loss: 0.0313\n",
            "Epoch 3, Sample 14846: Loss: 0.2639\n",
            "Epoch 3, Sample 14847: Loss: 0.0001\n",
            "Epoch 3, Sample 14848: Loss: 0.0960\n",
            "Epoch 3, Sample 14849: Loss: 0.0699\n",
            "Epoch 3, Sample 14850: Loss: 1.0155\n",
            "Epoch 3, Sample 14851: Loss: 0.0026\n",
            "Epoch 3, Sample 14852: Loss: 0.2036\n",
            "Epoch 3, Sample 14853: Loss: 0.0026\n",
            "Epoch 3, Sample 14854: Loss: 0.5160\n",
            "Epoch 3, Sample 14855: Loss: 0.0018\n",
            "Epoch 3, Sample 14856: Loss: 0.0042\n",
            "Epoch 3, Sample 14857: Loss: 0.2832\n",
            "Epoch 3, Sample 14858: Loss: 0.7484\n",
            "Epoch 3, Sample 14859: Loss: 0.0108\n",
            "Epoch 3, Sample 14860: Loss: 0.5393\n",
            "Epoch 3, Sample 14861: Loss: 0.0567\n",
            "Epoch 3, Sample 14862: Loss: 0.3399\n",
            "Epoch 3, Sample 14863: Loss: 1.0359\n",
            "Epoch 3, Sample 14864: Loss: 0.3441\n",
            "Epoch 3, Sample 14865: Loss: 0.0391\n",
            "Epoch 3, Sample 14866: Loss: 0.0477\n",
            "Epoch 3, Sample 14867: Loss: 1.0530\n",
            "Epoch 3, Sample 14868: Loss: 0.0380\n",
            "Epoch 3, Sample 14869: Loss: 2.7770\n",
            "Epoch 3, Sample 14870: Loss: 0.0005\n",
            "Epoch 3, Sample 14871: Loss: 0.0282\n",
            "Epoch 3, Sample 14872: Loss: 0.8951\n",
            "Epoch 3, Sample 14873: Loss: 0.0507\n",
            "Epoch 3, Sample 14874: Loss: 0.0203\n",
            "Epoch 3, Sample 14875: Loss: 0.4607\n",
            "Epoch 3, Sample 14876: Loss: 0.1559\n",
            "Epoch 3, Sample 14877: Loss: 0.0140\n",
            "Epoch 3, Sample 14878: Loss: 0.9367\n",
            "Epoch 3, Sample 14879: Loss: 0.2494\n",
            "Epoch 3, Sample 14880: Loss: 0.7453\n",
            "Epoch 3, Sample 14881: Loss: 0.1248\n",
            "Epoch 3, Sample 14882: Loss: 0.3126\n",
            "Epoch 3, Sample 14883: Loss: 0.5000\n",
            "Epoch 3, Sample 14884: Loss: 0.2036\n",
            "Epoch 3, Sample 14885: Loss: 1.0530\n",
            "Epoch 3, Sample 14886: Loss: 0.1170\n",
            "Epoch 3, Sample 14887: Loss: 0.2044\n",
            "Epoch 3, Sample 14888: Loss: 0.4032\n",
            "Epoch 3, Sample 14889: Loss: 0.3441\n",
            "Epoch 3, Sample 14890: Loss: 0.3399\n",
            "Epoch 3, Sample 14891: Loss: 0.0938\n",
            "Epoch 3, Sample 14892: Loss: 0.7036\n",
            "Epoch 3, Sample 14893: Loss: 2.3232\n",
            "Epoch 3, Sample 14894: Loss: 0.0258\n",
            "Epoch 3, Sample 14895: Loss: 0.0286\n",
            "Epoch 3, Sample 14896: Loss: 0.0034\n",
            "Epoch 3, Sample 14897: Loss: 0.6092\n",
            "Epoch 3, Sample 14898: Loss: 1.0524\n",
            "Epoch 3, Sample 14899: Loss: 1.4187\n",
            "Epoch 3, Sample 14900: Loss: 0.3949\n",
            "Epoch 3, Sample 14901: Loss: 0.6867\n",
            "Epoch 3, Sample 14902: Loss: 0.1056\n",
            "Epoch 3, Sample 14903: Loss: 0.0026\n",
            "Epoch 3, Sample 14904: Loss: 0.3758\n",
            "Epoch 3, Sample 14905: Loss: 1.0524\n",
            "Epoch 3, Sample 14906: Loss: 0.1217\n",
            "Epoch 3, Sample 14907: Loss: 0.8397\n",
            "Epoch 3, Sample 14908: Loss: 0.4644\n",
            "Epoch 3, Sample 14909: Loss: 1.0155\n",
            "Epoch 3, Sample 14910: Loss: 0.0018\n",
            "Epoch 3, Sample 14911: Loss: 0.2044\n",
            "Epoch 3, Sample 14912: Loss: 0.0026\n",
            "Epoch 3, Sample 14913: Loss: 0.0205\n",
            "Epoch 3, Sample 14914: Loss: 0.0368\n",
            "Epoch 3, Sample 14915: Loss: 0.5003\n",
            "Epoch 3, Sample 14916: Loss: 0.0363\n",
            "Epoch 3, Sample 14917: Loss: 0.6990\n",
            "Epoch 3, Sample 14918: Loss: 0.3441\n",
            "Epoch 3, Sample 14919: Loss: 2.4584\n",
            "Epoch 3, Sample 14920: Loss: 0.2032\n",
            "Epoch 3, Sample 14921: Loss: 0.0150\n",
            "Epoch 3, Sample 14922: Loss: 0.1170\n",
            "Epoch 3, Sample 14923: Loss: 0.0062\n",
            "Epoch 3, Sample 14924: Loss: 0.0007\n",
            "Epoch 3, Sample 14925: Loss: 0.0626\n",
            "Epoch 3, Sample 14926: Loss: 0.0001\n",
            "Epoch 3, Sample 14927: Loss: 0.6304\n",
            "Epoch 3, Sample 14928: Loss: 0.0025\n",
            "Epoch 3, Sample 14929: Loss: 2.0330\n",
            "Epoch 3, Sample 14930: Loss: 0.0018\n",
            "Epoch 3, Sample 14931: Loss: 0.0802\n",
            "Epoch 3, Sample 14932: Loss: 0.3399\n",
            "Epoch 3, Sample 14933: Loss: 0.0108\n",
            "Epoch 3, Sample 14934: Loss: 3.0448\n",
            "Epoch 3, Sample 14935: Loss: 0.2631\n",
            "Epoch 3, Sample 14936: Loss: 0.3441\n",
            "Epoch 3, Sample 14937: Loss: 0.2182\n",
            "Epoch 3, Sample 14938: Loss: 0.0013\n",
            "Epoch 3, Sample 14939: Loss: 0.3399\n",
            "Epoch 3, Sample 14940: Loss: 0.6304\n",
            "Epoch 3, Sample 14941: Loss: 0.1701\n",
            "Epoch 3, Sample 14942: Loss: 0.1170\n",
            "Epoch 3, Sample 14943: Loss: 1.0530\n",
            "Epoch 3, Sample 14944: Loss: 0.2481\n",
            "Epoch 3, Sample 14945: Loss: 0.3399\n",
            "Epoch 3, Sample 14946: Loss: 0.4607\n",
            "Epoch 3, Sample 14947: Loss: 0.0630\n",
            "Epoch 3, Sample 14948: Loss: 0.2639\n",
            "Epoch 3, Sample 14949: Loss: 0.0062\n",
            "Epoch 3, Sample 14950: Loss: 0.5858\n",
            "Epoch 3, Sample 14951: Loss: 0.0084\n",
            "Epoch 3, Sample 14952: Loss: 0.0258\n",
            "Epoch 3, Sample 14953: Loss: 0.1397\n",
            "Epoch 3, Sample 14954: Loss: 0.3284\n",
            "Epoch 3, Sample 14955: Loss: 0.1559\n",
            "Epoch 3, Sample 14956: Loss: 0.2032\n",
            "Epoch 3, Sample 14957: Loss: 0.0474\n",
            "Epoch 3, Sample 14958: Loss: 0.3399\n",
            "Epoch 3, Sample 14959: Loss: 0.0626\n",
            "Epoch 3, Sample 14960: Loss: 0.6758\n",
            "Epoch 3, Sample 14961: Loss: 0.2219\n",
            "Epoch 3, Sample 14962: Loss: 0.0301\n",
            "Epoch 3, Sample 14963: Loss: 0.2044\n",
            "Epoch 3, Sample 14964: Loss: 0.0030\n",
            "Epoch 3, Sample 14965: Loss: 0.7036\n",
            "Epoch 3, Sample 14966: Loss: 0.0712\n",
            "Epoch 3, Sample 14967: Loss: 0.1252\n",
            "Epoch 3, Sample 14968: Loss: 0.0026\n",
            "Epoch 3, Sample 14969: Loss: 2.0108\n",
            "Epoch 3, Sample 14970: Loss: 0.0420\n",
            "Epoch 3, Sample 14971: Loss: 0.5003\n",
            "Epoch 3, Sample 14972: Loss: 0.0466\n",
            "Epoch 3, Sample 14973: Loss: 0.1246\n",
            "Epoch 3, Sample 14974: Loss: 1.0524\n",
            "Epoch 3, Sample 14975: Loss: 0.0176\n",
            "Epoch 3, Sample 14976: Loss: 0.0466\n",
            "Epoch 3, Sample 14977: Loss: 1.0524\n",
            "Epoch 3, Sample 14978: Loss: 0.2931\n",
            "Epoch 3, Sample 14979: Loss: 0.0026\n",
            "Epoch 3, Sample 14980: Loss: 0.0026\n",
            "Epoch 3, Sample 14981: Loss: 0.4799\n",
            "Epoch 3, Sample 14982: Loss: 0.8484\n",
            "Epoch 3, Sample 14983: Loss: 0.4930\n",
            "Epoch 3, Sample 14984: Loss: 1.0155\n",
            "Epoch 3, Sample 14985: Loss: 0.0026\n",
            "Epoch 3, Sample 14986: Loss: 0.0026\n",
            "Epoch 3, Sample 14987: Loss: 0.6073\n",
            "Epoch 3, Sample 14988: Loss: 1.0688\n",
            "Epoch 3, Sample 14989: Loss: 0.2361\n",
            "Epoch 3, Sample 14990: Loss: 0.1250\n",
            "Epoch 3, Sample 14991: Loss: 0.1225\n",
            "Epoch 3, Sample 14992: Loss: 1.0524\n",
            "Epoch 3, Sample 14993: Loss: 0.9785\n",
            "Epoch 3, Sample 14994: Loss: 0.4611\n",
            "Epoch 3, Sample 14995: Loss: 0.6990\n",
            "Epoch 3, Sample 14996: Loss: 0.4641\n",
            "Epoch 3, Sample 14997: Loss: 0.6990\n",
            "Epoch 3, Sample 14998: Loss: 0.6867\n",
            "Epoch 3, Sample 14999: Loss: 0.8165\n",
            "Epoch 3, Sample 15000: Loss: 0.3949\n",
            "Epoch 3, Sample 15001: Loss: 0.0018\n",
            "Epoch 3, Sample 15002: Loss: 0.2832\n",
            "Epoch 3, Sample 15003: Loss: 0.5174\n",
            "Epoch 3, Sample 15004: Loss: 0.2182\n",
            "Epoch 3, Sample 15005: Loss: 0.0316\n",
            "Epoch 3, Sample 15006: Loss: 0.1964\n",
            "Epoch 3, Sample 15007: Loss: 0.2032\n",
            "Epoch 3, Sample 15008: Loss: 0.2044\n",
            "Epoch 3, Sample 15009: Loss: 0.2219\n",
            "Epoch 3, Sample 15010: Loss: 0.3949\n",
            "Epoch 3, Sample 15011: Loss: 0.4930\n",
            "Epoch 3, Sample 15012: Loss: 0.2044\n",
            "Epoch 3, Sample 15013: Loss: 0.0006\n",
            "Epoch 3, Sample 15014: Loss: 1.0524\n",
            "Epoch 3, Sample 15015: Loss: 0.3399\n",
            "Epoch 3, Sample 15016: Loss: 0.0018\n",
            "Epoch 3, Sample 15017: Loss: 1.0524\n",
            "Epoch 3, Sample 15018: Loss: 0.7702\n",
            "Epoch 3, Sample 15019: Loss: 0.0046\n",
            "Epoch 3, Sample 15020: Loss: 2.2302\n",
            "Epoch 3, Sample 15021: Loss: 0.3402\n",
            "Epoch 3, Sample 15022: Loss: 0.7702\n",
            "Epoch 3, Sample 15023: Loss: 0.2044\n",
            "Epoch 3, Sample 15024: Loss: 0.1622\n",
            "Epoch 3, Sample 15025: Loss: 1.0155\n",
            "Epoch 3, Sample 15026: Loss: 0.0303\n",
            "Epoch 3, Sample 15027: Loss: 0.2148\n",
            "Epoch 3, Sample 15028: Loss: 0.1186\n",
            "Epoch 3, Sample 15029: Loss: 0.1039\n",
            "Epoch 3, Sample 15030: Loss: 1.0155\n",
            "Epoch 3, Sample 15031: Loss: 3.1355\n",
            "Epoch 3, Sample 15032: Loss: 0.0333\n",
            "Epoch 3, Sample 15033: Loss: 0.3332\n",
            "Epoch 3, Sample 15034: Loss: 0.0026\n",
            "Epoch 3, Sample 15035: Loss: 0.6990\n",
            "Epoch 3, Sample 15036: Loss: 0.1225\n",
            "Epoch 3, Sample 15037: Loss: 0.0002\n",
            "Epoch 3, Sample 15038: Loss: 0.1067\n",
            "Epoch 3, Sample 15039: Loss: 0.2034\n",
            "Epoch 3, Sample 15040: Loss: 0.5858\n",
            "Epoch 3, Sample 15041: Loss: 0.8951\n",
            "Epoch 3, Sample 15042: Loss: 1.0524\n",
            "Epoch 3, Sample 15043: Loss: 0.0868\n",
            "Epoch 3, Sample 15044: Loss: 0.0034\n",
            "Epoch 3, Sample 15045: Loss: 10.2782\n",
            "Epoch 3, Sample 15046: Loss: 1.0524\n",
            "Epoch 3, Sample 15047: Loss: 0.0026\n",
            "Epoch 3, Sample 15048: Loss: 1.5113\n",
            "Epoch 3, Sample 15049: Loss: 0.2558\n",
            "Epoch 3, Sample 15050: Loss: 0.7036\n",
            "Epoch 3, Sample 15051: Loss: 1.0524\n",
            "Epoch 3, Sample 15052: Loss: 0.1040\n",
            "Epoch 3, Sample 15053: Loss: 0.8949\n",
            "Epoch 3, Sample 15054: Loss: 0.2034\n",
            "Epoch 3, Sample 15055: Loss: 0.3399\n",
            "Epoch 3, Sample 15056: Loss: 0.6215\n",
            "Epoch 3, Sample 15057: Loss: 0.3984\n",
            "Epoch 3, Sample 15058: Loss: 14.0076\n",
            "Epoch 3, Sample 15059: Loss: 0.2044\n",
            "Epoch 3, Sample 15060: Loss: 0.2874\n",
            "Epoch 3, Sample 15061: Loss: 1.4086\n",
            "Epoch 3, Sample 15062: Loss: 0.3399\n",
            "Epoch 3, Sample 15063: Loss: 0.5636\n",
            "Epoch 3, Sample 15064: Loss: 0.1536\n",
            "Epoch 3, Sample 15065: Loss: 0.0037\n",
            "Epoch 3, Sample 15066: Loss: 0.3441\n",
            "Epoch 3, Sample 15067: Loss: 0.2032\n",
            "Epoch 3, Sample 15068: Loss: 0.2036\n",
            "Epoch 3, Sample 15069: Loss: 0.1250\n",
            "Epoch 3, Sample 15070: Loss: 1.0530\n",
            "Epoch 3, Sample 15071: Loss: 0.0026\n",
            "Epoch 3, Sample 15072: Loss: 0.0516\n",
            "Epoch 3, Sample 15073: Loss: 0.0162\n",
            "Epoch 3, Sample 15074: Loss: 0.4032\n",
            "Epoch 3, Sample 15075: Loss: 2.5992\n",
            "Epoch 3, Sample 15076: Loss: 0.4799\n",
            "Epoch 3, Sample 15077: Loss: 0.7036\n",
            "Epoch 3, Sample 15078: Loss: 0.0025\n",
            "Epoch 3, Sample 15079: Loss: 0.1240\n",
            "Epoch 3, Sample 15080: Loss: 0.2832\n",
            "Epoch 3, Sample 15081: Loss: 0.1170\n",
            "Epoch 3, Sample 15082: Loss: 0.2935\n",
            "Epoch 3, Sample 15083: Loss: 0.0000\n",
            "Epoch 3, Sample 15084: Loss: 0.0025\n",
            "Epoch 3, Sample 15085: Loss: 0.1055\n",
            "Epoch 3, Sample 15086: Loss: 1.1992\n",
            "Epoch 3, Sample 15087: Loss: 0.1252\n",
            "Epoch 3, Sample 15088: Loss: 0.3441\n",
            "Epoch 3, Sample 15089: Loss: 0.2032\n",
            "Epoch 3, Sample 15090: Loss: 0.0001\n",
            "Epoch 3, Sample 15091: Loss: 0.0637\n",
            "Epoch 3, Sample 15092: Loss: 0.0971\n",
            "Epoch 3, Sample 15093: Loss: 0.6990\n",
            "Epoch 3, Sample 15094: Loss: 0.0026\n",
            "Epoch 3, Sample 15095: Loss: 0.5000\n",
            "Epoch 3, Sample 15096: Loss: 0.0692\n",
            "Epoch 3, Sample 15097: Loss: 0.0026\n",
            "Epoch 3, Sample 15098: Loss: 0.3186\n",
            "Epoch 3, Sample 15099: Loss: 0.0306\n",
            "Epoch 3, Sample 15100: Loss: 0.0026\n",
            "Epoch 3, Sample 15101: Loss: 0.0026\n",
            "Epoch 3, Sample 15102: Loss: 0.7702\n",
            "Epoch 3, Sample 15103: Loss: 0.3949\n",
            "Epoch 3, Sample 15104: Loss: 1.0524\n",
            "Epoch 3, Sample 15105: Loss: 0.5003\n",
            "Epoch 3, Sample 15106: Loss: 0.2044\n",
            "Epoch 3, Sample 15107: Loss: 1.0155\n",
            "Epoch 3, Sample 15108: Loss: 0.0963\n",
            "Epoch 3, Sample 15109: Loss: 0.1248\n",
            "Epoch 3, Sample 15110: Loss: 1.0524\n",
            "Epoch 3, Sample 15111: Loss: 0.1397\n",
            "Epoch 3, Sample 15112: Loss: 0.0005\n",
            "Epoch 3, Sample 15113: Loss: 0.5707\n",
            "Epoch 3, Sample 15114: Loss: 0.4762\n",
            "Epoch 3, Sample 15115: Loss: 3.5504\n",
            "Epoch 3, Sample 15116: Loss: 0.5636\n",
            "Epoch 3, Sample 15117: Loss: 0.3441\n",
            "Epoch 3, Sample 15118: Loss: 1.0688\n",
            "Epoch 3, Sample 15119: Loss: 0.1170\n",
            "Epoch 3, Sample 15120: Loss: 1.0524\n",
            "Epoch 3, Sample 15121: Loss: 1.0524\n",
            "Epoch 3, Sample 15122: Loss: 0.0018\n",
            "Epoch 3, Sample 15123: Loss: 0.1627\n",
            "Epoch 3, Sample 15124: Loss: 0.0867\n",
            "Epoch 3, Sample 15125: Loss: 0.0630\n",
            "Epoch 3, Sample 15126: Loss: 0.0466\n",
            "Epoch 3, Sample 15127: Loss: 0.5563\n",
            "Epoch 3, Sample 15128: Loss: 0.2044\n",
            "Epoch 3, Sample 15129: Loss: 0.2034\n",
            "Epoch 3, Sample 15130: Loss: 0.8974\n",
            "Epoch 3, Sample 15131: Loss: 0.2759\n",
            "Epoch 3, Sample 15132: Loss: 0.1225\n",
            "Epoch 3, Sample 15133: Loss: 0.0312\n",
            "Epoch 3, Sample 15134: Loss: 0.0001\n",
            "Epoch 3, Sample 15135: Loss: 0.2086\n",
            "Epoch 3, Sample 15136: Loss: 0.2962\n",
            "Epoch 3, Sample 15137: Loss: 0.3872\n",
            "Epoch 3, Sample 15138: Loss: 0.6768\n",
            "Epoch 3, Sample 15139: Loss: 1.0524\n",
            "Epoch 3, Sample 15140: Loss: 0.3568\n",
            "Epoch 3, Sample 15141: Loss: 0.2044\n",
            "Epoch 3, Sample 15142: Loss: 1.0524\n",
            "Epoch 3, Sample 15143: Loss: 0.0023\n",
            "Epoch 3, Sample 15144: Loss: 0.0001\n",
            "Epoch 3, Sample 15145: Loss: 0.0026\n",
            "Epoch 3, Sample 15146: Loss: 1.0524\n",
            "Epoch 3, Sample 15147: Loss: 0.0026\n",
            "Epoch 3, Sample 15148: Loss: 0.6092\n",
            "Epoch 3, Sample 15149: Loss: 3.8030\n",
            "Epoch 3, Sample 15150: Loss: 0.0743\n",
            "Epoch 3, Sample 15151: Loss: 0.7036\n",
            "Epoch 3, Sample 15152: Loss: 0.5078\n",
            "Epoch 3, Sample 15153: Loss: 0.0625\n",
            "Epoch 3, Sample 15154: Loss: 0.2845\n",
            "Epoch 3, Sample 15155: Loss: 0.7036\n",
            "Epoch 3, Sample 15156: Loss: 0.0062\n",
            "Epoch 3, Sample 15157: Loss: 0.0026\n",
            "Epoch 3, Sample 15158: Loss: 0.0150\n",
            "Epoch 3, Sample 15159: Loss: 0.0476\n",
            "Epoch 3, Sample 15160: Loss: 1.0104\n",
            "Epoch 3, Sample 15161: Loss: 0.0258\n",
            "Epoch 3, Sample 15162: Loss: 0.4930\n",
            "Epoch 3, Sample 15163: Loss: 1.0524\n",
            "Epoch 3, Sample 15164: Loss: 1.1805\n",
            "Epoch 3, Sample 15165: Loss: 0.4588\n",
            "Epoch 3, Sample 15166: Loss: 0.1246\n",
            "Epoch 3, Sample 15167: Loss: 0.2759\n",
            "Epoch 3, Sample 15168: Loss: 0.7129\n",
            "Epoch 3, Sample 15169: Loss: 0.1924\n",
            "Epoch 3, Sample 15170: Loss: 0.5858\n",
            "Epoch 3, Sample 15171: Loss: 0.0000\n",
            "Epoch 3, Sample 15172: Loss: 1.6479\n",
            "Epoch 3, Sample 15173: Loss: 1.5507\n",
            "Epoch 3, Sample 15174: Loss: 0.0001\n",
            "Epoch 3, Sample 15175: Loss: 0.1523\n",
            "Epoch 3, Sample 15176: Loss: 0.3367\n",
            "Epoch 3, Sample 15177: Loss: 1.0524\n",
            "Epoch 3, Sample 15178: Loss: 0.3399\n",
            "Epoch 3, Sample 15179: Loss: 0.4032\n",
            "Epoch 3, Sample 15180: Loss: 0.1238\n",
            "Epoch 3, Sample 15181: Loss: 0.2034\n",
            "Epoch 3, Sample 15182: Loss: 0.1170\n",
            "Epoch 3, Sample 15183: Loss: 0.0018\n",
            "Epoch 3, Sample 15184: Loss: 0.6990\n",
            "Epoch 3, Sample 15185: Loss: 0.0212\n",
            "Epoch 3, Sample 15186: Loss: 0.4799\n",
            "Epoch 3, Sample 15187: Loss: 0.2494\n",
            "Epoch 3, Sample 15188: Loss: 0.4927\n",
            "Epoch 3, Sample 15189: Loss: 0.0461\n",
            "Epoch 3, Sample 15190: Loss: 1.0530\n",
            "Epoch 3, Sample 15191: Loss: 0.2103\n",
            "Epoch 3, Sample 15192: Loss: 0.2032\n",
            "Epoch 3, Sample 15193: Loss: 0.2032\n",
            "Epoch 3, Sample 15194: Loss: 0.2219\n",
            "Epoch 3, Sample 15195: Loss: 17.7319\n",
            "Epoch 3, Sample 15196: Loss: 0.4996\n",
            "Epoch 3, Sample 15197: Loss: 0.6304\n",
            "Epoch 3, Sample 15198: Loss: 0.0915\n",
            "Epoch 3, Sample 15199: Loss: 0.1170\n",
            "Epoch 3, Sample 15200: Loss: 1.0530\n",
            "Epoch 3, Sample 15201: Loss: 0.0049\n",
            "Epoch 3, Sample 15202: Loss: 0.1248\n",
            "Epoch 3, Sample 15203: Loss: 0.2132\n",
            "Epoch 3, Sample 15204: Loss: 0.2034\n",
            "Epoch 3, Sample 15205: Loss: 2.3187\n",
            "Epoch 3, Sample 15206: Loss: 0.0915\n",
            "Epoch 3, Sample 15207: Loss: 0.2219\n",
            "Epoch 3, Sample 15208: Loss: 0.0349\n",
            "Epoch 3, Sample 15209: Loss: 0.0426\n",
            "Epoch 3, Sample 15210: Loss: 0.0084\n",
            "Epoch 3, Sample 15211: Loss: 0.3949\n",
            "Epoch 3, Sample 15212: Loss: 0.7326\n",
            "Epoch 3, Sample 15213: Loss: 0.2112\n",
            "Epoch 3, Sample 15214: Loss: 0.3399\n",
            "Epoch 3, Sample 15215: Loss: 1.0524\n",
            "Epoch 3, Sample 15216: Loss: 0.3477\n",
            "Epoch 3, Sample 15217: Loss: 0.0415\n",
            "Epoch 3, Sample 15218: Loss: 0.0000\n",
            "Epoch 3, Sample 15219: Loss: 0.3474\n",
            "Epoch 3, Sample 15220: Loss: 0.0017\n",
            "Epoch 3, Sample 15221: Loss: 0.2759\n",
            "Epoch 3, Sample 15222: Loss: 0.3399\n",
            "Epoch 3, Sample 15223: Loss: 0.3908\n",
            "Epoch 3, Sample 15224: Loss: 0.2034\n",
            "Epoch 3, Sample 15225: Loss: 0.0630\n",
            "Epoch 3, Sample 15226: Loss: 0.0212\n",
            "Epoch 3, Sample 15227: Loss: 0.0898\n",
            "Epoch 3, Sample 15228: Loss: 1.0524\n",
            "Epoch 3, Sample 15229: Loss: 0.7036\n",
            "Epoch 3, Sample 15230: Loss: 0.2034\n",
            "Epoch 3, Sample 15231: Loss: 0.1559\n",
            "Epoch 3, Sample 15232: Loss: 0.0802\n",
            "Epoch 3, Sample 15233: Loss: 0.0938\n",
            "Epoch 3, Sample 15234: Loss: 0.1817\n",
            "Epoch 3, Sample 15235: Loss: 1.0524\n",
            "Epoch 3, Sample 15236: Loss: 0.2452\n",
            "Epoch 3, Sample 15237: Loss: 0.7482\n",
            "Epoch 3, Sample 15238: Loss: 1.0524\n",
            "Epoch 3, Sample 15239: Loss: 0.3949\n",
            "Epoch 3, Sample 15240: Loss: 0.0751\n",
            "Epoch 3, Sample 15241: Loss: 0.4607\n",
            "Epoch 3, Sample 15242: Loss: 0.3441\n",
            "Epoch 3, Sample 15243: Loss: 1.0524\n",
            "Epoch 3, Sample 15244: Loss: 0.1472\n",
            "Epoch 3, Sample 15245: Loss: 0.1170\n",
            "Epoch 3, Sample 15246: Loss: 0.7036\n",
            "Epoch 3, Sample 15247: Loss: 0.1911\n",
            "Epoch 3, Sample 15248: Loss: 0.2032\n",
            "Epoch 3, Sample 15249: Loss: 0.8951\n",
            "Epoch 3, Sample 15250: Loss: 1.0524\n",
            "Epoch 3, Sample 15251: Loss: 0.2034\n",
            "Epoch 3, Sample 15252: Loss: 0.0006\n",
            "Epoch 3, Sample 15253: Loss: 0.0026\n",
            "Epoch 3, Sample 15254: Loss: 0.6139\n",
            "Epoch 3, Sample 15255: Loss: 1.9820\n",
            "Epoch 3, Sample 15256: Loss: 1.0155\n",
            "Epoch 3, Sample 15257: Loss: 0.0067\n",
            "Epoch 3, Sample 15258: Loss: 0.1039\n",
            "Epoch 3, Sample 15259: Loss: 0.2759\n",
            "Epoch 3, Sample 15260: Loss: 0.5858\n",
            "Epoch 3, Sample 15261: Loss: 0.3441\n",
            "Epoch 3, Sample 15262: Loss: 1.0524\n",
            "Epoch 3, Sample 15263: Loss: 1.0530\n",
            "Epoch 3, Sample 15264: Loss: 1.1962\n",
            "Epoch 3, Sample 15265: Loss: 0.2759\n",
            "Epoch 3, Sample 15266: Loss: 0.0337\n",
            "Epoch 3, Sample 15267: Loss: 0.5636\n",
            "Epoch 3, Sample 15268: Loss: 0.2032\n",
            "Epoch 3, Sample 15269: Loss: 0.0682\n",
            "Epoch 3, Sample 15270: Loss: 0.0036\n",
            "Epoch 3, Sample 15271: Loss: 0.0026\n",
            "Epoch 3, Sample 15272: Loss: 1.0524\n",
            "Epoch 3, Sample 15273: Loss: 0.0000\n",
            "Epoch 3, Sample 15274: Loss: 0.2032\n",
            "Epoch 3, Sample 15275: Loss: 0.9387\n",
            "Epoch 3, Sample 15276: Loss: 0.1170\n",
            "Epoch 3, Sample 15277: Loss: 0.1736\n",
            "Epoch 3, Sample 15278: Loss: 0.1968\n",
            "Epoch 3, Sample 15279: Loss: 0.1264\n",
            "Epoch 3, Sample 15280: Loss: 0.9785\n",
            "Epoch 3, Sample 15281: Loss: 1.1569\n",
            "Epoch 3, Sample 15282: Loss: 0.0945\n",
            "Epoch 3, Sample 15283: Loss: 0.3418\n",
            "Epoch 3, Sample 15284: Loss: 0.0027\n",
            "Epoch 3, Sample 15285: Loss: 0.8985\n",
            "Epoch 3, Sample 15286: Loss: 0.0270\n",
            "Epoch 3, Sample 15287: Loss: 0.0000\n",
            "Epoch 3, Sample 15288: Loss: 0.3441\n",
            "Epoch 3, Sample 15289: Loss: 0.2044\n",
            "Epoch 3, Sample 15290: Loss: 0.2051\n",
            "Epoch 3, Sample 15291: Loss: 0.2034\n",
            "Epoch 3, Sample 15292: Loss: 0.2034\n",
            "Epoch 3, Sample 15293: Loss: 0.4799\n",
            "Epoch 3, Sample 15294: Loss: 0.1036\n",
            "Epoch 3, Sample 15295: Loss: 0.0025\n",
            "Epoch 3, Sample 15296: Loss: 0.2036\n",
            "Epoch 3, Sample 15297: Loss: 0.1397\n",
            "Epoch 3, Sample 15298: Loss: 0.1170\n",
            "Epoch 3, Sample 15299: Loss: 0.3033\n",
            "Epoch 3, Sample 15300: Loss: 0.2421\n",
            "Epoch 3, Sample 15301: Loss: 0.0856\n",
            "Epoch 3, Sample 15302: Loss: 0.0170\n",
            "Epoch 3, Sample 15303: Loss: 0.1574\n",
            "Epoch 3, Sample 15304: Loss: 1.5591\n",
            "Epoch 3, Sample 15305: Loss: 0.1040\n",
            "Epoch 3, Sample 15306: Loss: 0.3399\n",
            "Epoch 3, Sample 15307: Loss: 0.0626\n",
            "Epoch 3, Sample 15308: Loss: 0.1465\n",
            "Epoch 3, Sample 15309: Loss: 0.5636\n",
            "Epoch 3, Sample 15310: Loss: 10.3220\n",
            "Epoch 3, Sample 15311: Loss: 0.0466\n",
            "Epoch 3, Sample 15312: Loss: 1.0524\n",
            "Epoch 3, Sample 15313: Loss: 0.2639\n",
            "Epoch 3, Sample 15314: Loss: 0.3288\n",
            "Epoch 3, Sample 15315: Loss: 0.3477\n",
            "Epoch 3, Sample 15316: Loss: 0.6990\n",
            "Epoch 3, Sample 15317: Loss: 0.2044\n",
            "Epoch 3, Sample 15318: Loss: 0.0222\n",
            "Epoch 3, Sample 15319: Loss: 0.5550\n",
            "Epoch 3, Sample 15320: Loss: 1.0524\n",
            "Epoch 3, Sample 15321: Loss: 0.5799\n",
            "Epoch 3, Sample 15322: Loss: 0.4996\n",
            "Epoch 3, Sample 15323: Loss: 1.0155\n",
            "Epoch 3, Sample 15324: Loss: 0.0802\n",
            "Epoch 3, Sample 15325: Loss: 1.0524\n",
            "Epoch 3, Sample 15326: Loss: 0.0082\n",
            "Epoch 3, Sample 15327: Loss: 0.2032\n",
            "Epoch 3, Sample 15328: Loss: 0.3399\n",
            "Epoch 3, Sample 15329: Loss: 1.0524\n",
            "Epoch 3, Sample 15330: Loss: 1.0524\n",
            "Epoch 3, Sample 15331: Loss: 0.2034\n",
            "Epoch 3, Sample 15332: Loss: 0.0752\n",
            "Epoch 3, Sample 15333: Loss: 0.1546\n",
            "Epoch 3, Sample 15334: Loss: 0.1005\n",
            "Epoch 3, Sample 15335: Loss: 0.0018\n",
            "Epoch 3, Sample 15336: Loss: 0.0001\n",
            "Epoch 3, Sample 15337: Loss: 5.5128\n",
            "Epoch 3, Sample 15338: Loss: 0.0630\n",
            "Epoch 3, Sample 15339: Loss: 0.1039\n",
            "Epoch 3, Sample 15340: Loss: 0.0460\n",
            "Epoch 3, Sample 15341: Loss: 0.0270\n",
            "Epoch 3, Sample 15342: Loss: 0.7203\n",
            "Epoch 3, Sample 15343: Loss: 0.0640\n",
            "Epoch 3, Sample 15344: Loss: 0.7036\n",
            "Epoch 3, Sample 15345: Loss: 1.0524\n",
            "Epoch 3, Sample 15346: Loss: 0.9617\n",
            "Epoch 3, Sample 15347: Loss: 0.0426\n",
            "Epoch 3, Sample 15348: Loss: 0.0811\n",
            "Epoch 3, Sample 15349: Loss: 0.5819\n",
            "Epoch 3, Sample 15350: Loss: 0.2219\n",
            "Epoch 3, Sample 15351: Loss: 0.2036\n",
            "Epoch 3, Sample 15352: Loss: 0.1164\n",
            "Epoch 3, Sample 15353: Loss: 0.1559\n",
            "Epoch 3, Sample 15354: Loss: 1.0524\n",
            "Epoch 3, Sample 15355: Loss: 0.3949\n",
            "Epoch 3, Sample 15356: Loss: 0.1170\n",
            "Epoch 3, Sample 15357: Loss: 0.0952\n",
            "Epoch 3, Sample 15358: Loss: 0.0286\n",
            "Epoch 3, Sample 15359: Loss: 0.3399\n",
            "Epoch 3, Sample 15360: Loss: 1.6809\n",
            "Epoch 3, Sample 15361: Loss: 0.0001\n",
            "Epoch 3, Sample 15362: Loss: 0.3399\n",
            "Epoch 3, Sample 15363: Loss: 4.2335\n",
            "Epoch 3, Sample 15364: Loss: 1.5542\n",
            "Epoch 3, Sample 15365: Loss: 0.6990\n",
            "Epoch 3, Sample 15366: Loss: 1.0039\n",
            "Epoch 3, Sample 15367: Loss: 0.2759\n",
            "Epoch 3, Sample 15368: Loss: 0.3598\n",
            "Epoch 3, Sample 15369: Loss: 0.0915\n",
            "Epoch 3, Sample 15370: Loss: 0.7036\n",
            "Epoch 3, Sample 15371: Loss: 0.0175\n",
            "Epoch 3, Sample 15372: Loss: 0.3284\n",
            "Epoch 3, Sample 15373: Loss: 1.0530\n",
            "Epoch 3, Sample 15374: Loss: 0.2044\n",
            "Epoch 3, Sample 15375: Loss: 0.4520\n",
            "Epoch 3, Sample 15376: Loss: 0.0532\n",
            "Epoch 3, Sample 15377: Loss: 9.7379\n",
            "Epoch 3, Sample 15378: Loss: 0.6990\n",
            "Epoch 3, Sample 15379: Loss: 0.2044\n",
            "Epoch 3, Sample 15380: Loss: 0.1989\n",
            "Epoch 3, Sample 15381: Loss: 1.0524\n",
            "Epoch 3, Sample 15382: Loss: 0.5058\n",
            "Epoch 3, Sample 15383: Loss: 0.0005\n",
            "Epoch 3, Sample 15384: Loss: 0.9454\n",
            "Epoch 3, Sample 15385: Loss: 0.5000\n",
            "Epoch 3, Sample 15386: Loss: 0.9367\n",
            "Epoch 3, Sample 15387: Loss: 0.0559\n",
            "Epoch 3, Sample 15388: Loss: 1.8245\n",
            "Epoch 3, Sample 15389: Loss: 0.0063\n",
            "Epoch 3, Sample 15390: Loss: 1.0524\n",
            "Epoch 3, Sample 15391: Loss: 0.2075\n",
            "Epoch 3, Sample 15392: Loss: 0.4799\n",
            "Epoch 3, Sample 15393: Loss: 0.2778\n",
            "Epoch 3, Sample 15394: Loss: 0.0630\n",
            "Epoch 3, Sample 15395: Loss: 0.0063\n",
            "Epoch 3, Sample 15396: Loss: 0.0230\n",
            "Epoch 3, Sample 15397: Loss: 0.6092\n",
            "Epoch 3, Sample 15398: Loss: 0.0808\n",
            "Epoch 3, Sample 15399: Loss: 0.4996\n",
            "Epoch 3, Sample 15400: Loss: 0.2669\n",
            "Epoch 3, Sample 15401: Loss: 1.0062\n",
            "Epoch 3, Sample 15402: Loss: 1.0530\n",
            "Epoch 3, Sample 15403: Loss: 0.0001\n",
            "Epoch 3, Sample 15404: Loss: 0.0026\n",
            "Epoch 3, Sample 15405: Loss: 0.1608\n",
            "Epoch 3, Sample 15406: Loss: 0.5000\n",
            "Epoch 3, Sample 15407: Loss: 0.0838\n",
            "Epoch 3, Sample 15408: Loss: 0.0460\n",
            "Epoch 3, Sample 15409: Loss: 0.0001\n",
            "Epoch 3, Sample 15410: Loss: 0.0684\n",
            "Epoch 3, Sample 15411: Loss: 0.0632\n",
            "Epoch 3, Sample 15412: Loss: 0.7036\n",
            "Epoch 3, Sample 15413: Loss: 0.7453\n",
            "Epoch 3, Sample 15414: Loss: 0.2032\n",
            "Epoch 3, Sample 15415: Loss: 1.0524\n",
            "Epoch 3, Sample 15416: Loss: 0.7486\n",
            "Epoch 3, Sample 15417: Loss: 0.1170\n",
            "Epoch 3, Sample 15418: Loss: 0.5799\n",
            "Epoch 3, Sample 15419: Loss: 0.0026\n",
            "Epoch 3, Sample 15420: Loss: 0.5078\n",
            "Epoch 3, Sample 15421: Loss: 0.0000\n",
            "Epoch 3, Sample 15422: Loss: 1.0524\n",
            "Epoch 3, Sample 15423: Loss: 0.3062\n",
            "Epoch 3, Sample 15424: Loss: 0.0270\n",
            "Epoch 3, Sample 15425: Loss: 0.2032\n",
            "Epoch 3, Sample 15426: Loss: 0.0018\n",
            "Epoch 3, Sample 15427: Loss: 0.9309\n",
            "Epoch 3, Sample 15428: Loss: 0.4744\n",
            "Epoch 3, Sample 15429: Loss: 0.0351\n",
            "Epoch 3, Sample 15430: Loss: 0.7432\n",
            "Epoch 3, Sample 15431: Loss: 0.2341\n",
            "Epoch 3, Sample 15432: Loss: 0.4032\n",
            "Epoch 3, Sample 15433: Loss: 0.0915\n",
            "Epoch 3, Sample 15434: Loss: 0.2639\n",
            "Epoch 3, Sample 15435: Loss: 0.0095\n",
            "Epoch 3, Sample 15436: Loss: 0.0286\n",
            "Epoch 3, Sample 15437: Loss: 0.2222\n",
            "Epoch 3, Sample 15438: Loss: 0.8951\n",
            "Epoch 3, Sample 15439: Loss: 0.1588\n",
            "Epoch 3, Sample 15440: Loss: 0.1326\n",
            "Epoch 3, Sample 15441: Loss: 1.0524\n",
            "Epoch 3, Sample 15442: Loss: 0.5858\n",
            "Epoch 3, Sample 15443: Loss: 0.4304\n",
            "Epoch 3, Sample 15444: Loss: 0.2639\n",
            "Epoch 3, Sample 15445: Loss: 0.0004\n",
            "Epoch 3, Sample 15446: Loss: 1.0530\n",
            "Epoch 3, Sample 15447: Loss: 5.3897\n",
            "Epoch 3, Sample 15448: Loss: 0.2044\n",
            "Epoch 3, Sample 15449: Loss: 0.1170\n",
            "Epoch 3, Sample 15450: Loss: 0.0026\n",
            "Epoch 3, Sample 15451: Loss: 0.3399\n",
            "Epoch 3, Sample 15452: Loss: 0.5953\n",
            "Epoch 3, Sample 15453: Loss: 0.0625\n",
            "Epoch 3, Sample 15454: Loss: 0.7036\n",
            "Epoch 3, Sample 15455: Loss: 0.0267\n",
            "Epoch 3, Sample 15456: Loss: 0.0207\n",
            "Epoch 3, Sample 15457: Loss: 0.0213\n",
            "Epoch 3, Sample 15458: Loss: 0.0339\n",
            "Epoch 3, Sample 15459: Loss: 0.7036\n",
            "Epoch 3, Sample 15460: Loss: 0.9460\n",
            "Epoch 3, Sample 15461: Loss: 0.0630\n",
            "Epoch 3, Sample 15462: Loss: 0.0062\n",
            "Epoch 3, Sample 15463: Loss: 0.1525\n",
            "Epoch 3, Sample 15464: Loss: 0.3450\n",
            "Epoch 3, Sample 15465: Loss: 0.1719\n",
            "Epoch 3, Sample 15466: Loss: 0.0630\n",
            "Epoch 3, Sample 15467: Loss: 0.2044\n",
            "Epoch 3, Sample 15468: Loss: 0.5058\n",
            "Epoch 3, Sample 15469: Loss: 0.0821\n",
            "Epoch 3, Sample 15470: Loss: 0.2034\n",
            "Epoch 3, Sample 15471: Loss: 0.1417\n",
            "Epoch 3, Sample 15472: Loss: 0.4930\n",
            "Epoch 3, Sample 15473: Loss: 0.1559\n",
            "Epoch 3, Sample 15474: Loss: 0.0071\n",
            "Epoch 3, Sample 15475: Loss: 0.8951\n",
            "Epoch 3, Sample 15476: Loss: 1.2361\n",
            "Epoch 3, Sample 15477: Loss: 0.3584\n",
            "Epoch 3, Sample 15478: Loss: 1.0155\n",
            "Epoch 3, Sample 15479: Loss: 0.0220\n",
            "Epoch 3, Sample 15480: Loss: 0.5003\n",
            "Epoch 3, Sample 15481: Loss: 1.0155\n",
            "Epoch 3, Sample 15482: Loss: 0.7036\n",
            "Epoch 3, Sample 15483: Loss: 0.0313\n",
            "Epoch 3, Sample 15484: Loss: 0.6867\n",
            "Epoch 3, Sample 15485: Loss: 0.1399\n",
            "Epoch 3, Sample 15486: Loss: 0.3332\n",
            "Epoch 3, Sample 15487: Loss: 0.0640\n",
            "Epoch 3, Sample 15488: Loss: 0.7142\n",
            "Epoch 3, Sample 15489: Loss: 0.3418\n",
            "Epoch 3, Sample 15490: Loss: 0.0372\n",
            "Epoch 3, Sample 15491: Loss: 1.0524\n",
            "Epoch 3, Sample 15492: Loss: 1.0227\n",
            "Epoch 3, Sample 15493: Loss: 0.5000\n",
            "Epoch 3, Sample 15494: Loss: 0.5871\n",
            "Epoch 3, Sample 15495: Loss: 0.1225\n",
            "Epoch 3, Sample 15496: Loss: 0.0022\n",
            "Epoch 3, Sample 15497: Loss: 0.2355\n",
            "Epoch 3, Sample 15498: Loss: 0.3301\n",
            "Epoch 3, Sample 15499: Loss: 0.0018\n",
            "Epoch 3, Sample 15500: Loss: 1.0524\n",
            "Epoch 3, Sample 15501: Loss: 0.0001\n",
            "Epoch 3, Sample 15502: Loss: 0.7453\n",
            "Epoch 3, Sample 15503: Loss: 0.3156\n",
            "Epoch 3, Sample 15504: Loss: 0.2759\n",
            "Epoch 3, Sample 15505: Loss: 0.0002\n",
            "Epoch 3, Sample 15506: Loss: 3.0075\n",
            "Epoch 3, Sample 15507: Loss: 0.0270\n",
            "Epoch 3, Sample 15508: Loss: 0.1678\n",
            "Epoch 3, Sample 15509: Loss: 0.9367\n",
            "Epoch 3, Sample 15510: Loss: 1.0524\n",
            "Epoch 3, Sample 15511: Loss: 0.0018\n",
            "Epoch 3, Sample 15512: Loss: 0.2832\n",
            "Epoch 3, Sample 15513: Loss: 0.7036\n",
            "Epoch 3, Sample 15514: Loss: 4.0306\n",
            "Epoch 3, Sample 15515: Loss: 0.0825\n",
            "Epoch 3, Sample 15516: Loss: 0.0018\n",
            "Epoch 3, Sample 15517: Loss: 0.3441\n",
            "Epoch 3, Sample 15518: Loss: 0.2832\n",
            "Epoch 3, Sample 15519: Loss: 0.2175\n",
            "Epoch 3, Sample 15520: Loss: 0.2032\n",
            "Epoch 3, Sample 15521: Loss: 0.0240\n",
            "Epoch 3, Sample 15522: Loss: 0.0575\n",
            "Epoch 3, Sample 15523: Loss: 0.7036\n",
            "Epoch 3, Sample 15524: Loss: 0.3441\n",
            "Epoch 3, Sample 15525: Loss: 0.0212\n",
            "Epoch 3, Sample 15526: Loss: 1.0530\n",
            "Epoch 3, Sample 15527: Loss: 0.0212\n",
            "Epoch 3, Sample 15528: Loss: 0.1248\n",
            "Epoch 3, Sample 15529: Loss: 0.9712\n",
            "Epoch 3, Sample 15530: Loss: 0.0366\n",
            "Epoch 3, Sample 15531: Loss: 0.2704\n",
            "Epoch 3, Sample 15532: Loss: 0.0050\n",
            "Epoch 3, Sample 15533: Loss: 0.1588\n",
            "Epoch 3, Sample 15534: Loss: 0.3949\n",
            "Epoch 3, Sample 15535: Loss: 0.0680\n",
            "Epoch 3, Sample 15536: Loss: 0.1397\n",
            "Epoch 3, Sample 15537: Loss: 0.0135\n",
            "Epoch 3, Sample 15538: Loss: 1.0524\n",
            "Epoch 3, Sample 15539: Loss: 0.1546\n",
            "Epoch 3, Sample 15540: Loss: 0.0501\n",
            "Epoch 3, Sample 15541: Loss: 0.2851\n",
            "Epoch 3, Sample 15542: Loss: 0.3402\n",
            "Epoch 3, Sample 15543: Loss: 0.2759\n",
            "Epoch 3, Sample 15544: Loss: 0.2044\n",
            "Epoch 3, Sample 15545: Loss: 0.9367\n",
            "Epoch 3, Sample 15546: Loss: 0.2639\n",
            "Epoch 3, Sample 15547: Loss: 1.0524\n",
            "Epoch 3, Sample 15548: Loss: 0.1250\n",
            "Epoch 3, Sample 15549: Loss: 2.5784\n",
            "Epoch 3, Sample 15550: Loss: 0.0270\n",
            "Epoch 3, Sample 15551: Loss: 0.2962\n",
            "Epoch 3, Sample 15552: Loss: 0.0005\n",
            "Epoch 3, Sample 15553: Loss: 0.0494\n",
            "Epoch 3, Sample 15554: Loss: 0.8951\n",
            "Epoch 3, Sample 15555: Loss: 0.2759\n",
            "Epoch 3, Sample 15556: Loss: 2.8013\n",
            "Epoch 3, Sample 15557: Loss: 1.0266\n",
            "Epoch 3, Sample 15558: Loss: 0.0026\n",
            "Epoch 3, Sample 15559: Loss: 0.3902\n",
            "Epoch 3, Sample 15560: Loss: 1.0524\n",
            "Epoch 3, Sample 15561: Loss: 0.0145\n",
            "Epoch 3, Sample 15562: Loss: 0.3441\n",
            "Epoch 3, Sample 15563: Loss: 0.0026\n",
            "Epoch 3, Sample 15564: Loss: 0.0517\n",
            "Epoch 3, Sample 15565: Loss: 1.0524\n",
            "Epoch 3, Sample 15566: Loss: 0.1559\n",
            "Epoch 3, Sample 15567: Loss: 2.1081\n",
            "Epoch 3, Sample 15568: Loss: 0.2032\n",
            "Epoch 3, Sample 15569: Loss: 0.0915\n",
            "Epoch 3, Sample 15570: Loss: 0.2759\n",
            "Epoch 3, Sample 15571: Loss: 1.0524\n",
            "Epoch 3, Sample 15572: Loss: 0.3758\n",
            "Epoch 3, Sample 15573: Loss: 0.6139\n",
            "Epoch 3, Sample 15574: Loss: 1.0524\n",
            "Epoch 3, Sample 15575: Loss: 0.0018\n",
            "Epoch 3, Sample 15576: Loss: 1.1789\n",
            "Epoch 3, Sample 15577: Loss: 0.0000\n",
            "Epoch 3, Sample 15578: Loss: 0.0000\n",
            "Epoch 3, Sample 15579: Loss: 1.0524\n",
            "Epoch 3, Sample 15580: Loss: 0.2044\n",
            "Epoch 3, Sample 15581: Loss: 0.6141\n",
            "Epoch 3, Sample 15582: Loss: 0.2759\n",
            "Epoch 3, Sample 15583: Loss: 0.0630\n",
            "Epoch 3, Sample 15584: Loss: 0.1170\n",
            "Epoch 3, Sample 15585: Loss: 0.0001\n",
            "Epoch 3, Sample 15586: Loss: 0.2036\n",
            "Epoch 3, Sample 15587: Loss: 0.0018\n",
            "Epoch 3, Sample 15588: Loss: 1.0530\n",
            "Epoch 3, Sample 15589: Loss: 1.0524\n",
            "Epoch 3, Sample 15590: Loss: 2.2706\n",
            "Epoch 3, Sample 15591: Loss: 0.0457\n",
            "Epoch 3, Sample 15592: Loss: 0.0505\n",
            "Epoch 3, Sample 15593: Loss: 0.0630\n",
            "Epoch 3, Sample 15594: Loss: 0.4611\n",
            "Epoch 3, Sample 15595: Loss: 0.0630\n",
            "Epoch 3, Sample 15596: Loss: 1.0524\n",
            "Epoch 3, Sample 15597: Loss: 0.2588\n",
            "Epoch 3, Sample 15598: Loss: 0.1533\n",
            "Epoch 3, Sample 15599: Loss: 0.1248\n",
            "Epoch 3, Sample 15600: Loss: 0.8095\n",
            "Epoch 3, Sample 15601: Loss: 0.2832\n",
            "Epoch 3, Sample 15602: Loss: 0.1482\n",
            "Epoch 3, Sample 15603: Loss: 0.1250\n",
            "Epoch 3, Sample 15604: Loss: 0.9651\n",
            "Epoch 3, Sample 15605: Loss: 0.3247\n",
            "Epoch 3, Sample 15606: Loss: 1.0524\n",
            "Epoch 3, Sample 15607: Loss: 0.1924\n",
            "Epoch 3, Sample 15608: Loss: 0.0532\n",
            "Epoch 3, Sample 15609: Loss: 0.0026\n",
            "Epoch 3, Sample 15610: Loss: 0.4466\n",
            "Epoch 3, Sample 15611: Loss: 1.0524\n",
            "Epoch 3, Sample 15612: Loss: 0.7036\n",
            "Epoch 3, Sample 15613: Loss: 0.2044\n",
            "Epoch 3, Sample 15614: Loss: 0.4996\n",
            "Epoch 3, Sample 15615: Loss: 0.2034\n",
            "Epoch 3, Sample 15616: Loss: 0.4102\n",
            "Epoch 3, Sample 15617: Loss: 0.2639\n",
            "Epoch 3, Sample 15618: Loss: 0.6092\n",
            "Epoch 3, Sample 15619: Loss: 0.2044\n",
            "Epoch 3, Sample 15620: Loss: 0.2032\n",
            "Epoch 3, Sample 15621: Loss: 0.0838\n",
            "Epoch 3, Sample 15622: Loss: 0.1627\n",
            "Epoch 3, Sample 15623: Loss: 0.2639\n",
            "Epoch 3, Sample 15624: Loss: 0.5871\n",
            "Epoch 3, Sample 15625: Loss: 0.0413\n",
            "Epoch 3, Sample 15626: Loss: 0.3399\n",
            "Epoch 3, Sample 15627: Loss: 1.0524\n",
            "Epoch 3, Sample 15628: Loss: 0.0054\n",
            "Epoch 3, Sample 15629: Loss: 0.5719\n",
            "Epoch 3, Sample 15630: Loss: 0.1170\n",
            "Epoch 3, Sample 15631: Loss: 0.1989\n",
            "Epoch 3, Sample 15632: Loss: 0.1559\n",
            "Epoch 3, Sample 15633: Loss: 0.4611\n",
            "Epoch 3, Sample 15634: Loss: 0.4663\n",
            "Epoch 3, Sample 15635: Loss: 0.2032\n",
            "Epoch 3, Sample 15636: Loss: 0.2759\n",
            "Epoch 3, Sample 15637: Loss: 0.1337\n",
            "Epoch 3, Sample 15638: Loss: 0.5989\n",
            "Epoch 3, Sample 15639: Loss: 0.4930\n",
            "Epoch 3, Sample 15640: Loss: 0.2034\n",
            "Epoch 3, Sample 15641: Loss: 1.0524\n",
            "Epoch 3, Sample 15642: Loss: 0.1559\n",
            "Epoch 3, Sample 15643: Loss: 0.5019\n",
            "Epoch 3, Sample 15644: Loss: 1.0155\n",
            "Epoch 3, Sample 15645: Loss: 0.0145\n",
            "Epoch 3, Sample 15646: Loss: 0.3399\n",
            "Epoch 3, Sample 15647: Loss: 0.0938\n",
            "Epoch 3, Sample 15648: Loss: 0.0006\n",
            "Epoch 3, Sample 15649: Loss: 0.1170\n",
            "Epoch 3, Sample 15650: Loss: 0.7036\n",
            "Epoch 3, Sample 15651: Loss: 0.0145\n",
            "Epoch 3, Sample 15652: Loss: 0.7036\n",
            "Epoch 3, Sample 15653: Loss: 0.1170\n",
            "Epoch 3, Sample 15654: Loss: 0.5858\n",
            "Epoch 3, Sample 15655: Loss: 1.0818\n",
            "Epoch 3, Sample 15656: Loss: 0.7036\n",
            "Epoch 3, Sample 15657: Loss: 0.1336\n",
            "Epoch 3, Sample 15658: Loss: 0.0915\n",
            "Epoch 3, Sample 15659: Loss: 0.5000\n",
            "Epoch 3, Sample 15660: Loss: 0.2044\n",
            "Epoch 3, Sample 15661: Loss: 0.3731\n",
            "Epoch 3, Sample 15662: Loss: 0.2799\n",
            "Epoch 3, Sample 15663: Loss: 0.6068\n",
            "Epoch 3, Sample 15664: Loss: 0.4611\n",
            "Epoch 3, Sample 15665: Loss: 0.3223\n",
            "Epoch 3, Sample 15666: Loss: 0.7203\n",
            "Epoch 3, Sample 15667: Loss: 1.0155\n",
            "Epoch 3, Sample 15668: Loss: 1.0266\n",
            "Epoch 3, Sample 15669: Loss: 0.5044\n",
            "Epoch 3, Sample 15670: Loss: 0.0026\n",
            "Epoch 3, Sample 15671: Loss: 0.0972\n",
            "Epoch 3, Sample 15672: Loss: 0.1250\n",
            "Epoch 3, Sample 15673: Loss: 0.2989\n",
            "Epoch 3, Sample 15674: Loss: 0.0025\n",
            "Epoch 3, Sample 15675: Loss: 0.1346\n",
            "Epoch 3, Sample 15676: Loss: 0.4930\n",
            "Epoch 3, Sample 15677: Loss: 1.0524\n",
            "Epoch 3, Sample 15678: Loss: 0.3402\n",
            "Epoch 3, Sample 15679: Loss: 0.2112\n",
            "Epoch 3, Sample 15680: Loss: 1.0524\n",
            "Epoch 3, Sample 15681: Loss: 0.0025\n",
            "Epoch 3, Sample 15682: Loss: 0.3568\n",
            "Epoch 3, Sample 15683: Loss: 2.2273\n",
            "Epoch 3, Sample 15684: Loss: 0.1817\n",
            "Epoch 3, Sample 15685: Loss: 0.1036\n",
            "Epoch 3, Sample 15686: Loss: 0.6650\n",
            "Epoch 3, Sample 15687: Loss: 0.6645\n",
            "Epoch 3, Sample 15688: Loss: 0.0451\n",
            "Epoch 3, Sample 15689: Loss: 0.0730\n",
            "Epoch 3, Sample 15690: Loss: 0.2044\n",
            "Epoch 3, Sample 15691: Loss: 0.1730\n",
            "Epoch 3, Sample 15692: Loss: 0.2044\n",
            "Epoch 3, Sample 15693: Loss: 5.0404\n",
            "Epoch 3, Sample 15694: Loss: 1.0524\n",
            "Epoch 3, Sample 15695: Loss: 0.4550\n",
            "Epoch 3, Sample 15696: Loss: 0.7036\n",
            "Epoch 3, Sample 15697: Loss: 0.7453\n",
            "Epoch 3, Sample 15698: Loss: 0.3399\n",
            "Epoch 3, Sample 15699: Loss: 0.0026\n",
            "Epoch 3, Sample 15700: Loss: 0.0630\n",
            "Epoch 3, Sample 15701: Loss: 0.0026\n",
            "Epoch 3, Sample 15702: Loss: 0.2121\n",
            "Epoch 3, Sample 15703: Loss: 0.3247\n",
            "Epoch 3, Sample 15704: Loss: 0.0625\n",
            "Epoch 3, Sample 15705: Loss: 0.6990\n",
            "Epoch 3, Sample 15706: Loss: 0.3402\n",
            "Epoch 3, Sample 15707: Loss: 0.0478\n",
            "Epoch 3, Sample 15708: Loss: 0.2706\n",
            "Epoch 3, Sample 15709: Loss: 0.1495\n",
            "Epoch 3, Sample 15710: Loss: 0.3441\n",
            "Epoch 3, Sample 15711: Loss: 0.2759\n",
            "Epoch 3, Sample 15712: Loss: 1.7963\n",
            "Epoch 3, Sample 15713: Loss: 0.0055\n",
            "Epoch 3, Sample 15714: Loss: 0.6990\n",
            "Epoch 3, Sample 15715: Loss: 0.3399\n",
            "Epoch 3, Sample 15716: Loss: 0.0610\n",
            "Epoch 3, Sample 15717: Loss: 2.7331\n",
            "Epoch 3, Sample 15718: Loss: 0.1250\n",
            "Epoch 3, Sample 15719: Loss: 0.9260\n",
            "Epoch 3, Sample 15720: Loss: 0.1941\n",
            "Epoch 3, Sample 15721: Loss: 0.0906\n",
            "Epoch 3, Sample 15722: Loss: 0.0306\n",
            "Epoch 3, Sample 15723: Loss: 0.3949\n",
            "Epoch 3, Sample 15724: Loss: 2.9718\n",
            "Epoch 3, Sample 15725: Loss: 0.3174\n",
            "Epoch 3, Sample 15726: Loss: 0.2755\n",
            "Epoch 3, Sample 15727: Loss: 1.9640\n",
            "Epoch 3, Sample 15728: Loss: 1.0155\n",
            "Epoch 3, Sample 15729: Loss: 0.3949\n",
            "Epoch 3, Sample 15730: Loss: 0.6139\n",
            "Epoch 3, Sample 15731: Loss: 0.1559\n",
            "Epoch 3, Sample 15732: Loss: 2.2434\n",
            "Epoch 3, Sample 15733: Loss: 0.3332\n",
            "Epoch 3, Sample 15734: Loss: 0.1170\n",
            "Epoch 3, Sample 15735: Loss: 0.0505\n",
            "Epoch 3, Sample 15736: Loss: 1.0376\n",
            "Epoch 3, Sample 15737: Loss: 0.8951\n",
            "Epoch 3, Sample 15738: Loss: 0.4996\n",
            "Epoch 3, Sample 15739: Loss: 0.2219\n",
            "Epoch 3, Sample 15740: Loss: 0.2032\n",
            "Epoch 3, Sample 15741: Loss: 0.2044\n",
            "Epoch 3, Sample 15742: Loss: 0.4996\n",
            "Epoch 3, Sample 15743: Loss: 0.2219\n",
            "Epoch 3, Sample 15744: Loss: 0.3399\n",
            "Epoch 3, Sample 15745: Loss: 0.0460\n",
            "Epoch 3, Sample 15746: Loss: 0.1559\n",
            "Epoch 3, Sample 15747: Loss: 0.0630\n",
            "Epoch 3, Sample 15748: Loss: 0.1250\n",
            "Epoch 3, Sample 15749: Loss: 0.7486\n",
            "Epoch 3, Sample 15750: Loss: 0.0040\n",
            "Epoch 3, Sample 15751: Loss: 0.2044\n",
            "Epoch 3, Sample 15752: Loss: 0.1559\n",
            "Epoch 3, Sample 15753: Loss: 0.0018\n",
            "Epoch 3, Sample 15754: Loss: 0.0590\n",
            "Epoch 3, Sample 15755: Loss: 0.5000\n",
            "Epoch 3, Sample 15756: Loss: 0.0026\n",
            "Epoch 3, Sample 15757: Loss: 0.0782\n",
            "Epoch 3, Sample 15758: Loss: 0.1246\n",
            "Epoch 3, Sample 15759: Loss: 0.9367\n",
            "Epoch 3, Sample 15760: Loss: 0.1170\n",
            "Epoch 3, Sample 15761: Loss: 0.0294\n",
            "Epoch 3, Sample 15762: Loss: 0.4799\n",
            "Epoch 3, Sample 15763: Loss: 0.7453\n",
            "Epoch 3, Sample 15764: Loss: 0.6990\n",
            "Epoch 3, Sample 15765: Loss: 0.5003\n",
            "Epoch 3, Sample 15766: Loss: 1.0155\n",
            "Epoch 3, Sample 15767: Loss: 1.0524\n",
            "Epoch 3, Sample 15768: Loss: 0.3441\n",
            "Epoch 3, Sample 15769: Loss: 0.1219\n",
            "Epoch 3, Sample 15770: Loss: 0.0072\n",
            "Epoch 3, Sample 15771: Loss: 0.3539\n",
            "Epoch 3, Sample 15772: Loss: 0.6990\n",
            "Epoch 3, Sample 15773: Loss: 0.0042\n",
            "Epoch 3, Sample 15774: Loss: 0.7036\n",
            "Epoch 3, Sample 15775: Loss: 0.5871\n",
            "Epoch 3, Sample 15776: Loss: 0.3949\n",
            "Epoch 3, Sample 15777: Loss: 0.3441\n",
            "Epoch 3, Sample 15778: Loss: 0.0144\n",
            "Epoch 3, Sample 15779: Loss: 0.9355\n",
            "Epoch 3, Sample 15780: Loss: 0.1399\n",
            "Epoch 3, Sample 15781: Loss: 0.7036\n",
            "Epoch 3, Sample 15782: Loss: 0.1968\n",
            "Epoch 3, Sample 15783: Loss: 0.1397\n",
            "Epoch 3, Sample 15784: Loss: 0.8731\n",
            "Epoch 3, Sample 15785: Loss: 0.5003\n",
            "Epoch 3, Sample 15786: Loss: 0.5443\n",
            "Epoch 3, Sample 15787: Loss: 0.2034\n",
            "Epoch 3, Sample 15788: Loss: 1.0530\n",
            "Epoch 3, Sample 15789: Loss: 0.3441\n",
            "Epoch 3, Sample 15790: Loss: 0.1654\n",
            "Epoch 3, Sample 15791: Loss: 0.3399\n",
            "Epoch 3, Sample 15792: Loss: 0.4611\n",
            "Epoch 3, Sample 15793: Loss: 1.0524\n",
            "Epoch 3, Sample 15794: Loss: 1.0524\n",
            "Epoch 3, Sample 15795: Loss: 1.0524\n",
            "Epoch 3, Sample 15796: Loss: 0.0014\n",
            "Epoch 3, Sample 15797: Loss: 0.7486\n",
            "Epoch 3, Sample 15798: Loss: 0.1250\n",
            "Epoch 3, Sample 15799: Loss: 0.1185\n",
            "Epoch 3, Sample 15800: Loss: 1.0524\n",
            "Epoch 3, Sample 15801: Loss: 0.2034\n",
            "Epoch 3, Sample 15802: Loss: 0.3441\n",
            "Epoch 3, Sample 15803: Loss: 0.0838\n",
            "Epoch 3, Sample 15804: Loss: 0.4930\n",
            "Epoch 3, Sample 15805: Loss: 0.0763\n",
            "Epoch 3, Sample 15806: Loss: 0.6781\n",
            "Epoch 3, Sample 15807: Loss: 0.8807\n",
            "Epoch 3, Sample 15808: Loss: 1.0524\n",
            "Epoch 3, Sample 15809: Loss: 0.0110\n",
            "Epoch 3, Sample 15810: Loss: 0.0554\n",
            "Epoch 3, Sample 15811: Loss: 0.7036\n",
            "Epoch 3, Sample 15812: Loss: 0.3471\n",
            "Epoch 3, Sample 15813: Loss: 0.0145\n",
            "Epoch 3, Sample 15814: Loss: 0.2034\n",
            "Epoch 3, Sample 15815: Loss: 0.3441\n",
            "Epoch 3, Sample 15816: Loss: 0.0307\n",
            "Epoch 3, Sample 15817: Loss: 0.0018\n",
            "Epoch 3, Sample 15818: Loss: 0.0212\n",
            "Epoch 3, Sample 15819: Loss: 0.0368\n",
            "Epoch 3, Sample 15820: Loss: 0.1811\n",
            "Epoch 3, Sample 15821: Loss: 0.0024\n",
            "Epoch 3, Sample 15822: Loss: 0.4032\n",
            "Epoch 3, Sample 15823: Loss: 0.2989\n",
            "Epoch 3, Sample 15824: Loss: 0.2340\n",
            "Epoch 3, Sample 15825: Loss: 0.0026\n",
            "Epoch 3, Sample 15826: Loss: 0.0026\n",
            "Epoch 3, Sample 15827: Loss: 0.3207\n",
            "Epoch 3, Sample 15828: Loss: 3.3471\n",
            "Epoch 3, Sample 15829: Loss: 0.0012\n",
            "Epoch 3, Sample 15830: Loss: 0.9367\n",
            "Epoch 3, Sample 15831: Loss: 1.0524\n",
            "Epoch 3, Sample 15832: Loss: 0.2044\n",
            "Epoch 3, Sample 15833: Loss: 0.1387\n",
            "Epoch 3, Sample 15834: Loss: 0.0460\n",
            "Epoch 3, Sample 15835: Loss: 0.2935\n",
            "Epoch 3, Sample 15836: Loss: 0.3688\n",
            "Epoch 3, Sample 15837: Loss: 0.2044\n",
            "Epoch 3, Sample 15838: Loss: 0.2704\n",
            "Epoch 3, Sample 15839: Loss: 0.6139\n",
            "Epoch 3, Sample 15840: Loss: 2.6860\n",
            "Epoch 3, Sample 15841: Loss: 9.1118\n",
            "Epoch 3, Sample 15842: Loss: 0.1250\n",
            "Epoch 3, Sample 15843: Loss: 0.1170\n",
            "Epoch 3, Sample 15844: Loss: 0.0608\n",
            "Epoch 3, Sample 15845: Loss: 0.7036\n",
            "Epoch 3, Sample 15846: Loss: 0.4799\n",
            "Epoch 3, Sample 15847: Loss: 0.0026\n",
            "Epoch 3, Sample 15848: Loss: 0.2759\n",
            "Epoch 3, Sample 15849: Loss: 0.3949\n",
            "Epoch 3, Sample 15850: Loss: 0.6249\n",
            "Epoch 3, Sample 15851: Loss: 1.1516\n",
            "Epoch 3, Sample 15852: Loss: 0.5959\n",
            "Epoch 3, Sample 15853: Loss: 0.0018\n",
            "Epoch 3, Sample 15854: Loss: 0.8951\n",
            "Epoch 3, Sample 15855: Loss: 0.4382\n",
            "Epoch 3, Sample 15856: Loss: 0.3758\n",
            "Epoch 3, Sample 15857: Loss: 0.0018\n",
            "Epoch 3, Sample 15858: Loss: 0.0026\n",
            "Epoch 3, Sample 15859: Loss: 0.4902\n",
            "Epoch 3, Sample 15860: Loss: 0.2034\n",
            "Epoch 3, Sample 15861: Loss: 0.0692\n",
            "Epoch 3, Sample 15862: Loss: 0.3399\n",
            "Epoch 3, Sample 15863: Loss: 0.0008\n",
            "Epoch 3, Sample 15864: Loss: 0.2032\n",
            "Epoch 3, Sample 15865: Loss: 0.9367\n",
            "Epoch 3, Sample 15866: Loss: 0.2036\n",
            "Epoch 3, Sample 15867: Loss: 0.3503\n",
            "Epoch 3, Sample 15868: Loss: 2.1901\n",
            "Epoch 3, Sample 15869: Loss: 0.2032\n",
            "Epoch 3, Sample 15870: Loss: 0.8951\n",
            "Epoch 3, Sample 15871: Loss: 0.1250\n",
            "Epoch 3, Sample 15872: Loss: 0.2826\n",
            "Epoch 3, Sample 15873: Loss: 0.3441\n",
            "Epoch 3, Sample 15874: Loss: 0.1399\n",
            "Epoch 3, Sample 15875: Loss: 0.1807\n",
            "Epoch 3, Sample 15876: Loss: 0.1767\n",
            "Epoch 3, Sample 15877: Loss: 0.2759\n",
            "Epoch 3, Sample 15878: Loss: 0.0026\n",
            "Epoch 3, Sample 15879: Loss: 0.1559\n",
            "Epoch 3, Sample 15880: Loss: 0.1233\n",
            "Epoch 3, Sample 15881: Loss: 0.2034\n",
            "Epoch 3, Sample 15882: Loss: 0.1170\n",
            "Epoch 3, Sample 15883: Loss: 0.0001\n",
            "Epoch 3, Sample 15884: Loss: 0.8951\n",
            "Epoch 3, Sample 15885: Loss: 0.2759\n",
            "Epoch 3, Sample 15886: Loss: 0.1170\n",
            "Epoch 3, Sample 15887: Loss: 0.1170\n",
            "Epoch 3, Sample 15888: Loss: 0.2832\n",
            "Epoch 3, Sample 15889: Loss: 0.3938\n",
            "Epoch 3, Sample 15890: Loss: 0.0606\n",
            "Epoch 3, Sample 15891: Loss: 0.2340\n",
            "Epoch 3, Sample 15892: Loss: 0.7178\n",
            "Epoch 3, Sample 15893: Loss: 0.2044\n",
            "Epoch 3, Sample 15894: Loss: 0.2778\n",
            "Epoch 3, Sample 15895: Loss: 1.0155\n",
            "Epoch 3, Sample 15896: Loss: 0.4799\n",
            "Epoch 3, Sample 15897: Loss: 0.0026\n",
            "Epoch 3, Sample 15898: Loss: 0.0001\n",
            "Epoch 3, Sample 15899: Loss: 0.1166\n",
            "Epoch 3, Sample 15900: Loss: 0.3399\n",
            "Epoch 3, Sample 15901: Loss: 0.6304\n",
            "Epoch 3, Sample 15902: Loss: 1.2521\n",
            "Epoch 3, Sample 15903: Loss: 0.2167\n",
            "Epoch 3, Sample 15904: Loss: 0.5858\n",
            "Epoch 3, Sample 15905: Loss: 0.2034\n",
            "Epoch 3, Sample 15906: Loss: 0.0205\n",
            "Epoch 3, Sample 15907: Loss: 0.6990\n",
            "Epoch 3, Sample 15908: Loss: 0.5858\n",
            "Epoch 3, Sample 15909: Loss: 0.8951\n",
            "Epoch 3, Sample 15910: Loss: 0.2121\n",
            "Epoch 3, Sample 15911: Loss: 0.0625\n",
            "Epoch 3, Sample 15912: Loss: 0.2341\n",
            "Epoch 3, Sample 15913: Loss: 0.0001\n",
            "Epoch 3, Sample 15914: Loss: 9.7269\n",
            "Epoch 3, Sample 15915: Loss: 0.0630\n",
            "Epoch 3, Sample 15916: Loss: 0.0108\n",
            "Epoch 3, Sample 15917: Loss: 0.2032\n",
            "Epoch 3, Sample 15918: Loss: 0.3441\n",
            "Epoch 3, Sample 15919: Loss: 0.2791\n",
            "Epoch 3, Sample 15920: Loss: 0.5196\n",
            "Epoch 3, Sample 15921: Loss: 0.3126\n",
            "Epoch 3, Sample 15922: Loss: 0.7036\n",
            "Epoch 3, Sample 15923: Loss: 0.7036\n",
            "Epoch 3, Sample 15924: Loss: 0.4799\n",
            "Epoch 3, Sample 15925: Loss: 0.0026\n",
            "Epoch 3, Sample 15926: Loss: 0.0014\n",
            "Epoch 3, Sample 15927: Loss: 1.0530\n",
            "Epoch 3, Sample 15928: Loss: 0.0838\n",
            "Epoch 3, Sample 15929: Loss: 0.0001\n",
            "Epoch 3, Sample 15930: Loss: 0.3758\n",
            "Epoch 3, Sample 15931: Loss: 0.0306\n",
            "Epoch 3, Sample 15932: Loss: 0.3450\n",
            "Epoch 3, Sample 15933: Loss: 0.0413\n",
            "Epoch 3, Sample 15934: Loss: 0.0001\n",
            "Epoch 3, Sample 15935: Loss: 0.0960\n",
            "Epoch 3, Sample 15936: Loss: 0.3214\n",
            "Epoch 3, Sample 15937: Loss: 0.5089\n",
            "Epoch 3, Sample 15938: Loss: 1.0373\n",
            "Epoch 3, Sample 15939: Loss: 0.0626\n",
            "Epoch 3, Sample 15940: Loss: 0.6990\n",
            "Epoch 3, Sample 15941: Loss: 0.4797\n",
            "Epoch 3, Sample 15942: Loss: 0.1588\n",
            "Epoch 3, Sample 15943: Loss: 0.2935\n",
            "Epoch 3, Sample 15944: Loss: 0.3399\n",
            "Epoch 3, Sample 15945: Loss: 0.0652\n",
            "Epoch 3, Sample 15946: Loss: 0.1252\n",
            "Epoch 3, Sample 15947: Loss: 0.1545\n",
            "Epoch 3, Sample 15948: Loss: 0.0062\n",
            "Epoch 3, Sample 15949: Loss: 0.0303\n",
            "Epoch 3, Sample 15950: Loss: 0.1672\n",
            "Epoch 3, Sample 15951: Loss: 1.0524\n",
            "Epoch 3, Sample 15952: Loss: 0.2759\n",
            "Epoch 3, Sample 15953: Loss: 0.1627\n",
            "Epoch 3, Sample 15954: Loss: 0.2030\n",
            "Epoch 3, Sample 15955: Loss: 0.3399\n",
            "Epoch 3, Sample 15956: Loss: 0.6867\n",
            "Epoch 3, Sample 15957: Loss: 0.8225\n",
            "Epoch 3, Sample 15958: Loss: 0.1033\n",
            "Epoch 3, Sample 15959: Loss: 0.0933\n",
            "Epoch 3, Sample 15960: Loss: 0.2340\n",
            "Epoch 3, Sample 15961: Loss: 0.5320\n",
            "Epoch 3, Sample 15962: Loss: 0.0895\n",
            "Epoch 3, Sample 15963: Loss: 1.0530\n",
            "Epoch 3, Sample 15964: Loss: 0.2552\n",
            "Epoch 3, Sample 15965: Loss: 0.3332\n",
            "Epoch 3, Sample 15966: Loss: 0.6139\n",
            "Epoch 3, Sample 15967: Loss: 0.2962\n",
            "Epoch 3, Sample 15968: Loss: 0.0530\n",
            "Epoch 3, Sample 15969: Loss: 0.1104\n",
            "Epoch 3, Sample 15970: Loss: 0.1999\n",
            "Epoch 3, Sample 15971: Loss: 0.6904\n",
            "Epoch 3, Sample 15972: Loss: 0.0026\n",
            "Epoch 3, Sample 15973: Loss: 0.6123\n",
            "Epoch 3, Sample 15974: Loss: 0.3399\n",
            "Epoch 3, Sample 15975: Loss: 0.8028\n",
            "Epoch 3, Sample 15976: Loss: 1.0524\n",
            "Epoch 3, Sample 15977: Loss: 0.6867\n",
            "Epoch 3, Sample 15978: Loss: 0.2044\n",
            "Epoch 3, Sample 15979: Loss: 0.0630\n",
            "Epoch 3, Sample 15980: Loss: 0.8951\n",
            "Epoch 3, Sample 15981: Loss: 0.3441\n",
            "Epoch 3, Sample 15982: Loss: 0.3399\n",
            "Epoch 3, Sample 15983: Loss: 1.0524\n",
            "Epoch 3, Sample 15984: Loss: 0.0018\n",
            "Epoch 3, Sample 15985: Loss: 0.8951\n",
            "Epoch 3, Sample 15986: Loss: 0.0767\n",
            "Epoch 3, Sample 15987: Loss: 0.0026\n",
            "Epoch 3, Sample 15988: Loss: 0.0026\n",
            "Epoch 3, Sample 15989: Loss: 1.0155\n",
            "Epoch 3, Sample 15990: Loss: 0.4641\n",
            "Epoch 3, Sample 15991: Loss: 0.0392\n",
            "Epoch 3, Sample 15992: Loss: 0.1219\n",
            "Epoch 3, Sample 15993: Loss: 0.2182\n",
            "Epoch 3, Sample 15994: Loss: 0.1246\n",
            "Epoch 3, Sample 15995: Loss: 0.6139\n",
            "Epoch 3, Sample 15996: Loss: 2.0560\n",
            "Epoch 3, Sample 15997: Loss: 0.1457\n",
            "Epoch 3, Sample 15998: Loss: 0.5972\n",
            "Epoch 3, Sample 15999: Loss: 0.0050\n",
            "Epoch 3, Sample 16000: Loss: 0.6867\n",
            "\n",
            "Epoch 3 Average Loss: 0.5441\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 7th trial we chose these settings\n",
        "epochs = 3\n",
        "learning_rate = .005\n",
        "input_size = 20\n",
        "Neurons = 150\n",
        "activation_input = 150\n",
        "activation function = relu\n",
        "output = 1"
      ],
      "metadata": {
        "id": "tqMsy2ieeL-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "learning_rate = .005\n",
        "\n",
        "\n",
        "# Initializing Parameters\n",
        "w = 50\n",
        "\n",
        "loss_set = {}\n",
        "\n",
        "# 1. Creating a FeedForwardNetwork\n",
        "# 1.1 Structure (Architecture) of NN\n",
        "model_net7 = torch.nn.Sequential(torch.nn.Linear(20,150),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Dropout(0.33),\n",
        "\n",
        "                                 torch.nn.Linear(150,1),\n",
        "                                 torch.nn.ReLU(),\n",
        "\n",
        "                                 );\n",
        "\n",
        "# 1.2 Loss Function\n",
        "loss_mse = torch.nn.MSELoss()\n",
        "\n",
        "# 1.3 Optmization Approch\n",
        "optimizer = torch.optim.SGD(model_net7.parameters(), lr=learning_rate)\n",
        "\n",
        "w_his = []\n",
        "w_his.append(w)\n",
        "# Loop over the number of epochs\n",
        "for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Loop over each sample in the dataset\n",
        "    for i in range(tensor_data_X.size(0)):\n",
        "\n",
        "      # 2. Forward Pass\n",
        "      output = model_net7.forward(tensor_data_X[i].reshape(-1))\n",
        "\n",
        "      # 3. FeedForward Evaluation\n",
        "      loss = loss_mse(output, tensor_data_Y[i].reshape(-1))\n",
        "      optimizer.zero_grad();\n",
        "\n",
        "      # 4. Backward Pass / Gradient Calculation\n",
        "      loss.backward()\n",
        "\n",
        "      # Store the loss for each epoch\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      # 5. Back Propagation / Update Weights\n",
        "      optimizer.step()\n",
        "\n",
        "      # Store the weight value for each sample of data\n",
        "      w_his.append(float(model_net7[0].weight.data[0][0]))\n",
        "\n",
        "      # Display the loss for the current sample\n",
        "      print(f\"Epoch {epoch+1}, Sample {i+1}: Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    # Calculate and display average loss for the epoch\n",
        "    epoch_loss /= tensor_data_X.size(0)\n",
        "\n",
        "    # Store the loss for each sample of data\n",
        "    loss_set[epoch] = epoch_loss\n",
        "    print(f\"\\nEpoch {epoch+1} Average Loss: {epoch_loss:.4f}\\n{'-'*50}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3b9877aecdd748e5a5b9899bb1dbed2f",
            "63ed299e38df4d08a84e182d353730b8",
            "d1443db93e0f4e5aaa5c6fd1a1a0fc42",
            "4e27e026b1204d8f8e82ad5bfb6a7ace",
            "01d4b4a66b814998942f15039a65fce0",
            "93c32080c66e474b84c995ace371731a",
            "03dacb15e4144d3fbef377739fdbe160",
            "e14b4d98feaf480ab549677dfd99661b",
            "5fd6b49303d04afca4cf2617680b3262",
            "1f4e7ae3143a4fb89ee9563a33c5cbd0",
            "f38cceb21b684b9fa213093d68ecb6ee"
          ]
        },
        "id": "l0280t8wdtjz",
        "outputId": "d6f765b4-7495-4a4a-9074-f54dde14eda2"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-284-763b4addd60f>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for epoch in tqdm_notebook(range(epochs), desc=\"Epochs\"):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b9877aecdd748e5a5b9899bb1dbed2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 3, Sample 11005: Loss: 0.2832\n",
            "Epoch 3, Sample 11006: Loss: 0.1296\n",
            "Epoch 3, Sample 11007: Loss: 0.0322\n",
            "Epoch 3, Sample 11008: Loss: 0.7036\n",
            "Epoch 3, Sample 11009: Loss: 0.5125\n",
            "Epoch 3, Sample 11010: Loss: 0.0008\n",
            "Epoch 3, Sample 11011: Loss: 0.0026\n",
            "Epoch 3, Sample 11012: Loss: 0.7453\n",
            "Epoch 3, Sample 11013: Loss: 0.1437\n",
            "Epoch 3, Sample 11014: Loss: 0.2032\n",
            "Epoch 3, Sample 11015: Loss: 1.2107\n",
            "Epoch 3, Sample 11016: Loss: 0.3399\n",
            "Epoch 3, Sample 11017: Loss: 0.2339\n",
            "Epoch 3, Sample 11018: Loss: 1.9680\n",
            "Epoch 3, Sample 11019: Loss: 0.0505\n",
            "Epoch 3, Sample 11020: Loss: 0.1170\n",
            "Epoch 3, Sample 11021: Loss: 0.4663\n",
            "Epoch 3, Sample 11022: Loss: 1.6418\n",
            "Epoch 3, Sample 11023: Loss: 0.2750\n",
            "Epoch 3, Sample 11024: Loss: 0.9367\n",
            "Epoch 3, Sample 11025: Loss: 0.0025\n",
            "Epoch 3, Sample 11026: Loss: 1.1265\n",
            "Epoch 3, Sample 11027: Loss: 1.0155\n",
            "Epoch 3, Sample 11028: Loss: 0.7036\n",
            "Epoch 3, Sample 11029: Loss: 0.5871\n",
            "Epoch 3, Sample 11030: Loss: 0.0212\n",
            "Epoch 3, Sample 11031: Loss: 0.0505\n",
            "Epoch 3, Sample 11032: Loss: 1.0524\n",
            "Epoch 3, Sample 11033: Loss: 0.5576\n",
            "Epoch 3, Sample 11034: Loss: 0.1838\n",
            "Epoch 3, Sample 11035: Loss: 0.0189\n",
            "Epoch 3, Sample 11036: Loss: 0.0004\n",
            "Epoch 3, Sample 11037: Loss: 0.2098\n",
            "Epoch 3, Sample 11038: Loss: 0.5795\n",
            "Epoch 3, Sample 11039: Loss: 1.0155\n",
            "Epoch 3, Sample 11040: Loss: 1.0524\n",
            "Epoch 3, Sample 11041: Loss: 0.0391\n",
            "Epoch 3, Sample 11042: Loss: 3.2535\n",
            "Epoch 3, Sample 11043: Loss: 0.0287\n",
            "Epoch 3, Sample 11044: Loss: 0.2639\n",
            "Epoch 3, Sample 11045: Loss: 0.0630\n",
            "Epoch 3, Sample 11046: Loss: 0.3441\n",
            "Epoch 3, Sample 11047: Loss: 0.0090\n",
            "Epoch 3, Sample 11048: Loss: 0.9367\n",
            "Epoch 3, Sample 11049: Loss: 0.2759\n",
            "Epoch 3, Sample 11050: Loss: 0.0084\n",
            "Epoch 3, Sample 11051: Loss: 0.0001\n",
            "Epoch 3, Sample 11052: Loss: 2.5380\n",
            "Epoch 3, Sample 11053: Loss: 0.2032\n",
            "Epoch 3, Sample 11054: Loss: 0.0554\n",
            "Epoch 3, Sample 11055: Loss: 0.1248\n",
            "Epoch 3, Sample 11056: Loss: 0.0018\n",
            "Epoch 3, Sample 11057: Loss: 0.1082\n",
            "Epoch 3, Sample 11058: Loss: 1.1656\n",
            "Epoch 3, Sample 11059: Loss: 0.5972\n",
            "Epoch 3, Sample 11060: Loss: 0.0625\n",
            "Epoch 3, Sample 11061: Loss: 1.5886\n",
            "Epoch 3, Sample 11062: Loss: 0.0234\n",
            "Epoch 3, Sample 11063: Loss: 0.2044\n",
            "Epoch 3, Sample 11064: Loss: 0.9017\n",
            "Epoch 3, Sample 11065: Loss: 0.7036\n",
            "Epoch 3, Sample 11066: Loss: 0.1836\n",
            "Epoch 3, Sample 11067: Loss: 0.0969\n",
            "Epoch 3, Sample 11068: Loss: 1.0530\n",
            "Epoch 3, Sample 11069: Loss: 0.7036\n",
            "Epoch 3, Sample 11070: Loss: 0.2639\n",
            "Epoch 3, Sample 11071: Loss: 0.7036\n",
            "Epoch 3, Sample 11072: Loss: 0.5858\n",
            "Epoch 3, Sample 11073: Loss: 0.0068\n",
            "Epoch 3, Sample 11074: Loss: 0.1287\n",
            "Epoch 3, Sample 11075: Loss: 0.0026\n",
            "Epoch 3, Sample 11076: Loss: 0.0456\n",
            "Epoch 3, Sample 11077: Loss: 0.4367\n",
            "Epoch 3, Sample 11078: Loss: 0.2412\n",
            "Epoch 3, Sample 11079: Loss: 0.3399\n",
            "Epoch 3, Sample 11080: Loss: 0.2744\n",
            "Epoch 3, Sample 11081: Loss: 0.0145\n",
            "Epoch 3, Sample 11082: Loss: 0.0026\n",
            "Epoch 3, Sample 11083: Loss: 0.2639\n",
            "Epoch 3, Sample 11084: Loss: 0.0205\n",
            "Epoch 3, Sample 11085: Loss: 1.0524\n",
            "Epoch 3, Sample 11086: Loss: 0.3399\n",
            "Epoch 3, Sample 11087: Loss: 0.1559\n",
            "Epoch 3, Sample 11088: Loss: 1.0155\n",
            "Epoch 3, Sample 11089: Loss: 0.0022\n",
            "Epoch 3, Sample 11090: Loss: 0.0630\n",
            "Epoch 3, Sample 11091: Loss: 0.2044\n",
            "Epoch 3, Sample 11092: Loss: 0.0018\n",
            "Epoch 3, Sample 11093: Loss: 0.0942\n",
            "Epoch 3, Sample 11094: Loss: 0.0026\n",
            "Epoch 3, Sample 11095: Loss: 1.0524\n",
            "Epoch 3, Sample 11096: Loss: 0.2340\n",
            "Epoch 3, Sample 11097: Loss: 0.5078\n",
            "Epoch 3, Sample 11098: Loss: 0.0108\n",
            "Epoch 3, Sample 11099: Loss: 0.2295\n",
            "Epoch 3, Sample 11100: Loss: 0.2044\n",
            "Epoch 3, Sample 11101: Loss: 0.1170\n",
            "Epoch 3, Sample 11102: Loss: 0.2036\n",
            "Epoch 3, Sample 11103: Loss: 0.5858\n",
            "Epoch 3, Sample 11104: Loss: 0.2034\n",
            "Epoch 3, Sample 11105: Loss: 0.1248\n",
            "Epoch 3, Sample 11106: Loss: 0.2032\n",
            "Epoch 3, Sample 11107: Loss: 0.2738\n",
            "Epoch 3, Sample 11108: Loss: 0.0630\n",
            "Epoch 3, Sample 11109: Loss: 0.2340\n",
            "Epoch 3, Sample 11110: Loss: 1.0524\n",
            "Epoch 3, Sample 11111: Loss: 0.2032\n",
            "Epoch 3, Sample 11112: Loss: 0.0038\n",
            "Epoch 3, Sample 11113: Loss: 1.0524\n",
            "Epoch 3, Sample 11114: Loss: 1.0155\n",
            "Epoch 3, Sample 11115: Loss: 0.1250\n",
            "Epoch 3, Sample 11116: Loss: 0.4607\n",
            "Epoch 3, Sample 11117: Loss: 1.0524\n",
            "Epoch 3, Sample 11118: Loss: 0.0034\n",
            "Epoch 3, Sample 11119: Loss: 1.0524\n",
            "Epoch 3, Sample 11120: Loss: 0.7036\n",
            "Epoch 3, Sample 11121: Loss: 0.2044\n",
            "Epoch 3, Sample 11122: Loss: 0.1170\n",
            "Epoch 3, Sample 11123: Loss: 0.5278\n",
            "Epoch 3, Sample 11124: Loss: 0.2759\n",
            "Epoch 3, Sample 11125: Loss: 0.0630\n",
            "Epoch 3, Sample 11126: Loss: 0.7036\n",
            "Epoch 3, Sample 11127: Loss: 2.8141\n",
            "Epoch 3, Sample 11128: Loss: 0.4930\n",
            "Epoch 3, Sample 11129: Loss: 0.9367\n",
            "Epoch 3, Sample 11130: Loss: 0.1410\n",
            "Epoch 3, Sample 11131: Loss: 0.4062\n",
            "Epoch 3, Sample 11132: Loss: 1.0524\n",
            "Epoch 3, Sample 11133: Loss: 0.9148\n",
            "Epoch 3, Sample 11134: Loss: 0.0460\n",
            "Epoch 3, Sample 11135: Loss: 0.2036\n",
            "Epoch 3, Sample 11136: Loss: 0.0018\n",
            "Epoch 3, Sample 11137: Loss: 0.0141\n",
            "Epoch 3, Sample 11138: Loss: 1.2813\n",
            "Epoch 3, Sample 11139: Loss: 0.0001\n",
            "Epoch 3, Sample 11140: Loss: 0.7151\n",
            "Epoch 3, Sample 11141: Loss: 0.2759\n",
            "Epoch 3, Sample 11142: Loss: 0.4611\n",
            "Epoch 3, Sample 11143: Loss: 0.2032\n",
            "Epoch 3, Sample 11144: Loss: 0.2219\n",
            "Epoch 3, Sample 11145: Loss: 0.7036\n",
            "Epoch 3, Sample 11146: Loss: 0.0062\n",
            "Epoch 3, Sample 11147: Loss: 4.8640\n",
            "Epoch 3, Sample 11148: Loss: 0.1711\n",
            "Epoch 3, Sample 11149: Loss: 0.7036\n",
            "Epoch 3, Sample 11150: Loss: 0.1817\n",
            "Epoch 3, Sample 11151: Loss: 0.2036\n",
            "Epoch 3, Sample 11152: Loss: 0.0268\n",
            "Epoch 3, Sample 11153: Loss: 0.6990\n",
            "Epoch 3, Sample 11154: Loss: 0.0802\n",
            "Epoch 3, Sample 11155: Loss: 0.1250\n",
            "Epoch 3, Sample 11156: Loss: 0.6304\n",
            "Epoch 3, Sample 11157: Loss: 0.9785\n",
            "Epoch 3, Sample 11158: Loss: 0.8951\n",
            "Epoch 3, Sample 11159: Loss: 0.2044\n",
            "Epoch 3, Sample 11160: Loss: 1.2202\n",
            "Epoch 3, Sample 11161: Loss: 0.3760\n",
            "Epoch 3, Sample 11162: Loss: 0.0026\n",
            "Epoch 3, Sample 11163: Loss: 1.0448\n",
            "Epoch 3, Sample 11164: Loss: 0.0213\n",
            "Epoch 3, Sample 11165: Loss: 0.0144\n",
            "Epoch 3, Sample 11166: Loss: 0.2032\n",
            "Epoch 3, Sample 11167: Loss: 0.7036\n",
            "Epoch 3, Sample 11168: Loss: 0.3873\n",
            "Epoch 3, Sample 11169: Loss: 0.8046\n",
            "Epoch 3, Sample 11170: Loss: 0.9122\n",
            "Epoch 3, Sample 11171: Loss: 1.0530\n",
            "Epoch 3, Sample 11172: Loss: 0.0026\n",
            "Epoch 3, Sample 11173: Loss: 0.2036\n",
            "Epoch 3, Sample 11174: Loss: 0.1523\n",
            "Epoch 3, Sample 11175: Loss: 0.2759\n",
            "Epoch 3, Sample 11176: Loss: 0.0637\n",
            "Epoch 3, Sample 11177: Loss: 1.5460\n",
            "Epoch 3, Sample 11178: Loss: 0.8951\n",
            "Epoch 3, Sample 11179: Loss: 2.7389\n",
            "Epoch 3, Sample 11180: Loss: 0.5000\n",
            "Epoch 3, Sample 11181: Loss: 0.5599\n",
            "Epoch 3, Sample 11182: Loss: 1.0155\n",
            "Epoch 3, Sample 11183: Loss: 0.0039\n",
            "Epoch 3, Sample 11184: Loss: 1.0524\n",
            "Epoch 3, Sample 11185: Loss: 0.3605\n",
            "Epoch 3, Sample 11186: Loss: 0.4611\n",
            "Epoch 3, Sample 11187: Loss: 0.0030\n",
            "Epoch 3, Sample 11188: Loss: 0.2032\n",
            "Epoch 3, Sample 11189: Loss: 1.0155\n",
            "Epoch 3, Sample 11190: Loss: 1.8670\n",
            "Epoch 3, Sample 11191: Loss: 0.3399\n",
            "Epoch 3, Sample 11192: Loss: 0.7036\n",
            "Epoch 3, Sample 11193: Loss: 0.2639\n",
            "Epoch 3, Sample 11194: Loss: 0.2034\n",
            "Epoch 3, Sample 11195: Loss: 0.7036\n",
            "Epoch 3, Sample 11196: Loss: 0.2036\n",
            "Epoch 3, Sample 11197: Loss: 1.0524\n",
            "Epoch 3, Sample 11198: Loss: 0.0626\n",
            "Epoch 3, Sample 11199: Loss: 1.0530\n",
            "Epoch 3, Sample 11200: Loss: 2.6384\n",
            "Epoch 3, Sample 11201: Loss: 0.5793\n",
            "Epoch 3, Sample 11202: Loss: 0.0027\n",
            "Epoch 3, Sample 11203: Loss: 0.2034\n",
            "Epoch 3, Sample 11204: Loss: 0.1033\n",
            "Epoch 3, Sample 11205: Loss: 0.4611\n",
            "Epoch 3, Sample 11206: Loss: 1.0524\n",
            "Epoch 3, Sample 11207: Loss: 1.0524\n",
            "Epoch 3, Sample 11208: Loss: 0.1900\n",
            "Epoch 3, Sample 11209: Loss: 0.0630\n",
            "Epoch 3, Sample 11210: Loss: 0.0026\n",
            "Epoch 3, Sample 11211: Loss: 0.2044\n",
            "Epoch 3, Sample 11212: Loss: 0.2832\n",
            "Epoch 3, Sample 11213: Loss: 0.3441\n",
            "Epoch 3, Sample 11214: Loss: 0.4996\n",
            "Epoch 3, Sample 11215: Loss: 0.5375\n",
            "Epoch 3, Sample 11216: Loss: 0.0460\n",
            "Epoch 3, Sample 11217: Loss: 0.5101\n",
            "Epoch 3, Sample 11218: Loss: 0.0090\n",
            "Epoch 3, Sample 11219: Loss: 1.0524\n",
            "Epoch 3, Sample 11220: Loss: 0.0027\n",
            "Epoch 3, Sample 11221: Loss: 0.0108\n",
            "Epoch 3, Sample 11222: Loss: 1.0155\n",
            "Epoch 3, Sample 11223: Loss: 0.0026\n",
            "Epoch 3, Sample 11224: Loss: 0.1170\n",
            "Epoch 3, Sample 11225: Loss: 0.0018\n",
            "Epoch 3, Sample 11226: Loss: 0.2034\n",
            "Epoch 3, Sample 11227: Loss: 0.2340\n",
            "Epoch 3, Sample 11228: Loss: 2.0108\n",
            "Epoch 3, Sample 11229: Loss: 0.1225\n",
            "Epoch 3, Sample 11230: Loss: 0.1674\n",
            "Epoch 3, Sample 11231: Loss: 1.0155\n",
            "Epoch 3, Sample 11232: Loss: 0.3402\n",
            "Epoch 3, Sample 11233: Loss: 0.2340\n",
            "Epoch 3, Sample 11234: Loss: 0.0026\n",
            "Epoch 3, Sample 11235: Loss: 0.1463\n",
            "Epoch 3, Sample 11236: Loss: 0.8951\n",
            "Epoch 3, Sample 11237: Loss: 0.2044\n",
            "Epoch 3, Sample 11238: Loss: 0.4032\n",
            "Epoch 3, Sample 11239: Loss: 0.8584\n",
            "Epoch 3, Sample 11240: Loss: 0.4032\n",
            "Epoch 3, Sample 11241: Loss: 0.0234\n",
            "Epoch 3, Sample 11242: Loss: 0.6990\n",
            "Epoch 3, Sample 11243: Loss: 0.0363\n",
            "Epoch 3, Sample 11244: Loss: 0.8356\n",
            "Epoch 3, Sample 11245: Loss: 0.0625\n",
            "Epoch 3, Sample 11246: Loss: 0.6592\n",
            "Epoch 3, Sample 11247: Loss: 0.1546\n",
            "Epoch 3, Sample 11248: Loss: 0.1306\n",
            "Epoch 3, Sample 11249: Loss: 0.2098\n",
            "Epoch 3, Sample 11250: Loss: 1.0155\n",
            "Epoch 3, Sample 11251: Loss: 0.0915\n",
            "Epoch 3, Sample 11252: Loss: 0.9367\n",
            "Epoch 3, Sample 11253: Loss: 1.3894\n",
            "Epoch 3, Sample 11254: Loss: 0.1559\n",
            "Epoch 3, Sample 11255: Loss: 0.3399\n",
            "Epoch 3, Sample 11256: Loss: 0.3402\n",
            "Epoch 3, Sample 11257: Loss: 0.0804\n",
            "Epoch 3, Sample 11258: Loss: 0.2606\n",
            "Epoch 3, Sample 11259: Loss: 0.6990\n",
            "Epoch 3, Sample 11260: Loss: 1.0524\n",
            "Epoch 3, Sample 11261: Loss: 0.3303\n",
            "Epoch 3, Sample 11262: Loss: 0.0026\n",
            "Epoch 3, Sample 11263: Loss: 0.0391\n",
            "Epoch 3, Sample 11264: Loss: 0.3441\n",
            "Epoch 3, Sample 11265: Loss: 0.8951\n",
            "Epoch 3, Sample 11266: Loss: 2.5845\n",
            "Epoch 3, Sample 11267: Loss: 0.0001\n",
            "Epoch 3, Sample 11268: Loss: 0.2759\n",
            "Epoch 3, Sample 11269: Loss: 0.6304\n",
            "Epoch 3, Sample 11270: Loss: 0.2759\n",
            "Epoch 3, Sample 11271: Loss: 0.2034\n",
            "Epoch 3, Sample 11272: Loss: 0.5858\n",
            "Epoch 3, Sample 11273: Loss: 0.0018\n",
            "Epoch 3, Sample 11274: Loss: 0.3399\n",
            "Epoch 3, Sample 11275: Loss: 1.0266\n",
            "Epoch 3, Sample 11276: Loss: 0.4212\n",
            "Epoch 3, Sample 11277: Loss: 0.0915\n",
            "Epoch 3, Sample 11278: Loss: 0.2044\n",
            "Epoch 3, Sample 11279: Loss: 0.7036\n",
            "Epoch 3, Sample 11280: Loss: 0.3399\n",
            "Epoch 3, Sample 11281: Loss: 2.2434\n",
            "Epoch 3, Sample 11282: Loss: 0.1392\n",
            "Epoch 3, Sample 11283: Loss: 1.4786\n",
            "Epoch 3, Sample 11284: Loss: 0.0018\n",
            "Epoch 3, Sample 11285: Loss: 0.4930\n",
            "Epoch 3, Sample 11286: Loss: 1.4884\n",
            "Epoch 3, Sample 11287: Loss: 0.0971\n",
            "Epoch 3, Sample 11288: Loss: 0.4032\n",
            "Epoch 3, Sample 11289: Loss: 0.2759\n",
            "Epoch 3, Sample 11290: Loss: 1.1626\n",
            "Epoch 3, Sample 11291: Loss: 0.4032\n",
            "Epoch 3, Sample 11292: Loss: 0.6542\n",
            "Epoch 3, Sample 11293: Loss: 0.5871\n",
            "Epoch 3, Sample 11294: Loss: 0.3399\n",
            "Epoch 3, Sample 11295: Loss: 1.5597\n",
            "Epoch 3, Sample 11296: Loss: 0.0630\n",
            "Epoch 3, Sample 11297: Loss: 0.4032\n",
            "Epoch 3, Sample 11298: Loss: 0.2044\n",
            "Epoch 3, Sample 11299: Loss: 0.4867\n",
            "Epoch 3, Sample 11300: Loss: 0.0601\n",
            "Epoch 3, Sample 11301: Loss: 1.0189\n",
            "Epoch 3, Sample 11302: Loss: 0.2044\n",
            "Epoch 3, Sample 11303: Loss: 0.1559\n",
            "Epoch 3, Sample 11304: Loss: 0.2659\n",
            "Epoch 3, Sample 11305: Loss: 7.3966\n",
            "Epoch 3, Sample 11306: Loss: 0.0212\n",
            "Epoch 3, Sample 11307: Loss: 0.2901\n",
            "Epoch 3, Sample 11308: Loss: 1.9021\n",
            "Epoch 3, Sample 11309: Loss: 0.6990\n",
            "Epoch 3, Sample 11310: Loss: 0.1911\n",
            "Epoch 3, Sample 11311: Loss: 0.7167\n",
            "Epoch 3, Sample 11312: Loss: 0.0212\n",
            "Epoch 3, Sample 11313: Loss: 0.2182\n",
            "Epoch 3, Sample 11314: Loss: 0.3399\n",
            "Epoch 3, Sample 11315: Loss: 0.3399\n",
            "Epoch 3, Sample 11316: Loss: 0.0915\n",
            "Epoch 3, Sample 11317: Loss: 0.7036\n",
            "Epoch 3, Sample 11318: Loss: 0.0576\n",
            "Epoch 3, Sample 11319: Loss: 0.4611\n",
            "Epoch 3, Sample 11320: Loss: 0.6092\n",
            "Epoch 3, Sample 11321: Loss: 0.1523\n",
            "Epoch 3, Sample 11322: Loss: 0.3949\n",
            "Epoch 3, Sample 11323: Loss: 0.2738\n",
            "Epoch 3, Sample 11324: Loss: 0.9367\n",
            "Epoch 3, Sample 11325: Loss: 0.1040\n",
            "Epoch 3, Sample 11326: Loss: 1.0524\n",
            "Epoch 3, Sample 11327: Loss: 0.3949\n",
            "Epoch 3, Sample 11328: Loss: 0.1264\n",
            "Epoch 3, Sample 11329: Loss: 0.0013\n",
            "Epoch 3, Sample 11330: Loss: 0.2044\n",
            "Epoch 3, Sample 11331: Loss: 0.0455\n",
            "Epoch 3, Sample 11332: Loss: 0.3399\n",
            "Epoch 3, Sample 11333: Loss: 0.4565\n",
            "Epoch 3, Sample 11334: Loss: 0.0785\n",
            "Epoch 3, Sample 11335: Loss: 0.3079\n",
            "Epoch 3, Sample 11336: Loss: 0.5799\n",
            "Epoch 3, Sample 11337: Loss: 0.2729\n",
            "Epoch 3, Sample 11338: Loss: 0.4761\n",
            "Epoch 3, Sample 11339: Loss: 0.0466\n",
            "Epoch 3, Sample 11340: Loss: 0.3332\n",
            "Epoch 3, Sample 11341: Loss: 0.2044\n",
            "Epoch 3, Sample 11342: Loss: 0.7036\n",
            "Epoch 3, Sample 11343: Loss: 0.2079\n",
            "Epoch 3, Sample 11344: Loss: 0.1250\n",
            "Epoch 3, Sample 11345: Loss: 0.2014\n",
            "Epoch 3, Sample 11346: Loss: 5.5027\n",
            "Epoch 3, Sample 11347: Loss: 0.2832\n",
            "Epoch 3, Sample 11348: Loss: 0.5019\n",
            "Epoch 3, Sample 11349: Loss: 0.0260\n",
            "Epoch 3, Sample 11350: Loss: 0.3399\n",
            "Epoch 3, Sample 11351: Loss: 0.4948\n",
            "Epoch 3, Sample 11352: Loss: 0.9651\n",
            "Epoch 3, Sample 11353: Loss: 0.8951\n",
            "Epoch 3, Sample 11354: Loss: 0.3367\n",
            "Epoch 3, Sample 11355: Loss: 0.2760\n",
            "Epoch 3, Sample 11356: Loss: 0.7226\n",
            "Epoch 3, Sample 11357: Loss: 0.5972\n",
            "Epoch 3, Sample 11358: Loss: 0.2044\n",
            "Epoch 3, Sample 11359: Loss: 0.1627\n",
            "Epoch 3, Sample 11360: Loss: 0.1853\n",
            "Epoch 3, Sample 11361: Loss: 0.1225\n",
            "Epoch 3, Sample 11362: Loss: 0.3805\n",
            "Epoch 3, Sample 11363: Loss: 0.0026\n",
            "Epoch 3, Sample 11364: Loss: 0.1013\n",
            "Epoch 3, Sample 11365: Loss: 1.6785\n",
            "Epoch 3, Sample 11366: Loss: 0.2034\n",
            "Epoch 3, Sample 11367: Loss: 0.4032\n",
            "Epoch 3, Sample 11368: Loss: 0.5858\n",
            "Epoch 3, Sample 11369: Loss: 0.1267\n",
            "Epoch 3, Sample 11370: Loss: 0.1250\n",
            "Epoch 3, Sample 11371: Loss: 0.0161\n",
            "Epoch 3, Sample 11372: Loss: 0.0144\n",
            "Epoch 3, Sample 11373: Loss: 0.0005\n",
            "Epoch 3, Sample 11374: Loss: 1.0524\n",
            "Epoch 3, Sample 11375: Loss: 0.2759\n",
            "Epoch 3, Sample 11376: Loss: 0.2084\n",
            "Epoch 3, Sample 11377: Loss: 0.3985\n",
            "Epoch 3, Sample 11378: Loss: 0.0114\n",
            "Epoch 3, Sample 11379: Loss: 0.2962\n",
            "Epoch 3, Sample 11380: Loss: 0.0460\n",
            "Epoch 3, Sample 11381: Loss: 1.0524\n",
            "Epoch 3, Sample 11382: Loss: 0.0838\n",
            "Epoch 3, Sample 11383: Loss: 0.7036\n",
            "Epoch 3, Sample 11384: Loss: 2.6934\n",
            "Epoch 3, Sample 11385: Loss: 0.2079\n",
            "Epoch 3, Sample 11386: Loss: 0.1250\n",
            "Epoch 3, Sample 11387: Loss: 0.0834\n",
            "Epoch 3, Sample 11388: Loss: 0.0972\n",
            "Epoch 3, Sample 11389: Loss: 0.0020\n",
            "Epoch 3, Sample 11390: Loss: 0.5871\n",
            "Epoch 3, Sample 11391: Loss: 1.0266\n",
            "Epoch 3, Sample 11392: Loss: 0.6099\n",
            "Epoch 3, Sample 11393: Loss: 0.0700\n",
            "Epoch 3, Sample 11394: Loss: 0.3441\n",
            "Epoch 3, Sample 11395: Loss: 0.0241\n",
            "Epoch 3, Sample 11396: Loss: 1.0524\n",
            "Epoch 3, Sample 11397: Loss: 0.0567\n",
            "Epoch 3, Sample 11398: Loss: 0.2215\n",
            "Epoch 3, Sample 11399: Loss: 0.4792\n",
            "Epoch 3, Sample 11400: Loss: 0.1219\n",
            "Epoch 3, Sample 11401: Loss: 0.4206\n",
            "Epoch 3, Sample 11402: Loss: 0.6780\n",
            "Epoch 3, Sample 11403: Loss: 0.0626\n",
            "Epoch 3, Sample 11404: Loss: 0.2759\n",
            "Epoch 3, Sample 11405: Loss: 1.0524\n",
            "Epoch 3, Sample 11406: Loss: 1.0524\n",
            "Epoch 3, Sample 11407: Loss: 1.0155\n",
            "Epoch 3, Sample 11408: Loss: 1.0055\n",
            "Epoch 3, Sample 11409: Loss: 0.0018\n",
            "Epoch 3, Sample 11410: Loss: 0.0018\n",
            "Epoch 3, Sample 11411: Loss: 0.2044\n",
            "Epoch 3, Sample 11412: Loss: 0.8951\n",
            "Epoch 3, Sample 11413: Loss: 0.0101\n",
            "Epoch 3, Sample 11414: Loss: 0.2832\n",
            "Epoch 3, Sample 11415: Loss: 0.0777\n",
            "Epoch 3, Sample 11416: Loss: 0.3402\n",
            "Epoch 3, Sample 11417: Loss: 0.0003\n",
            "Epoch 3, Sample 11418: Loss: 0.0001\n",
            "Epoch 3, Sample 11419: Loss: 0.2044\n",
            "Epoch 3, Sample 11420: Loss: 0.9024\n",
            "Epoch 3, Sample 11421: Loss: 0.7453\n",
            "Epoch 3, Sample 11422: Loss: 0.2759\n",
            "Epoch 3, Sample 11423: Loss: 0.7036\n",
            "Epoch 3, Sample 11424: Loss: 0.0286\n",
            "Epoch 3, Sample 11425: Loss: 0.2034\n",
            "Epoch 3, Sample 11426: Loss: 0.2044\n",
            "Epoch 3, Sample 11427: Loss: 0.5858\n",
            "Epoch 3, Sample 11428: Loss: 1.0524\n",
            "Epoch 3, Sample 11429: Loss: 0.0018\n",
            "Epoch 3, Sample 11430: Loss: 0.5871\n",
            "Epoch 3, Sample 11431: Loss: 0.0125\n",
            "Epoch 3, Sample 11432: Loss: 0.2044\n",
            "Epoch 3, Sample 11433: Loss: 0.0026\n",
            "Epoch 3, Sample 11434: Loss: 0.1463\n",
            "Epoch 3, Sample 11435: Loss: 0.0838\n",
            "Epoch 3, Sample 11436: Loss: 0.6304\n",
            "Epoch 3, Sample 11437: Loss: 0.0720\n",
            "Epoch 3, Sample 11438: Loss: 0.2044\n",
            "Epoch 3, Sample 11439: Loss: 0.0670\n",
            "Epoch 3, Sample 11440: Loss: 0.6243\n",
            "Epoch 3, Sample 11441: Loss: 0.0862\n",
            "Epoch 3, Sample 11442: Loss: 1.2715\n",
            "Epoch 3, Sample 11443: Loss: 0.0390\n",
            "Epoch 3, Sample 11444: Loss: 1.0524\n",
            "Epoch 3, Sample 11445: Loss: 0.2590\n",
            "Epoch 3, Sample 11446: Loss: 0.3441\n",
            "Epoch 3, Sample 11447: Loss: 0.8951\n",
            "Epoch 3, Sample 11448: Loss: 0.5078\n",
            "Epoch 3, Sample 11449: Loss: 1.0524\n",
            "Epoch 3, Sample 11450: Loss: 0.9780\n",
            "Epoch 3, Sample 11451: Loss: 0.0713\n",
            "Epoch 3, Sample 11452: Loss: 0.2340\n",
            "Epoch 3, Sample 11453: Loss: 0.2832\n",
            "Epoch 3, Sample 11454: Loss: 5.7330\n",
            "Epoch 3, Sample 11455: Loss: 0.0018\n",
            "Epoch 3, Sample 11456: Loss: 0.0654\n",
            "Epoch 3, Sample 11457: Loss: 0.1210\n",
            "Epoch 3, Sample 11458: Loss: 1.0155\n",
            "Epoch 3, Sample 11459: Loss: 0.3949\n",
            "Epoch 3, Sample 11460: Loss: 0.4644\n",
            "Epoch 3, Sample 11461: Loss: 0.8484\n",
            "Epoch 3, Sample 11462: Loss: 0.1170\n",
            "Epoch 3, Sample 11463: Loss: 0.9367\n",
            "Epoch 3, Sample 11464: Loss: 0.2032\n",
            "Epoch 3, Sample 11465: Loss: 0.0022\n",
            "Epoch 3, Sample 11466: Loss: 0.6999\n",
            "Epoch 3, Sample 11467: Loss: 0.0228\n",
            "Epoch 3, Sample 11468: Loss: 0.0001\n",
            "Epoch 3, Sample 11469: Loss: 0.2639\n",
            "Epoch 3, Sample 11470: Loss: 0.5858\n",
            "Epoch 3, Sample 11471: Loss: 1.0530\n",
            "Epoch 3, Sample 11472: Loss: 0.5972\n",
            "Epoch 3, Sample 11473: Loss: 0.1484\n",
            "Epoch 3, Sample 11474: Loss: 0.0180\n",
            "Epoch 3, Sample 11475: Loss: 1.0649\n",
            "Epoch 3, Sample 11476: Loss: 0.0630\n",
            "Epoch 3, Sample 11477: Loss: 0.8951\n",
            "Epoch 3, Sample 11478: Loss: 0.7036\n",
            "Epoch 3, Sample 11479: Loss: 0.0108\n",
            "Epoch 3, Sample 11480: Loss: 0.0625\n",
            "Epoch 3, Sample 11481: Loss: 0.3441\n",
            "Epoch 3, Sample 11482: Loss: 0.0063\n",
            "Epoch 3, Sample 11483: Loss: 5.4289\n",
            "Epoch 3, Sample 11484: Loss: 0.2759\n",
            "Epoch 3, Sample 11485: Loss: 0.5972\n",
            "Epoch 3, Sample 11486: Loss: 0.2890\n",
            "Epoch 3, Sample 11487: Loss: 0.0466\n",
            "Epoch 3, Sample 11488: Loss: 0.0026\n",
            "Epoch 3, Sample 11489: Loss: 0.2034\n",
            "Epoch 3, Sample 11490: Loss: 0.0513\n",
            "Epoch 3, Sample 11491: Loss: 0.1822\n",
            "Epoch 3, Sample 11492: Loss: 0.1559\n",
            "Epoch 3, Sample 11493: Loss: 1.0438\n",
            "Epoch 3, Sample 11494: Loss: 0.4930\n",
            "Epoch 3, Sample 11495: Loss: 0.0116\n",
            "Epoch 3, Sample 11496: Loss: 0.7036\n",
            "Epoch 3, Sample 11497: Loss: 0.7036\n",
            "Epoch 3, Sample 11498: Loss: 0.2036\n",
            "Epoch 3, Sample 11499: Loss: 1.0554\n",
            "Epoch 3, Sample 11500: Loss: 0.2699\n",
            "Epoch 3, Sample 11501: Loss: 0.0110\n",
            "Epoch 3, Sample 11502: Loss: 0.3007\n",
            "Epoch 3, Sample 11503: Loss: 1.0524\n",
            "Epoch 3, Sample 11504: Loss: 0.3598\n",
            "Epoch 3, Sample 11505: Loss: 0.7036\n",
            "Epoch 3, Sample 11506: Loss: 0.0026\n",
            "Epoch 3, Sample 11507: Loss: 0.0013\n",
            "Epoch 3, Sample 11508: Loss: 0.3399\n",
            "Epoch 3, Sample 11509: Loss: 0.3441\n",
            "Epoch 3, Sample 11510: Loss: 0.0026\n",
            "Epoch 3, Sample 11511: Loss: 0.9367\n",
            "Epoch 3, Sample 11512: Loss: 1.0941\n",
            "Epoch 3, Sample 11513: Loss: 0.4005\n",
            "Epoch 3, Sample 11514: Loss: 0.0258\n",
            "Epoch 3, Sample 11515: Loss: 0.2044\n",
            "Epoch 3, Sample 11516: Loss: 6.9129\n",
            "Epoch 3, Sample 11517: Loss: 0.1588\n",
            "Epoch 3, Sample 11518: Loss: 0.0212\n",
            "Epoch 3, Sample 11519: Loss: 0.2832\n",
            "Epoch 3, Sample 11520: Loss: 0.2329\n",
            "Epoch 3, Sample 11521: Loss: 1.0458\n",
            "Epoch 3, Sample 11522: Loss: 1.5795\n",
            "Epoch 3, Sample 11523: Loss: 0.0026\n",
            "Epoch 3, Sample 11524: Loss: 0.2112\n",
            "Epoch 3, Sample 11525: Loss: 0.6977\n",
            "Epoch 3, Sample 11526: Loss: 2.1755\n",
            "Epoch 3, Sample 11527: Loss: 0.1131\n",
            "Epoch 3, Sample 11528: Loss: 0.8951\n",
            "Epoch 3, Sample 11529: Loss: 1.0155\n",
            "Epoch 3, Sample 11530: Loss: 1.0524\n",
            "Epoch 3, Sample 11531: Loss: 0.3399\n",
            "Epoch 3, Sample 11532: Loss: 0.1328\n",
            "Epoch 3, Sample 11533: Loss: 0.0084\n",
            "Epoch 3, Sample 11534: Loss: 0.0630\n",
            "Epoch 3, Sample 11535: Loss: 1.7854\n",
            "Epoch 3, Sample 11536: Loss: 0.0627\n",
            "Epoch 3, Sample 11537: Loss: 0.2558\n",
            "Epoch 3, Sample 11538: Loss: 1.0524\n",
            "Epoch 3, Sample 11539: Loss: 0.2822\n",
            "Epoch 3, Sample 11540: Loss: 0.9531\n",
            "Epoch 3, Sample 11541: Loss: 0.0018\n",
            "Epoch 3, Sample 11542: Loss: 0.7036\n",
            "Epoch 3, Sample 11543: Loss: 0.2034\n",
            "Epoch 3, Sample 11544: Loss: 0.0258\n",
            "Epoch 3, Sample 11545: Loss: 1.7891\n",
            "Epoch 3, Sample 11546: Loss: 0.1559\n",
            "Epoch 3, Sample 11547: Loss: 1.0524\n",
            "Epoch 3, Sample 11548: Loss: 1.0524\n",
            "Epoch 3, Sample 11549: Loss: 1.0155\n",
            "Epoch 3, Sample 11550: Loss: 0.6990\n",
            "Epoch 3, Sample 11551: Loss: 0.7596\n",
            "Epoch 3, Sample 11552: Loss: 0.3441\n",
            "Epoch 3, Sample 11553: Loss: 0.9224\n",
            "Epoch 3, Sample 11554: Loss: 0.7036\n",
            "Epoch 3, Sample 11555: Loss: 0.0018\n",
            "Epoch 3, Sample 11556: Loss: 0.5003\n",
            "Epoch 3, Sample 11557: Loss: 1.0155\n",
            "Epoch 3, Sample 11558: Loss: 0.2044\n",
            "Epoch 3, Sample 11559: Loss: 0.1838\n",
            "Epoch 3, Sample 11560: Loss: 0.0626\n",
            "Epoch 3, Sample 11561: Loss: 0.9934\n",
            "Epoch 3, Sample 11562: Loss: 0.5310\n",
            "Epoch 3, Sample 11563: Loss: 0.0423\n",
            "Epoch 3, Sample 11564: Loss: 0.2098\n",
            "Epoch 3, Sample 11565: Loss: 0.2112\n",
            "Epoch 3, Sample 11566: Loss: 0.2989\n",
            "Epoch 3, Sample 11567: Loss: 0.0000\n",
            "Epoch 3, Sample 11568: Loss: 0.2699\n",
            "Epoch 3, Sample 11569: Loss: 1.0524\n",
            "Epoch 3, Sample 11570: Loss: 0.2044\n",
            "Epoch 3, Sample 11571: Loss: 0.5858\n",
            "Epoch 3, Sample 11572: Loss: 0.0466\n",
            "Epoch 3, Sample 11573: Loss: 0.1817\n",
            "Epoch 3, Sample 11574: Loss: 0.1559\n",
            "Epoch 3, Sample 11575: Loss: 0.2032\n",
            "Epoch 3, Sample 11576: Loss: 0.6893\n",
            "Epoch 3, Sample 11577: Loss: 1.0524\n",
            "Epoch 3, Sample 11578: Loss: 0.2044\n",
            "Epoch 3, Sample 11579: Loss: 0.1252\n",
            "Epoch 3, Sample 11580: Loss: 0.7036\n",
            "Epoch 3, Sample 11581: Loss: 0.0062\n",
            "Epoch 3, Sample 11582: Loss: 1.2237\n",
            "Epoch 3, Sample 11583: Loss: 0.1523\n",
            "Epoch 3, Sample 11584: Loss: 1.0155\n",
            "Epoch 3, Sample 11585: Loss: 0.1654\n",
            "Epoch 3, Sample 11586: Loss: 0.5858\n",
            "Epoch 3, Sample 11587: Loss: 0.5858\n",
            "Epoch 3, Sample 11588: Loss: 0.0212\n",
            "Epoch 3, Sample 11589: Loss: 0.0501\n",
            "Epoch 3, Sample 11590: Loss: 0.0630\n",
            "Epoch 3, Sample 11591: Loss: 0.1248\n",
            "Epoch 3, Sample 11592: Loss: 0.2032\n",
            "Epoch 3, Sample 11593: Loss: 0.0018\n",
            "Epoch 3, Sample 11594: Loss: 0.2340\n",
            "Epoch 3, Sample 11595: Loss: 1.4780\n",
            "Epoch 3, Sample 11596: Loss: 0.3399\n",
            "Epoch 3, Sample 11597: Loss: 0.2034\n",
            "Epoch 3, Sample 11598: Loss: 0.3202\n",
            "Epoch 3, Sample 11599: Loss: 0.0293\n",
            "Epoch 3, Sample 11600: Loss: 0.0019\n",
            "Epoch 3, Sample 11601: Loss: 0.2044\n",
            "Epoch 3, Sample 11602: Loss: 0.6948\n",
            "Epoch 3, Sample 11603: Loss: 1.0155\n",
            "Epoch 3, Sample 11604: Loss: 0.0466\n",
            "Epoch 3, Sample 11605: Loss: 0.3787\n",
            "Epoch 3, Sample 11606: Loss: 0.3568\n",
            "Epoch 3, Sample 11607: Loss: 0.2361\n",
            "Epoch 3, Sample 11608: Loss: 0.0026\n",
            "Epoch 3, Sample 11609: Loss: 0.6092\n",
            "Epoch 3, Sample 11610: Loss: 0.3062\n",
            "Epoch 3, Sample 11611: Loss: 0.4996\n",
            "Epoch 3, Sample 11612: Loss: 1.0530\n",
            "Epoch 3, Sample 11613: Loss: 0.3650\n",
            "Epoch 3, Sample 11614: Loss: 1.0155\n",
            "Epoch 3, Sample 11615: Loss: 0.0477\n",
            "Epoch 3, Sample 11616: Loss: 8.2868\n",
            "Epoch 3, Sample 11617: Loss: 0.6696\n",
            "Epoch 3, Sample 11618: Loss: 0.2459\n",
            "Epoch 3, Sample 11619: Loss: 0.7036\n",
            "Epoch 3, Sample 11620: Loss: 0.7702\n",
            "Epoch 3, Sample 11621: Loss: 0.4996\n",
            "Epoch 3, Sample 11622: Loss: 0.2032\n",
            "Epoch 3, Sample 11623: Loss: 0.5000\n",
            "Epoch 3, Sample 11624: Loss: 0.1170\n",
            "Epoch 3, Sample 11625: Loss: 0.0460\n",
            "Epoch 3, Sample 11626: Loss: 0.2363\n",
            "Epoch 3, Sample 11627: Loss: 7.6726\n",
            "Epoch 3, Sample 11628: Loss: 0.2044\n",
            "Epoch 3, Sample 11629: Loss: 1.6760\n",
            "Epoch 3, Sample 11630: Loss: 1.0155\n",
            "Epoch 3, Sample 11631: Loss: 1.0155\n",
            "Epoch 3, Sample 11632: Loss: 0.1250\n",
            "Epoch 3, Sample 11633: Loss: 0.6139\n",
            "Epoch 3, Sample 11634: Loss: 0.0630\n",
            "Epoch 3, Sample 11635: Loss: 0.0034\n",
            "Epoch 3, Sample 11636: Loss: 0.7036\n",
            "Epoch 3, Sample 11637: Loss: 0.2032\n",
            "Epoch 3, Sample 11638: Loss: 0.2339\n",
            "Epoch 3, Sample 11639: Loss: 0.2044\n",
            "Epoch 3, Sample 11640: Loss: 0.3399\n",
            "Epoch 3, Sample 11641: Loss: 0.3399\n",
            "Epoch 3, Sample 11642: Loss: 0.0018\n",
            "Epoch 3, Sample 11643: Loss: 0.0720\n",
            "Epoch 3, Sample 11644: Loss: 1.5597\n",
            "Epoch 3, Sample 11645: Loss: 0.7036\n",
            "Epoch 3, Sample 11646: Loss: 0.2404\n",
            "Epoch 3, Sample 11647: Loss: 0.0026\n",
            "Epoch 3, Sample 11648: Loss: 0.7036\n",
            "Epoch 3, Sample 11649: Loss: 0.0018\n",
            "Epoch 3, Sample 11650: Loss: 0.5858\n",
            "Epoch 3, Sample 11651: Loss: 0.5858\n",
            "Epoch 3, Sample 11652: Loss: 0.0026\n",
            "Epoch 3, Sample 11653: Loss: 0.7036\n",
            "Epoch 3, Sample 11654: Loss: 0.1862\n",
            "Epoch 3, Sample 11655: Loss: 0.0018\n",
            "Epoch 3, Sample 11656: Loss: 0.3399\n",
            "Epoch 3, Sample 11657: Loss: 0.4032\n",
            "Epoch 3, Sample 11658: Loss: 0.0026\n",
            "Epoch 3, Sample 11659: Loss: 0.0150\n",
            "Epoch 3, Sample 11660: Loss: 0.2639\n",
            "Epoch 3, Sample 11661: Loss: 0.1277\n",
            "Epoch 3, Sample 11662: Loss: 0.5196\n",
            "Epoch 3, Sample 11663: Loss: 0.3441\n",
            "Epoch 3, Sample 11664: Loss: 1.0155\n",
            "Epoch 3, Sample 11665: Loss: 0.1170\n",
            "Epoch 3, Sample 11666: Loss: 0.2036\n",
            "Epoch 3, Sample 11667: Loss: 0.5078\n",
            "Epoch 3, Sample 11668: Loss: 0.4032\n",
            "Epoch 3, Sample 11669: Loss: 0.2832\n",
            "Epoch 3, Sample 11670: Loss: 0.2044\n",
            "Epoch 3, Sample 11671: Loss: 0.0026\n",
            "Epoch 3, Sample 11672: Loss: 0.2709\n",
            "Epoch 3, Sample 11673: Loss: 0.0001\n",
            "Epoch 3, Sample 11674: Loss: 1.0851\n",
            "Epoch 3, Sample 11675: Loss: 0.5078\n",
            "Epoch 3, Sample 11676: Loss: 0.0460\n",
            "Epoch 3, Sample 11677: Loss: 2.6384\n",
            "Epoch 3, Sample 11678: Loss: 0.0635\n",
            "Epoch 3, Sample 11679: Loss: 0.2044\n",
            "Epoch 3, Sample 11680: Loss: 0.1815\n",
            "Epoch 3, Sample 11681: Loss: 1.0524\n",
            "Epoch 3, Sample 11682: Loss: 0.5078\n",
            "Epoch 3, Sample 11683: Loss: 0.4799\n",
            "Epoch 3, Sample 11684: Loss: 1.2926\n",
            "Epoch 3, Sample 11685: Loss: 0.1170\n",
            "Epoch 3, Sample 11686: Loss: 0.0119\n",
            "Epoch 3, Sample 11687: Loss: 0.0018\n",
            "Epoch 3, Sample 11688: Loss: 0.2219\n",
            "Epoch 3, Sample 11689: Loss: 0.0015\n",
            "Epoch 3, Sample 11690: Loss: 0.0006\n",
            "Epoch 3, Sample 11691: Loss: 0.2044\n",
            "Epoch 3, Sample 11692: Loss: 0.0026\n",
            "Epoch 3, Sample 11693: Loss: 0.0498\n",
            "Epoch 3, Sample 11694: Loss: 0.5000\n",
            "Epoch 3, Sample 11695: Loss: 0.3399\n",
            "Epoch 3, Sample 11696: Loss: 0.2949\n",
            "Epoch 3, Sample 11697: Loss: 0.1791\n",
            "Epoch 3, Sample 11698: Loss: 0.8597\n",
            "Epoch 3, Sample 11699: Loss: 0.0026\n",
            "Epoch 3, Sample 11700: Loss: 0.2036\n",
            "Epoch 3, Sample 11701: Loss: 0.0032\n",
            "Epoch 3, Sample 11702: Loss: 0.0115\n",
            "Epoch 3, Sample 11703: Loss: 0.0554\n",
            "Epoch 3, Sample 11704: Loss: 0.1250\n",
            "Epoch 3, Sample 11705: Loss: 0.1679\n",
            "Epoch 3, Sample 11706: Loss: 6.8653\n",
            "Epoch 3, Sample 11707: Loss: 0.0133\n",
            "Epoch 3, Sample 11708: Loss: 2.9652\n",
            "Epoch 3, Sample 11709: Loss: 0.5710\n",
            "Epoch 3, Sample 11710: Loss: 0.0667\n",
            "Epoch 3, Sample 11711: Loss: 0.0054\n",
            "Epoch 3, Sample 11712: Loss: 0.0003\n",
            "Epoch 3, Sample 11713: Loss: 0.2759\n",
            "Epoch 3, Sample 11714: Loss: 0.2759\n",
            "Epoch 3, Sample 11715: Loss: 0.5858\n",
            "Epoch 3, Sample 11716: Loss: 1.0524\n",
            "Epoch 3, Sample 11717: Loss: 0.0630\n",
            "Epoch 3, Sample 11718: Loss: 0.5000\n",
            "Epoch 3, Sample 11719: Loss: 0.3450\n",
            "Epoch 3, Sample 11720: Loss: 1.0155\n",
            "Epoch 3, Sample 11721: Loss: 0.0000\n",
            "Epoch 3, Sample 11722: Loss: 0.2112\n",
            "Epoch 3, Sample 11723: Loss: 1.0070\n",
            "Epoch 3, Sample 11724: Loss: 0.3136\n",
            "Epoch 3, Sample 11725: Loss: 0.2112\n",
            "Epoch 3, Sample 11726: Loss: 0.2044\n",
            "Epoch 3, Sample 11727: Loss: 0.2759\n",
            "Epoch 3, Sample 11728: Loss: 0.4841\n",
            "Epoch 3, Sample 11729: Loss: 0.1559\n",
            "Epoch 3, Sample 11730: Loss: 0.3007\n",
            "Epoch 3, Sample 11731: Loss: 0.0018\n",
            "Epoch 3, Sample 11732: Loss: 0.0507\n",
            "Epoch 3, Sample 11733: Loss: 0.0000\n",
            "Epoch 3, Sample 11734: Loss: 0.3399\n",
            "Epoch 3, Sample 11735: Loss: 0.3520\n",
            "Epoch 3, Sample 11736: Loss: 0.4595\n",
            "Epoch 3, Sample 11737: Loss: 0.0026\n",
            "Epoch 3, Sample 11738: Loss: 0.0013\n",
            "Epoch 3, Sample 11739: Loss: 0.7453\n",
            "Epoch 3, Sample 11740: Loss: 0.0474\n",
            "Epoch 3, Sample 11741: Loss: 0.0002\n",
            "Epoch 3, Sample 11742: Loss: 0.1248\n",
            "Epoch 3, Sample 11743: Loss: 0.9367\n",
            "Epoch 3, Sample 11744: Loss: 0.1170\n",
            "Epoch 3, Sample 11745: Loss: 0.3441\n",
            "Epoch 3, Sample 11746: Loss: 0.5196\n",
            "Epoch 3, Sample 11747: Loss: 0.0040\n",
            "Epoch 3, Sample 11748: Loss: 0.0072\n",
            "Epoch 3, Sample 11749: Loss: 0.0630\n",
            "Epoch 3, Sample 11750: Loss: 0.1250\n",
            "Epoch 3, Sample 11751: Loss: 0.1326\n",
            "Epoch 3, Sample 11752: Loss: 0.1427\n",
            "Epoch 3, Sample 11753: Loss: 0.2832\n",
            "Epoch 3, Sample 11754: Loss: 0.0092\n",
            "Epoch 3, Sample 11755: Loss: 0.0084\n",
            "Epoch 3, Sample 11756: Loss: 1.7978\n",
            "Epoch 3, Sample 11757: Loss: 0.2036\n",
            "Epoch 3, Sample 11758: Loss: 0.4644\n",
            "Epoch 3, Sample 11759: Loss: 0.2032\n",
            "Epoch 3, Sample 11760: Loss: 0.6990\n",
            "Epoch 3, Sample 11761: Loss: 0.0006\n",
            "Epoch 3, Sample 11762: Loss: 0.0775\n",
            "Epoch 3, Sample 11763: Loss: 0.1250\n",
            "Epoch 3, Sample 11764: Loss: 0.0306\n",
            "Epoch 3, Sample 11765: Loss: 0.7058\n",
            "Epoch 3, Sample 11766: Loss: 0.0018\n",
            "Epoch 3, Sample 11767: Loss: 0.0744\n",
            "Epoch 3, Sample 11768: Loss: 0.1523\n",
            "Epoch 3, Sample 11769: Loss: 1.0155\n",
            "Epoch 3, Sample 11770: Loss: 0.5989\n",
            "Epoch 3, Sample 11771: Loss: 0.3399\n",
            "Epoch 3, Sample 11772: Loss: 1.0155\n",
            "Epoch 3, Sample 11773: Loss: 0.0021\n",
            "Epoch 3, Sample 11774: Loss: 0.1250\n",
            "Epoch 3, Sample 11775: Loss: 0.0007\n",
            "Epoch 3, Sample 11776: Loss: 1.0524\n",
            "Epoch 3, Sample 11777: Loss: 0.7638\n",
            "Epoch 3, Sample 11778: Loss: 0.2044\n",
            "Epoch 3, Sample 11779: Loss: 0.2759\n",
            "Epoch 3, Sample 11780: Loss: 0.0626\n",
            "Epoch 3, Sample 11781: Loss: 0.5000\n",
            "Epoch 3, Sample 11782: Loss: 1.0227\n",
            "Epoch 3, Sample 11783: Loss: 0.2032\n",
            "Epoch 3, Sample 11784: Loss: 0.6304\n",
            "Epoch 3, Sample 11785: Loss: 0.4841\n",
            "Epoch 3, Sample 11786: Loss: 1.0155\n",
            "Epoch 3, Sample 11787: Loss: 0.2941\n",
            "Epoch 3, Sample 11788: Loss: 0.5089\n",
            "Epoch 3, Sample 11789: Loss: 0.3949\n",
            "Epoch 3, Sample 11790: Loss: 0.0039\n",
            "Epoch 3, Sample 11791: Loss: 0.0026\n",
            "Epoch 3, Sample 11792: Loss: 0.0630\n",
            "Epoch 3, Sample 11793: Loss: 1.0155\n",
            "Epoch 3, Sample 11794: Loss: 0.0018\n",
            "Epoch 3, Sample 11795: Loss: 0.3514\n",
            "Epoch 3, Sample 11796: Loss: 0.2044\n",
            "Epoch 3, Sample 11797: Loss: 0.7453\n",
            "Epoch 3, Sample 11798: Loss: 1.9766\n",
            "Epoch 3, Sample 11799: Loss: 0.2832\n",
            "Epoch 3, Sample 11800: Loss: 0.2034\n",
            "Epoch 3, Sample 11801: Loss: 0.1195\n",
            "Epoch 3, Sample 11802: Loss: 0.0027\n",
            "Epoch 3, Sample 11803: Loss: 2.2005\n",
            "Epoch 3, Sample 11804: Loss: 0.5003\n",
            "Epoch 3, Sample 11805: Loss: 0.0000\n",
            "Epoch 3, Sample 11806: Loss: 0.0212\n",
            "Epoch 3, Sample 11807: Loss: 0.0022\n",
            "Epoch 3, Sample 11808: Loss: 0.0168\n",
            "Epoch 3, Sample 11809: Loss: 3.6256\n",
            "Epoch 3, Sample 11810: Loss: 0.0026\n",
            "Epoch 3, Sample 11811: Loss: 0.0026\n",
            "Epoch 3, Sample 11812: Loss: 0.2044\n",
            "Epoch 3, Sample 11813: Loss: 1.0837\n",
            "Epoch 3, Sample 11814: Loss: 0.2941\n",
            "Epoch 3, Sample 11815: Loss: 0.1546\n",
            "Epoch 3, Sample 11816: Loss: 0.1559\n",
            "Epoch 3, Sample 11817: Loss: 0.5858\n",
            "Epoch 3, Sample 11818: Loss: 0.3399\n",
            "Epoch 3, Sample 11819: Loss: 0.4032\n",
            "Epoch 3, Sample 11820: Loss: 0.2036\n",
            "Epoch 3, Sample 11821: Loss: 0.2639\n",
            "Epoch 3, Sample 11822: Loss: 1.0530\n",
            "Epoch 3, Sample 11823: Loss: 0.1420\n",
            "Epoch 3, Sample 11824: Loss: 0.2639\n",
            "Epoch 3, Sample 11825: Loss: 0.7036\n",
            "Epoch 3, Sample 11826: Loss: 0.9885\n",
            "Epoch 3, Sample 11827: Loss: 0.0038\n",
            "Epoch 3, Sample 11828: Loss: 0.6315\n",
            "Epoch 3, Sample 11829: Loss: 1.0530\n",
            "Epoch 3, Sample 11830: Loss: 0.2044\n",
            "Epoch 3, Sample 11831: Loss: 0.0240\n",
            "Epoch 3, Sample 11832: Loss: 0.4486\n",
            "Epoch 3, Sample 11833: Loss: 0.2044\n",
            "Epoch 3, Sample 11834: Loss: 0.2044\n",
            "Epoch 3, Sample 11835: Loss: 0.3399\n",
            "Epoch 3, Sample 11836: Loss: 0.0875\n",
            "Epoch 3, Sample 11837: Loss: 0.3983\n",
            "Epoch 3, Sample 11838: Loss: 0.0554\n",
            "Epoch 3, Sample 11839: Loss: 0.3441\n",
            "Epoch 3, Sample 11840: Loss: 1.8340\n",
            "Epoch 3, Sample 11841: Loss: 3.8056\n",
            "Epoch 3, Sample 11842: Loss: 0.7036\n",
            "Epoch 3, Sample 11843: Loss: 0.7036\n",
            "Epoch 3, Sample 11844: Loss: 0.0873\n",
            "Epoch 3, Sample 11845: Loss: 0.3584\n",
            "Epoch 3, Sample 11846: Loss: 0.3949\n",
            "Epoch 3, Sample 11847: Loss: 0.0421\n",
            "Epoch 3, Sample 11848: Loss: 0.2759\n",
            "Epoch 3, Sample 11849: Loss: 0.2759\n",
            "Epoch 3, Sample 11850: Loss: 0.2759\n",
            "Epoch 3, Sample 11851: Loss: 0.6278\n",
            "Epoch 3, Sample 11852: Loss: 0.2443\n",
            "Epoch 3, Sample 11853: Loss: 4.1025\n",
            "Epoch 3, Sample 11854: Loss: 0.8951\n",
            "Epoch 3, Sample 11855: Loss: 0.2375\n",
            "Epoch 3, Sample 11856: Loss: 0.0938\n",
            "Epoch 3, Sample 11857: Loss: 0.0018\n",
            "Epoch 3, Sample 11858: Loss: 0.0455\n",
            "Epoch 3, Sample 11859: Loss: 0.1627\n",
            "Epoch 3, Sample 11860: Loss: 0.0773\n",
            "Epoch 3, Sample 11861: Loss: 0.5375\n",
            "Epoch 3, Sample 11862: Loss: 1.0511\n",
            "Epoch 3, Sample 11863: Loss: 0.2044\n",
            "Epoch 3, Sample 11864: Loss: 0.0030\n",
            "Epoch 3, Sample 11865: Loss: 7.0400\n",
            "Epoch 3, Sample 11866: Loss: 0.7036\n",
            "Epoch 3, Sample 11867: Loss: 0.0368\n",
            "Epoch 3, Sample 11868: Loss: 0.3092\n",
            "Epoch 3, Sample 11869: Loss: 0.3620\n",
            "Epoch 3, Sample 11870: Loss: 0.0026\n",
            "Epoch 3, Sample 11871: Loss: 0.4588\n",
            "Epoch 3, Sample 11872: Loss: 0.0938\n",
            "Epoch 3, Sample 11873: Loss: 0.0466\n",
            "Epoch 3, Sample 11874: Loss: 0.0246\n",
            "Epoch 3, Sample 11875: Loss: 0.0205\n",
            "Epoch 3, Sample 11876: Loss: 1.0227\n",
            "Epoch 3, Sample 11877: Loss: 0.3399\n",
            "Epoch 3, Sample 11878: Loss: 1.0688\n",
            "Epoch 3, Sample 11879: Loss: 0.5972\n",
            "Epoch 3, Sample 11880: Loss: 0.0030\n",
            "Epoch 3, Sample 11881: Loss: 11.5326\n",
            "Epoch 3, Sample 11882: Loss: 0.5858\n",
            "Epoch 3, Sample 11883: Loss: 0.0505\n",
            "Epoch 3, Sample 11884: Loss: 0.0013\n",
            "Epoch 3, Sample 11885: Loss: 0.7036\n",
            "Epoch 3, Sample 11886: Loss: 1.0155\n",
            "Epoch 3, Sample 11887: Loss: 0.2034\n",
            "Epoch 3, Sample 11888: Loss: 0.5141\n",
            "Epoch 3, Sample 11889: Loss: 0.7036\n",
            "Epoch 3, Sample 11890: Loss: 0.2686\n",
            "Epoch 3, Sample 11891: Loss: 0.6990\n",
            "Epoch 3, Sample 11892: Loss: 0.1170\n",
            "Epoch 3, Sample 11893: Loss: 0.0026\n",
            "Epoch 3, Sample 11894: Loss: 0.2032\n",
            "Epoch 3, Sample 11895: Loss: 0.5858\n",
            "Epoch 3, Sample 11896: Loss: 0.3225\n",
            "Epoch 3, Sample 11897: Loss: 0.2639\n",
            "Epoch 3, Sample 11898: Loss: 0.0439\n",
            "Epoch 3, Sample 11899: Loss: 0.3399\n",
            "Epoch 3, Sample 11900: Loss: 8.7194\n",
            "Epoch 3, Sample 11901: Loss: 0.5003\n",
            "Epoch 3, Sample 11902: Loss: 0.3092\n",
            "Epoch 3, Sample 11903: Loss: 0.1250\n",
            "Epoch 3, Sample 11904: Loss: 0.0444\n",
            "Epoch 3, Sample 11905: Loss: 0.2832\n",
            "Epoch 3, Sample 11906: Loss: 0.3441\n",
            "Epoch 3, Sample 11907: Loss: 0.0205\n",
            "Epoch 3, Sample 11908: Loss: 0.1721\n",
            "Epoch 3, Sample 11909: Loss: 0.0026\n",
            "Epoch 3, Sample 11910: Loss: 0.3399\n",
            "Epoch 3, Sample 11911: Loss: 0.4868\n",
            "Epoch 3, Sample 11912: Loss: 0.1399\n",
            "Epoch 3, Sample 11913: Loss: 0.0625\n",
            "Epoch 3, Sample 11914: Loss: 0.2639\n",
            "Epoch 3, Sample 11915: Loss: 0.2034\n",
            "Epoch 3, Sample 11916: Loss: 0.0243\n",
            "Epoch 3, Sample 11917: Loss: 0.3065\n",
            "Epoch 3, Sample 11918: Loss: 0.0760\n",
            "Epoch 3, Sample 11919: Loss: 0.0630\n",
            "Epoch 3, Sample 11920: Loss: 0.0967\n",
            "Epoch 3, Sample 11921: Loss: 0.6990\n",
            "Epoch 3, Sample 11922: Loss: 0.3441\n",
            "Epoch 3, Sample 11923: Loss: 0.3399\n",
            "Epoch 3, Sample 11924: Loss: 0.5000\n",
            "Epoch 3, Sample 11925: Loss: 0.0630\n",
            "Epoch 3, Sample 11926: Loss: 0.3481\n",
            "Epoch 3, Sample 11927: Loss: 0.2340\n",
            "Epoch 3, Sample 11928: Loss: 0.3624\n",
            "Epoch 3, Sample 11929: Loss: 0.4129\n",
            "Epoch 3, Sample 11930: Loss: 0.4367\n",
            "Epoch 3, Sample 11931: Loss: 0.0060\n",
            "Epoch 3, Sample 11932: Loss: 1.4494\n",
            "Epoch 3, Sample 11933: Loss: 0.0554\n",
            "Epoch 3, Sample 11934: Loss: 0.9651\n",
            "Epoch 3, Sample 11935: Loss: 0.4930\n",
            "Epoch 3, Sample 11936: Loss: 0.5167\n",
            "Epoch 3, Sample 11937: Loss: 0.0278\n",
            "Epoch 3, Sample 11938: Loss: 0.1372\n",
            "Epoch 3, Sample 11939: Loss: 0.2044\n",
            "Epoch 3, Sample 11940: Loss: 1.0524\n",
            "Epoch 3, Sample 11941: Loss: 0.2044\n",
            "Epoch 3, Sample 11942: Loss: 0.0215\n",
            "Epoch 3, Sample 11943: Loss: 0.7702\n",
            "Epoch 3, Sample 11944: Loss: 0.0025\n",
            "Epoch 3, Sample 11945: Loss: 0.5858\n",
            "Epoch 3, Sample 11946: Loss: 1.0524\n",
            "Epoch 3, Sample 11947: Loss: 0.1170\n",
            "Epoch 3, Sample 11948: Loss: 0.0212\n",
            "Epoch 3, Sample 11949: Loss: 0.2036\n",
            "Epoch 3, Sample 11950: Loss: 0.7226\n",
            "Epoch 3, Sample 11951: Loss: 0.8217\n",
            "Epoch 3, Sample 11952: Loss: 0.5000\n",
            "Epoch 3, Sample 11953: Loss: 0.0838\n",
            "Epoch 3, Sample 11954: Loss: 0.0122\n",
            "Epoch 3, Sample 11955: Loss: 0.1337\n",
            "Epoch 3, Sample 11956: Loss: 0.4799\n",
            "Epoch 3, Sample 11957: Loss: 1.6253\n",
            "Epoch 3, Sample 11958: Loss: 0.4384\n",
            "Epoch 3, Sample 11959: Loss: 2.5032\n",
            "Epoch 3, Sample 11960: Loss: 0.3007\n",
            "Epoch 3, Sample 11961: Loss: 0.2759\n",
            "Epoch 3, Sample 11962: Loss: 0.1577\n",
            "Epoch 3, Sample 11963: Loss: 0.0083\n",
            "Epoch 3, Sample 11964: Loss: 0.7702\n",
            "Epoch 3, Sample 11965: Loss: 0.0018\n",
            "Epoch 3, Sample 11966: Loss: 0.2034\n",
            "Epoch 3, Sample 11967: Loss: 0.0640\n",
            "Epoch 3, Sample 11968: Loss: 4.6715\n",
            "Epoch 3, Sample 11969: Loss: 0.6990\n",
            "Epoch 3, Sample 11970: Loss: 0.2342\n",
            "Epoch 3, Sample 11971: Loss: 0.3399\n",
            "Epoch 3, Sample 11972: Loss: 0.0062\n",
            "Epoch 3, Sample 11973: Loss: 0.4799\n",
            "Epoch 3, Sample 11974: Loss: 0.4611\n",
            "Epoch 3, Sample 11975: Loss: 1.0524\n",
            "Epoch 3, Sample 11976: Loss: 0.5871\n",
            "Epoch 3, Sample 11977: Loss: 1.0524\n",
            "Epoch 3, Sample 11978: Loss: 0.2044\n",
            "Epoch 3, Sample 11979: Loss: 0.0884\n",
            "Epoch 3, Sample 11980: Loss: 0.6867\n",
            "Epoch 3, Sample 11981: Loss: 0.0000\n",
            "Epoch 3, Sample 11982: Loss: 0.5000\n",
            "Epoch 3, Sample 11983: Loss: 0.0018\n",
            "Epoch 3, Sample 11984: Loss: 0.1508\n",
            "Epoch 3, Sample 11985: Loss: 0.3506\n",
            "Epoch 3, Sample 11986: Loss: 2.6000\n",
            "Epoch 3, Sample 11987: Loss: 0.3803\n",
            "Epoch 3, Sample 11988: Loss: 0.0077\n",
            "Epoch 3, Sample 11989: Loss: 0.3980\n",
            "Epoch 3, Sample 11990: Loss: 0.2034\n",
            "Epoch 3, Sample 11991: Loss: 0.2034\n",
            "Epoch 3, Sample 11992: Loss: 0.5003\n",
            "Epoch 3, Sample 11993: Loss: 0.3598\n",
            "Epoch 3, Sample 11994: Loss: 0.0536\n",
            "Epoch 3, Sample 11995: Loss: 1.0524\n",
            "Epoch 3, Sample 11996: Loss: 0.1091\n",
            "Epoch 3, Sample 11997: Loss: 0.2036\n",
            "Epoch 3, Sample 11998: Loss: 0.0125\n",
            "Epoch 3, Sample 11999: Loss: 8.7405\n",
            "Epoch 3, Sample 12000: Loss: 0.0018\n",
            "Epoch 3, Sample 12001: Loss: 0.9886\n",
            "Epoch 3, Sample 12002: Loss: 0.0306\n",
            "Epoch 3, Sample 12003: Loss: 0.0001\n",
            "Epoch 3, Sample 12004: Loss: 0.0050\n",
            "Epoch 3, Sample 12005: Loss: 0.7344\n",
            "Epoch 3, Sample 12006: Loss: 0.1890\n",
            "Epoch 3, Sample 12007: Loss: 0.4672\n",
            "Epoch 3, Sample 12008: Loss: 0.0001\n",
            "Epoch 3, Sample 12009: Loss: 0.2044\n",
            "Epoch 3, Sample 12010: Loss: 0.0476\n",
            "Epoch 3, Sample 12011: Loss: 1.5808\n",
            "Epoch 3, Sample 12012: Loss: 0.0000\n",
            "Epoch 3, Sample 12013: Loss: 0.4930\n",
            "Epoch 3, Sample 12014: Loss: 0.1114\n",
            "Epoch 3, Sample 12015: Loss: 0.3598\n",
            "Epoch 3, Sample 12016: Loss: 0.2044\n",
            "Epoch 3, Sample 12017: Loss: 0.8090\n",
            "Epoch 3, Sample 12018: Loss: 0.0626\n",
            "Epoch 3, Sample 12019: Loss: 0.2044\n",
            "Epoch 3, Sample 12020: Loss: 0.2522\n",
            "Epoch 3, Sample 12021: Loss: 0.3949\n",
            "Epoch 3, Sample 12022: Loss: 0.3949\n",
            "Epoch 3, Sample 12023: Loss: 0.1250\n",
            "Epoch 3, Sample 12024: Loss: 1.0524\n",
            "Epoch 3, Sample 12025: Loss: 1.0524\n",
            "Epoch 3, Sample 12026: Loss: 0.2759\n",
            "Epoch 3, Sample 12027: Loss: 0.0060\n",
            "Epoch 3, Sample 12028: Loss: 0.5019\n",
            "Epoch 3, Sample 12029: Loss: 0.2219\n",
            "Epoch 3, Sample 12030: Loss: 1.3216\n",
            "Epoch 3, Sample 12031: Loss: 0.0006\n",
            "Epoch 3, Sample 12032: Loss: 0.3441\n",
            "Epoch 3, Sample 12033: Loss: 7.3391\n",
            "Epoch 3, Sample 12034: Loss: 0.3441\n",
            "Epoch 3, Sample 12035: Loss: 0.2459\n",
            "Epoch 3, Sample 12036: Loss: 0.1039\n",
            "Epoch 3, Sample 12037: Loss: 0.0018\n",
            "Epoch 3, Sample 12038: Loss: 0.7218\n",
            "Epoch 3, Sample 12039: Loss: 0.4663\n",
            "Epoch 3, Sample 12040: Loss: 0.1526\n",
            "Epoch 3, Sample 12041: Loss: 0.3367\n",
            "Epoch 3, Sample 12042: Loss: 0.0558\n",
            "Epoch 3, Sample 12043: Loss: 0.0247\n",
            "Epoch 3, Sample 12044: Loss: 0.7036\n",
            "Epoch 3, Sample 12045: Loss: 0.0026\n",
            "Epoch 3, Sample 12046: Loss: 0.2034\n",
            "Epoch 3, Sample 12047: Loss: 0.0009\n",
            "Epoch 3, Sample 12048: Loss: 0.6139\n",
            "Epoch 3, Sample 12049: Loss: 0.1559\n",
            "Epoch 3, Sample 12050: Loss: 0.5003\n",
            "Epoch 3, Sample 12051: Loss: 0.0334\n",
            "Epoch 3, Sample 12052: Loss: 0.0026\n",
            "Epoch 3, Sample 12053: Loss: 0.3584\n",
            "Epoch 3, Sample 12054: Loss: 0.1250\n",
            "Epoch 3, Sample 12055: Loss: 0.0625\n",
            "Epoch 3, Sample 12056: Loss: 0.5019\n",
            "Epoch 3, Sample 12057: Loss: 0.0194\n",
            "Epoch 3, Sample 12058: Loss: 0.2587\n",
            "Epoch 3, Sample 12059: Loss: 0.2034\n",
            "Epoch 3, Sample 12060: Loss: 0.6990\n",
            "Epoch 3, Sample 12061: Loss: 0.0029\n",
            "Epoch 3, Sample 12062: Loss: 0.0018\n",
            "Epoch 3, Sample 12063: Loss: 0.3441\n",
            "Epoch 3, Sample 12064: Loss: 0.3399\n",
            "Epoch 3, Sample 12065: Loss: 0.0201\n",
            "Epoch 3, Sample 12066: Loss: 0.0505\n",
            "Epoch 3, Sample 12067: Loss: 0.0002\n",
            "Epoch 3, Sample 12068: Loss: 0.0025\n",
            "Epoch 3, Sample 12069: Loss: 0.2032\n",
            "Epoch 3, Sample 12070: Loss: 0.2388\n",
            "Epoch 3, Sample 12071: Loss: 0.4543\n",
            "Epoch 3, Sample 12072: Loss: 7.3277\n",
            "Epoch 3, Sample 12073: Loss: 1.0155\n",
            "Epoch 3, Sample 12074: Loss: 0.7036\n",
            "Epoch 3, Sample 12075: Loss: 0.1170\n",
            "Epoch 3, Sample 12076: Loss: 0.0012\n",
            "Epoch 3, Sample 12077: Loss: 0.2044\n",
            "Epoch 3, Sample 12078: Loss: 0.0026\n",
            "Epoch 3, Sample 12079: Loss: 2.0389\n",
            "Epoch 3, Sample 12080: Loss: 0.7453\n",
            "Epoch 3, Sample 12081: Loss: 0.6867\n",
            "Epoch 3, Sample 12082: Loss: 0.7036\n",
            "Epoch 3, Sample 12083: Loss: 0.6304\n",
            "Epoch 3, Sample 12084: Loss: 0.1399\n",
            "Epoch 3, Sample 12085: Loss: 0.2759\n",
            "Epoch 3, Sample 12086: Loss: 0.8951\n",
            "Epoch 3, Sample 12087: Loss: 0.7036\n",
            "Epoch 3, Sample 12088: Loss: 1.0524\n",
            "Epoch 3, Sample 12089: Loss: 0.2044\n",
            "Epoch 3, Sample 12090: Loss: 3.0239\n",
            "Epoch 3, Sample 12091: Loss: 0.2639\n",
            "Epoch 3, Sample 12092: Loss: 0.2044\n",
            "Epoch 3, Sample 12093: Loss: 0.5314\n",
            "Epoch 3, Sample 12094: Loss: 0.0018\n",
            "Epoch 3, Sample 12095: Loss: 0.7036\n",
            "Epoch 3, Sample 12096: Loss: 0.6990\n",
            "Epoch 3, Sample 12097: Loss: 0.7036\n",
            "Epoch 3, Sample 12098: Loss: 0.0108\n",
            "Epoch 3, Sample 12099: Loss: 0.8477\n",
            "Epoch 3, Sample 12100: Loss: 0.0725\n",
            "Epoch 3, Sample 12101: Loss: 0.2036\n",
            "Epoch 3, Sample 12102: Loss: 0.2044\n",
            "Epoch 3, Sample 12103: Loss: 0.3441\n",
            "Epoch 3, Sample 12104: Loss: 0.2032\n",
            "Epoch 3, Sample 12105: Loss: 1.6800\n",
            "Epoch 3, Sample 12106: Loss: 1.0530\n",
            "Epoch 3, Sample 12107: Loss: 0.0063\n",
            "Epoch 3, Sample 12108: Loss: 0.1397\n",
            "Epoch 3, Sample 12109: Loss: 0.0116\n",
            "Epoch 3, Sample 12110: Loss: 0.0630\n",
            "Epoch 3, Sample 12111: Loss: 0.1559\n",
            "Epoch 3, Sample 12112: Loss: 0.7970\n",
            "Epoch 3, Sample 12113: Loss: 1.0524\n",
            "Epoch 3, Sample 12114: Loss: 0.7036\n",
            "Epoch 3, Sample 12115: Loss: 2.0233\n",
            "Epoch 3, Sample 12116: Loss: 1.5149\n",
            "Epoch 3, Sample 12117: Loss: 0.5972\n",
            "Epoch 3, Sample 12118: Loss: 4.7649\n",
            "Epoch 3, Sample 12119: Loss: 1.1018\n",
            "Epoch 3, Sample 12120: Loss: 0.3399\n",
            "Epoch 3, Sample 12121: Loss: 0.5196\n",
            "Epoch 3, Sample 12122: Loss: 0.2832\n",
            "Epoch 3, Sample 12123: Loss: 0.6990\n",
            "Epoch 3, Sample 12124: Loss: 0.1056\n",
            "Epoch 3, Sample 12125: Loss: 0.0145\n",
            "Epoch 3, Sample 12126: Loss: 0.0018\n",
            "Epoch 3, Sample 12127: Loss: 0.0017\n",
            "Epoch 3, Sample 12128: Loss: 0.2044\n",
            "Epoch 3, Sample 12129: Loss: 1.0530\n",
            "Epoch 3, Sample 12130: Loss: 0.0630\n",
            "Epoch 3, Sample 12131: Loss: 0.8951\n",
            "Epoch 3, Sample 12132: Loss: 0.0853\n",
            "Epoch 3, Sample 12133: Loss: 2.1293\n",
            "Epoch 3, Sample 12134: Loss: 0.2034\n",
            "Epoch 3, Sample 12135: Loss: 0.2044\n",
            "Epoch 3, Sample 12136: Loss: 0.0096\n",
            "Epoch 3, Sample 12137: Loss: 0.2759\n",
            "Epoch 3, Sample 12138: Loss: 0.1822\n",
            "Epoch 3, Sample 12139: Loss: 0.2759\n",
            "Epoch 3, Sample 12140: Loss: 0.2044\n",
            "Epoch 3, Sample 12141: Loss: 0.0144\n",
            "Epoch 3, Sample 12142: Loss: 0.2726\n",
            "Epoch 3, Sample 12143: Loss: 1.0155\n",
            "Epoch 3, Sample 12144: Loss: 0.2759\n",
            "Epoch 3, Sample 12145: Loss: 0.3402\n",
            "Epoch 3, Sample 12146: Loss: 0.5062\n",
            "Epoch 3, Sample 12147: Loss: 0.1170\n",
            "Epoch 3, Sample 12148: Loss: 0.1697\n",
            "Epoch 3, Sample 12149: Loss: 0.0626\n",
            "Epoch 3, Sample 12150: Loss: 0.1559\n",
            "Epoch 3, Sample 12151: Loss: 0.0026\n",
            "Epoch 3, Sample 12152: Loss: 0.3711\n",
            "Epoch 3, Sample 12153: Loss: 0.1250\n",
            "Epoch 3, Sample 12154: Loss: 0.3259\n",
            "Epoch 3, Sample 12155: Loss: 0.2044\n",
            "Epoch 3, Sample 12156: Loss: 0.1170\n",
            "Epoch 3, Sample 12157: Loss: 1.0530\n",
            "Epoch 3, Sample 12158: Loss: 0.0819\n",
            "Epoch 3, Sample 12159: Loss: 0.2044\n",
            "Epoch 3, Sample 12160: Loss: 0.2044\n",
            "Epoch 3, Sample 12161: Loss: 0.3399\n",
            "Epoch 3, Sample 12162: Loss: 0.0206\n",
            "Epoch 3, Sample 12163: Loss: 0.0018\n",
            "Epoch 3, Sample 12164: Loss: 0.3399\n",
            "Epoch 3, Sample 12165: Loss: 0.0618\n",
            "Epoch 3, Sample 12166: Loss: 1.0072\n",
            "Epoch 3, Sample 12167: Loss: 0.1882\n",
            "Epoch 3, Sample 12168: Loss: 0.8318\n",
            "Epoch 3, Sample 12169: Loss: 0.0212\n",
            "Epoch 3, Sample 12170: Loss: 0.7036\n",
            "Epoch 3, Sample 12171: Loss: 0.3399\n",
            "Epoch 3, Sample 12172: Loss: 0.2044\n",
            "Epoch 3, Sample 12173: Loss: 0.0013\n",
            "Epoch 3, Sample 12174: Loss: 0.1170\n",
            "Epoch 3, Sample 12175: Loss: 0.7036\n",
            "Epoch 3, Sample 12176: Loss: 0.0830\n",
            "Epoch 3, Sample 12177: Loss: 1.0524\n",
            "Epoch 3, Sample 12178: Loss: 0.0026\n",
            "Epoch 3, Sample 12179: Loss: 0.3240\n",
            "Epoch 3, Sample 12180: Loss: 0.7036\n",
            "Epoch 3, Sample 12181: Loss: 1.0524\n",
            "Epoch 3, Sample 12182: Loss: 0.0838\n",
            "Epoch 3, Sample 12183: Loss: 0.7036\n",
            "Epoch 3, Sample 12184: Loss: 0.7036\n",
            "Epoch 3, Sample 12185: Loss: 0.0034\n",
            "Epoch 3, Sample 12186: Loss: 0.4514\n",
            "Epoch 3, Sample 12187: Loss: 0.0014\n",
            "Epoch 3, Sample 12188: Loss: 0.2036\n",
            "Epoch 3, Sample 12189: Loss: 1.0524\n",
            "Epoch 3, Sample 12190: Loss: 0.0838\n",
            "Epoch 3, Sample 12191: Loss: 0.0810\n",
            "Epoch 3, Sample 12192: Loss: 0.2962\n",
            "Epoch 3, Sample 12193: Loss: 0.0304\n",
            "Epoch 3, Sample 12194: Loss: 0.0026\n",
            "Epoch 3, Sample 12195: Loss: 0.3399\n",
            "Epoch 3, Sample 12196: Loss: 0.3402\n",
            "Epoch 3, Sample 12197: Loss: 0.3441\n",
            "Epoch 3, Sample 12198: Loss: 0.7779\n",
            "Epoch 3, Sample 12199: Loss: 0.0018\n",
            "Epoch 3, Sample 12200: Loss: 0.1699\n",
            "Epoch 3, Sample 12201: Loss: 0.3399\n",
            "Epoch 3, Sample 12202: Loss: 0.1559\n",
            "Epoch 3, Sample 12203: Loss: 0.2219\n",
            "Epoch 3, Sample 12204: Loss: 0.2044\n",
            "Epoch 3, Sample 12205: Loss: 0.2759\n",
            "Epoch 3, Sample 12206: Loss: 0.5858\n",
            "Epoch 3, Sample 12207: Loss: 1.9375\n",
            "Epoch 3, Sample 12208: Loss: 0.0026\n",
            "Epoch 3, Sample 12209: Loss: 0.0415\n",
            "Epoch 3, Sample 12210: Loss: 0.0000\n",
            "Epoch 3, Sample 12211: Loss: 0.0030\n",
            "Epoch 3, Sample 12212: Loss: 0.0035\n",
            "Epoch 3, Sample 12213: Loss: 1.6883\n",
            "Epoch 3, Sample 12214: Loss: 0.5858\n",
            "Epoch 3, Sample 12215: Loss: 0.3399\n",
            "Epoch 3, Sample 12216: Loss: 0.0108\n",
            "Epoch 3, Sample 12217: Loss: 0.0026\n",
            "Epoch 3, Sample 12218: Loss: 0.3441\n",
            "Epoch 3, Sample 12219: Loss: 1.0524\n",
            "Epoch 3, Sample 12220: Loss: 0.6990\n",
            "Epoch 3, Sample 12221: Loss: 0.2044\n",
            "Epoch 3, Sample 12222: Loss: 0.6301\n",
            "Epoch 3, Sample 12223: Loss: 0.0306\n",
            "Epoch 3, Sample 12224: Loss: 0.2340\n",
            "Epoch 3, Sample 12225: Loss: 0.2034\n",
            "Epoch 3, Sample 12226: Loss: 1.0551\n",
            "Epoch 3, Sample 12227: Loss: 0.1248\n",
            "Epoch 3, Sample 12228: Loss: 0.2219\n",
            "Epoch 3, Sample 12229: Loss: 0.3818\n",
            "Epoch 3, Sample 12230: Loss: 0.0284\n",
            "Epoch 3, Sample 12231: Loss: 0.4761\n",
            "Epoch 3, Sample 12232: Loss: 0.0505\n",
            "Epoch 3, Sample 12233: Loss: 0.0000\n",
            "Epoch 3, Sample 12234: Loss: 0.2832\n",
            "Epoch 3, Sample 12235: Loss: 0.9367\n",
            "Epoch 3, Sample 12236: Loss: 0.1250\n",
            "Epoch 3, Sample 12237: Loss: 0.0379\n",
            "Epoch 3, Sample 12238: Loss: 0.0238\n",
            "Epoch 3, Sample 12239: Loss: 0.3441\n",
            "Epoch 3, Sample 12240: Loss: 0.0005\n",
            "Epoch 3, Sample 12241: Loss: 3.9629\n",
            "Epoch 3, Sample 12242: Loss: 0.6867\n",
            "Epoch 3, Sample 12243: Loss: 0.0060\n",
            "Epoch 3, Sample 12244: Loss: 0.2044\n",
            "Epoch 3, Sample 12245: Loss: 1.0155\n",
            "Epoch 3, Sample 12246: Loss: 0.0144\n",
            "Epoch 3, Sample 12247: Loss: 0.9988\n",
            "Epoch 3, Sample 12248: Loss: 0.3441\n",
            "Epoch 3, Sample 12249: Loss: 0.2112\n",
            "Epoch 3, Sample 12250: Loss: 0.7036\n",
            "Epoch 3, Sample 12251: Loss: 0.0145\n",
            "Epoch 3, Sample 12252: Loss: 0.0067\n",
            "Epoch 3, Sample 12253: Loss: 1.0524\n",
            "Epoch 3, Sample 12254: Loss: 0.0303\n",
            "Epoch 3, Sample 12255: Loss: 0.2832\n",
            "Epoch 3, Sample 12256: Loss: 2.4541\n",
            "Epoch 3, Sample 12257: Loss: 0.2032\n",
            "Epoch 3, Sample 12258: Loss: 1.0524\n",
            "Epoch 3, Sample 12259: Loss: 0.2036\n",
            "Epoch 3, Sample 12260: Loss: 0.0611\n",
            "Epoch 3, Sample 12261: Loss: 0.8951\n",
            "Epoch 3, Sample 12262: Loss: 0.5972\n",
            "Epoch 3, Sample 12263: Loss: 0.0630\n",
            "Epoch 3, Sample 12264: Loss: 0.1252\n",
            "Epoch 3, Sample 12265: Loss: 0.5678\n",
            "Epoch 3, Sample 12266: Loss: 0.4930\n",
            "Epoch 3, Sample 12267: Loss: 5.9390\n",
            "Epoch 3, Sample 12268: Loss: 0.2044\n",
            "Epoch 3, Sample 12269: Loss: 0.1170\n",
            "Epoch 3, Sample 12270: Loss: 1.0524\n",
            "Epoch 3, Sample 12271: Loss: 4.1820\n",
            "Epoch 3, Sample 12272: Loss: 1.0524\n",
            "Epoch 3, Sample 12273: Loss: 0.0055\n",
            "Epoch 3, Sample 12274: Loss: 0.4328\n",
            "Epoch 3, Sample 12275: Loss: 0.0626\n",
            "Epoch 3, Sample 12276: Loss: 1.1052\n",
            "Epoch 3, Sample 12277: Loss: 0.8484\n",
            "Epoch 3, Sample 12278: Loss: 1.0524\n",
            "Epoch 3, Sample 12279: Loss: 1.9155\n",
            "Epoch 3, Sample 12280: Loss: 0.0270\n",
            "Epoch 3, Sample 12281: Loss: 0.2032\n",
            "Epoch 3, Sample 12282: Loss: 0.1248\n",
            "Epoch 3, Sample 12283: Loss: 0.4222\n",
            "Epoch 3, Sample 12284: Loss: 0.5972\n",
            "Epoch 3, Sample 12285: Loss: 1.0155\n",
            "Epoch 3, Sample 12286: Loss: 0.4750\n",
            "Epoch 3, Sample 12287: Loss: 0.2759\n",
            "Epoch 3, Sample 12288: Loss: 0.8486\n",
            "Epoch 3, Sample 12289: Loss: 0.0026\n",
            "Epoch 3, Sample 12290: Loss: 0.0082\n",
            "Epoch 3, Sample 12291: Loss: 0.3441\n",
            "Epoch 3, Sample 12292: Loss: 0.1273\n",
            "Epoch 3, Sample 12293: Loss: 0.7036\n",
            "Epoch 3, Sample 12294: Loss: 0.1617\n",
            "Epoch 3, Sample 12295: Loss: 0.0071\n",
            "Epoch 3, Sample 12296: Loss: 0.3294\n",
            "Epoch 3, Sample 12297: Loss: 0.0047\n",
            "Epoch 3, Sample 12298: Loss: 1.0524\n",
            "Epoch 3, Sample 12299: Loss: 0.1992\n",
            "Epoch 3, Sample 12300: Loss: 0.3490\n",
            "Epoch 3, Sample 12301: Loss: 0.1113\n",
            "Epoch 3, Sample 12302: Loss: 0.4799\n",
            "Epoch 3, Sample 12303: Loss: 0.5000\n",
            "Epoch 3, Sample 12304: Loss: 0.5858\n",
            "Epoch 3, Sample 12305: Loss: 0.2938\n",
            "Epoch 3, Sample 12306: Loss: 0.0630\n",
            "Epoch 3, Sample 12307: Loss: 0.0022\n",
            "Epoch 3, Sample 12308: Loss: 0.0001\n",
            "Epoch 3, Sample 12309: Loss: 1.0530\n",
            "Epoch 3, Sample 12310: Loss: 0.7036\n",
            "Epoch 3, Sample 12311: Loss: 0.1170\n",
            "Epoch 3, Sample 12312: Loss: 0.1983\n",
            "Epoch 3, Sample 12313: Loss: 0.3399\n",
            "Epoch 3, Sample 12314: Loss: 0.7394\n",
            "Epoch 3, Sample 12315: Loss: 0.1170\n",
            "Epoch 3, Sample 12316: Loss: 0.1248\n",
            "Epoch 3, Sample 12317: Loss: 0.2044\n",
            "Epoch 3, Sample 12318: Loss: 0.1248\n",
            "Epoch 3, Sample 12319: Loss: 0.6990\n",
            "Epoch 3, Sample 12320: Loss: 0.2032\n",
            "Epoch 3, Sample 12321: Loss: 0.5062\n",
            "Epoch 3, Sample 12322: Loss: 1.0524\n",
            "Epoch 3, Sample 12323: Loss: 0.2962\n",
            "Epoch 3, Sample 12324: Loss: 1.0524\n",
            "Epoch 3, Sample 12325: Loss: 1.0524\n",
            "Epoch 3, Sample 12326: Loss: 0.8490\n",
            "Epoch 3, Sample 12327: Loss: 1.0530\n",
            "Epoch 3, Sample 12328: Loss: 0.1372\n",
            "Epoch 3, Sample 12329: Loss: 0.1559\n",
            "Epoch 3, Sample 12330: Loss: 0.0005\n",
            "Epoch 3, Sample 12331: Loss: 0.0031\n",
            "Epoch 3, Sample 12332: Loss: 0.7618\n",
            "Epoch 3, Sample 12333: Loss: 0.9024\n",
            "Epoch 3, Sample 12334: Loss: 0.0000\n",
            "Epoch 3, Sample 12335: Loss: 0.2157\n",
            "Epoch 3, Sample 12336: Loss: 0.1039\n",
            "Epoch 3, Sample 12337: Loss: 0.5806\n",
            "Epoch 3, Sample 12338: Loss: 0.2765\n",
            "Epoch 3, Sample 12339: Loss: 0.6867\n",
            "Epoch 3, Sample 12340: Loss: 0.3949\n",
            "Epoch 3, Sample 12341: Loss: 0.0026\n",
            "Epoch 3, Sample 12342: Loss: 1.0155\n",
            "Epoch 3, Sample 12343: Loss: 12.8536\n",
            "Epoch 3, Sample 12344: Loss: 0.7036\n",
            "Epoch 3, Sample 12345: Loss: 0.0001\n",
            "Epoch 3, Sample 12346: Loss: 0.4930\n",
            "Epoch 3, Sample 12347: Loss: 0.7036\n",
            "Epoch 3, Sample 12348: Loss: 0.5196\n",
            "Epoch 3, Sample 12349: Loss: 0.2036\n",
            "Epoch 3, Sample 12350: Loss: 0.0526\n",
            "Epoch 3, Sample 12351: Loss: 1.0155\n",
            "Epoch 3, Sample 12352: Loss: 0.1463\n",
            "Epoch 3, Sample 12353: Loss: 0.6092\n",
            "Epoch 3, Sample 12354: Loss: 1.2998\n",
            "Epoch 3, Sample 12355: Loss: 0.0062\n",
            "Epoch 3, Sample 12356: Loss: 0.2832\n",
            "Epoch 3, Sample 12357: Loss: 0.5858\n",
            "Epoch 3, Sample 12358: Loss: 0.3949\n",
            "Epoch 3, Sample 12359: Loss: 0.0415\n",
            "Epoch 3, Sample 12360: Loss: 1.6641\n",
            "Epoch 3, Sample 12361: Loss: 0.0026\n",
            "Epoch 3, Sample 12362: Loss: 0.7036\n",
            "Epoch 3, Sample 12363: Loss: 0.0630\n",
            "Epoch 3, Sample 12364: Loss: 1.0266\n",
            "Epoch 3, Sample 12365: Loss: 0.1138\n",
            "Epoch 3, Sample 12366: Loss: 0.3402\n",
            "Epoch 3, Sample 12367: Loss: 0.0085\n",
            "Epoch 3, Sample 12368: Loss: 0.5675\n",
            "Epoch 3, Sample 12369: Loss: 1.0524\n",
            "Epoch 3, Sample 12370: Loss: 1.0155\n",
            "Epoch 3, Sample 12371: Loss: 0.1478\n",
            "Epoch 3, Sample 12372: Loss: 0.3399\n",
            "Epoch 3, Sample 12373: Loss: 1.3138\n",
            "Epoch 3, Sample 12374: Loss: 0.1508\n",
            "Epoch 3, Sample 12375: Loss: 0.0306\n",
            "Epoch 3, Sample 12376: Loss: 0.2034\n",
            "Epoch 3, Sample 12377: Loss: 0.2044\n",
            "Epoch 3, Sample 12378: Loss: 0.8484\n",
            "Epoch 3, Sample 12379: Loss: 7.4427\n",
            "Epoch 3, Sample 12380: Loss: 0.0026\n",
            "Epoch 3, Sample 12381: Loss: 0.2034\n",
            "Epoch 3, Sample 12382: Loss: 0.6079\n",
            "Epoch 3, Sample 12383: Loss: 0.0012\n",
            "Epoch 3, Sample 12384: Loss: 0.0013\n",
            "Epoch 3, Sample 12385: Loss: 0.8309\n",
            "Epoch 3, Sample 12386: Loss: 2.3150\n",
            "Epoch 3, Sample 12387: Loss: 0.7036\n",
            "Epoch 3, Sample 12388: Loss: 0.5972\n",
            "Epoch 3, Sample 12389: Loss: 0.4799\n",
            "Epoch 3, Sample 12390: Loss: 0.0018\n",
            "Epoch 3, Sample 12391: Loss: 0.3441\n",
            "Epoch 3, Sample 12392: Loss: 0.7036\n",
            "Epoch 3, Sample 12393: Loss: 0.0293\n",
            "Epoch 3, Sample 12394: Loss: 0.8580\n",
            "Epoch 3, Sample 12395: Loss: 1.0524\n",
            "Epoch 3, Sample 12396: Loss: 0.4841\n",
            "Epoch 3, Sample 12397: Loss: 0.2204\n",
            "Epoch 3, Sample 12398: Loss: 0.2759\n",
            "Epoch 3, Sample 12399: Loss: 0.0555\n",
            "Epoch 3, Sample 12400: Loss: 1.0155\n",
            "Epoch 3, Sample 12401: Loss: 1.3377\n",
            "Epoch 3, Sample 12402: Loss: 0.7702\n",
            "Epoch 3, Sample 12403: Loss: 0.0026\n",
            "Epoch 3, Sample 12404: Loss: 0.2989\n",
            "Epoch 3, Sample 12405: Loss: 0.1170\n",
            "Epoch 3, Sample 12406: Loss: 0.0860\n",
            "Epoch 3, Sample 12407: Loss: 1.0524\n",
            "Epoch 3, Sample 12408: Loss: 0.1588\n",
            "Epoch 3, Sample 12409: Loss: 0.0026\n",
            "Epoch 3, Sample 12410: Loss: 1.7195\n",
            "Epoch 3, Sample 12411: Loss: 0.1250\n",
            "Epoch 3, Sample 12412: Loss: 0.3706\n",
            "Epoch 3, Sample 12413: Loss: 1.0524\n",
            "Epoch 3, Sample 12414: Loss: 0.0018\n",
            "Epoch 3, Sample 12415: Loss: 1.0793\n",
            "Epoch 3, Sample 12416: Loss: 0.0066\n",
            "Epoch 3, Sample 12417: Loss: 0.5858\n",
            "Epoch 3, Sample 12418: Loss: 1.0530\n",
            "Epoch 3, Sample 12419: Loss: 0.4466\n",
            "Epoch 3, Sample 12420: Loss: 0.0915\n",
            "Epoch 3, Sample 12421: Loss: 1.2198\n",
            "Epoch 3, Sample 12422: Loss: 0.2699\n",
            "Epoch 3, Sample 12423: Loss: 0.1559\n",
            "Epoch 3, Sample 12424: Loss: 0.7036\n",
            "Epoch 3, Sample 12425: Loss: 0.4536\n",
            "Epoch 3, Sample 12426: Loss: 0.5393\n",
            "Epoch 3, Sample 12427: Loss: 0.0630\n",
            "Epoch 3, Sample 12428: Loss: 0.1372\n",
            "Epoch 3, Sample 12429: Loss: 0.2034\n",
            "Epoch 3, Sample 12430: Loss: 0.5972\n",
            "Epoch 3, Sample 12431: Loss: 0.0095\n",
            "Epoch 3, Sample 12432: Loss: 0.3399\n",
            "Epoch 3, Sample 12433: Loss: 1.1311\n",
            "Epoch 3, Sample 12434: Loss: 0.7036\n",
            "Epoch 3, Sample 12435: Loss: 0.4841\n",
            "Epoch 3, Sample 12436: Loss: 0.1559\n",
            "Epoch 3, Sample 12437: Loss: 0.2032\n",
            "Epoch 3, Sample 12438: Loss: 0.0026\n",
            "Epoch 3, Sample 12439: Loss: 0.0208\n",
            "Epoch 3, Sample 12440: Loss: 1.0155\n",
            "Epoch 3, Sample 12441: Loss: 1.0524\n",
            "Epoch 3, Sample 12442: Loss: 0.2200\n",
            "Epoch 3, Sample 12443: Loss: 0.0513\n",
            "Epoch 3, Sample 12444: Loss: 2.1222\n",
            "Epoch 3, Sample 12445: Loss: 0.1196\n",
            "Epoch 3, Sample 12446: Loss: 0.5003\n",
            "Epoch 3, Sample 12447: Loss: 0.0974\n",
            "Epoch 3, Sample 12448: Loss: 0.0147\n",
            "Epoch 3, Sample 12449: Loss: 1.0524\n",
            "Epoch 3, Sample 12450: Loss: 0.4032\n",
            "Epoch 3, Sample 12451: Loss: 0.0063\n",
            "Epoch 3, Sample 12452: Loss: 0.3949\n",
            "Epoch 3, Sample 12453: Loss: 0.8951\n",
            "Epoch 3, Sample 12454: Loss: 3.8219\n",
            "Epoch 3, Sample 12455: Loss: 0.1770\n",
            "Epoch 3, Sample 12456: Loss: 0.0005\n",
            "Epoch 3, Sample 12457: Loss: 0.1478\n",
            "Epoch 3, Sample 12458: Loss: 0.7036\n",
            "Epoch 3, Sample 12459: Loss: 0.8951\n",
            "Epoch 3, Sample 12460: Loss: 0.3949\n",
            "Epoch 3, Sample 12461: Loss: 2.3799\n",
            "Epoch 3, Sample 12462: Loss: 0.5972\n",
            "Epoch 3, Sample 12463: Loss: 0.5000\n",
            "Epoch 3, Sample 12464: Loss: 0.1792\n",
            "Epoch 3, Sample 12465: Loss: 0.6304\n",
            "Epoch 3, Sample 12466: Loss: 0.0205\n",
            "Epoch 3, Sample 12467: Loss: 0.2219\n",
            "Epoch 3, Sample 12468: Loss: 1.4070\n",
            "Epoch 3, Sample 12469: Loss: 0.0391\n",
            "Epoch 3, Sample 12470: Loss: 0.2034\n",
            "Epoch 3, Sample 12471: Loss: 0.6867\n",
            "Epoch 3, Sample 12472: Loss: 0.2044\n",
            "Epoch 3, Sample 12473: Loss: 0.2036\n",
            "Epoch 3, Sample 12474: Loss: 0.0041\n",
            "Epoch 3, Sample 12475: Loss: 0.9367\n",
            "Epoch 3, Sample 12476: Loss: 0.7453\n",
            "Epoch 3, Sample 12477: Loss: 0.0364\n",
            "Epoch 3, Sample 12478: Loss: 0.1549\n",
            "Epoch 3, Sample 12479: Loss: 0.0744\n",
            "Epoch 3, Sample 12480: Loss: 0.2112\n",
            "Epoch 3, Sample 12481: Loss: 0.1896\n",
            "Epoch 3, Sample 12482: Loss: 0.4367\n",
            "Epoch 3, Sample 12483: Loss: 0.2036\n",
            "Epoch 3, Sample 12484: Loss: 0.3402\n",
            "Epoch 3, Sample 12485: Loss: 0.0293\n",
            "Epoch 3, Sample 12486: Loss: 0.4906\n",
            "Epoch 3, Sample 12487: Loss: 0.2653\n",
            "Epoch 3, Sample 12488: Loss: 0.1706\n",
            "Epoch 3, Sample 12489: Loss: 0.0809\n",
            "Epoch 3, Sample 12490: Loss: 0.7036\n",
            "Epoch 3, Sample 12491: Loss: 0.0108\n",
            "Epoch 3, Sample 12492: Loss: 0.7036\n",
            "Epoch 3, Sample 12493: Loss: 0.2044\n",
            "Epoch 3, Sample 12494: Loss: 1.0530\n",
            "Epoch 3, Sample 12495: Loss: 0.2759\n",
            "Epoch 3, Sample 12496: Loss: 0.3940\n",
            "Epoch 3, Sample 12497: Loss: 0.1170\n",
            "Epoch 3, Sample 12498: Loss: 0.2034\n",
            "Epoch 3, Sample 12499: Loss: 0.7036\n",
            "Epoch 3, Sample 12500: Loss: 0.0026\n",
            "Epoch 3, Sample 12501: Loss: 0.0018\n",
            "Epoch 3, Sample 12502: Loss: 0.6408\n",
            "Epoch 3, Sample 12503: Loss: 0.1594\n",
            "Epoch 3, Sample 12504: Loss: 0.1351\n",
            "Epoch 3, Sample 12505: Loss: 0.0108\n",
            "Epoch 3, Sample 12506: Loss: 0.1219\n",
            "Epoch 3, Sample 12507: Loss: 0.1389\n",
            "Epoch 3, Sample 12508: Loss: 0.2941\n",
            "Epoch 3, Sample 12509: Loss: 0.2044\n",
            "Epoch 3, Sample 12510: Loss: 0.4611\n",
            "Epoch 3, Sample 12511: Loss: 0.2340\n",
            "Epoch 3, Sample 12512: Loss: 0.1114\n",
            "Epoch 3, Sample 12513: Loss: 0.1056\n",
            "Epoch 3, Sample 12514: Loss: 0.7036\n",
            "Epoch 3, Sample 12515: Loss: 1.0524\n",
            "Epoch 3, Sample 12516: Loss: 0.0026\n",
            "Epoch 3, Sample 12517: Loss: 0.1248\n",
            "Epoch 3, Sample 12518: Loss: 0.0755\n",
            "Epoch 3, Sample 12519: Loss: 0.0847\n",
            "Epoch 3, Sample 12520: Loss: 0.0122\n",
            "Epoch 3, Sample 12521: Loss: 0.3594\n",
            "Epoch 3, Sample 12522: Loss: 0.0031\n",
            "Epoch 3, Sample 12523: Loss: 0.0001\n",
            "Epoch 3, Sample 12524: Loss: 0.3399\n",
            "Epoch 3, Sample 12525: Loss: 0.9367\n",
            "Epoch 3, Sample 12526: Loss: 0.8815\n",
            "Epoch 3, Sample 12527: Loss: 1.0524\n",
            "Epoch 3, Sample 12528: Loss: 0.3399\n",
            "Epoch 3, Sample 12529: Loss: 6.8276\n",
            "Epoch 3, Sample 12530: Loss: 0.2363\n",
            "Epoch 3, Sample 12531: Loss: 0.3167\n",
            "Epoch 3, Sample 12532: Loss: 0.0212\n",
            "Epoch 3, Sample 12533: Loss: 0.0027\n",
            "Epoch 3, Sample 12534: Loss: 1.0155\n",
            "Epoch 3, Sample 12535: Loss: 0.0943\n",
            "Epoch 3, Sample 12536: Loss: 0.3539\n",
            "Epoch 3, Sample 12537: Loss: 0.3402\n",
            "Epoch 3, Sample 12538: Loss: 0.8951\n",
            "Epoch 3, Sample 12539: Loss: 0.2044\n",
            "Epoch 3, Sample 12540: Loss: 0.2855\n",
            "Epoch 3, Sample 12541: Loss: 0.2044\n",
            "Epoch 3, Sample 12542: Loss: 0.1250\n",
            "Epoch 3, Sample 12543: Loss: 0.0938\n",
            "Epoch 3, Sample 12544: Loss: 0.7036\n",
            "Epoch 3, Sample 12545: Loss: 1.0524\n",
            "Epoch 3, Sample 12546: Loss: 1.2926\n",
            "Epoch 3, Sample 12547: Loss: 0.0938\n",
            "Epoch 3, Sample 12548: Loss: 0.1355\n",
            "Epoch 3, Sample 12549: Loss: 1.0653\n",
            "Epoch 3, Sample 12550: Loss: 0.0000\n",
            "Epoch 3, Sample 12551: Loss: 2.0233\n",
            "Epoch 3, Sample 12552: Loss: 0.0013\n",
            "Epoch 3, Sample 12553: Loss: 0.2044\n",
            "Epoch 3, Sample 12554: Loss: 0.0189\n",
            "Epoch 3, Sample 12555: Loss: 0.0326\n",
            "Epoch 3, Sample 12556: Loss: 0.0026\n",
            "Epoch 3, Sample 12557: Loss: 0.1233\n",
            "Epoch 3, Sample 12558: Loss: 0.1250\n",
            "Epoch 3, Sample 12559: Loss: 0.0331\n",
            "Epoch 3, Sample 12560: Loss: 0.0795\n",
            "Epoch 3, Sample 12561: Loss: 0.1250\n",
            "Epoch 3, Sample 12562: Loss: 0.7163\n",
            "Epoch 3, Sample 12563: Loss: 0.3655\n",
            "Epoch 3, Sample 12564: Loss: 0.0213\n",
            "Epoch 3, Sample 12565: Loss: 0.0021\n",
            "Epoch 3, Sample 12566: Loss: 0.1463\n",
            "Epoch 3, Sample 12567: Loss: 0.1508\n",
            "Epoch 3, Sample 12568: Loss: 0.7036\n",
            "Epoch 3, Sample 12569: Loss: 1.2393\n",
            "Epoch 3, Sample 12570: Loss: 0.0108\n",
            "Epoch 3, Sample 12571: Loss: 0.0007\n",
            "Epoch 3, Sample 12572: Loss: 0.0106\n",
            "Epoch 3, Sample 12573: Loss: 0.0349\n",
            "Epoch 3, Sample 12574: Loss: 2.5509\n",
            "Epoch 3, Sample 12575: Loss: 0.2034\n",
            "Epoch 3, Sample 12576: Loss: 0.0016\n",
            "Epoch 3, Sample 12577: Loss: 0.0466\n",
            "Epoch 3, Sample 12578: Loss: 1.6732\n",
            "Epoch 3, Sample 12579: Loss: 0.0205\n",
            "Epoch 3, Sample 12580: Loss: 0.0108\n",
            "Epoch 3, Sample 12581: Loss: 0.2989\n",
            "Epoch 3, Sample 12582: Loss: 0.0063\n",
            "Epoch 3, Sample 12583: Loss: 1.0524\n",
            "Epoch 3, Sample 12584: Loss: 0.0026\n",
            "Epoch 3, Sample 12585: Loss: 0.4013\n",
            "Epoch 3, Sample 12586: Loss: 0.1179\n",
            "Epoch 3, Sample 12587: Loss: 0.4953\n",
            "Epoch 3, Sample 12588: Loss: 1.0524\n",
            "Epoch 3, Sample 12589: Loss: 0.0557\n",
            "Epoch 3, Sample 12590: Loss: 0.0483\n",
            "Epoch 3, Sample 12591: Loss: 0.0630\n",
            "Epoch 3, Sample 12592: Loss: 0.4222\n",
            "Epoch 3, Sample 12593: Loss: 0.8792\n",
            "Epoch 3, Sample 12594: Loss: 0.9367\n",
            "Epoch 3, Sample 12595: Loss: 0.0522\n",
            "Epoch 3, Sample 12596: Loss: 0.2034\n",
            "Epoch 3, Sample 12597: Loss: 2.4326\n",
            "Epoch 3, Sample 12598: Loss: 0.2759\n",
            "Epoch 3, Sample 12599: Loss: 0.7453\n",
            "Epoch 3, Sample 12600: Loss: 0.2429\n",
            "Epoch 3, Sample 12601: Loss: 0.0022\n",
            "Epoch 3, Sample 12602: Loss: 1.0524\n",
            "Epoch 3, Sample 12603: Loss: 6.9205\n",
            "Epoch 3, Sample 12604: Loss: 0.0026\n",
            "Epoch 3, Sample 12605: Loss: 0.7036\n",
            "Epoch 3, Sample 12606: Loss: 0.0237\n",
            "Epoch 3, Sample 12607: Loss: 0.0741\n",
            "Epoch 3, Sample 12608: Loss: 0.1225\n",
            "Epoch 3, Sample 12609: Loss: 4.0559\n",
            "Epoch 3, Sample 12610: Loss: 0.4806\n",
            "Epoch 3, Sample 12611: Loss: 0.0205\n",
            "Epoch 3, Sample 12612: Loss: 0.2034\n",
            "Epoch 3, Sample 12613: Loss: 0.0025\n",
            "Epoch 3, Sample 12614: Loss: 0.0604\n",
            "Epoch 3, Sample 12615: Loss: 0.1281\n",
            "Epoch 3, Sample 12616: Loss: 0.9873\n",
            "Epoch 3, Sample 12617: Loss: 0.2044\n",
            "Epoch 3, Sample 12618: Loss: 0.2811\n",
            "Epoch 3, Sample 12619: Loss: 0.1170\n",
            "Epoch 3, Sample 12620: Loss: 0.2759\n",
            "Epoch 3, Sample 12621: Loss: 0.2044\n",
            "Epoch 3, Sample 12622: Loss: 0.5858\n",
            "Epoch 3, Sample 12623: Loss: 0.0306\n",
            "Epoch 3, Sample 12624: Loss: 1.2821\n",
            "Epoch 3, Sample 12625: Loss: 0.2962\n",
            "Epoch 3, Sample 12626: Loss: 0.3441\n",
            "Epoch 3, Sample 12627: Loss: 0.0258\n",
            "Epoch 3, Sample 12628: Loss: 0.1549\n",
            "Epoch 3, Sample 12629: Loss: 0.2032\n",
            "Epoch 3, Sample 12630: Loss: 0.0993\n",
            "Epoch 3, Sample 12631: Loss: 0.9367\n",
            "Epoch 3, Sample 12632: Loss: 0.2034\n",
            "Epoch 3, Sample 12633: Loss: 0.0099\n",
            "Epoch 3, Sample 12634: Loss: 0.0363\n",
            "Epoch 3, Sample 12635: Loss: 0.1523\n",
            "Epoch 3, Sample 12636: Loss: 0.0513\n",
            "Epoch 3, Sample 12637: Loss: 0.1417\n",
            "Epoch 3, Sample 12638: Loss: 0.3314\n",
            "Epoch 3, Sample 12639: Loss: 0.0630\n",
            "Epoch 3, Sample 12640: Loss: 0.0063\n",
            "Epoch 3, Sample 12641: Loss: 0.7910\n",
            "Epoch 3, Sample 12642: Loss: 0.1777\n",
            "Epoch 3, Sample 12643: Loss: 0.3699\n",
            "Epoch 3, Sample 12644: Loss: 1.0524\n",
            "Epoch 3, Sample 12645: Loss: 0.3568\n",
            "Epoch 3, Sample 12646: Loss: 0.7453\n",
            "Epoch 3, Sample 12647: Loss: 0.0062\n",
            "Epoch 3, Sample 12648: Loss: 0.0205\n",
            "Epoch 3, Sample 12649: Loss: 0.0630\n",
            "Epoch 3, Sample 12650: Loss: 0.4611\n",
            "Epoch 3, Sample 12651: Loss: 0.1692\n",
            "Epoch 3, Sample 12652: Loss: 0.2044\n",
            "Epoch 3, Sample 12653: Loss: 0.0248\n",
            "Epoch 3, Sample 12654: Loss: 1.0155\n",
            "Epoch 3, Sample 12655: Loss: 2.9349\n",
            "Epoch 3, Sample 12656: Loss: 0.2292\n",
            "Epoch 3, Sample 12657: Loss: 0.3441\n",
            "Epoch 3, Sample 12658: Loss: 0.4841\n",
            "Epoch 3, Sample 12659: Loss: 0.1546\n",
            "Epoch 3, Sample 12660: Loss: 0.4930\n",
            "Epoch 3, Sample 12661: Loss: 0.0018\n",
            "Epoch 3, Sample 12662: Loss: 2.0554\n",
            "Epoch 3, Sample 12663: Loss: 0.0212\n",
            "Epoch 3, Sample 12664: Loss: 0.1546\n",
            "Epoch 3, Sample 12665: Loss: 0.3399\n",
            "Epoch 3, Sample 12666: Loss: 0.2044\n",
            "Epoch 3, Sample 12667: Loss: 1.0530\n",
            "Epoch 3, Sample 12668: Loss: 0.0084\n",
            "Epoch 3, Sample 12669: Loss: 0.0607\n",
            "Epoch 3, Sample 12670: Loss: 0.0028\n",
            "Epoch 3, Sample 12671: Loss: 0.5858\n",
            "Epoch 3, Sample 12672: Loss: 0.0600\n",
            "Epoch 3, Sample 12673: Loss: 0.7453\n",
            "Epoch 3, Sample 12674: Loss: 0.0001\n",
            "Epoch 3, Sample 12675: Loss: 0.5799\n",
            "Epoch 3, Sample 12676: Loss: 0.5149\n",
            "Epoch 3, Sample 12677: Loss: 0.8411\n",
            "Epoch 3, Sample 12678: Loss: 0.3399\n",
            "Epoch 3, Sample 12679: Loss: 0.2032\n",
            "Epoch 3, Sample 12680: Loss: 3.2348\n",
            "Epoch 3, Sample 12681: Loss: 1.0524\n",
            "Epoch 3, Sample 12682: Loss: 0.3441\n",
            "Epoch 3, Sample 12683: Loss: 0.1863\n",
            "Epoch 3, Sample 12684: Loss: 0.0840\n",
            "Epoch 3, Sample 12685: Loss: 0.1555\n",
            "Epoch 3, Sample 12686: Loss: 7.7241\n",
            "Epoch 3, Sample 12687: Loss: 0.0021\n",
            "Epoch 3, Sample 12688: Loss: 0.2032\n",
            "Epoch 3, Sample 12689: Loss: 1.0524\n",
            "Epoch 3, Sample 12690: Loss: 0.2032\n",
            "Epoch 3, Sample 12691: Loss: 0.0590\n",
            "Epoch 3, Sample 12692: Loss: 0.0234\n",
            "Epoch 3, Sample 12693: Loss: 0.2219\n",
            "Epoch 3, Sample 12694: Loss: 0.2962\n",
            "Epoch 3, Sample 12695: Loss: 0.9367\n",
            "Epoch 3, Sample 12696: Loss: 0.5858\n",
            "Epoch 3, Sample 12697: Loss: 0.2044\n",
            "Epoch 3, Sample 12698: Loss: 6.4494\n",
            "Epoch 3, Sample 12699: Loss: 0.4799\n",
            "Epoch 3, Sample 12700: Loss: 0.2036\n",
            "Epoch 3, Sample 12701: Loss: 0.2593\n",
            "Epoch 3, Sample 12702: Loss: 3.6780\n",
            "Epoch 3, Sample 12703: Loss: 0.6740\n",
            "Epoch 3, Sample 12704: Loss: 1.0530\n",
            "Epoch 3, Sample 12705: Loss: 0.1248\n",
            "Epoch 3, Sample 12706: Loss: 0.2832\n",
            "Epoch 3, Sample 12707: Loss: 0.8951\n",
            "Epoch 3, Sample 12708: Loss: 0.1890\n",
            "Epoch 3, Sample 12709: Loss: 0.1394\n",
            "Epoch 3, Sample 12710: Loss: 0.2034\n",
            "Epoch 3, Sample 12711: Loss: 0.0630\n",
            "Epoch 3, Sample 12712: Loss: 0.2935\n",
            "Epoch 3, Sample 12713: Loss: 0.3271\n",
            "Epoch 3, Sample 12714: Loss: 0.0018\n",
            "Epoch 3, Sample 12715: Loss: 0.2044\n",
            "Epoch 3, Sample 12716: Loss: 0.0026\n",
            "Epoch 3, Sample 12717: Loss: 0.6990\n",
            "Epoch 3, Sample 12718: Loss: 1.0524\n",
            "Epoch 3, Sample 12719: Loss: 0.7702\n",
            "Epoch 3, Sample 12720: Loss: 0.0002\n",
            "Epoch 3, Sample 12721: Loss: 2.6573\n",
            "Epoch 3, Sample 12722: Loss: 0.4220\n",
            "Epoch 3, Sample 12723: Loss: 0.2750\n",
            "Epoch 3, Sample 12724: Loss: 0.5019\n",
            "Epoch 3, Sample 12725: Loss: 0.7036\n",
            "Epoch 3, Sample 12726: Loss: 0.7453\n",
            "Epoch 3, Sample 12727: Loss: 0.0542\n",
            "Epoch 3, Sample 12728: Loss: 0.1746\n",
            "Epoch 3, Sample 12729: Loss: 1.0155\n",
            "Epoch 3, Sample 12730: Loss: 1.0155\n",
            "Epoch 3, Sample 12731: Loss: 0.1767\n",
            "Epoch 3, Sample 12732: Loss: 0.1785\n",
            "Epoch 3, Sample 12733: Loss: 0.0460\n",
            "Epoch 3, Sample 12734: Loss: 1.5851\n",
            "Epoch 3, Sample 12735: Loss: 0.0558\n",
            "Epoch 3, Sample 12736: Loss: 1.1074\n",
            "Epoch 3, Sample 12737: Loss: 0.3824\n",
            "Epoch 3, Sample 12738: Loss: 1.3999\n",
            "Epoch 3, Sample 12739: Loss: 0.0667\n",
            "Epoch 3, Sample 12740: Loss: 1.4734\n",
            "Epoch 3, Sample 12741: Loss: 0.2832\n",
            "Epoch 3, Sample 12742: Loss: 0.2639\n",
            "Epoch 3, Sample 12743: Loss: 0.0027\n",
            "Epoch 3, Sample 12744: Loss: 1.0524\n",
            "Epoch 3, Sample 12745: Loss: 0.0379\n",
            "Epoch 3, Sample 12746: Loss: 0.0026\n",
            "Epoch 3, Sample 12747: Loss: 1.0206\n",
            "Epoch 3, Sample 12748: Loss: 0.1794\n",
            "Epoch 3, Sample 12749: Loss: 0.0018\n",
            "Epoch 3, Sample 12750: Loss: 1.0155\n",
            "Epoch 3, Sample 12751: Loss: 0.5858\n",
            "Epoch 3, Sample 12752: Loss: 0.0297\n",
            "Epoch 3, Sample 12753: Loss: 1.5451\n",
            "Epoch 3, Sample 12754: Loss: 2.4022\n",
            "Epoch 3, Sample 12755: Loss: 0.3399\n",
            "Epoch 3, Sample 12756: Loss: 0.1040\n",
            "Epoch 3, Sample 12757: Loss: 0.0590\n",
            "Epoch 3, Sample 12758: Loss: 1.0511\n",
            "Epoch 3, Sample 12759: Loss: 0.1337\n",
            "Epoch 3, Sample 12760: Loss: 0.1170\n",
            "Epoch 3, Sample 12761: Loss: 0.2112\n",
            "Epoch 3, Sample 12762: Loss: 0.7429\n",
            "Epoch 3, Sample 12763: Loss: 0.2132\n",
            "Epoch 3, Sample 12764: Loss: 0.2034\n",
            "Epoch 3, Sample 12765: Loss: 1.9658\n",
            "Epoch 3, Sample 12766: Loss: 0.0004\n",
            "Epoch 3, Sample 12767: Loss: 4.8044\n",
            "Epoch 3, Sample 12768: Loss: 0.2044\n",
            "Epoch 3, Sample 12769: Loss: 0.0205\n",
            "Epoch 3, Sample 12770: Loss: 0.0274\n",
            "Epoch 3, Sample 12771: Loss: 1.0155\n",
            "Epoch 3, Sample 12772: Loss: 0.0013\n",
            "Epoch 3, Sample 12773: Loss: 0.3399\n",
            "Epoch 3, Sample 12774: Loss: 0.6881\n",
            "Epoch 3, Sample 12775: Loss: 0.2036\n",
            "Epoch 3, Sample 12776: Loss: 1.4439\n",
            "Epoch 3, Sample 12777: Loss: 1.0530\n",
            "Epoch 3, Sample 12778: Loss: 1.7048\n",
            "Epoch 3, Sample 12779: Loss: 1.0764\n",
            "Epoch 3, Sample 12780: Loss: 1.1967\n",
            "Epoch 3, Sample 12781: Loss: 0.6020\n",
            "Epoch 3, Sample 12782: Loss: 1.0155\n",
            "Epoch 3, Sample 12783: Loss: 0.3568\n",
            "Epoch 3, Sample 12784: Loss: 0.0223\n",
            "Epoch 3, Sample 12785: Loss: 0.2175\n",
            "Epoch 3, Sample 12786: Loss: 0.2832\n",
            "Epoch 3, Sample 12787: Loss: 0.1002\n",
            "Epoch 3, Sample 12788: Loss: 0.7036\n",
            "Epoch 3, Sample 12789: Loss: 0.7036\n",
            "Epoch 3, Sample 12790: Loss: 1.0530\n",
            "Epoch 3, Sample 12791: Loss: 0.2204\n",
            "Epoch 3, Sample 12792: Loss: 0.9367\n",
            "Epoch 3, Sample 12793: Loss: 0.5196\n",
            "Epoch 3, Sample 12794: Loss: 0.2759\n",
            "Epoch 3, Sample 12795: Loss: 0.7036\n",
            "Epoch 3, Sample 12796: Loss: 0.0018\n",
            "Epoch 3, Sample 12797: Loss: 0.1252\n",
            "Epoch 3, Sample 12798: Loss: 0.2044\n",
            "Epoch 3, Sample 12799: Loss: 0.7036\n",
            "Epoch 3, Sample 12800: Loss: 0.2036\n",
            "Epoch 3, Sample 12801: Loss: 0.3402\n",
            "Epoch 3, Sample 12802: Loss: 0.3367\n",
            "Epoch 3, Sample 12803: Loss: 0.0067\n",
            "Epoch 3, Sample 12804: Loss: 0.2639\n",
            "Epoch 3, Sample 12805: Loss: 0.2296\n",
            "Epoch 3, Sample 12806: Loss: 0.0979\n",
            "Epoch 3, Sample 12807: Loss: 0.2032\n",
            "Epoch 3, Sample 12808: Loss: 0.2219\n",
            "Epoch 3, Sample 12809: Loss: 0.1246\n",
            "Epoch 3, Sample 12810: Loss: 0.1748\n",
            "Epoch 3, Sample 12811: Loss: 0.2034\n",
            "Epoch 3, Sample 12812: Loss: 0.5858\n",
            "Epoch 3, Sample 12813: Loss: 0.0160\n",
            "Epoch 3, Sample 12814: Loss: 0.2032\n",
            "Epoch 3, Sample 12815: Loss: 0.8951\n",
            "Epoch 3, Sample 12816: Loss: 0.4032\n",
            "Epoch 3, Sample 12817: Loss: 1.0155\n",
            "Epoch 3, Sample 12818: Loss: 0.0205\n",
            "Epoch 3, Sample 12819: Loss: 0.0108\n",
            "Epoch 3, Sample 12820: Loss: 0.2074\n",
            "Epoch 3, Sample 12821: Loss: 0.0573\n",
            "Epoch 3, Sample 12822: Loss: 0.2032\n",
            "Epoch 3, Sample 12823: Loss: 0.1199\n",
            "Epoch 3, Sample 12824: Loss: 0.1508\n",
            "Epoch 3, Sample 12825: Loss: 0.2977\n",
            "Epoch 3, Sample 12826: Loss: 0.2340\n",
            "Epoch 3, Sample 12827: Loss: 0.2032\n",
            "Epoch 3, Sample 12828: Loss: 0.2832\n",
            "Epoch 3, Sample 12829: Loss: 0.5858\n",
            "Epoch 3, Sample 12830: Loss: 0.0026\n",
            "Epoch 3, Sample 12831: Loss: 0.4415\n",
            "Epoch 3, Sample 12832: Loss: 0.1442\n",
            "Epoch 3, Sample 12833: Loss: 0.0031\n",
            "Epoch 3, Sample 12834: Loss: 0.0026\n",
            "Epoch 3, Sample 12835: Loss: 0.2290\n",
            "Epoch 3, Sample 12836: Loss: 0.0626\n",
            "Epoch 3, Sample 12837: Loss: 0.8328\n",
            "Epoch 3, Sample 12838: Loss: 0.0245\n",
            "Epoch 3, Sample 12839: Loss: 0.3945\n",
            "Epoch 3, Sample 12840: Loss: 0.2935\n",
            "Epoch 3, Sample 12841: Loss: 0.2756\n",
            "Epoch 3, Sample 12842: Loss: 0.0306\n",
            "Epoch 3, Sample 12843: Loss: 0.2032\n",
            "Epoch 3, Sample 12844: Loss: 0.0026\n",
            "Epoch 3, Sample 12845: Loss: 0.7036\n",
            "Epoch 3, Sample 12846: Loss: 0.5972\n",
            "Epoch 3, Sample 12847: Loss: 0.1559\n",
            "Epoch 3, Sample 12848: Loss: 0.0391\n",
            "Epoch 3, Sample 12849: Loss: 0.0915\n",
            "Epoch 3, Sample 12850: Loss: 0.4032\n",
            "Epoch 3, Sample 12851: Loss: 0.0306\n",
            "Epoch 3, Sample 12852: Loss: 1.1704\n",
            "Epoch 3, Sample 12853: Loss: 0.2554\n",
            "Epoch 3, Sample 12854: Loss: 0.2044\n",
            "Epoch 3, Sample 12855: Loss: 0.3441\n",
            "Epoch 3, Sample 12856: Loss: 0.0380\n",
            "Epoch 3, Sample 12857: Loss: 0.2032\n",
            "Epoch 3, Sample 12858: Loss: 0.4996\n",
            "Epoch 3, Sample 12859: Loss: 0.1252\n",
            "Epoch 3, Sample 12860: Loss: 0.0986\n",
            "Epoch 3, Sample 12861: Loss: 0.0002\n",
            "Epoch 3, Sample 12862: Loss: 0.8951\n",
            "Epoch 3, Sample 12863: Loss: 0.1250\n",
            "Epoch 3, Sample 12864: Loss: 0.0212\n",
            "Epoch 3, Sample 12865: Loss: 0.0680\n",
            "Epoch 3, Sample 12866: Loss: 0.0013\n",
            "Epoch 3, Sample 12867: Loss: 0.0363\n",
            "Epoch 3, Sample 12868: Loss: 0.2935\n",
            "Epoch 3, Sample 12869: Loss: 0.1757\n",
            "Epoch 3, Sample 12870: Loss: 0.8951\n",
            "Epoch 3, Sample 12871: Loss: 0.0205\n",
            "Epoch 3, Sample 12872: Loss: 0.8951\n",
            "Epoch 3, Sample 12873: Loss: 0.2032\n",
            "Epoch 3, Sample 12874: Loss: 0.7445\n",
            "Epoch 3, Sample 12875: Loss: 0.0108\n",
            "Epoch 3, Sample 12876: Loss: 0.3949\n",
            "Epoch 3, Sample 12877: Loss: 2.2765\n",
            "Epoch 3, Sample 12878: Loss: 1.5160\n",
            "Epoch 3, Sample 12879: Loss: 6.1960\n",
            "Epoch 3, Sample 12880: Loss: 0.7453\n",
            "Epoch 3, Sample 12881: Loss: 0.2887\n",
            "Epoch 3, Sample 12882: Loss: 0.4032\n",
            "Epoch 3, Sample 12883: Loss: 0.2034\n",
            "Epoch 3, Sample 12884: Loss: 0.9367\n",
            "Epoch 3, Sample 12885: Loss: 0.1622\n",
            "Epoch 3, Sample 12886: Loss: 0.2044\n",
            "Epoch 3, Sample 12887: Loss: 0.0026\n",
            "Epoch 3, Sample 12888: Loss: 0.7453\n",
            "Epoch 3, Sample 12889: Loss: 0.2832\n",
            "Epoch 3, Sample 12890: Loss: 0.0201\n",
            "Epoch 3, Sample 12891: Loss: 0.5858\n",
            "Epoch 3, Sample 12892: Loss: 0.5989\n",
            "Epoch 3, Sample 12893: Loss: 1.0524\n",
            "Epoch 3, Sample 12894: Loss: 0.0838\n",
            "Epoch 3, Sample 12895: Loss: 0.1257\n",
            "Epoch 3, Sample 12896: Loss: 0.2832\n",
            "Epoch 3, Sample 12897: Loss: 0.0011\n",
            "Epoch 3, Sample 12898: Loss: 0.0006\n",
            "Epoch 3, Sample 12899: Loss: 0.1786\n",
            "Epoch 3, Sample 12900: Loss: 1.0524\n",
            "Epoch 3, Sample 12901: Loss: 0.0347\n",
            "Epoch 3, Sample 12902: Loss: 0.0205\n",
            "Epoch 3, Sample 12903: Loss: 0.0049\n",
            "Epoch 3, Sample 12904: Loss: 0.1482\n",
            "Epoch 3, Sample 12905: Loss: 0.5972\n",
            "Epoch 3, Sample 12906: Loss: 1.0266\n",
            "Epoch 3, Sample 12907: Loss: 0.1997\n",
            "Epoch 3, Sample 12908: Loss: 0.0067\n",
            "Epoch 3, Sample 12909: Loss: 0.0001\n",
            "Epoch 3, Sample 12910: Loss: 0.0026\n",
            "Epoch 3, Sample 12911: Loss: 0.3288\n",
            "Epoch 3, Sample 12912: Loss: 0.1349\n",
            "Epoch 3, Sample 12913: Loss: 0.0447\n",
            "Epoch 3, Sample 12914: Loss: 0.0039\n",
            "Epoch 3, Sample 12915: Loss: 0.1508\n",
            "Epoch 3, Sample 12916: Loss: 0.7036\n",
            "Epoch 3, Sample 12917: Loss: 0.0018\n",
            "Epoch 3, Sample 12918: Loss: 0.0498\n",
            "Epoch 3, Sample 12919: Loss: 0.3247\n",
            "Epoch 3, Sample 12920: Loss: 0.5972\n",
            "Epoch 3, Sample 12921: Loss: 0.2219\n",
            "Epoch 3, Sample 12922: Loss: 0.2002\n",
            "Epoch 3, Sample 12923: Loss: 0.1006\n",
            "Epoch 3, Sample 12924: Loss: 0.3179\n",
            "Epoch 3, Sample 12925: Loss: 1.9255\n",
            "Epoch 3, Sample 12926: Loss: 0.2759\n",
            "Epoch 3, Sample 12927: Loss: 0.6304\n",
            "Epoch 3, Sample 12928: Loss: 0.0287\n",
            "Epoch 3, Sample 12929: Loss: 0.1170\n",
            "Epoch 3, Sample 12930: Loss: 0.1559\n",
            "Epoch 3, Sample 12931: Loss: 0.0010\n",
            "Epoch 3, Sample 12932: Loss: 0.0001\n",
            "Epoch 3, Sample 12933: Loss: 0.2034\n",
            "Epoch 3, Sample 12934: Loss: 1.0155\n",
            "Epoch 3, Sample 12935: Loss: 0.1356\n",
            "Epoch 3, Sample 12936: Loss: 0.1010\n",
            "Epoch 3, Sample 12937: Loss: 0.3009\n",
            "Epoch 3, Sample 12938: Loss: 0.0626\n",
            "Epoch 3, Sample 12939: Loss: 0.1559\n",
            "Epoch 3, Sample 12940: Loss: 0.4796\n",
            "Epoch 3, Sample 12941: Loss: 0.1588\n",
            "Epoch 3, Sample 12942: Loss: 0.1523\n",
            "Epoch 3, Sample 12943: Loss: 0.4799\n",
            "Epoch 3, Sample 12944: Loss: 2.4027\n",
            "Epoch 3, Sample 12945: Loss: 0.0972\n",
            "Epoch 3, Sample 12946: Loss: 0.1114\n",
            "Epoch 3, Sample 12947: Loss: 0.2182\n",
            "Epoch 3, Sample 12948: Loss: 0.4611\n",
            "Epoch 3, Sample 12949: Loss: 0.0108\n",
            "Epoch 3, Sample 12950: Loss: 0.0018\n",
            "Epoch 3, Sample 12951: Loss: 0.0915\n",
            "Epoch 3, Sample 12952: Loss: 0.5858\n",
            "Epoch 3, Sample 12953: Loss: 0.5633\n",
            "Epoch 3, Sample 12954: Loss: 1.0155\n",
            "Epoch 3, Sample 12955: Loss: 0.0015\n",
            "Epoch 3, Sample 12956: Loss: 1.9155\n",
            "Epoch 3, Sample 12957: Loss: 0.0225\n",
            "Epoch 3, Sample 12958: Loss: 0.3441\n",
            "Epoch 3, Sample 12959: Loss: 0.0018\n",
            "Epoch 3, Sample 12960: Loss: 0.2032\n",
            "Epoch 3, Sample 12961: Loss: 0.8951\n",
            "Epoch 3, Sample 12962: Loss: 0.0270\n",
            "Epoch 3, Sample 12963: Loss: 6.4922\n",
            "Epoch 3, Sample 12964: Loss: 0.1921\n",
            "Epoch 3, Sample 12965: Loss: 0.2044\n",
            "Epoch 3, Sample 12966: Loss: 4.8085\n",
            "Epoch 3, Sample 12967: Loss: 0.1248\n",
            "Epoch 3, Sample 12968: Loss: 0.1250\n",
            "Epoch 3, Sample 12969: Loss: 0.0363\n",
            "Epoch 3, Sample 12970: Loss: 0.2032\n",
            "Epoch 3, Sample 12971: Loss: 1.4809\n",
            "Epoch 3, Sample 12972: Loss: 0.2044\n",
            "Epoch 3, Sample 12973: Loss: 0.5858\n",
            "Epoch 3, Sample 12974: Loss: 0.0578\n",
            "Epoch 3, Sample 12975: Loss: 0.4611\n",
            "Epoch 3, Sample 12976: Loss: 0.0287\n",
            "Epoch 3, Sample 12977: Loss: 1.0524\n",
            "Epoch 3, Sample 12978: Loss: 0.2750\n",
            "Epoch 3, Sample 12979: Loss: 0.1170\n",
            "Epoch 3, Sample 12980: Loss: 0.2044\n",
            "Epoch 3, Sample 12981: Loss: 0.6990\n",
            "Epoch 3, Sample 12982: Loss: 0.0003\n",
            "Epoch 3, Sample 12983: Loss: 0.5972\n",
            "Epoch 3, Sample 12984: Loss: 1.0524\n",
            "Epoch 3, Sample 12985: Loss: 0.1250\n",
            "Epoch 3, Sample 12986: Loss: 1.5767\n",
            "Epoch 3, Sample 12987: Loss: 0.0005\n",
            "Epoch 3, Sample 12988: Loss: 0.1687\n",
            "Epoch 3, Sample 12989: Loss: 0.2759\n",
            "Epoch 3, Sample 12990: Loss: 0.4601\n",
            "Epoch 3, Sample 12991: Loss: 0.1250\n",
            "Epoch 3, Sample 12992: Loss: 0.3399\n",
            "Epoch 3, Sample 12993: Loss: 0.0001\n",
            "Epoch 3, Sample 12994: Loss: 0.8570\n",
            "Epoch 3, Sample 12995: Loss: 0.0640\n",
            "Epoch 3, Sample 12996: Loss: 0.7036\n",
            "Epoch 3, Sample 12997: Loss: 0.0026\n",
            "Epoch 3, Sample 12998: Loss: 1.0524\n",
            "Epoch 3, Sample 12999: Loss: 0.0062\n",
            "Epoch 3, Sample 13000: Loss: 0.1559\n",
            "Epoch 3, Sample 13001: Loss: 0.2044\n",
            "Epoch 3, Sample 13002: Loss: 3.1794\n",
            "Epoch 3, Sample 13003: Loss: 1.0155\n",
            "Epoch 3, Sample 13004: Loss: 0.8464\n",
            "Epoch 3, Sample 13005: Loss: 0.0026\n",
            "Epoch 3, Sample 13006: Loss: 0.0026\n",
            "Epoch 3, Sample 13007: Loss: 0.5247\n",
            "Epoch 3, Sample 13008: Loss: 0.2686\n",
            "Epoch 3, Sample 13009: Loss: 1.0524\n",
            "Epoch 3, Sample 13010: Loss: 0.1523\n",
            "Epoch 3, Sample 13011: Loss: 0.0067\n",
            "Epoch 3, Sample 13012: Loss: 0.0314\n",
            "Epoch 3, Sample 13013: Loss: 1.0524\n",
            "Epoch 3, Sample 13014: Loss: 0.2034\n",
            "Epoch 3, Sample 13015: Loss: 0.3399\n",
            "Epoch 3, Sample 13016: Loss: 0.2036\n",
            "Epoch 3, Sample 13017: Loss: 0.0947\n",
            "Epoch 3, Sample 13018: Loss: 1.0524\n",
            "Epoch 3, Sample 13019: Loss: 1.7323\n",
            "Epoch 3, Sample 13020: Loss: 0.0366\n",
            "Epoch 3, Sample 13021: Loss: 0.6689\n",
            "Epoch 3, Sample 13022: Loss: 0.2044\n",
            "Epoch 3, Sample 13023: Loss: 0.2044\n",
            "Epoch 3, Sample 13024: Loss: 0.3477\n",
            "Epoch 3, Sample 13025: Loss: 0.2583\n",
            "Epoch 3, Sample 13026: Loss: 0.5871\n",
            "Epoch 3, Sample 13027: Loss: 1.0155\n",
            "Epoch 3, Sample 13028: Loss: 0.0455\n",
            "Epoch 3, Sample 13029: Loss: 1.0155\n",
            "Epoch 3, Sample 13030: Loss: 0.0455\n",
            "Epoch 3, Sample 13031: Loss: 1.0530\n",
            "Epoch 3, Sample 13032: Loss: 0.1291\n",
            "Epoch 3, Sample 13033: Loss: 0.0936\n",
            "Epoch 3, Sample 13034: Loss: 0.3399\n",
            "Epoch 3, Sample 13035: Loss: 0.3399\n",
            "Epoch 3, Sample 13036: Loss: 0.5858\n",
            "Epoch 3, Sample 13037: Loss: 0.3805\n",
            "Epoch 3, Sample 13038: Loss: 0.3949\n",
            "Epoch 3, Sample 13039: Loss: 0.7036\n",
            "Epoch 3, Sample 13040: Loss: 0.2034\n",
            "Epoch 3, Sample 13041: Loss: 0.4845\n",
            "Epoch 3, Sample 13042: Loss: 1.0524\n",
            "Epoch 3, Sample 13043: Loss: 0.7910\n",
            "Epoch 3, Sample 13044: Loss: 0.2187\n",
            "Epoch 3, Sample 13045: Loss: 0.5871\n",
            "Epoch 3, Sample 13046: Loss: 0.1187\n",
            "Epoch 3, Sample 13047: Loss: 0.0062\n",
            "Epoch 3, Sample 13048: Loss: 0.0630\n",
            "Epoch 3, Sample 13049: Loss: 0.2770\n",
            "Epoch 3, Sample 13050: Loss: 0.2036\n",
            "Epoch 3, Sample 13051: Loss: 0.0000\n",
            "Epoch 3, Sample 13052: Loss: 0.0002\n",
            "Epoch 3, Sample 13053: Loss: 0.2034\n",
            "Epoch 3, Sample 13054: Loss: 0.2832\n",
            "Epoch 3, Sample 13055: Loss: 0.1246\n",
            "Epoch 3, Sample 13056: Loss: 0.1170\n",
            "Epoch 3, Sample 13057: Loss: 0.3441\n",
            "Epoch 3, Sample 13058: Loss: 0.0095\n",
            "Epoch 3, Sample 13059: Loss: 0.7036\n",
            "Epoch 3, Sample 13060: Loss: 0.2759\n",
            "Epoch 3, Sample 13061: Loss: 0.5858\n",
            "Epoch 3, Sample 13062: Loss: 1.0155\n",
            "Epoch 3, Sample 13063: Loss: 0.3949\n",
            "Epoch 3, Sample 13064: Loss: 1.0524\n",
            "Epoch 3, Sample 13065: Loss: 0.5310\n",
            "Epoch 3, Sample 13066: Loss: 0.6058\n",
            "Epoch 3, Sample 13067: Loss: 0.0630\n",
            "Epoch 3, Sample 13068: Loss: 0.3949\n",
            "Epoch 3, Sample 13069: Loss: 0.7036\n",
            "Epoch 3, Sample 13070: Loss: 0.2034\n",
            "Epoch 3, Sample 13071: Loss: 0.0563\n",
            "Epoch 3, Sample 13072: Loss: 0.3399\n",
            "Epoch 3, Sample 13073: Loss: 0.1367\n",
            "Epoch 3, Sample 13074: Loss: 1.0524\n",
            "Epoch 3, Sample 13075: Loss: 0.0205\n",
            "Epoch 3, Sample 13076: Loss: 0.2034\n",
            "Epoch 3, Sample 13077: Loss: 0.7036\n",
            "Epoch 3, Sample 13078: Loss: 0.3450\n",
            "Epoch 3, Sample 13079: Loss: 0.5000\n",
            "Epoch 3, Sample 13080: Loss: 0.6092\n",
            "Epoch 3, Sample 13081: Loss: 0.5453\n",
            "Epoch 3, Sample 13082: Loss: 0.0013\n",
            "Epoch 3, Sample 13083: Loss: 0.6990\n",
            "Epoch 3, Sample 13084: Loss: 0.2044\n",
            "Epoch 3, Sample 13085: Loss: 0.0019\n",
            "Epoch 3, Sample 13086: Loss: 0.5062\n",
            "Epoch 3, Sample 13087: Loss: 0.9651\n",
            "Epoch 3, Sample 13088: Loss: 0.6990\n",
            "Epoch 3, Sample 13089: Loss: 0.7453\n",
            "Epoch 3, Sample 13090: Loss: 0.8059\n",
            "Epoch 3, Sample 13091: Loss: 0.0025\n",
            "Epoch 3, Sample 13092: Loss: 0.1250\n",
            "Epoch 3, Sample 13093: Loss: 0.3399\n",
            "Epoch 3, Sample 13094: Loss: 0.0630\n",
            "Epoch 3, Sample 13095: Loss: 0.2114\n",
            "Epoch 3, Sample 13096: Loss: 0.6867\n",
            "Epoch 3, Sample 13097: Loss: 0.0108\n",
            "Epoch 3, Sample 13098: Loss: 0.5871\n",
            "Epoch 3, Sample 13099: Loss: 0.2336\n",
            "Epoch 3, Sample 13100: Loss: 3.0999\n",
            "Epoch 3, Sample 13101: Loss: 0.2212\n",
            "Epoch 3, Sample 13102: Loss: 0.5871\n",
            "Epoch 3, Sample 13103: Loss: 1.0530\n",
            "Epoch 3, Sample 13104: Loss: 0.0108\n",
            "Epoch 3, Sample 13105: Loss: 0.2044\n",
            "Epoch 3, Sample 13106: Loss: 0.1250\n",
            "Epoch 3, Sample 13107: Loss: 0.2034\n",
            "Epoch 3, Sample 13108: Loss: 0.7036\n",
            "Epoch 3, Sample 13109: Loss: 0.3019\n",
            "Epoch 3, Sample 13110: Loss: 0.1080\n",
            "Epoch 3, Sample 13111: Loss: 3.4982\n",
            "Epoch 3, Sample 13112: Loss: 0.4930\n",
            "Epoch 3, Sample 13113: Loss: 0.0707\n",
            "Epoch 3, Sample 13114: Loss: 0.6981\n",
            "Epoch 3, Sample 13115: Loss: 0.1193\n",
            "Epoch 3, Sample 13116: Loss: 0.0234\n",
            "Epoch 3, Sample 13117: Loss: 0.6990\n",
            "Epoch 3, Sample 13118: Loss: 1.0530\n",
            "Epoch 3, Sample 13119: Loss: 1.2663\n",
            "Epoch 3, Sample 13120: Loss: 0.8033\n",
            "Epoch 3, Sample 13121: Loss: 0.2044\n",
            "Epoch 3, Sample 13122: Loss: 1.4515\n",
            "Epoch 3, Sample 13123: Loss: 0.7453\n",
            "Epoch 3, Sample 13124: Loss: 0.1588\n",
            "Epoch 3, Sample 13125: Loss: 0.1170\n",
            "Epoch 3, Sample 13126: Loss: 0.1114\n",
            "Epoch 3, Sample 13127: Loss: 0.9978\n",
            "Epoch 3, Sample 13128: Loss: 0.2034\n",
            "Epoch 3, Sample 13129: Loss: 0.2034\n",
            "Epoch 3, Sample 13130: Loss: 0.4032\n",
            "Epoch 3, Sample 13131: Loss: 1.0524\n",
            "Epoch 3, Sample 13132: Loss: 0.0270\n",
            "Epoch 3, Sample 13133: Loss: 0.0026\n",
            "Epoch 3, Sample 13134: Loss: 3.8163\n",
            "Epoch 3, Sample 13135: Loss: 0.1292\n",
            "Epoch 3, Sample 13136: Loss: 0.3290\n",
            "Epoch 3, Sample 13137: Loss: 0.2639\n",
            "Epoch 3, Sample 13138: Loss: 0.3399\n",
            "Epoch 3, Sample 13139: Loss: 0.2502\n",
            "Epoch 3, Sample 13140: Loss: 0.0498\n",
            "Epoch 3, Sample 13141: Loss: 0.7453\n",
            "Epoch 3, Sample 13142: Loss: 0.0117\n",
            "Epoch 3, Sample 13143: Loss: 0.3989\n",
            "Epoch 3, Sample 13144: Loss: 0.2494\n",
            "Epoch 3, Sample 13145: Loss: 0.2044\n",
            "Epoch 3, Sample 13146: Loss: 0.1372\n",
            "Epoch 3, Sample 13147: Loss: 0.0491\n",
            "Epoch 3, Sample 13148: Loss: 0.5858\n",
            "Epoch 3, Sample 13149: Loss: 1.0155\n",
            "Epoch 3, Sample 13150: Loss: 0.0018\n",
            "Epoch 3, Sample 13151: Loss: 0.3399\n",
            "Epoch 3, Sample 13152: Loss: 0.0001\n",
            "Epoch 3, Sample 13153: Loss: 0.0001\n",
            "Epoch 3, Sample 13154: Loss: 0.9999\n",
            "Epoch 3, Sample 13155: Loss: 0.8951\n",
            "Epoch 3, Sample 13156: Loss: 6.2712\n",
            "Epoch 3, Sample 13157: Loss: 0.0719\n",
            "Epoch 3, Sample 13158: Loss: 0.0030\n",
            "Epoch 3, Sample 13159: Loss: 0.2525\n",
            "Epoch 3, Sample 13160: Loss: 0.2759\n",
            "Epoch 3, Sample 13161: Loss: 0.0147\n",
            "Epoch 3, Sample 13162: Loss: 0.1250\n",
            "Epoch 3, Sample 13163: Loss: 1.8616\n",
            "Epoch 3, Sample 13164: Loss: 0.2036\n",
            "Epoch 3, Sample 13165: Loss: 0.0867\n",
            "Epoch 3, Sample 13166: Loss: 0.0303\n",
            "Epoch 3, Sample 13167: Loss: 0.0229\n",
            "Epoch 3, Sample 13168: Loss: 0.4773\n",
            "Epoch 3, Sample 13169: Loss: 0.1625\n",
            "Epoch 3, Sample 13170: Loss: 0.3539\n",
            "Epoch 3, Sample 13171: Loss: 0.7036\n",
            "Epoch 3, Sample 13172: Loss: 0.0026\n",
            "Epoch 3, Sample 13173: Loss: 0.0000\n",
            "Epoch 3, Sample 13174: Loss: 1.1990\n",
            "Epoch 3, Sample 13175: Loss: 0.1170\n",
            "Epoch 3, Sample 13176: Loss: 1.0155\n",
            "Epoch 3, Sample 13177: Loss: 0.5881\n",
            "Epoch 3, Sample 13178: Loss: 3.5827\n",
            "Epoch 3, Sample 13179: Loss: 0.0625\n",
            "Epoch 3, Sample 13180: Loss: 0.1170\n",
            "Epoch 3, Sample 13181: Loss: 0.0026\n",
            "Epoch 3, Sample 13182: Loss: 0.1838\n",
            "Epoch 3, Sample 13183: Loss: 0.6990\n",
            "Epoch 3, Sample 13184: Loss: 0.3441\n",
            "Epoch 3, Sample 13185: Loss: 0.0026\n",
            "Epoch 3, Sample 13186: Loss: 0.2160\n",
            "Epoch 3, Sample 13187: Loss: 0.6984\n",
            "Epoch 3, Sample 13188: Loss: 0.0438\n",
            "Epoch 3, Sample 13189: Loss: 0.7036\n",
            "Epoch 3, Sample 13190: Loss: 1.0524\n",
            "Epoch 3, Sample 13191: Loss: 0.0117\n",
            "Epoch 3, Sample 13192: Loss: 0.0006\n",
            "Epoch 3, Sample 13193: Loss: 1.0530\n",
            "Epoch 3, Sample 13194: Loss: 1.0530\n",
            "Epoch 3, Sample 13195: Loss: 0.5000\n",
            "Epoch 3, Sample 13196: Loss: 0.2759\n",
            "Epoch 3, Sample 13197: Loss: 0.4607\n",
            "Epoch 3, Sample 13198: Loss: 1.9066\n",
            "Epoch 3, Sample 13199: Loss: 1.0524\n",
            "Epoch 3, Sample 13200: Loss: 0.0062\n",
            "Epoch 3, Sample 13201: Loss: 1.0530\n",
            "Epoch 3, Sample 13202: Loss: 0.2832\n",
            "Epoch 3, Sample 13203: Loss: 0.0630\n",
            "Epoch 3, Sample 13204: Loss: 0.0276\n",
            "Epoch 3, Sample 13205: Loss: 0.1838\n",
            "Epoch 3, Sample 13206: Loss: 0.3568\n",
            "Epoch 3, Sample 13207: Loss: 0.0018\n",
            "Epoch 3, Sample 13208: Loss: 0.2044\n",
            "Epoch 3, Sample 13209: Loss: 0.2032\n",
            "Epoch 3, Sample 13210: Loss: 6.7938\n",
            "Epoch 3, Sample 13211: Loss: 0.0001\n",
            "Epoch 3, Sample 13212: Loss: 0.0169\n",
            "Epoch 3, Sample 13213: Loss: 0.5336\n",
            "Epoch 3, Sample 13214: Loss: 1.0155\n",
            "Epoch 3, Sample 13215: Loss: 1.3842\n",
            "Epoch 3, Sample 13216: Loss: 0.6549\n",
            "Epoch 3, Sample 13217: Loss: 0.3964\n",
            "Epoch 3, Sample 13218: Loss: 0.7453\n",
            "Epoch 3, Sample 13219: Loss: 1.3854\n",
            "Epoch 3, Sample 13220: Loss: 0.2001\n",
            "Epoch 3, Sample 13221: Loss: 1.0524\n",
            "Epoch 3, Sample 13222: Loss: 5.9530\n",
            "Epoch 3, Sample 13223: Loss: 0.2219\n",
            "Epoch 3, Sample 13224: Loss: 0.0026\n",
            "Epoch 3, Sample 13225: Loss: 0.0212\n",
            "Epoch 3, Sample 13226: Loss: 0.0026\n",
            "Epoch 3, Sample 13227: Loss: 0.7036\n",
            "Epoch 3, Sample 13228: Loss: 0.3371\n",
            "Epoch 3, Sample 13229: Loss: 0.3598\n",
            "Epoch 3, Sample 13230: Loss: 0.0369\n",
            "Epoch 3, Sample 13231: Loss: 0.2639\n",
            "Epoch 3, Sample 13232: Loss: 1.0155\n",
            "Epoch 3, Sample 13233: Loss: 3.2677\n",
            "Epoch 3, Sample 13234: Loss: 0.0001\n",
            "Epoch 3, Sample 13235: Loss: 0.2032\n",
            "Epoch 3, Sample 13236: Loss: 0.0915\n",
            "Epoch 3, Sample 13237: Loss: 0.6092\n",
            "Epoch 3, Sample 13238: Loss: 10.3238\n",
            "Epoch 3, Sample 13239: Loss: 0.1114\n",
            "Epoch 3, Sample 13240: Loss: 6.9441\n",
            "Epoch 3, Sample 13241: Loss: 0.0026\n",
            "Epoch 3, Sample 13242: Loss: 0.0018\n",
            "Epoch 3, Sample 13243: Loss: 0.2044\n",
            "Epoch 3, Sample 13244: Loss: 0.3474\n",
            "Epoch 3, Sample 13245: Loss: 0.0087\n",
            "Epoch 3, Sample 13246: Loss: 0.1559\n",
            "Epoch 3, Sample 13247: Loss: 0.1559\n",
            "Epoch 3, Sample 13248: Loss: 0.3332\n",
            "Epoch 3, Sample 13249: Loss: 0.1250\n",
            "Epoch 3, Sample 13250: Loss: 0.0001\n",
            "Epoch 3, Sample 13251: Loss: 1.0524\n",
            "Epoch 3, Sample 13252: Loss: 4.5815\n",
            "Epoch 3, Sample 13253: Loss: 0.0026\n",
            "Epoch 3, Sample 13254: Loss: 0.0329\n",
            "Epoch 3, Sample 13255: Loss: 0.3399\n",
            "Epoch 3, Sample 13256: Loss: 0.2483\n",
            "Epoch 3, Sample 13257: Loss: 0.1783\n",
            "Epoch 3, Sample 13258: Loss: 0.0915\n",
            "Epoch 3, Sample 13259: Loss: 0.4841\n",
            "Epoch 3, Sample 13260: Loss: 1.0524\n",
            "Epoch 3, Sample 13261: Loss: 0.0026\n",
            "Epoch 3, Sample 13262: Loss: 0.4032\n",
            "Epoch 3, Sample 13263: Loss: 0.3399\n",
            "Epoch 3, Sample 13264: Loss: 0.4611\n",
            "Epoch 3, Sample 13265: Loss: 0.0000\n",
            "Epoch 3, Sample 13266: Loss: 2.6585\n",
            "Epoch 3, Sample 13267: Loss: 0.1114\n",
            "Epoch 3, Sample 13268: Loss: 0.3450\n",
            "Epoch 3, Sample 13269: Loss: 0.5858\n",
            "Epoch 3, Sample 13270: Loss: 0.0000\n",
            "Epoch 3, Sample 13271: Loss: 0.2759\n",
            "Epoch 3, Sample 13272: Loss: 0.0055\n",
            "Epoch 3, Sample 13273: Loss: 0.2759\n",
            "Epoch 3, Sample 13274: Loss: 0.1559\n",
            "Epoch 3, Sample 13275: Loss: 1.0524\n",
            "Epoch 3, Sample 13276: Loss: 0.2044\n",
            "Epoch 3, Sample 13277: Loss: 0.0364\n",
            "Epoch 3, Sample 13278: Loss: 0.3450\n",
            "Epoch 3, Sample 13279: Loss: 1.1569\n",
            "Epoch 3, Sample 13280: Loss: 0.2504\n",
            "Epoch 3, Sample 13281: Loss: 1.0524\n",
            "Epoch 3, Sample 13282: Loss: 0.2759\n",
            "Epoch 3, Sample 13283: Loss: 0.3399\n",
            "Epoch 3, Sample 13284: Loss: 0.6139\n",
            "Epoch 3, Sample 13285: Loss: 1.0155\n",
            "Epoch 3, Sample 13286: Loss: 0.0486\n",
            "Epoch 3, Sample 13287: Loss: 0.3399\n",
            "Epoch 3, Sample 13288: Loss: 0.1687\n",
            "Epoch 3, Sample 13289: Loss: 0.0026\n",
            "Epoch 3, Sample 13290: Loss: 0.2219\n",
            "Epoch 3, Sample 13291: Loss: 1.0524\n",
            "Epoch 3, Sample 13292: Loss: 0.1250\n",
            "Epoch 3, Sample 13293: Loss: 0.2558\n",
            "Epoch 3, Sample 13294: Loss: 0.4906\n",
            "Epoch 3, Sample 13295: Loss: 1.0029\n",
            "Epoch 3, Sample 13296: Loss: 0.3399\n",
            "Epoch 3, Sample 13297: Loss: 0.1613\n",
            "Epoch 3, Sample 13298: Loss: 0.5858\n",
            "Epoch 3, Sample 13299: Loss: 0.0108\n",
            "Epoch 3, Sample 13300: Loss: 0.2639\n",
            "Epoch 3, Sample 13301: Loss: 0.2941\n",
            "Epoch 3, Sample 13302: Loss: 0.2044\n",
            "Epoch 3, Sample 13303: Loss: 0.0018\n",
            "Epoch 3, Sample 13304: Loss: 0.4799\n",
            "Epoch 3, Sample 13305: Loss: 0.1791\n",
            "Epoch 3, Sample 13306: Loss: 0.0143\n",
            "Epoch 3, Sample 13307: Loss: 0.0505\n",
            "Epoch 3, Sample 13308: Loss: 0.8951\n",
            "Epoch 3, Sample 13309: Loss: 0.2680\n",
            "Epoch 3, Sample 13310: Loss: 0.6141\n",
            "Epoch 3, Sample 13311: Loss: 0.0026\n",
            "Epoch 3, Sample 13312: Loss: 1.0070\n",
            "Epoch 3, Sample 13313: Loss: 0.2044\n",
            "Epoch 3, Sample 13314: Loss: 0.2044\n",
            "Epoch 3, Sample 13315: Loss: 0.2044\n",
            "Epoch 3, Sample 13316: Loss: 0.3166\n",
            "Epoch 3, Sample 13317: Loss: 2.1865\n",
            "Epoch 3, Sample 13318: Loss: 0.0001\n",
            "Epoch 3, Sample 13319: Loss: 0.4930\n",
            "Epoch 3, Sample 13320: Loss: 0.2349\n",
            "Epoch 3, Sample 13321: Loss: 2.0208\n",
            "Epoch 3, Sample 13322: Loss: 0.2907\n",
            "Epoch 3, Sample 13323: Loss: 15.5823\n",
            "Epoch 3, Sample 13324: Loss: 1.0524\n",
            "Epoch 3, Sample 13325: Loss: 0.7036\n",
            "Epoch 3, Sample 13326: Loss: 2.5564\n",
            "Epoch 3, Sample 13327: Loss: 0.4045\n",
            "Epoch 3, Sample 13328: Loss: 0.0205\n",
            "Epoch 3, Sample 13329: Loss: 0.7043\n",
            "Epoch 3, Sample 13330: Loss: 0.0761\n",
            "Epoch 3, Sample 13331: Loss: 6.5695\n",
            "Epoch 3, Sample 13332: Loss: 0.3949\n",
            "Epoch 3, Sample 13333: Loss: 0.2759\n",
            "Epoch 3, Sample 13334: Loss: 1.0530\n",
            "Epoch 3, Sample 13335: Loss: 0.0018\n",
            "Epoch 3, Sample 13336: Loss: 0.1246\n",
            "Epoch 3, Sample 13337: Loss: 0.8951\n",
            "Epoch 3, Sample 13338: Loss: 1.0155\n",
            "Epoch 3, Sample 13339: Loss: 0.0018\n",
            "Epoch 3, Sample 13340: Loss: 0.2034\n",
            "Epoch 3, Sample 13341: Loss: 0.2832\n",
            "Epoch 3, Sample 13342: Loss: 6.1079\n",
            "Epoch 3, Sample 13343: Loss: 1.9869\n",
            "Epoch 3, Sample 13344: Loss: 1.9967\n",
            "Epoch 3, Sample 13345: Loss: 1.0524\n",
            "Epoch 3, Sample 13346: Loss: 0.6990\n",
            "Epoch 3, Sample 13347: Loss: 5.3681\n",
            "Epoch 3, Sample 13348: Loss: 0.0090\n",
            "Epoch 3, Sample 13349: Loss: 0.0444\n",
            "Epoch 3, Sample 13350: Loss: 0.3441\n",
            "Epoch 3, Sample 13351: Loss: 0.3399\n",
            "Epoch 3, Sample 13352: Loss: 1.0530\n",
            "Epoch 3, Sample 13353: Loss: 0.2713\n",
            "Epoch 3, Sample 13354: Loss: 0.6031\n",
            "Epoch 3, Sample 13355: Loss: 2.9652\n",
            "Epoch 3, Sample 13356: Loss: 1.1090\n",
            "Epoch 3, Sample 13357: Loss: 0.0060\n",
            "Epoch 3, Sample 13358: Loss: 1.3131\n",
            "Epoch 3, Sample 13359: Loss: 0.4963\n",
            "Epoch 3, Sample 13360: Loss: 0.2036\n",
            "Epoch 3, Sample 13361: Loss: 0.5972\n",
            "Epoch 3, Sample 13362: Loss: 0.0018\n",
            "Epoch 3, Sample 13363: Loss: 0.0838\n",
            "Epoch 3, Sample 13364: Loss: 0.1170\n",
            "Epoch 3, Sample 13365: Loss: 0.5858\n",
            "Epoch 3, Sample 13366: Loss: 0.3441\n",
            "Epoch 3, Sample 13367: Loss: 1.0524\n",
            "Epoch 3, Sample 13368: Loss: 0.2759\n",
            "Epoch 3, Sample 13369: Loss: 0.7659\n",
            "Epoch 3, Sample 13370: Loss: 3.6517\n",
            "Epoch 3, Sample 13371: Loss: 1.6701\n",
            "Epoch 3, Sample 13372: Loss: 0.3441\n",
            "Epoch 3, Sample 13373: Loss: 0.0018\n",
            "Epoch 3, Sample 13374: Loss: 0.0630\n",
            "Epoch 3, Sample 13375: Loss: 0.2044\n",
            "Epoch 3, Sample 13376: Loss: 0.0212\n",
            "Epoch 3, Sample 13377: Loss: 0.0026\n",
            "Epoch 3, Sample 13378: Loss: 0.0539\n",
            "Epoch 3, Sample 13379: Loss: 0.3399\n",
            "Epoch 3, Sample 13380: Loss: 0.5415\n",
            "Epoch 3, Sample 13381: Loss: 0.3367\n",
            "Epoch 3, Sample 13382: Loss: 0.7036\n",
            "Epoch 3, Sample 13383: Loss: 0.2044\n",
            "Epoch 3, Sample 13384: Loss: 0.0168\n",
            "Epoch 3, Sample 13385: Loss: 0.4799\n",
            "Epoch 3, Sample 13386: Loss: 0.1763\n",
            "Epoch 3, Sample 13387: Loss: 0.0005\n",
            "Epoch 3, Sample 13388: Loss: 0.0025\n",
            "Epoch 3, Sample 13389: Loss: 0.0640\n",
            "Epoch 3, Sample 13390: Loss: 0.0148\n",
            "Epoch 3, Sample 13391: Loss: 0.3441\n",
            "Epoch 3, Sample 13392: Loss: 0.3399\n",
            "Epoch 3, Sample 13393: Loss: 0.0384\n",
            "Epoch 3, Sample 13394: Loss: 1.2324\n",
            "Epoch 3, Sample 13395: Loss: 0.3949\n",
            "Epoch 3, Sample 13396: Loss: 2.4513\n",
            "Epoch 3, Sample 13397: Loss: 0.3506\n",
            "Epoch 3, Sample 13398: Loss: 0.0454\n",
            "Epoch 3, Sample 13399: Loss: 1.1884\n",
            "Epoch 3, Sample 13400: Loss: 0.9367\n",
            "Epoch 3, Sample 13401: Loss: 0.4691\n",
            "Epoch 3, Sample 13402: Loss: 0.2759\n",
            "Epoch 3, Sample 13403: Loss: 0.3399\n",
            "Epoch 3, Sample 13404: Loss: 0.0001\n",
            "Epoch 3, Sample 13405: Loss: 1.3673\n",
            "Epoch 3, Sample 13406: Loss: 0.7324\n",
            "Epoch 3, Sample 13407: Loss: 0.7036\n",
            "Epoch 3, Sample 13408: Loss: 1.0530\n",
            "Epoch 3, Sample 13409: Loss: 0.3399\n",
            "Epoch 3, Sample 13410: Loss: 0.0303\n",
            "Epoch 3, Sample 13411: Loss: 0.0018\n",
            "Epoch 3, Sample 13412: Loss: 0.1523\n",
            "Epoch 3, Sample 13413: Loss: 0.2044\n",
            "Epoch 3, Sample 13414: Loss: 1.0530\n",
            "Epoch 3, Sample 13415: Loss: 0.2832\n",
            "Epoch 3, Sample 13416: Loss: 1.0530\n",
            "Epoch 3, Sample 13417: Loss: 0.3399\n",
            "Epoch 3, Sample 13418: Loss: 0.2962\n",
            "Epoch 3, Sample 13419: Loss: 0.8211\n",
            "Epoch 3, Sample 13420: Loss: 0.9082\n",
            "Epoch 3, Sample 13421: Loss: 0.1559\n",
            "Epoch 3, Sample 13422: Loss: 1.0155\n",
            "Epoch 3, Sample 13423: Loss: 0.3598\n",
            "Epoch 3, Sample 13424: Loss: 1.0524\n",
            "Epoch 3, Sample 13425: Loss: 0.2483\n",
            "Epoch 3, Sample 13426: Loss: 1.0155\n",
            "Epoch 3, Sample 13427: Loss: 0.0757\n",
            "Epoch 3, Sample 13428: Loss: 1.3123\n",
            "Epoch 3, Sample 13429: Loss: 1.5542\n",
            "Epoch 3, Sample 13430: Loss: 0.1372\n",
            "Epoch 3, Sample 13431: Loss: 0.0018\n",
            "Epoch 3, Sample 13432: Loss: 0.0018\n",
            "Epoch 3, Sample 13433: Loss: 0.2340\n",
            "Epoch 3, Sample 13434: Loss: 1.1805\n",
            "Epoch 3, Sample 13435: Loss: 0.0000\n",
            "Epoch 3, Sample 13436: Loss: 0.1091\n",
            "Epoch 3, Sample 13437: Loss: 0.2034\n",
            "Epoch 3, Sample 13438: Loss: 0.0046\n",
            "Epoch 3, Sample 13439: Loss: 0.1696\n",
            "Epoch 3, Sample 13440: Loss: 0.2506\n",
            "Epoch 3, Sample 13441: Loss: 0.9427\n",
            "Epoch 3, Sample 13442: Loss: 0.3399\n",
            "Epoch 3, Sample 13443: Loss: 1.0524\n",
            "Epoch 3, Sample 13444: Loss: 0.3399\n",
            "Epoch 3, Sample 13445: Loss: 0.0026\n",
            "Epoch 3, Sample 13446: Loss: 0.1252\n",
            "Epoch 3, Sample 13447: Loss: 1.4958\n",
            "Epoch 3, Sample 13448: Loss: 0.0062\n",
            "Epoch 3, Sample 13449: Loss: 0.0117\n",
            "Epoch 3, Sample 13450: Loss: 0.1326\n",
            "Epoch 3, Sample 13451: Loss: 0.2219\n",
            "Epoch 3, Sample 13452: Loss: 0.7036\n",
            "Epoch 3, Sample 13453: Loss: 0.6047\n",
            "Epoch 3, Sample 13454: Loss: 0.2639\n",
            "Epoch 3, Sample 13455: Loss: 0.0630\n",
            "Epoch 3, Sample 13456: Loss: 0.0803\n",
            "Epoch 3, Sample 13457: Loss: 0.0429\n",
            "Epoch 3, Sample 13458: Loss: 2.1236\n",
            "Epoch 3, Sample 13459: Loss: 0.1783\n",
            "Epoch 3, Sample 13460: Loss: 0.0205\n",
            "Epoch 3, Sample 13461: Loss: 0.7486\n",
            "Epoch 3, Sample 13462: Loss: 0.7036\n",
            "Epoch 3, Sample 13463: Loss: 4.5516\n",
            "Epoch 3, Sample 13464: Loss: 0.7036\n",
            "Epoch 3, Sample 13465: Loss: 0.1252\n",
            "Epoch 3, Sample 13466: Loss: 0.2984\n",
            "Epoch 3, Sample 13467: Loss: 0.0915\n",
            "Epoch 3, Sample 13468: Loss: 0.3399\n",
            "Epoch 3, Sample 13469: Loss: 0.0018\n",
            "Epoch 3, Sample 13470: Loss: 0.3813\n",
            "Epoch 3, Sample 13471: Loss: 0.0966\n",
            "Epoch 3, Sample 13472: Loss: 0.4930\n",
            "Epoch 3, Sample 13473: Loss: 0.0103\n",
            "Epoch 3, Sample 13474: Loss: 0.0000\n",
            "Epoch 3, Sample 13475: Loss: 0.0086\n",
            "Epoch 3, Sample 13476: Loss: 0.3126\n",
            "Epoch 3, Sample 13477: Loss: 0.3260\n",
            "Epoch 3, Sample 13478: Loss: 1.0524\n",
            "Epoch 3, Sample 13479: Loss: 0.6990\n",
            "Epoch 3, Sample 13480: Loss: 0.3399\n",
            "Epoch 3, Sample 13481: Loss: 0.7036\n",
            "Epoch 3, Sample 13482: Loss: 0.0306\n",
            "Epoch 3, Sample 13483: Loss: 0.3399\n",
            "Epoch 3, Sample 13484: Loss: 0.0838\n",
            "Epoch 3, Sample 13485: Loss: 0.7036\n",
            "Epoch 3, Sample 13486: Loss: 0.9714\n",
            "Epoch 3, Sample 13487: Loss: 0.4024\n",
            "Epoch 3, Sample 13488: Loss: 0.0099\n",
            "Epoch 3, Sample 13489: Loss: 0.1989\n",
            "Epoch 3, Sample 13490: Loss: 1.9317\n",
            "Epoch 3, Sample 13491: Loss: 1.0155\n",
            "Epoch 3, Sample 13492: Loss: 0.2044\n",
            "Epoch 3, Sample 13493: Loss: 0.2759\n",
            "Epoch 3, Sample 13494: Loss: 0.8474\n",
            "Epoch 3, Sample 13495: Loss: 0.2759\n",
            "Epoch 3, Sample 13496: Loss: 16.7283\n",
            "Epoch 3, Sample 13497: Loss: 0.1170\n",
            "Epoch 3, Sample 13498: Loss: 0.9367\n",
            "Epoch 3, Sample 13499: Loss: 0.0013\n",
            "Epoch 3, Sample 13500: Loss: 0.2044\n",
            "Epoch 3, Sample 13501: Loss: 0.2032\n",
            "Epoch 3, Sample 13502: Loss: 1.6241\n",
            "Epoch 3, Sample 13503: Loss: 0.2044\n",
            "Epoch 3, Sample 13504: Loss: 0.1337\n",
            "Epoch 3, Sample 13505: Loss: 0.2219\n",
            "Epoch 3, Sample 13506: Loss: 0.1250\n",
            "Epoch 3, Sample 13507: Loss: 0.1559\n",
            "Epoch 3, Sample 13508: Loss: 0.6990\n",
            "Epoch 3, Sample 13509: Loss: 0.3441\n",
            "Epoch 3, Sample 13510: Loss: 0.4663\n",
            "Epoch 3, Sample 13511: Loss: 0.2568\n",
            "Epoch 3, Sample 13512: Loss: 0.4799\n",
            "Epoch 3, Sample 13513: Loss: 1.0524\n",
            "Epoch 3, Sample 13514: Loss: 0.2034\n",
            "Epoch 3, Sample 13515: Loss: 0.4930\n",
            "Epoch 3, Sample 13516: Loss: 0.5878\n",
            "Epoch 3, Sample 13517: Loss: 0.4930\n",
            "Epoch 3, Sample 13518: Loss: 1.3040\n",
            "Epoch 3, Sample 13519: Loss: 0.0001\n",
            "Epoch 3, Sample 13520: Loss: 0.0630\n",
            "Epoch 3, Sample 13521: Loss: 0.0212\n",
            "Epoch 3, Sample 13522: Loss: 0.2704\n",
            "Epoch 3, Sample 13523: Loss: 0.5062\n",
            "Epoch 3, Sample 13524: Loss: 0.2247\n",
            "Epoch 3, Sample 13525: Loss: 0.0026\n",
            "Epoch 3, Sample 13526: Loss: 0.5830\n",
            "Epoch 3, Sample 13527: Loss: 0.3949\n",
            "Epoch 3, Sample 13528: Loss: 0.2044\n",
            "Epoch 3, Sample 13529: Loss: 0.3626\n",
            "Epoch 3, Sample 13530: Loss: 0.0018\n",
            "Epoch 3, Sample 13531: Loss: 0.7036\n",
            "Epoch 3, Sample 13532: Loss: 0.2107\n",
            "Epoch 3, Sample 13533: Loss: 0.1248\n",
            "Epoch 3, Sample 13534: Loss: 0.5858\n",
            "Epoch 3, Sample 13535: Loss: 0.0460\n",
            "Epoch 3, Sample 13536: Loss: 0.4799\n",
            "Epoch 3, Sample 13537: Loss: 0.6990\n",
            "Epoch 3, Sample 13538: Loss: 0.1698\n",
            "Epoch 3, Sample 13539: Loss: 0.5871\n",
            "Epoch 3, Sample 13540: Loss: 0.0234\n",
            "Epoch 3, Sample 13541: Loss: 0.0875\n",
            "Epoch 3, Sample 13542: Loss: 0.0258\n",
            "Epoch 3, Sample 13543: Loss: 0.2558\n",
            "Epoch 3, Sample 13544: Loss: 1.6712\n",
            "Epoch 3, Sample 13545: Loss: 1.0524\n",
            "Epoch 3, Sample 13546: Loss: 0.3758\n",
            "Epoch 3, Sample 13547: Loss: 1.0530\n",
            "Epoch 3, Sample 13548: Loss: 0.5000\n",
            "Epoch 3, Sample 13549: Loss: 0.0108\n",
            "Epoch 3, Sample 13550: Loss: 0.3441\n",
            "Epoch 3, Sample 13551: Loss: 0.5391\n",
            "Epoch 3, Sample 13552: Loss: 0.3745\n",
            "Epoch 3, Sample 13553: Loss: 0.2620\n",
            "Epoch 3, Sample 13554: Loss: 0.2044\n",
            "Epoch 3, Sample 13555: Loss: 0.0060\n",
            "Epoch 3, Sample 13556: Loss: 0.0315\n",
            "Epoch 3, Sample 13557: Loss: 0.9899\n",
            "Epoch 3, Sample 13558: Loss: 0.0018\n",
            "Epoch 3, Sample 13559: Loss: 1.0266\n",
            "Epoch 3, Sample 13560: Loss: 0.1250\n",
            "Epoch 3, Sample 13561: Loss: 0.1170\n",
            "Epoch 3, Sample 13562: Loss: 1.0524\n",
            "Epoch 3, Sample 13563: Loss: 0.3506\n",
            "Epoch 3, Sample 13564: Loss: 0.0838\n",
            "Epoch 3, Sample 13565: Loss: 0.0020\n",
            "Epoch 3, Sample 13566: Loss: 0.6152\n",
            "Epoch 3, Sample 13567: Loss: 0.5973\n",
            "Epoch 3, Sample 13568: Loss: 0.0915\n",
            "Epoch 3, Sample 13569: Loss: 1.0489\n",
            "Epoch 3, Sample 13570: Loss: 1.0266\n",
            "Epoch 3, Sample 13571: Loss: 0.0541\n",
            "Epoch 3, Sample 13572: Loss: 0.4372\n",
            "Epoch 3, Sample 13573: Loss: 1.7195\n",
            "Epoch 3, Sample 13574: Loss: 0.5196\n",
            "Epoch 3, Sample 13575: Loss: 0.8951\n",
            "Epoch 3, Sample 13576: Loss: 0.3247\n",
            "Epoch 3, Sample 13577: Loss: 0.0026\n",
            "Epoch 3, Sample 13578: Loss: 0.0000\n",
            "Epoch 3, Sample 13579: Loss: 0.2036\n",
            "Epoch 3, Sample 13580: Loss: 0.0205\n",
            "Epoch 3, Sample 13581: Loss: 0.3399\n",
            "Epoch 3, Sample 13582: Loss: 0.6541\n",
            "Epoch 3, Sample 13583: Loss: 0.2044\n",
            "Epoch 3, Sample 13584: Loss: 0.3399\n",
            "Epoch 3, Sample 13585: Loss: 0.4071\n",
            "Epoch 3, Sample 13586: Loss: 0.0745\n",
            "Epoch 3, Sample 13587: Loss: 0.8951\n",
            "Epoch 3, Sample 13588: Loss: 0.2851\n",
            "Epoch 3, Sample 13589: Loss: 0.2176\n",
            "Epoch 3, Sample 13590: Loss: 0.2759\n",
            "Epoch 3, Sample 13591: Loss: 2.8708\n",
            "Epoch 3, Sample 13592: Loss: 0.7486\n",
            "Epoch 3, Sample 13593: Loss: 1.2316\n",
            "Epoch 3, Sample 13594: Loss: 0.3441\n",
            "Epoch 3, Sample 13595: Loss: 0.2832\n",
            "Epoch 3, Sample 13596: Loss: 0.2034\n",
            "Epoch 3, Sample 13597: Loss: 0.2855\n",
            "Epoch 3, Sample 13598: Loss: 0.1504\n",
            "Epoch 3, Sample 13599: Loss: 0.0148\n",
            "Epoch 3, Sample 13600: Loss: 0.0026\n",
            "Epoch 3, Sample 13601: Loss: 0.4930\n",
            "Epoch 3, Sample 13602: Loss: 0.0001\n",
            "Epoch 3, Sample 13603: Loss: 0.1250\n",
            "Epoch 3, Sample 13604: Loss: 0.0303\n",
            "Epoch 3, Sample 13605: Loss: 0.1923\n",
            "Epoch 3, Sample 13606: Loss: 0.2044\n",
            "Epoch 3, Sample 13607: Loss: 0.2735\n",
            "Epoch 3, Sample 13608: Loss: 0.0084\n",
            "Epoch 3, Sample 13609: Loss: 0.0659\n",
            "Epoch 3, Sample 13610: Loss: 0.2340\n",
            "Epoch 3, Sample 13611: Loss: 0.0026\n",
            "Epoch 3, Sample 13612: Loss: 0.3938\n",
            "Epoch 3, Sample 13613: Loss: 0.0042\n",
            "Epoch 3, Sample 13614: Loss: 4.5067\n",
            "Epoch 3, Sample 13615: Loss: 0.1635\n",
            "Epoch 3, Sample 13616: Loss: 1.0524\n",
            "Epoch 3, Sample 13617: Loss: 0.0630\n",
            "Epoch 3, Sample 13618: Loss: 0.0026\n",
            "Epoch 3, Sample 13619: Loss: 0.2034\n",
            "Epoch 3, Sample 13620: Loss: 3.3382\n",
            "Epoch 3, Sample 13621: Loss: 0.0026\n",
            "Epoch 3, Sample 13622: Loss: 0.1250\n",
            "Epoch 3, Sample 13623: Loss: 0.0102\n",
            "Epoch 3, Sample 13624: Loss: 0.6990\n",
            "Epoch 3, Sample 13625: Loss: 0.4367\n",
            "Epoch 3, Sample 13626: Loss: 0.2393\n",
            "Epoch 3, Sample 13627: Loss: 0.0018\n",
            "Epoch 3, Sample 13628: Loss: 2.7331\n",
            "Epoch 3, Sample 13629: Loss: 0.1703\n",
            "Epoch 3, Sample 13630: Loss: 0.1372\n",
            "Epoch 3, Sample 13631: Loss: 5.2376\n",
            "Epoch 3, Sample 13632: Loss: 0.0002\n",
            "Epoch 3, Sample 13633: Loss: 0.3758\n",
            "Epoch 3, Sample 13634: Loss: 0.3441\n",
            "Epoch 3, Sample 13635: Loss: 0.1250\n",
            "Epoch 3, Sample 13636: Loss: 0.2155\n",
            "Epoch 3, Sample 13637: Loss: 0.1508\n",
            "Epoch 3, Sample 13638: Loss: 1.0524\n",
            "Epoch 3, Sample 13639: Loss: 0.9367\n",
            "Epoch 3, Sample 13640: Loss: 1.0266\n",
            "Epoch 3, Sample 13641: Loss: 1.0524\n",
            "Epoch 3, Sample 13642: Loss: 0.1523\n",
            "Epoch 3, Sample 13643: Loss: 0.3399\n",
            "Epoch 3, Sample 13644: Loss: 1.0524\n",
            "Epoch 3, Sample 13645: Loss: 0.7818\n",
            "Epoch 3, Sample 13646: Loss: 0.2285\n",
            "Epoch 3, Sample 13647: Loss: 0.3441\n",
            "Epoch 3, Sample 13648: Loss: 0.5858\n",
            "Epoch 3, Sample 13649: Loss: 0.0108\n",
            "Epoch 3, Sample 13650: Loss: 0.8951\n",
            "Epoch 3, Sample 13651: Loss: 0.7036\n",
            "Epoch 3, Sample 13652: Loss: 0.0026\n",
            "Epoch 3, Sample 13653: Loss: 0.5072\n",
            "Epoch 3, Sample 13654: Loss: 0.3150\n",
            "Epoch 3, Sample 13655: Loss: 0.0915\n",
            "Epoch 3, Sample 13656: Loss: 1.0524\n",
            "Epoch 3, Sample 13657: Loss: 0.5000\n",
            "Epoch 3, Sample 13658: Loss: 0.1588\n",
            "Epoch 3, Sample 13659: Loss: 0.3450\n",
            "Epoch 3, Sample 13660: Loss: 0.2759\n",
            "Epoch 3, Sample 13661: Loss: 0.1062\n",
            "Epoch 3, Sample 13662: Loss: 0.0026\n",
            "Epoch 3, Sample 13663: Loss: 0.2778\n",
            "Epoch 3, Sample 13664: Loss: 0.0962\n",
            "Epoch 3, Sample 13665: Loss: 0.0000\n",
            "Epoch 3, Sample 13666: Loss: 0.2759\n",
            "Epoch 3, Sample 13667: Loss: 0.4841\n",
            "Epoch 3, Sample 13668: Loss: 0.8951\n",
            "Epoch 3, Sample 13669: Loss: 1.0155\n",
            "Epoch 3, Sample 13670: Loss: 0.0026\n",
            "Epoch 3, Sample 13671: Loss: 0.4611\n",
            "Epoch 3, Sample 13672: Loss: 0.3438\n",
            "Epoch 3, Sample 13673: Loss: 1.0145\n",
            "Epoch 3, Sample 13674: Loss: 0.8549\n",
            "Epoch 3, Sample 13675: Loss: 16.7603\n",
            "Epoch 3, Sample 13676: Loss: 0.7036\n",
            "Epoch 3, Sample 13677: Loss: 0.2112\n",
            "Epoch 3, Sample 13678: Loss: 0.7036\n",
            "Epoch 3, Sample 13679: Loss: 0.4611\n",
            "Epoch 3, Sample 13680: Loss: 0.5196\n",
            "Epoch 3, Sample 13681: Loss: 0.0123\n",
            "Epoch 3, Sample 13682: Loss: 0.2759\n",
            "Epoch 3, Sample 13683: Loss: 4.9051\n",
            "Epoch 3, Sample 13684: Loss: 0.9334\n",
            "Epoch 3, Sample 13685: Loss: 2.3818\n",
            "Epoch 3, Sample 13686: Loss: 0.4799\n",
            "Epoch 3, Sample 13687: Loss: 0.5744\n",
            "Epoch 3, Sample 13688: Loss: 0.5972\n",
            "Epoch 3, Sample 13689: Loss: 0.0026\n",
            "Epoch 3, Sample 13690: Loss: 0.3758\n",
            "Epoch 3, Sample 13691: Loss: 0.3441\n",
            "Epoch 3, Sample 13692: Loss: 0.0026\n",
            "Epoch 3, Sample 13693: Loss: 0.7036\n",
            "Epoch 3, Sample 13694: Loss: 0.3568\n",
            "Epoch 3, Sample 13695: Loss: 0.1627\n",
            "Epoch 3, Sample 13696: Loss: 0.1246\n",
            "Epoch 3, Sample 13697: Loss: 0.2034\n",
            "Epoch 3, Sample 13698: Loss: 0.2219\n",
            "Epoch 3, Sample 13699: Loss: 0.0530\n",
            "Epoch 3, Sample 13700: Loss: 0.0915\n",
            "Epoch 3, Sample 13701: Loss: 0.4032\n",
            "Epoch 3, Sample 13702: Loss: 0.3402\n",
            "Epoch 3, Sample 13703: Loss: 0.7036\n",
            "Epoch 3, Sample 13704: Loss: 1.1592\n",
            "Epoch 3, Sample 13705: Loss: 0.2034\n",
            "Epoch 3, Sample 13706: Loss: 0.0006\n",
            "Epoch 3, Sample 13707: Loss: 0.0005\n",
            "Epoch 3, Sample 13708: Loss: 0.4902\n",
            "Epoch 3, Sample 13709: Loss: 0.7036\n",
            "Epoch 3, Sample 13710: Loss: 1.0524\n",
            "Epoch 3, Sample 13711: Loss: 0.6092\n",
            "Epoch 3, Sample 13712: Loss: 0.2044\n",
            "Epoch 3, Sample 13713: Loss: 0.3399\n",
            "Epoch 3, Sample 13714: Loss: 0.3441\n",
            "Epoch 3, Sample 13715: Loss: 0.2044\n",
            "Epoch 3, Sample 13716: Loss: 0.2832\n",
            "Epoch 3, Sample 13717: Loss: 0.1326\n",
            "Epoch 3, Sample 13718: Loss: 0.0640\n",
            "Epoch 3, Sample 13719: Loss: 0.2989\n",
            "Epoch 3, Sample 13720: Loss: 0.9653\n",
            "Epoch 3, Sample 13721: Loss: 1.0530\n",
            "Epoch 3, Sample 13722: Loss: 0.4996\n",
            "Epoch 3, Sample 13723: Loss: 0.2044\n",
            "Epoch 3, Sample 13724: Loss: 0.0821\n",
            "Epoch 3, Sample 13725: Loss: 1.0155\n",
            "Epoch 3, Sample 13726: Loss: 1.0155\n",
            "Epoch 3, Sample 13727: Loss: 0.6988\n",
            "Epoch 3, Sample 13728: Loss: 0.2851\n",
            "Epoch 3, Sample 13729: Loss: 0.2034\n",
            "Epoch 3, Sample 13730: Loss: 0.1091\n",
            "Epoch 3, Sample 13731: Loss: 0.5636\n",
            "Epoch 3, Sample 13732: Loss: 4.4935\n",
            "Epoch 3, Sample 13733: Loss: 0.1817\n",
            "Epoch 3, Sample 13734: Loss: 0.7036\n",
            "Epoch 3, Sample 13735: Loss: 0.0001\n",
            "Epoch 3, Sample 13736: Loss: 1.0155\n",
            "Epoch 3, Sample 13737: Loss: 0.1770\n",
            "Epoch 3, Sample 13738: Loss: 6.2321\n",
            "Epoch 3, Sample 13739: Loss: 0.2036\n",
            "Epoch 3, Sample 13740: Loss: 0.1465\n",
            "Epoch 3, Sample 13741: Loss: 0.0205\n",
            "Epoch 3, Sample 13742: Loss: 0.2989\n",
            "Epoch 3, Sample 13743: Loss: 1.0524\n",
            "Epoch 3, Sample 13744: Loss: 1.0155\n",
            "Epoch 3, Sample 13745: Loss: 0.8484\n",
            "Epoch 3, Sample 13746: Loss: 0.4032\n",
            "Epoch 3, Sample 13747: Loss: 0.2759\n",
            "Epoch 3, Sample 13748: Loss: 0.2851\n",
            "Epoch 3, Sample 13749: Loss: 0.2036\n",
            "Epoch 3, Sample 13750: Loss: 0.2722\n",
            "Epoch 3, Sample 13751: Loss: 0.0593\n",
            "Epoch 3, Sample 13752: Loss: 1.0524\n",
            "Epoch 3, Sample 13753: Loss: 1.2150\n",
            "Epoch 3, Sample 13754: Loss: 0.2044\n",
            "Epoch 3, Sample 13755: Loss: 0.0391\n",
            "Epoch 3, Sample 13756: Loss: 0.0744\n",
            "Epoch 3, Sample 13757: Loss: 3.0804\n",
            "Epoch 3, Sample 13758: Loss: 0.2044\n",
            "Epoch 3, Sample 13759: Loss: 0.0026\n",
            "Epoch 3, Sample 13760: Loss: 1.8874\n",
            "Epoch 3, Sample 13761: Loss: 0.3949\n",
            "Epoch 3, Sample 13762: Loss: 0.5000\n",
            "Epoch 3, Sample 13763: Loss: 0.0630\n",
            "Epoch 3, Sample 13764: Loss: 3.5149\n",
            "Epoch 3, Sample 13765: Loss: 0.8951\n",
            "Epoch 3, Sample 13766: Loss: 4.1907\n",
            "Epoch 3, Sample 13767: Loss: 0.2036\n",
            "Epoch 3, Sample 13768: Loss: 0.3399\n",
            "Epoch 3, Sample 13769: Loss: 0.0026\n",
            "Epoch 3, Sample 13770: Loss: 0.8951\n",
            "Epoch 3, Sample 13771: Loss: 0.5078\n",
            "Epoch 3, Sample 13772: Loss: 0.0915\n",
            "Epoch 3, Sample 13773: Loss: 0.3831\n",
            "Epoch 3, Sample 13774: Loss: 0.4611\n",
            "Epoch 3, Sample 13775: Loss: 0.7036\n",
            "Epoch 3, Sample 13776: Loss: 0.0475\n",
            "Epoch 3, Sample 13777: Loss: 0.2044\n",
            "Epoch 3, Sample 13778: Loss: 4.1179\n",
            "Epoch 3, Sample 13779: Loss: 2.3323\n",
            "Epoch 3, Sample 13780: Loss: 1.2433\n",
            "Epoch 3, Sample 13781: Loss: 0.4314\n",
            "Epoch 3, Sample 13782: Loss: 0.1170\n",
            "Epoch 3, Sample 13783: Loss: 0.0062\n",
            "Epoch 3, Sample 13784: Loss: 0.3399\n",
            "Epoch 3, Sample 13785: Loss: 0.0625\n",
            "Epoch 3, Sample 13786: Loss: 0.7036\n",
            "Epoch 3, Sample 13787: Loss: 0.0026\n",
            "Epoch 3, Sample 13788: Loss: 3.0647\n",
            "Epoch 3, Sample 13789: Loss: 0.4980\n",
            "Epoch 3, Sample 13790: Loss: 1.5415\n",
            "Epoch 3, Sample 13791: Loss: 0.6058\n",
            "Epoch 3, Sample 13792: Loss: 0.0145\n",
            "Epoch 3, Sample 13793: Loss: 0.3441\n",
            "Epoch 3, Sample 13794: Loss: 0.5245\n",
            "Epoch 3, Sample 13795: Loss: 0.3399\n",
            "Epoch 3, Sample 13796: Loss: 0.1516\n",
            "Epoch 3, Sample 13797: Loss: 0.0005\n",
            "Epoch 3, Sample 13798: Loss: 0.0202\n",
            "Epoch 3, Sample 13799: Loss: 1.0155\n",
            "Epoch 3, Sample 13800: Loss: 0.2511\n",
            "Epoch 3, Sample 13801: Loss: 0.0084\n",
            "Epoch 3, Sample 13802: Loss: 0.0067\n",
            "Epoch 3, Sample 13803: Loss: 0.4588\n",
            "Epoch 3, Sample 13804: Loss: 0.3399\n",
            "Epoch 3, Sample 13805: Loss: 1.0524\n",
            "Epoch 3, Sample 13806: Loss: 0.1250\n",
            "Epoch 3, Sample 13807: Loss: 0.6810\n",
            "Epoch 3, Sample 13808: Loss: 0.5858\n",
            "Epoch 3, Sample 13809: Loss: 0.2879\n",
            "Epoch 3, Sample 13810: Loss: 0.3441\n",
            "Epoch 3, Sample 13811: Loss: 0.5000\n",
            "Epoch 3, Sample 13812: Loss: 0.3420\n",
            "Epoch 3, Sample 13813: Loss: 0.3604\n",
            "Epoch 3, Sample 13814: Loss: 0.0018\n",
            "Epoch 3, Sample 13815: Loss: 1.0530\n",
            "Epoch 3, Sample 13816: Loss: 0.2044\n",
            "Epoch 3, Sample 13817: Loss: 0.2044\n",
            "Epoch 3, Sample 13818: Loss: 1.0524\n",
            "Epoch 3, Sample 13819: Loss: 0.4799\n",
            "Epoch 3, Sample 13820: Loss: 0.6058\n",
            "Epoch 3, Sample 13821: Loss: 0.3089\n",
            "Epoch 3, Sample 13822: Loss: 0.2034\n",
            "Epoch 3, Sample 13823: Loss: 0.0286\n",
            "Epoch 3, Sample 13824: Loss: 0.1139\n",
            "Epoch 3, Sample 13825: Loss: 0.0626\n",
            "Epoch 3, Sample 13826: Loss: 0.2832\n",
            "Epoch 3, Sample 13827: Loss: 0.4389\n",
            "Epoch 3, Sample 13828: Loss: 0.9785\n",
            "Epoch 3, Sample 13829: Loss: 0.1170\n",
            "Epoch 3, Sample 13830: Loss: 1.0524\n",
            "Epoch 3, Sample 13831: Loss: 0.2044\n",
            "Epoch 3, Sample 13832: Loss: 0.1170\n",
            "Epoch 3, Sample 13833: Loss: 0.1163\n",
            "Epoch 3, Sample 13834: Loss: 0.0774\n",
            "Epoch 3, Sample 13835: Loss: 0.7702\n",
            "Epoch 3, Sample 13836: Loss: 0.0267\n",
            "Epoch 3, Sample 13837: Loss: 1.0524\n",
            "Epoch 3, Sample 13838: Loss: 0.0475\n",
            "Epoch 3, Sample 13839: Loss: 2.6851\n",
            "Epoch 3, Sample 13840: Loss: 0.3024\n",
            "Epoch 3, Sample 13841: Loss: 0.1252\n",
            "Epoch 3, Sample 13842: Loss: 1.0524\n",
            "Epoch 3, Sample 13843: Loss: 1.5009\n",
            "Epoch 3, Sample 13844: Loss: 0.1170\n",
            "Epoch 3, Sample 13845: Loss: 0.5000\n",
            "Epoch 3, Sample 13846: Loss: 0.0060\n",
            "Epoch 3, Sample 13847: Loss: 0.2034\n",
            "Epoch 3, Sample 13848: Loss: 0.2832\n",
            "Epoch 3, Sample 13849: Loss: 0.2219\n",
            "Epoch 3, Sample 13850: Loss: 0.4841\n",
            "Epoch 3, Sample 13851: Loss: 1.0930\n",
            "Epoch 3, Sample 13852: Loss: 0.5871\n",
            "Epoch 3, Sample 13853: Loss: 1.0530\n",
            "Epoch 3, Sample 13854: Loss: 0.0026\n",
            "Epoch 3, Sample 13855: Loss: 0.7804\n",
            "Epoch 3, Sample 13856: Loss: 0.6304\n",
            "Epoch 3, Sample 13857: Loss: 0.1326\n",
            "Epoch 3, Sample 13858: Loss: 1.0524\n",
            "Epoch 3, Sample 13859: Loss: 0.0026\n",
            "Epoch 3, Sample 13860: Loss: 6.5183\n",
            "Epoch 3, Sample 13861: Loss: 0.0010\n",
            "Epoch 3, Sample 13862: Loss: 1.0524\n",
            "Epoch 3, Sample 13863: Loss: 0.1038\n",
            "Epoch 3, Sample 13864: Loss: 0.1536\n",
            "Epoch 3, Sample 13865: Loss: 0.2759\n",
            "Epoch 3, Sample 13866: Loss: 1.0155\n",
            "Epoch 3, Sample 13867: Loss: 0.0306\n",
            "Epoch 3, Sample 13868: Loss: 0.5871\n",
            "Epoch 3, Sample 13869: Loss: 0.0303\n",
            "Epoch 3, Sample 13870: Loss: 1.0524\n",
            "Epoch 3, Sample 13871: Loss: 0.2044\n",
            "Epoch 3, Sample 13872: Loss: 0.0630\n",
            "Epoch 3, Sample 13873: Loss: 0.9367\n",
            "Epoch 3, Sample 13874: Loss: 0.0000\n",
            "Epoch 3, Sample 13875: Loss: 0.0001\n",
            "Epoch 3, Sample 13876: Loss: 0.1091\n",
            "Epoch 3, Sample 13877: Loss: 0.0018\n",
            "Epoch 3, Sample 13878: Loss: 0.2446\n",
            "Epoch 3, Sample 13879: Loss: 0.0000\n",
            "Epoch 3, Sample 13880: Loss: 0.0026\n",
            "Epoch 3, Sample 13881: Loss: 0.0802\n",
            "Epoch 3, Sample 13882: Loss: 1.2926\n",
            "Epoch 3, Sample 13883: Loss: 0.5089\n",
            "Epoch 3, Sample 13884: Loss: 0.1252\n",
            "Epoch 3, Sample 13885: Loss: 0.6092\n",
            "Epoch 3, Sample 13886: Loss: 2.2055\n",
            "Epoch 3, Sample 13887: Loss: 0.2949\n",
            "Epoch 3, Sample 13888: Loss: 0.2036\n",
            "Epoch 3, Sample 13889: Loss: 0.7024\n",
            "Epoch 3, Sample 13890: Loss: 0.0025\n",
            "Epoch 3, Sample 13891: Loss: 0.2112\n",
            "Epoch 3, Sample 13892: Loss: 0.1482\n",
            "Epoch 3, Sample 13893: Loss: 0.7036\n",
            "Epoch 3, Sample 13894: Loss: 0.9734\n",
            "Epoch 3, Sample 13895: Loss: 0.6092\n",
            "Epoch 3, Sample 13896: Loss: 0.0630\n",
            "Epoch 3, Sample 13897: Loss: 0.0744\n",
            "Epoch 3, Sample 13898: Loss: 0.0000\n",
            "Epoch 3, Sample 13899: Loss: 0.2032\n",
            "Epoch 3, Sample 13900: Loss: 1.0155\n",
            "Epoch 3, Sample 13901: Loss: 4.4781\n",
            "Epoch 3, Sample 13902: Loss: 0.0013\n",
            "Epoch 3, Sample 13903: Loss: 0.7036\n",
            "Epoch 3, Sample 13904: Loss: 0.6674\n",
            "Epoch 3, Sample 13905: Loss: 0.2718\n",
            "Epoch 3, Sample 13906: Loss: 4.2162\n",
            "Epoch 3, Sample 13907: Loss: 0.4799\n",
            "Epoch 3, Sample 13908: Loss: 0.3399\n",
            "Epoch 3, Sample 13909: Loss: 0.0044\n",
            "Epoch 3, Sample 13910: Loss: 2.6829\n",
            "Epoch 3, Sample 13911: Loss: 0.1250\n",
            "Epoch 3, Sample 13912: Loss: 0.3598\n",
            "Epoch 3, Sample 13913: Loss: 0.2034\n",
            "Epoch 3, Sample 13914: Loss: 0.1337\n",
            "Epoch 3, Sample 13915: Loss: 0.0234\n",
            "Epoch 3, Sample 13916: Loss: 0.1416\n",
            "Epoch 3, Sample 13917: Loss: 0.0093\n",
            "Epoch 3, Sample 13918: Loss: 0.4930\n",
            "Epoch 3, Sample 13919: Loss: 0.2044\n",
            "Epoch 3, Sample 13920: Loss: 0.0361\n",
            "Epoch 3, Sample 13921: Loss: 0.7036\n",
            "Epoch 3, Sample 13922: Loss: 0.1627\n",
            "Epoch 3, Sample 13923: Loss: 0.0915\n",
            "Epoch 3, Sample 13924: Loss: 0.0307\n",
            "Epoch 3, Sample 13925: Loss: 0.3399\n",
            "Epoch 3, Sample 13926: Loss: 1.0524\n",
            "Epoch 3, Sample 13927: Loss: 0.5636\n",
            "Epoch 3, Sample 13928: Loss: 0.3399\n",
            "Epoch 3, Sample 13929: Loss: 0.0102\n",
            "Epoch 3, Sample 13930: Loss: 0.2034\n",
            "Epoch 3, Sample 13931: Loss: 1.0155\n",
            "Epoch 3, Sample 13932: Loss: 0.0018\n",
            "Epoch 3, Sample 13933: Loss: 0.2882\n",
            "Epoch 3, Sample 13934: Loss: 0.0501\n",
            "Epoch 3, Sample 13935: Loss: 0.1555\n",
            "Epoch 3, Sample 13936: Loss: 0.0293\n",
            "Epoch 3, Sample 13937: Loss: 0.1336\n",
            "Epoch 3, Sample 13938: Loss: 0.2034\n",
            "Epoch 3, Sample 13939: Loss: 0.2759\n",
            "Epoch 3, Sample 13940: Loss: 0.4611\n",
            "Epoch 3, Sample 13941: Loss: 0.0630\n",
            "Epoch 3, Sample 13942: Loss: 0.1250\n",
            "Epoch 3, Sample 13943: Loss: 0.3949\n",
            "Epoch 3, Sample 13944: Loss: 1.0155\n",
            "Epoch 3, Sample 13945: Loss: 0.1559\n",
            "Epoch 3, Sample 13946: Loss: 1.0524\n",
            "Epoch 3, Sample 13947: Loss: 0.2044\n",
            "Epoch 3, Sample 13948: Loss: 0.3568\n",
            "Epoch 3, Sample 13949: Loss: 0.4588\n",
            "Epoch 3, Sample 13950: Loss: 0.5003\n",
            "Epoch 3, Sample 13951: Loss: 0.2032\n",
            "Epoch 3, Sample 13952: Loss: 2.2821\n",
            "Epoch 3, Sample 13953: Loss: 0.1250\n",
            "Epoch 3, Sample 13954: Loss: 0.2032\n",
            "Epoch 3, Sample 13955: Loss: 0.4661\n",
            "Epoch 3, Sample 13956: Loss: 0.6867\n",
            "Epoch 3, Sample 13957: Loss: 0.3949\n",
            "Epoch 3, Sample 13958: Loss: 0.2699\n",
            "Epoch 3, Sample 13959: Loss: 0.7453\n",
            "Epoch 3, Sample 13960: Loss: 1.0155\n",
            "Epoch 3, Sample 13961: Loss: 0.3399\n",
            "Epoch 3, Sample 13962: Loss: 0.7036\n",
            "Epoch 3, Sample 13963: Loss: 0.5972\n",
            "Epoch 3, Sample 13964: Loss: 0.0000\n",
            "Epoch 3, Sample 13965: Loss: 0.4607\n",
            "Epoch 3, Sample 13966: Loss: 0.3441\n",
            "Epoch 3, Sample 13967: Loss: 0.2639\n",
            "Epoch 3, Sample 13968: Loss: 0.0595\n",
            "Epoch 3, Sample 13969: Loss: 1.1569\n",
            "Epoch 3, Sample 13970: Loss: 0.7453\n",
            "Epoch 3, Sample 13971: Loss: 0.2044\n",
            "Epoch 3, Sample 13972: Loss: 0.5078\n",
            "Epoch 3, Sample 13973: Loss: 11.0586\n",
            "Epoch 3, Sample 13974: Loss: 0.9367\n",
            "Epoch 3, Sample 13975: Loss: 0.7356\n",
            "Epoch 3, Sample 13976: Loss: 0.3399\n",
            "Epoch 3, Sample 13977: Loss: 0.2044\n",
            "Epoch 3, Sample 13978: Loss: 0.0303\n",
            "Epoch 3, Sample 13979: Loss: 0.0026\n",
            "Epoch 3, Sample 13980: Loss: 0.9367\n",
            "Epoch 3, Sample 13981: Loss: 0.5972\n",
            "Epoch 3, Sample 13982: Loss: 0.1250\n",
            "Epoch 3, Sample 13983: Loss: 0.0630\n",
            "Epoch 3, Sample 13984: Loss: 0.5552\n",
            "Epoch 3, Sample 13985: Loss: 0.0630\n",
            "Epoch 3, Sample 13986: Loss: 0.4128\n",
            "Epoch 3, Sample 13987: Loss: 0.1838\n",
            "Epoch 3, Sample 13988: Loss: 2.1819\n",
            "Epoch 3, Sample 13989: Loss: 0.9663\n",
            "Epoch 3, Sample 13990: Loss: 0.3332\n",
            "Epoch 3, Sample 13991: Loss: 0.2032\n",
            "Epoch 3, Sample 13992: Loss: 0.3402\n",
            "Epoch 3, Sample 13993: Loss: 0.2034\n",
            "Epoch 3, Sample 13994: Loss: 1.0524\n",
            "Epoch 3, Sample 13995: Loss: 0.4032\n",
            "Epoch 3, Sample 13996: Loss: 0.0010\n",
            "Epoch 3, Sample 13997: Loss: 0.6990\n",
            "Epoch 3, Sample 13998: Loss: 0.0026\n",
            "Epoch 3, Sample 13999: Loss: 0.0364\n",
            "Epoch 3, Sample 14000: Loss: 1.0155\n",
            "Epoch 3, Sample 14001: Loss: 0.0838\n",
            "Epoch 3, Sample 14002: Loss: 0.3239\n",
            "Epoch 3, Sample 14003: Loss: 0.0000\n",
            "Epoch 3, Sample 14004: Loss: 0.0001\n",
            "Epoch 3, Sample 14005: Loss: 0.1749\n",
            "Epoch 3, Sample 14006: Loss: 0.2036\n",
            "Epoch 3, Sample 14007: Loss: 0.0026\n",
            "Epoch 3, Sample 14008: Loss: 0.0084\n",
            "Epoch 3, Sample 14009: Loss: 0.1399\n",
            "Epoch 3, Sample 14010: Loss: 0.7036\n",
            "Epoch 3, Sample 14011: Loss: 0.4849\n",
            "Epoch 3, Sample 14012: Loss: 0.0138\n",
            "Epoch 3, Sample 14013: Loss: 0.3441\n",
            "Epoch 3, Sample 14014: Loss: 0.4799\n",
            "Epoch 3, Sample 14015: Loss: 2.0259\n",
            "Epoch 3, Sample 14016: Loss: 1.0155\n",
            "Epoch 3, Sample 14017: Loss: 0.1394\n",
            "Epoch 3, Sample 14018: Loss: 0.0040\n",
            "Epoch 3, Sample 14019: Loss: 5.7798\n",
            "Epoch 3, Sample 14020: Loss: 10.4292\n",
            "Epoch 3, Sample 14021: Loss: 0.3399\n",
            "Epoch 3, Sample 14022: Loss: 1.0524\n",
            "Epoch 3, Sample 14023: Loss: 1.0524\n",
            "Epoch 3, Sample 14024: Loss: 0.0915\n",
            "Epoch 3, Sample 14025: Loss: 0.3399\n",
            "Epoch 3, Sample 14026: Loss: 0.0466\n",
            "Epoch 3, Sample 14027: Loss: 0.3418\n",
            "Epoch 3, Sample 14028: Loss: 0.1559\n",
            "Epoch 3, Sample 14029: Loss: 0.2896\n",
            "Epoch 3, Sample 14030: Loss: 0.9785\n",
            "Epoch 3, Sample 14031: Loss: 0.9367\n",
            "Epoch 3, Sample 14032: Loss: 0.4032\n",
            "Epoch 3, Sample 14033: Loss: 0.6108\n",
            "Epoch 3, Sample 14034: Loss: 0.5003\n",
            "Epoch 3, Sample 14035: Loss: 0.0915\n",
            "Epoch 3, Sample 14036: Loss: 1.0070\n",
            "Epoch 3, Sample 14037: Loss: 0.8951\n",
            "Epoch 3, Sample 14038: Loss: 0.4382\n",
            "Epoch 3, Sample 14039: Loss: 0.1246\n",
            "Epoch 3, Sample 14040: Loss: 0.2494\n",
            "Epoch 3, Sample 14041: Loss: 2.0944\n",
            "Epoch 3, Sample 14042: Loss: 0.4494\n",
            "Epoch 3, Sample 14043: Loss: 0.1559\n",
            "Epoch 3, Sample 14044: Loss: 0.2551\n",
            "Epoch 3, Sample 14045: Loss: 0.1250\n",
            "Epoch 3, Sample 14046: Loss: 1.4905\n",
            "Epoch 3, Sample 14047: Loss: 0.6990\n",
            "Epoch 3, Sample 14048: Loss: 0.3598\n",
            "Epoch 3, Sample 14049: Loss: 0.2044\n",
            "Epoch 3, Sample 14050: Loss: 0.0062\n",
            "Epoch 3, Sample 14051: Loss: 0.4841\n",
            "Epoch 3, Sample 14052: Loss: 0.3288\n",
            "Epoch 3, Sample 14053: Loss: 0.9367\n",
            "Epoch 3, Sample 14054: Loss: 0.1989\n",
            "Epoch 3, Sample 14055: Loss: 0.2036\n",
            "Epoch 3, Sample 14056: Loss: 1.0524\n",
            "Epoch 3, Sample 14057: Loss: 0.2036\n",
            "Epoch 3, Sample 14058: Loss: 1.0524\n",
            "Epoch 3, Sample 14059: Loss: 0.3351\n",
            "Epoch 3, Sample 14060: Loss: 0.2044\n",
            "Epoch 3, Sample 14061: Loss: 0.4611\n",
            "Epoch 3, Sample 14062: Loss: 0.3539\n",
            "Epoch 3, Sample 14063: Loss: 1.0530\n",
            "Epoch 3, Sample 14064: Loss: 0.0176\n",
            "Epoch 3, Sample 14065: Loss: 0.0018\n",
            "Epoch 3, Sample 14066: Loss: 0.1170\n",
            "Epoch 3, Sample 14067: Loss: 0.0915\n",
            "Epoch 3, Sample 14068: Loss: 0.2219\n",
            "Epoch 3, Sample 14069: Loss: 0.0063\n",
            "Epoch 3, Sample 14070: Loss: 0.0630\n",
            "Epoch 3, Sample 14071: Loss: 0.2271\n",
            "Epoch 3, Sample 14072: Loss: 0.7036\n",
            "Epoch 3, Sample 14073: Loss: 0.1412\n",
            "Epoch 3, Sample 14074: Loss: 0.0625\n",
            "Epoch 3, Sample 14075: Loss: 0.8951\n",
            "Epoch 3, Sample 14076: Loss: 0.8951\n",
            "Epoch 3, Sample 14077: Loss: 0.6092\n",
            "Epoch 3, Sample 14078: Loss: 1.6408\n",
            "Epoch 3, Sample 14079: Loss: 0.9064\n",
            "Epoch 3, Sample 14080: Loss: 0.3266\n",
            "Epoch 3, Sample 14081: Loss: 0.0008\n",
            "Epoch 3, Sample 14082: Loss: 2.2768\n",
            "Epoch 3, Sample 14083: Loss: 0.2750\n",
            "Epoch 3, Sample 14084: Loss: 0.0915\n",
            "Epoch 3, Sample 14085: Loss: 0.8719\n",
            "Epoch 3, Sample 14086: Loss: 4.2325\n",
            "Epoch 3, Sample 14087: Loss: 0.3399\n",
            "Epoch 3, Sample 14088: Loss: 0.0168\n",
            "Epoch 3, Sample 14089: Loss: 0.3441\n",
            "Epoch 3, Sample 14090: Loss: 0.2044\n",
            "Epoch 3, Sample 14091: Loss: 0.1225\n",
            "Epoch 3, Sample 14092: Loss: 0.0915\n",
            "Epoch 3, Sample 14093: Loss: 0.0000\n",
            "Epoch 3, Sample 14094: Loss: 2.9557\n",
            "Epoch 3, Sample 14095: Loss: 0.3402\n",
            "Epoch 3, Sample 14096: Loss: 1.0530\n",
            "Epoch 3, Sample 14097: Loss: 0.1170\n",
            "Epoch 3, Sample 14098: Loss: 0.1091\n",
            "Epoch 3, Sample 14099: Loss: 0.4316\n",
            "Epoch 3, Sample 14100: Loss: 0.2034\n",
            "Epoch 3, Sample 14101: Loss: 0.2044\n",
            "Epoch 3, Sample 14102: Loss: 1.0524\n",
            "Epoch 3, Sample 14103: Loss: 0.3399\n",
            "Epoch 3, Sample 14104: Loss: 2.5287\n",
            "Epoch 3, Sample 14105: Loss: 0.7036\n",
            "Epoch 3, Sample 14106: Loss: 1.0524\n",
            "Epoch 3, Sample 14107: Loss: 0.2759\n",
            "Epoch 3, Sample 14108: Loss: 0.8951\n",
            "Epoch 3, Sample 14109: Loss: 0.1092\n",
            "Epoch 3, Sample 14110: Loss: 1.6977\n",
            "Epoch 3, Sample 14111: Loss: 0.2219\n",
            "Epoch 3, Sample 14112: Loss: 0.2846\n",
            "Epoch 3, Sample 14113: Loss: 0.1248\n",
            "Epoch 3, Sample 14114: Loss: 0.3949\n",
            "Epoch 3, Sample 14115: Loss: 0.4902\n",
            "Epoch 3, Sample 14116: Loss: 0.1364\n",
            "Epoch 3, Sample 14117: Loss: 0.0229\n",
            "Epoch 3, Sample 14118: Loss: 7.2306\n",
            "Epoch 3, Sample 14119: Loss: 0.0016\n",
            "Epoch 3, Sample 14120: Loss: 0.3399\n",
            "Epoch 3, Sample 14121: Loss: 1.0511\n",
            "Epoch 3, Sample 14122: Loss: 0.0021\n",
            "Epoch 3, Sample 14123: Loss: 0.3402\n",
            "Epoch 3, Sample 14124: Loss: 0.3967\n",
            "Epoch 3, Sample 14125: Loss: 0.2832\n",
            "Epoch 3, Sample 14126: Loss: 0.4456\n",
            "Epoch 3, Sample 14127: Loss: 0.3441\n",
            "Epoch 3, Sample 14128: Loss: 0.2044\n",
            "Epoch 3, Sample 14129: Loss: 0.2938\n",
            "Epoch 3, Sample 14130: Loss: 0.0303\n",
            "Epoch 3, Sample 14131: Loss: 1.1789\n",
            "Epoch 3, Sample 14132: Loss: 0.0002\n",
            "Epoch 3, Sample 14133: Loss: 0.1248\n",
            "Epoch 3, Sample 14134: Loss: 0.0363\n",
            "Epoch 3, Sample 14135: Loss: 0.5972\n",
            "Epoch 3, Sample 14136: Loss: 0.0915\n",
            "Epoch 3, Sample 14137: Loss: 0.0139\n",
            "Epoch 3, Sample 14138: Loss: 0.3399\n",
            "Epoch 3, Sample 14139: Loss: 1.0530\n",
            "Epoch 3, Sample 14140: Loss: 0.4841\n",
            "Epoch 3, Sample 14141: Loss: 0.6379\n",
            "Epoch 3, Sample 14142: Loss: 0.1250\n",
            "Epoch 3, Sample 14143: Loss: 0.3247\n",
            "Epoch 3, Sample 14144: Loss: 1.6575\n",
            "Epoch 3, Sample 14145: Loss: 0.3949\n",
            "Epoch 3, Sample 14146: Loss: 0.5858\n",
            "Epoch 3, Sample 14147: Loss: 0.2759\n",
            "Epoch 3, Sample 14148: Loss: 0.4032\n",
            "Epoch 3, Sample 14149: Loss: 0.3399\n",
            "Epoch 3, Sample 14150: Loss: 0.6092\n",
            "Epoch 3, Sample 14151: Loss: 0.1250\n",
            "Epoch 3, Sample 14152: Loss: 0.0144\n",
            "Epoch 3, Sample 14153: Loss: 0.1773\n",
            "Epoch 3, Sample 14154: Loss: 0.4930\n",
            "Epoch 3, Sample 14155: Loss: 0.1404\n",
            "Epoch 3, Sample 14156: Loss: 0.0306\n",
            "Epoch 3, Sample 14157: Loss: 0.0108\n",
            "Epoch 3, Sample 14158: Loss: 1.7304\n",
            "Epoch 3, Sample 14159: Loss: 0.0026\n",
            "Epoch 3, Sample 14160: Loss: 0.2687\n",
            "Epoch 3, Sample 14161: Loss: 0.4799\n",
            "Epoch 3, Sample 14162: Loss: 0.0064\n",
            "Epoch 3, Sample 14163: Loss: 0.0558\n",
            "Epoch 3, Sample 14164: Loss: 0.2044\n",
            "Epoch 3, Sample 14165: Loss: 0.1031\n",
            "Epoch 3, Sample 14166: Loss: 0.2032\n",
            "Epoch 3, Sample 14167: Loss: 0.0018\n",
            "Epoch 3, Sample 14168: Loss: 1.0524\n",
            "Epoch 3, Sample 14169: Loss: 0.0103\n",
            "Epoch 3, Sample 14170: Loss: 0.5375\n",
            "Epoch 3, Sample 14171: Loss: 0.0001\n",
            "Epoch 3, Sample 14172: Loss: 1.9442\n",
            "Epoch 3, Sample 14173: Loss: 0.4799\n",
            "Epoch 3, Sample 14174: Loss: 2.1953\n",
            "Epoch 3, Sample 14175: Loss: 0.0978\n",
            "Epoch 3, Sample 14176: Loss: 0.4032\n",
            "Epoch 3, Sample 14177: Loss: 0.2832\n",
            "Epoch 3, Sample 14178: Loss: 0.2044\n",
            "Epoch 3, Sample 14179: Loss: 0.2034\n",
            "Epoch 3, Sample 14180: Loss: 0.2290\n",
            "Epoch 3, Sample 14181: Loss: 0.5858\n",
            "Epoch 3, Sample 14182: Loss: 0.5972\n",
            "Epoch 3, Sample 14183: Loss: 0.0088\n",
            "Epoch 3, Sample 14184: Loss: 0.3441\n",
            "Epoch 3, Sample 14185: Loss: 0.1372\n",
            "Epoch 3, Sample 14186: Loss: 0.2832\n",
            "Epoch 3, Sample 14187: Loss: 0.0829\n",
            "Epoch 3, Sample 14188: Loss: 0.1559\n",
            "Epoch 3, Sample 14189: Loss: 0.2699\n",
            "Epoch 3, Sample 14190: Loss: 0.3450\n",
            "Epoch 3, Sample 14191: Loss: 0.0255\n",
            "Epoch 3, Sample 14192: Loss: 0.0026\n",
            "Epoch 3, Sample 14193: Loss: 0.3584\n",
            "Epoch 3, Sample 14194: Loss: 0.1170\n",
            "Epoch 3, Sample 14195: Loss: 0.6092\n",
            "Epoch 3, Sample 14196: Loss: 0.6139\n",
            "Epoch 3, Sample 14197: Loss: 1.0524\n",
            "Epoch 3, Sample 14198: Loss: 0.1215\n",
            "Epoch 3, Sample 14199: Loss: 0.0808\n",
            "Epoch 3, Sample 14200: Loss: 0.0168\n",
            "Epoch 3, Sample 14201: Loss: 0.0590\n",
            "Epoch 3, Sample 14202: Loss: 0.0026\n",
            "Epoch 3, Sample 14203: Loss: 0.2044\n",
            "Epoch 3, Sample 14204: Loss: 0.7036\n",
            "Epoch 3, Sample 14205: Loss: 0.2044\n",
            "Epoch 3, Sample 14206: Loss: 0.1113\n",
            "Epoch 3, Sample 14207: Loss: 0.0025\n",
            "Epoch 3, Sample 14208: Loss: 1.0524\n",
            "Epoch 3, Sample 14209: Loss: 0.0834\n",
            "Epoch 3, Sample 14210: Loss: 0.6666\n",
            "Epoch 3, Sample 14211: Loss: 0.4474\n",
            "Epoch 3, Sample 14212: Loss: 1.0524\n",
            "Epoch 3, Sample 14213: Loss: 0.3949\n",
            "Epoch 3, Sample 14214: Loss: 0.4611\n",
            "Epoch 3, Sample 14215: Loss: 0.8630\n",
            "Epoch 3, Sample 14216: Loss: 1.0524\n",
            "Epoch 3, Sample 14217: Loss: 0.0306\n",
            "Epoch 3, Sample 14218: Loss: 1.4187\n",
            "Epoch 3, Sample 14219: Loss: 0.2034\n",
            "Epoch 3, Sample 14220: Loss: 0.0026\n",
            "Epoch 3, Sample 14221: Loss: 0.0026\n",
            "Epoch 3, Sample 14222: Loss: 0.3057\n",
            "Epoch 3, Sample 14223: Loss: 0.1649\n",
            "Epoch 3, Sample 14224: Loss: 0.2053\n",
            "Epoch 3, Sample 14225: Loss: 0.3949\n",
            "Epoch 3, Sample 14226: Loss: 0.2639\n",
            "Epoch 3, Sample 14227: Loss: 0.2879\n",
            "Epoch 3, Sample 14228: Loss: 0.4663\n",
            "Epoch 3, Sample 14229: Loss: 0.2340\n",
            "Epoch 3, Sample 14230: Loss: 1.0530\n",
            "Epoch 3, Sample 14231: Loss: 0.0915\n",
            "Epoch 3, Sample 14232: Loss: 0.4799\n",
            "Epoch 3, Sample 14233: Loss: 1.0524\n",
            "Epoch 3, Sample 14234: Loss: 0.3399\n",
            "Epoch 3, Sample 14235: Loss: 0.2044\n",
            "Epoch 3, Sample 14236: Loss: 0.8951\n",
            "Epoch 3, Sample 14237: Loss: 0.3399\n",
            "Epoch 3, Sample 14238: Loss: 0.0921\n",
            "Epoch 3, Sample 14239: Loss: 0.1941\n",
            "Epoch 3, Sample 14240: Loss: 0.3313\n",
            "Epoch 3, Sample 14241: Loss: 0.0838\n",
            "Epoch 3, Sample 14242: Loss: 0.0604\n",
            "Epoch 3, Sample 14243: Loss: 0.0604\n",
            "Epoch 3, Sample 14244: Loss: 0.8620\n",
            "Epoch 3, Sample 14245: Loss: 0.2112\n",
            "Epoch 3, Sample 14246: Loss: 0.0026\n",
            "Epoch 3, Sample 14247: Loss: 0.2034\n",
            "Epoch 3, Sample 14248: Loss: 0.4611\n",
            "Epoch 3, Sample 14249: Loss: 0.0318\n",
            "Epoch 3, Sample 14250: Loss: 0.0915\n",
            "Epoch 3, Sample 14251: Loss: 0.0123\n",
            "Epoch 3, Sample 14252: Loss: 0.4930\n",
            "Epoch 3, Sample 14253: Loss: 0.0000\n",
            "Epoch 3, Sample 14254: Loss: 0.2579\n",
            "Epoch 3, Sample 14255: Loss: 0.2759\n",
            "Epoch 3, Sample 14256: Loss: 0.0026\n",
            "Epoch 3, Sample 14257: Loss: 0.3568\n",
            "Epoch 3, Sample 14258: Loss: 0.1062\n",
            "Epoch 3, Sample 14259: Loss: 0.0586\n",
            "Epoch 3, Sample 14260: Loss: 0.0018\n",
            "Epoch 3, Sample 14261: Loss: 0.6990\n",
            "Epoch 3, Sample 14262: Loss: 1.0266\n",
            "Epoch 3, Sample 14263: Loss: 0.1881\n",
            "Epoch 3, Sample 14264: Loss: 0.4382\n",
            "Epoch 3, Sample 14265: Loss: 0.7973\n",
            "Epoch 3, Sample 14266: Loss: 0.1559\n",
            "Epoch 3, Sample 14267: Loss: 0.3245\n",
            "Epoch 3, Sample 14268: Loss: 12.0464\n",
            "Epoch 3, Sample 14269: Loss: 0.0018\n",
            "Epoch 3, Sample 14270: Loss: 1.4588\n",
            "Epoch 3, Sample 14271: Loss: 0.3399\n",
            "Epoch 3, Sample 14272: Loss: 0.2639\n",
            "Epoch 3, Sample 14273: Loss: 0.0076\n",
            "Epoch 3, Sample 14274: Loss: 0.1377\n",
            "Epoch 3, Sample 14275: Loss: 0.0084\n",
            "Epoch 3, Sample 14276: Loss: 0.0028\n",
            "Epoch 3, Sample 14277: Loss: 0.0001\n",
            "Epoch 3, Sample 14278: Loss: 0.0303\n",
            "Epoch 3, Sample 14279: Loss: 0.0114\n",
            "Epoch 3, Sample 14280: Loss: 0.6990\n",
            "Epoch 3, Sample 14281: Loss: 0.5799\n",
            "Epoch 3, Sample 14282: Loss: 0.0002\n",
            "Epoch 3, Sample 14283: Loss: 0.9771\n",
            "Epoch 3, Sample 14284: Loss: 0.0938\n",
            "Epoch 3, Sample 14285: Loss: 0.5003\n",
            "Epoch 3, Sample 14286: Loss: 0.2032\n",
            "Epoch 3, Sample 14287: Loss: 0.0653\n",
            "Epoch 3, Sample 14288: Loss: 0.7453\n",
            "Epoch 3, Sample 14289: Loss: 0.2182\n",
            "Epoch 3, Sample 14290: Loss: 0.2132\n",
            "Epoch 3, Sample 14291: Loss: 0.0026\n",
            "Epoch 3, Sample 14292: Loss: 1.0530\n",
            "Epoch 3, Sample 14293: Loss: 0.0001\n",
            "Epoch 3, Sample 14294: Loss: 0.2034\n",
            "Epoch 3, Sample 14295: Loss: 0.0015\n",
            "Epoch 3, Sample 14296: Loss: 0.4799\n",
            "Epoch 3, Sample 14297: Loss: 0.2044\n",
            "Epoch 3, Sample 14298: Loss: 0.0063\n",
            "Epoch 3, Sample 14299: Loss: 0.0018\n",
            "Epoch 3, Sample 14300: Loss: 0.1170\n",
            "Epoch 3, Sample 14301: Loss: 1.0524\n",
            "Epoch 3, Sample 14302: Loss: 0.5858\n",
            "Epoch 3, Sample 14303: Loss: 1.0524\n",
            "Epoch 3, Sample 14304: Loss: 0.3402\n",
            "Epoch 3, Sample 14305: Loss: 0.3230\n",
            "Epoch 3, Sample 14306: Loss: 1.0524\n",
            "Epoch 3, Sample 14307: Loss: 0.1250\n",
            "Epoch 3, Sample 14308: Loss: 0.5871\n",
            "Epoch 3, Sample 14309: Loss: 0.0469\n",
            "Epoch 3, Sample 14310: Loss: 0.0415\n",
            "Epoch 3, Sample 14311: Loss: 0.3399\n",
            "Epoch 3, Sample 14312: Loss: 0.7036\n",
            "Epoch 3, Sample 14313: Loss: 0.2098\n",
            "Epoch 3, Sample 14314: Loss: 0.8951\n",
            "Epoch 3, Sample 14315: Loss: 0.3995\n",
            "Epoch 3, Sample 14316: Loss: 0.3399\n",
            "Epoch 3, Sample 14317: Loss: 0.4930\n",
            "Epoch 3, Sample 14318: Loss: 0.7036\n",
            "Epoch 3, Sample 14319: Loss: 0.2034\n",
            "Epoch 3, Sample 14320: Loss: 0.0640\n",
            "Epoch 3, Sample 14321: Loss: 0.6304\n",
            "Epoch 3, Sample 14322: Loss: 0.0838\n",
            "Epoch 3, Sample 14323: Loss: 0.0039\n",
            "Epoch 3, Sample 14324: Loss: 0.5858\n",
            "Epoch 3, Sample 14325: Loss: 0.2032\n",
            "Epoch 3, Sample 14326: Loss: 0.1250\n",
            "Epoch 3, Sample 14327: Loss: 0.2639\n",
            "Epoch 3, Sample 14328: Loss: 0.2044\n",
            "Epoch 3, Sample 14329: Loss: 0.5972\n",
            "Epoch 3, Sample 14330: Loss: 0.0073\n",
            "Epoch 3, Sample 14331: Loss: 1.0530\n",
            "Epoch 3, Sample 14332: Loss: 0.0001\n",
            "Epoch 3, Sample 14333: Loss: 0.1250\n",
            "Epoch 3, Sample 14334: Loss: 1.0530\n",
            "Epoch 3, Sample 14335: Loss: 0.0001\n",
            "Epoch 3, Sample 14336: Loss: 0.0891\n",
            "Epoch 3, Sample 14337: Loss: 0.1131\n",
            "Epoch 3, Sample 14338: Loss: 0.2832\n",
            "Epoch 3, Sample 14339: Loss: 1.0524\n",
            "Epoch 3, Sample 14340: Loss: 0.3758\n",
            "Epoch 3, Sample 14341: Loss: 0.9837\n",
            "Epoch 3, Sample 14342: Loss: 0.6304\n",
            "Epoch 3, Sample 14343: Loss: 0.0101\n",
            "Epoch 3, Sample 14344: Loss: 0.0063\n",
            "Epoch 3, Sample 14345: Loss: 0.1399\n",
            "Epoch 3, Sample 14346: Loss: 0.0006\n",
            "Epoch 3, Sample 14347: Loss: 1.0530\n",
            "Epoch 3, Sample 14348: Loss: 0.2639\n",
            "Epoch 3, Sample 14349: Loss: 0.7897\n",
            "Epoch 3, Sample 14350: Loss: 0.0005\n",
            "Epoch 3, Sample 14351: Loss: 0.1508\n",
            "Epoch 3, Sample 14352: Loss: 0.6990\n",
            "Epoch 3, Sample 14353: Loss: 0.0666\n",
            "Epoch 3, Sample 14354: Loss: 4.4589\n",
            "Epoch 3, Sample 14355: Loss: 0.0838\n",
            "Epoch 3, Sample 14356: Loss: 0.4464\n",
            "Epoch 3, Sample 14357: Loss: 1.0524\n",
            "Epoch 3, Sample 14358: Loss: 0.0018\n",
            "Epoch 3, Sample 14359: Loss: 0.4474\n",
            "Epoch 3, Sample 14360: Loss: 0.7480\n",
            "Epoch 3, Sample 14361: Loss: 0.1388\n",
            "Epoch 3, Sample 14362: Loss: 0.7453\n",
            "Epoch 3, Sample 14363: Loss: 0.6304\n",
            "Epoch 3, Sample 14364: Loss: 0.0712\n",
            "Epoch 3, Sample 14365: Loss: 0.0744\n",
            "Epoch 3, Sample 14366: Loss: 0.4694\n",
            "Epoch 3, Sample 14367: Loss: 0.5003\n",
            "Epoch 3, Sample 14368: Loss: 0.2498\n",
            "Epoch 3, Sample 14369: Loss: 0.4466\n",
            "Epoch 3, Sample 14370: Loss: 0.2032\n",
            "Epoch 3, Sample 14371: Loss: 0.0026\n",
            "Epoch 3, Sample 14372: Loss: 0.2044\n",
            "Epoch 3, Sample 14373: Loss: 0.3059\n",
            "Epoch 3, Sample 14374: Loss: 0.5000\n",
            "Epoch 3, Sample 14375: Loss: 0.2759\n",
            "Epoch 3, Sample 14376: Loss: 0.8484\n",
            "Epoch 3, Sample 14377: Loss: 0.9525\n",
            "Epoch 3, Sample 14378: Loss: 0.7036\n",
            "Epoch 3, Sample 14379: Loss: 0.0060\n",
            "Epoch 3, Sample 14380: Loss: 1.0530\n",
            "Epoch 3, Sample 14381: Loss: 0.0630\n",
            "Epoch 3, Sample 14382: Loss: 0.0270\n",
            "Epoch 3, Sample 14383: Loss: 0.2044\n",
            "Epoch 3, Sample 14384: Loss: 0.8461\n",
            "Epoch 3, Sample 14385: Loss: 0.0363\n",
            "Epoch 3, Sample 14386: Loss: 1.0070\n",
            "Epoch 3, Sample 14387: Loss: 0.3332\n",
            "Epoch 3, Sample 14388: Loss: 0.4382\n",
            "Epoch 3, Sample 14389: Loss: 0.3805\n",
            "Epoch 3, Sample 14390: Loss: 0.7036\n",
            "Epoch 3, Sample 14391: Loss: 0.7297\n",
            "Epoch 3, Sample 14392: Loss: 0.1559\n",
            "Epoch 3, Sample 14393: Loss: 0.5061\n",
            "Epoch 3, Sample 14394: Loss: 0.5858\n",
            "Epoch 3, Sample 14395: Loss: 1.1503\n",
            "Epoch 3, Sample 14396: Loss: 0.0168\n",
            "Epoch 3, Sample 14397: Loss: 1.0530\n",
            "Epoch 3, Sample 14398: Loss: 1.0524\n",
            "Epoch 3, Sample 14399: Loss: 0.7961\n",
            "Epoch 3, Sample 14400: Loss: 0.0013\n",
            "Epoch 3, Sample 14401: Loss: 0.2302\n",
            "Epoch 3, Sample 14402: Loss: 0.0026\n",
            "Epoch 3, Sample 14403: Loss: 0.5078\n",
            "Epoch 3, Sample 14404: Loss: 1.9077\n",
            "Epoch 3, Sample 14405: Loss: 1.0524\n",
            "Epoch 3, Sample 14406: Loss: 1.6694\n",
            "Epoch 3, Sample 14407: Loss: 1.0524\n",
            "Epoch 3, Sample 14408: Loss: 0.3399\n",
            "Epoch 3, Sample 14409: Loss: 0.8587\n",
            "Epoch 3, Sample 14410: Loss: 0.0018\n",
            "Epoch 3, Sample 14411: Loss: 0.0026\n",
            "Epoch 3, Sample 14412: Loss: 0.0026\n",
            "Epoch 3, Sample 14413: Loss: 0.2032\n",
            "Epoch 3, Sample 14414: Loss: 0.3830\n",
            "Epoch 3, Sample 14415: Loss: 0.5310\n",
            "Epoch 3, Sample 14416: Loss: 0.3586\n",
            "Epoch 3, Sample 14417: Loss: 3.1130\n",
            "Epoch 3, Sample 14418: Loss: 0.2044\n",
            "Epoch 3, Sample 14419: Loss: 0.1394\n",
            "Epoch 3, Sample 14420: Loss: 0.0001\n",
            "Epoch 3, Sample 14421: Loss: 0.2747\n",
            "Epoch 3, Sample 14422: Loss: 0.2759\n",
            "Epoch 3, Sample 14423: Loss: 0.3332\n",
            "Epoch 3, Sample 14424: Loss: 0.1357\n",
            "Epoch 3, Sample 14425: Loss: 0.4799\n",
            "Epoch 3, Sample 14426: Loss: 0.4474\n",
            "Epoch 3, Sample 14427: Loss: 0.2968\n",
            "Epoch 3, Sample 14428: Loss: 0.4841\n",
            "Epoch 3, Sample 14429: Loss: 1.2845\n",
            "Epoch 3, Sample 14430: Loss: 1.9277\n",
            "Epoch 3, Sample 14431: Loss: 0.0556\n",
            "Epoch 3, Sample 14432: Loss: 0.0707\n",
            "Epoch 3, Sample 14433: Loss: 0.3558\n",
            "Epoch 3, Sample 14434: Loss: 0.0018\n",
            "Epoch 3, Sample 14435: Loss: 1.0530\n",
            "Epoch 3, Sample 14436: Loss: 0.1170\n",
            "Epoch 3, Sample 14437: Loss: 0.2832\n",
            "Epoch 3, Sample 14438: Loss: 0.2034\n",
            "Epoch 3, Sample 14439: Loss: 0.3441\n",
            "Epoch 3, Sample 14440: Loss: 0.0026\n",
            "Epoch 3, Sample 14441: Loss: 0.7453\n",
            "Epoch 3, Sample 14442: Loss: 0.2962\n",
            "Epoch 3, Sample 14443: Loss: 0.1523\n",
            "Epoch 3, Sample 14444: Loss: 0.6304\n",
            "Epoch 3, Sample 14445: Loss: 1.0155\n",
            "Epoch 3, Sample 14446: Loss: 0.6601\n",
            "Epoch 3, Sample 14447: Loss: 0.0026\n",
            "Epoch 3, Sample 14448: Loss: 0.2044\n",
            "Epoch 3, Sample 14449: Loss: 0.7036\n",
            "Epoch 3, Sample 14450: Loss: 0.1559\n",
            "Epoch 3, Sample 14451: Loss: 0.8659\n",
            "Epoch 3, Sample 14452: Loss: 0.1170\n",
            "Epoch 3, Sample 14453: Loss: 0.2032\n",
            "Epoch 3, Sample 14454: Loss: 1.0524\n",
            "Epoch 3, Sample 14455: Loss: 0.2639\n",
            "Epoch 3, Sample 14456: Loss: 0.1559\n",
            "Epoch 3, Sample 14457: Loss: 0.7036\n",
            "Epoch 3, Sample 14458: Loss: 0.2112\n",
            "Epoch 3, Sample 14459: Loss: 4.6422\n",
            "Epoch 3, Sample 14460: Loss: 0.2032\n",
            "Epoch 3, Sample 14461: Loss: 0.0854\n",
            "Epoch 3, Sample 14462: Loss: 1.2218\n",
            "Epoch 3, Sample 14463: Loss: 0.2032\n",
            "Epoch 3, Sample 14464: Loss: 1.0524\n",
            "Epoch 3, Sample 14465: Loss: 0.5701\n",
            "Epoch 3, Sample 14466: Loss: 0.5000\n",
            "Epoch 3, Sample 14467: Loss: 0.1465\n",
            "Epoch 3, Sample 14468: Loss: 0.0056\n",
            "Epoch 3, Sample 14469: Loss: 0.6043\n",
            "Epoch 3, Sample 14470: Loss: 0.2832\n",
            "Epoch 3, Sample 14471: Loss: 0.0707\n",
            "Epoch 3, Sample 14472: Loss: 0.2036\n",
            "Epoch 3, Sample 14473: Loss: 0.5000\n",
            "Epoch 3, Sample 14474: Loss: 0.0528\n",
            "Epoch 3, Sample 14475: Loss: 0.0472\n",
            "Epoch 3, Sample 14476: Loss: 0.0000\n",
            "Epoch 3, Sample 14477: Loss: 0.0554\n",
            "Epoch 3, Sample 14478: Loss: 0.7036\n",
            "Epoch 3, Sample 14479: Loss: 0.0919\n",
            "Epoch 3, Sample 14480: Loss: 0.2704\n",
            "Epoch 3, Sample 14481: Loss: 0.2459\n",
            "Epoch 3, Sample 14482: Loss: 0.0231\n",
            "Epoch 3, Sample 14483: Loss: 0.0766\n",
            "Epoch 3, Sample 14484: Loss: 1.0155\n",
            "Epoch 3, Sample 14485: Loss: 0.0062\n",
            "Epoch 3, Sample 14486: Loss: 0.4799\n",
            "Epoch 3, Sample 14487: Loss: 0.0745\n",
            "Epoch 3, Sample 14488: Loss: 0.0011\n",
            "Epoch 3, Sample 14489: Loss: 0.2014\n",
            "Epoch 3, Sample 14490: Loss: 3.1555\n",
            "Epoch 3, Sample 14491: Loss: 0.8696\n",
            "Epoch 3, Sample 14492: Loss: 0.4032\n",
            "Epoch 3, Sample 14493: Loss: 1.0524\n",
            "Epoch 3, Sample 14494: Loss: 0.0915\n",
            "Epoch 3, Sample 14495: Loss: 0.1785\n",
            "Epoch 3, Sample 14496: Loss: 0.2855\n",
            "Epoch 3, Sample 14497: Loss: 0.5003\n",
            "Epoch 3, Sample 14498: Loss: 0.5696\n",
            "Epoch 3, Sample 14499: Loss: 0.2034\n",
            "Epoch 3, Sample 14500: Loss: 0.1225\n",
            "Epoch 3, Sample 14501: Loss: 0.4799\n",
            "Epoch 3, Sample 14502: Loss: 0.3399\n",
            "Epoch 3, Sample 14503: Loss: 0.0067\n",
            "Epoch 3, Sample 14504: Loss: 2.5107\n",
            "Epoch 3, Sample 14505: Loss: 2.2046\n",
            "Epoch 3, Sample 14506: Loss: 0.2034\n",
            "Epoch 3, Sample 14507: Loss: 1.1337\n",
            "Epoch 3, Sample 14508: Loss: 0.2832\n",
            "Epoch 3, Sample 14509: Loss: 0.5649\n",
            "Epoch 3, Sample 14510: Loss: 0.0001\n",
            "Epoch 3, Sample 14511: Loss: 0.0054\n",
            "Epoch 3, Sample 14512: Loss: 0.5858\n",
            "Epoch 3, Sample 14513: Loss: 0.7036\n",
            "Epoch 3, Sample 14514: Loss: 0.2036\n",
            "Epoch 3, Sample 14515: Loss: 0.3124\n",
            "Epoch 3, Sample 14516: Loss: 0.4799\n",
            "Epoch 3, Sample 14517: Loss: 0.0429\n",
            "Epoch 3, Sample 14518: Loss: 0.1170\n",
            "Epoch 3, Sample 14519: Loss: 0.0000\n",
            "Epoch 3, Sample 14520: Loss: 0.0625\n",
            "Epoch 3, Sample 14521: Loss: 0.8951\n",
            "Epoch 3, Sample 14522: Loss: 0.3506\n",
            "Epoch 3, Sample 14523: Loss: 0.4611\n",
            "Epoch 3, Sample 14524: Loss: 1.0524\n",
            "Epoch 3, Sample 14525: Loss: 0.2639\n",
            "Epoch 3, Sample 14526: Loss: 0.2759\n",
            "Epoch 3, Sample 14527: Loss: 0.7036\n",
            "Epoch 3, Sample 14528: Loss: 0.0759\n",
            "Epoch 3, Sample 14529: Loss: 0.0030\n",
            "Epoch 3, Sample 14530: Loss: 0.4611\n",
            "Epoch 3, Sample 14531: Loss: 0.0258\n",
            "Epoch 3, Sample 14532: Loss: 0.0618\n",
            "Epoch 3, Sample 14533: Loss: 0.3399\n",
            "Epoch 3, Sample 14534: Loss: 0.7036\n",
            "Epoch 3, Sample 14535: Loss: 0.0018\n",
            "Epoch 3, Sample 14536: Loss: 0.0258\n",
            "Epoch 3, Sample 14537: Loss: 1.0530\n",
            "Epoch 3, Sample 14538: Loss: 0.5000\n",
            "Epoch 3, Sample 14539: Loss: 0.0608\n",
            "Epoch 3, Sample 14540: Loss: 0.2044\n",
            "Epoch 3, Sample 14541: Loss: 0.2032\n",
            "Epoch 3, Sample 14542: Loss: 0.3441\n",
            "Epoch 3, Sample 14543: Loss: 1.0524\n",
            "Epoch 3, Sample 14544: Loss: 0.3399\n",
            "Epoch 3, Sample 14545: Loss: 0.2036\n",
            "Epoch 3, Sample 14546: Loss: 0.0018\n",
            "Epoch 3, Sample 14547: Loss: 0.2158\n",
            "Epoch 3, Sample 14548: Loss: 0.3441\n",
            "Epoch 3, Sample 14549: Loss: 0.0616\n",
            "Epoch 3, Sample 14550: Loss: 0.0415\n",
            "Epoch 3, Sample 14551: Loss: 0.1170\n",
            "Epoch 3, Sample 14552: Loss: 0.3598\n",
            "Epoch 3, Sample 14553: Loss: 0.2715\n",
            "Epoch 3, Sample 14554: Loss: 0.2494\n",
            "Epoch 3, Sample 14555: Loss: 0.1250\n",
            "Epoch 3, Sample 14556: Loss: 0.0915\n",
            "Epoch 3, Sample 14557: Loss: 0.0630\n",
            "Epoch 3, Sample 14558: Loss: 0.3758\n",
            "Epoch 3, Sample 14559: Loss: 0.4841\n",
            "Epoch 3, Sample 14560: Loss: 0.0145\n",
            "Epoch 3, Sample 14561: Loss: 0.1989\n",
            "Epoch 3, Sample 14562: Loss: 0.2036\n",
            "Epoch 3, Sample 14563: Loss: 1.0524\n",
            "Epoch 3, Sample 14564: Loss: 0.0018\n",
            "Epoch 3, Sample 14565: Loss: 1.0524\n",
            "Epoch 3, Sample 14566: Loss: 0.3568\n",
            "Epoch 3, Sample 14567: Loss: 1.0530\n",
            "Epoch 3, Sample 14568: Loss: 0.7036\n",
            "Epoch 3, Sample 14569: Loss: 0.0001\n",
            "Epoch 3, Sample 14570: Loss: 1.4529\n",
            "Epoch 3, Sample 14571: Loss: 0.2044\n",
            "Epoch 3, Sample 14572: Loss: 0.2044\n",
            "Epoch 3, Sample 14573: Loss: 0.2044\n",
            "Epoch 3, Sample 14574: Loss: 1.0524\n",
            "Epoch 3, Sample 14575: Loss: 0.0067\n",
            "Epoch 3, Sample 14576: Loss: 0.0667\n",
            "Epoch 3, Sample 14577: Loss: 0.0631\n",
            "Epoch 3, Sample 14578: Loss: 0.7036\n",
            "Epoch 3, Sample 14579: Loss: 0.1248\n",
            "Epoch 3, Sample 14580: Loss: 0.0036\n",
            "Epoch 3, Sample 14581: Loss: 0.0025\n",
            "Epoch 3, Sample 14582: Loss: 0.3949\n",
            "Epoch 3, Sample 14583: Loss: 0.0026\n",
            "Epoch 3, Sample 14584: Loss: 0.2112\n",
            "Epoch 3, Sample 14585: Loss: 0.2044\n",
            "Epoch 3, Sample 14586: Loss: 1.0524\n",
            "Epoch 3, Sample 14587: Loss: 1.3509\n",
            "Epoch 3, Sample 14588: Loss: 0.0212\n",
            "Epoch 3, Sample 14589: Loss: 16.6347\n",
            "Epoch 3, Sample 14590: Loss: 0.0759\n",
            "Epoch 3, Sample 14591: Loss: 0.0258\n",
            "Epoch 3, Sample 14592: Loss: 0.1523\n",
            "Epoch 3, Sample 14593: Loss: 0.8944\n",
            "Epoch 3, Sample 14594: Loss: 0.7036\n",
            "Epoch 3, Sample 14595: Loss: 0.0145\n",
            "Epoch 3, Sample 14596: Loss: 0.1250\n",
            "Epoch 3, Sample 14597: Loss: 0.5373\n",
            "Epoch 3, Sample 14598: Loss: 0.0630\n",
            "Epoch 3, Sample 14599: Loss: 0.2664\n",
            "Epoch 3, Sample 14600: Loss: 0.2339\n",
            "Epoch 3, Sample 14601: Loss: 0.0625\n",
            "Epoch 3, Sample 14602: Loss: 0.3399\n",
            "Epoch 3, Sample 14603: Loss: 4.4385\n",
            "Epoch 3, Sample 14604: Loss: 0.4492\n",
            "Epoch 3, Sample 14605: Loss: 0.2098\n",
            "Epoch 3, Sample 14606: Loss: 0.0820\n",
            "Epoch 3, Sample 14607: Loss: 0.0001\n",
            "Epoch 3, Sample 14608: Loss: 0.1419\n",
            "Epoch 3, Sample 14609: Loss: 0.4930\n",
            "Epoch 3, Sample 14610: Loss: 0.1492\n",
            "Epoch 3, Sample 14611: Loss: 0.1248\n",
            "Epoch 3, Sample 14612: Loss: 0.3036\n",
            "Epoch 3, Sample 14613: Loss: 0.0630\n",
            "Epoch 3, Sample 14614: Loss: 0.0027\n",
            "Epoch 3, Sample 14615: Loss: 0.2034\n",
            "Epoch 3, Sample 14616: Loss: 0.0219\n",
            "Epoch 3, Sample 14617: Loss: 0.0630\n",
            "Epoch 3, Sample 14618: Loss: 0.0018\n",
            "Epoch 3, Sample 14619: Loss: 0.0205\n",
            "Epoch 3, Sample 14620: Loss: 0.2759\n",
            "Epoch 3, Sample 14621: Loss: 0.3441\n",
            "Epoch 3, Sample 14622: Loss: 1.0227\n",
            "Epoch 3, Sample 14623: Loss: 0.2036\n",
            "Epoch 3, Sample 14624: Loss: 0.2032\n",
            "Epoch 3, Sample 14625: Loss: 0.4930\n",
            "Epoch 3, Sample 14626: Loss: 1.0524\n",
            "Epoch 3, Sample 14627: Loss: 0.2032\n",
            "Epoch 3, Sample 14628: Loss: 0.7036\n",
            "Epoch 3, Sample 14629: Loss: 0.1337\n",
            "Epoch 3, Sample 14630: Loss: 0.0265\n",
            "Epoch 3, Sample 14631: Loss: 0.0026\n",
            "Epoch 3, Sample 14632: Loss: 1.5204\n",
            "Epoch 3, Sample 14633: Loss: 0.2034\n",
            "Epoch 3, Sample 14634: Loss: 0.6990\n",
            "Epoch 3, Sample 14635: Loss: 0.1248\n",
            "Epoch 3, Sample 14636: Loss: 0.3399\n",
            "Epoch 3, Sample 14637: Loss: 0.5201\n",
            "Epoch 3, Sample 14638: Loss: 0.0630\n",
            "Epoch 3, Sample 14639: Loss: 0.2268\n",
            "Epoch 3, Sample 14640: Loss: 0.0915\n",
            "Epoch 3, Sample 14641: Loss: 1.0215\n",
            "Epoch 3, Sample 14642: Loss: 0.1559\n",
            "Epoch 3, Sample 14643: Loss: 0.6554\n",
            "Epoch 3, Sample 14644: Loss: 0.0026\n",
            "Epoch 3, Sample 14645: Loss: 0.2340\n",
            "Epoch 3, Sample 14646: Loss: 4.1010\n",
            "Epoch 3, Sample 14647: Loss: 0.4032\n",
            "Epoch 3, Sample 14648: Loss: 0.2032\n",
            "Epoch 3, Sample 14649: Loss: 1.1569\n",
            "Epoch 3, Sample 14650: Loss: 0.0013\n",
            "Epoch 3, Sample 14651: Loss: 0.0018\n",
            "Epoch 3, Sample 14652: Loss: 0.3987\n",
            "Epoch 3, Sample 14653: Loss: 1.0155\n",
            "Epoch 3, Sample 14654: Loss: 0.0819\n",
            "Epoch 3, Sample 14655: Loss: 0.7036\n",
            "Epoch 3, Sample 14656: Loss: 0.1092\n",
            "Epoch 3, Sample 14657: Loss: 0.2034\n",
            "Epoch 3, Sample 14658: Loss: 0.1817\n",
            "Epoch 3, Sample 14659: Loss: 0.8484\n",
            "Epoch 3, Sample 14660: Loss: 0.2032\n",
            "Epoch 3, Sample 14661: Loss: 0.2044\n",
            "Epoch 3, Sample 14662: Loss: 0.6841\n",
            "Epoch 3, Sample 14663: Loss: 0.7414\n",
            "Epoch 3, Sample 14664: Loss: 0.4827\n",
            "Epoch 3, Sample 14665: Loss: 0.0934\n",
            "Epoch 3, Sample 14666: Loss: 0.1588\n",
            "Epoch 3, Sample 14667: Loss: 0.2044\n",
            "Epoch 3, Sample 14668: Loss: 0.7036\n",
            "Epoch 3, Sample 14669: Loss: 0.0685\n",
            "Epoch 3, Sample 14670: Loss: 0.4996\n",
            "Epoch 3, Sample 14671: Loss: 0.0026\n",
            "Epoch 3, Sample 14672: Loss: 0.8951\n",
            "Epoch 3, Sample 14673: Loss: 0.1250\n",
            "Epoch 3, Sample 14674: Loss: 0.0703\n",
            "Epoch 3, Sample 14675: Loss: 0.2112\n",
            "Epoch 3, Sample 14676: Loss: 0.0072\n",
            "Epoch 3, Sample 14677: Loss: 0.2639\n",
            "Epoch 3, Sample 14678: Loss: 0.1555\n",
            "Epoch 3, Sample 14679: Loss: 0.0838\n",
            "Epoch 3, Sample 14680: Loss: 0.0938\n",
            "Epoch 3, Sample 14681: Loss: 0.3399\n",
            "Epoch 3, Sample 14682: Loss: 1.0524\n",
            "Epoch 3, Sample 14683: Loss: 1.4773\n",
            "Epoch 3, Sample 14684: Loss: 0.0947\n",
            "Epoch 3, Sample 14685: Loss: 0.1588\n",
            "Epoch 3, Sample 14686: Loss: 0.0108\n",
            "Epoch 3, Sample 14687: Loss: 0.2494\n",
            "Epoch 3, Sample 14688: Loss: 0.1559\n",
            "Epoch 3, Sample 14689: Loss: 0.0001\n",
            "Epoch 3, Sample 14690: Loss: 2.7331\n",
            "Epoch 3, Sample 14691: Loss: 0.0630\n",
            "Epoch 3, Sample 14692: Loss: 0.6059\n",
            "Epoch 3, Sample 14693: Loss: 1.0155\n",
            "Epoch 3, Sample 14694: Loss: 0.5871\n",
            "Epoch 3, Sample 14695: Loss: 0.5000\n",
            "Epoch 3, Sample 14696: Loss: 0.0018\n",
            "Epoch 3, Sample 14697: Loss: 0.1084\n",
            "Epoch 3, Sample 14698: Loss: 0.0630\n",
            "Epoch 3, Sample 14699: Loss: 0.2044\n",
            "Epoch 3, Sample 14700: Loss: 0.0350\n",
            "Epoch 3, Sample 14701: Loss: 1.0826\n",
            "Epoch 3, Sample 14702: Loss: 0.2639\n",
            "Epoch 3, Sample 14703: Loss: 0.1170\n",
            "Epoch 3, Sample 14704: Loss: 0.1250\n",
            "Epoch 3, Sample 14705: Loss: 0.7036\n",
            "Epoch 3, Sample 14706: Loss: 2.6787\n",
            "Epoch 3, Sample 14707: Loss: 1.0524\n",
            "Epoch 3, Sample 14708: Loss: 0.1250\n",
            "Epoch 3, Sample 14709: Loss: 0.0536\n",
            "Epoch 3, Sample 14710: Loss: 1.0227\n",
            "Epoch 3, Sample 14711: Loss: 1.0524\n",
            "Epoch 3, Sample 14712: Loss: 0.2704\n",
            "Epoch 3, Sample 14713: Loss: 0.1337\n",
            "Epoch 3, Sample 14714: Loss: 0.0731\n",
            "Epoch 3, Sample 14715: Loss: 0.2044\n",
            "Epoch 3, Sample 14716: Loss: 0.0056\n",
            "Epoch 3, Sample 14717: Loss: 0.4930\n",
            "Epoch 3, Sample 14718: Loss: 0.7326\n",
            "Epoch 3, Sample 14719: Loss: 0.0022\n",
            "Epoch 3, Sample 14720: Loss: 0.0630\n",
            "Epoch 3, Sample 14721: Loss: 0.2851\n",
            "Epoch 3, Sample 14722: Loss: 0.2044\n",
            "Epoch 3, Sample 14723: Loss: 0.0000\n",
            "Epoch 3, Sample 14724: Loss: 0.1252\n",
            "Epoch 3, Sample 14725: Loss: 0.7036\n",
            "Epoch 3, Sample 14726: Loss: 0.6092\n",
            "Epoch 3, Sample 14727: Loss: 0.2759\n",
            "Epoch 3, Sample 14728: Loss: 1.0524\n",
            "Epoch 3, Sample 14729: Loss: 0.4151\n",
            "Epoch 3, Sample 14730: Loss: 0.1863\n",
            "Epoch 3, Sample 14731: Loss: 0.2638\n",
            "Epoch 3, Sample 14732: Loss: 0.1378\n",
            "Epoch 3, Sample 14733: Loss: 0.0915\n",
            "Epoch 3, Sample 14734: Loss: 0.0009\n",
            "Epoch 3, Sample 14735: Loss: 0.7036\n",
            "Epoch 3, Sample 14736: Loss: 0.5858\n",
            "Epoch 3, Sample 14737: Loss: 0.0212\n",
            "Epoch 3, Sample 14738: Loss: 0.1523\n",
            "Epoch 3, Sample 14739: Loss: 0.0026\n",
            "Epoch 3, Sample 14740: Loss: 0.4032\n",
            "Epoch 3, Sample 14741: Loss: 1.1287\n",
            "Epoch 3, Sample 14742: Loss: 0.0838\n",
            "Epoch 3, Sample 14743: Loss: 0.7036\n",
            "Epoch 3, Sample 14744: Loss: 0.0160\n",
            "Epoch 3, Sample 14745: Loss: 0.2759\n",
            "Epoch 3, Sample 14746: Loss: 0.3441\n",
            "Epoch 3, Sample 14747: Loss: 3.3282\n",
            "Epoch 3, Sample 14748: Loss: 0.1337\n",
            "Epoch 3, Sample 14749: Loss: 0.5871\n",
            "Epoch 3, Sample 14750: Loss: 0.7453\n",
            "Epoch 3, Sample 14751: Loss: 0.0207\n",
            "Epoch 3, Sample 14752: Loss: 0.3399\n",
            "Epoch 3, Sample 14753: Loss: 0.0270\n",
            "Epoch 3, Sample 14754: Loss: 0.2639\n",
            "Epoch 3, Sample 14755: Loss: 0.0026\n",
            "Epoch 3, Sample 14756: Loss: 0.6978\n",
            "Epoch 3, Sample 14757: Loss: 0.1855\n",
            "Epoch 3, Sample 14758: Loss: 0.0091\n",
            "Epoch 3, Sample 14759: Loss: 3.4424\n",
            "Epoch 3, Sample 14760: Loss: 0.1210\n",
            "Epoch 3, Sample 14761: Loss: 0.0363\n",
            "Epoch 3, Sample 14762: Loss: 0.5196\n",
            "Epoch 3, Sample 14763: Loss: 0.2034\n",
            "Epoch 3, Sample 14764: Loss: 1.0266\n",
            "Epoch 3, Sample 14765: Loss: 0.0303\n",
            "Epoch 3, Sample 14766: Loss: 0.2923\n",
            "Epoch 3, Sample 14767: Loss: 0.0306\n",
            "Epoch 3, Sample 14768: Loss: 1.7530\n",
            "Epoch 3, Sample 14769: Loss: 1.7589\n",
            "Epoch 3, Sample 14770: Loss: 0.2962\n",
            "Epoch 3, Sample 14771: Loss: 0.7036\n",
            "Epoch 3, Sample 14772: Loss: 0.1250\n",
            "Epoch 3, Sample 14773: Loss: 0.3399\n",
            "Epoch 3, Sample 14774: Loss: 1.0155\n",
            "Epoch 3, Sample 14775: Loss: 0.0031\n",
            "Epoch 3, Sample 14776: Loss: 1.0524\n",
            "Epoch 3, Sample 14777: Loss: 0.2219\n",
            "Epoch 3, Sample 14778: Loss: 0.7036\n",
            "Epoch 3, Sample 14779: Loss: 0.1888\n",
            "Epoch 3, Sample 14780: Loss: 0.1199\n",
            "Epoch 3, Sample 14781: Loss: 0.6357\n",
            "Epoch 3, Sample 14782: Loss: 0.0025\n",
            "Epoch 3, Sample 14783: Loss: 0.1248\n",
            "Epoch 3, Sample 14784: Loss: 0.2044\n",
            "Epoch 3, Sample 14785: Loss: 0.0084\n",
            "Epoch 3, Sample 14786: Loss: 0.1170\n",
            "Epoch 3, Sample 14787: Loss: 0.0205\n",
            "Epoch 3, Sample 14788: Loss: 0.0915\n",
            "Epoch 3, Sample 14789: Loss: 0.5858\n",
            "Epoch 3, Sample 14790: Loss: 0.1250\n",
            "Epoch 3, Sample 14791: Loss: 0.1357\n",
            "Epoch 3, Sample 14792: Loss: 1.0530\n",
            "Epoch 3, Sample 14793: Loss: 0.2086\n",
            "Epoch 3, Sample 14794: Loss: 0.4232\n",
            "Epoch 3, Sample 14795: Loss: 0.5972\n",
            "Epoch 3, Sample 14796: Loss: 0.3399\n",
            "Epoch 3, Sample 14797: Loss: 0.2558\n",
            "Epoch 3, Sample 14798: Loss: 0.0006\n",
            "Epoch 3, Sample 14799: Loss: 1.0155\n",
            "Epoch 3, Sample 14800: Loss: 0.0026\n",
            "Epoch 3, Sample 14801: Loss: 0.2044\n",
            "Epoch 3, Sample 14802: Loss: 0.6990\n",
            "Epoch 3, Sample 14803: Loss: 0.2441\n",
            "Epoch 3, Sample 14804: Loss: 0.0630\n",
            "Epoch 3, Sample 14805: Loss: 0.0088\n",
            "Epoch 3, Sample 14806: Loss: 0.8484\n",
            "Epoch 3, Sample 14807: Loss: 0.2034\n",
            "Epoch 3, Sample 14808: Loss: 0.2032\n",
            "Epoch 3, Sample 14809: Loss: 0.2759\n",
            "Epoch 3, Sample 14810: Loss: 0.1250\n",
            "Epoch 3, Sample 14811: Loss: 1.0524\n",
            "Epoch 3, Sample 14812: Loss: 1.0155\n",
            "Epoch 3, Sample 14813: Loss: 0.7561\n",
            "Epoch 3, Sample 14814: Loss: 0.6591\n",
            "Epoch 3, Sample 14815: Loss: 0.2989\n",
            "Epoch 3, Sample 14816: Loss: 0.2430\n",
            "Epoch 3, Sample 14817: Loss: 1.0266\n",
            "Epoch 3, Sample 14818: Loss: 0.0838\n",
            "Epoch 3, Sample 14819: Loss: 0.2219\n",
            "Epoch 3, Sample 14820: Loss: 0.3402\n",
            "Epoch 3, Sample 14821: Loss: 0.1564\n",
            "Epoch 3, Sample 14822: Loss: 0.2759\n",
            "Epoch 3, Sample 14823: Loss: 1.0524\n",
            "Epoch 3, Sample 14824: Loss: 0.3949\n",
            "Epoch 3, Sample 14825: Loss: 0.5636\n",
            "Epoch 3, Sample 14826: Loss: 0.0645\n",
            "Epoch 3, Sample 14827: Loss: 1.0359\n",
            "Epoch 3, Sample 14828: Loss: 0.1609\n",
            "Epoch 3, Sample 14829: Loss: 0.7036\n",
            "Epoch 3, Sample 14830: Loss: 0.1749\n",
            "Epoch 3, Sample 14831: Loss: 3.0519\n",
            "Epoch 3, Sample 14832: Loss: 0.0133\n",
            "Epoch 3, Sample 14833: Loss: 0.7453\n",
            "Epoch 3, Sample 14834: Loss: 0.3441\n",
            "Epoch 3, Sample 14835: Loss: 0.1674\n",
            "Epoch 3, Sample 14836: Loss: 0.0554\n",
            "Epoch 3, Sample 14837: Loss: 0.4382\n",
            "Epoch 3, Sample 14838: Loss: 0.2044\n",
            "Epoch 3, Sample 14839: Loss: 0.3399\n",
            "Epoch 3, Sample 14840: Loss: 0.6139\n",
            "Epoch 3, Sample 14841: Loss: 1.0524\n",
            "Epoch 3, Sample 14842: Loss: 0.3441\n",
            "Epoch 3, Sample 14843: Loss: 0.6242\n",
            "Epoch 3, Sample 14844: Loss: 17.5078\n",
            "Epoch 3, Sample 14845: Loss: 0.0313\n",
            "Epoch 3, Sample 14846: Loss: 0.2639\n",
            "Epoch 3, Sample 14847: Loss: 0.0001\n",
            "Epoch 3, Sample 14848: Loss: 0.0078\n",
            "Epoch 3, Sample 14849: Loss: 0.0906\n",
            "Epoch 3, Sample 14850: Loss: 1.0155\n",
            "Epoch 3, Sample 14851: Loss: 0.0026\n",
            "Epoch 3, Sample 14852: Loss: 0.2036\n",
            "Epoch 3, Sample 14853: Loss: 0.0026\n",
            "Epoch 3, Sample 14854: Loss: 0.3628\n",
            "Epoch 3, Sample 14855: Loss: 0.0018\n",
            "Epoch 3, Sample 14856: Loss: 2.0807\n",
            "Epoch 3, Sample 14857: Loss: 0.2832\n",
            "Epoch 3, Sample 14858: Loss: 0.4606\n",
            "Epoch 3, Sample 14859: Loss: 0.0108\n",
            "Epoch 3, Sample 14860: Loss: 0.1567\n",
            "Epoch 3, Sample 14861: Loss: 0.0079\n",
            "Epoch 3, Sample 14862: Loss: 0.3399\n",
            "Epoch 3, Sample 14863: Loss: 1.0359\n",
            "Epoch 3, Sample 14864: Loss: 0.3441\n",
            "Epoch 3, Sample 14865: Loss: 0.0391\n",
            "Epoch 3, Sample 14866: Loss: 0.0477\n",
            "Epoch 3, Sample 14867: Loss: 1.0530\n",
            "Epoch 3, Sample 14868: Loss: 0.0380\n",
            "Epoch 3, Sample 14869: Loss: 2.2069\n",
            "Epoch 3, Sample 14870: Loss: 0.0005\n",
            "Epoch 3, Sample 14871: Loss: 0.0018\n",
            "Epoch 3, Sample 14872: Loss: 0.8951\n",
            "Epoch 3, Sample 14873: Loss: 0.0013\n",
            "Epoch 3, Sample 14874: Loss: 0.0072\n",
            "Epoch 3, Sample 14875: Loss: 0.4607\n",
            "Epoch 3, Sample 14876: Loss: 0.1559\n",
            "Epoch 3, Sample 14877: Loss: 0.0018\n",
            "Epoch 3, Sample 14878: Loss: 0.9367\n",
            "Epoch 3, Sample 14879: Loss: 0.0626\n",
            "Epoch 3, Sample 14880: Loss: 0.7453\n",
            "Epoch 3, Sample 14881: Loss: 0.1248\n",
            "Epoch 3, Sample 14882: Loss: 0.3126\n",
            "Epoch 3, Sample 14883: Loss: 0.5000\n",
            "Epoch 3, Sample 14884: Loss: 0.2036\n",
            "Epoch 3, Sample 14885: Loss: 1.0530\n",
            "Epoch 3, Sample 14886: Loss: 0.1170\n",
            "Epoch 3, Sample 14887: Loss: 0.2044\n",
            "Epoch 3, Sample 14888: Loss: 0.4032\n",
            "Epoch 3, Sample 14889: Loss: 0.3441\n",
            "Epoch 3, Sample 14890: Loss: 0.3399\n",
            "Epoch 3, Sample 14891: Loss: 0.0938\n",
            "Epoch 3, Sample 14892: Loss: 0.7036\n",
            "Epoch 3, Sample 14893: Loss: 3.3834\n",
            "Epoch 3, Sample 14894: Loss: 0.0099\n",
            "Epoch 3, Sample 14895: Loss: 0.0286\n",
            "Epoch 3, Sample 14896: Loss: 0.0034\n",
            "Epoch 3, Sample 14897: Loss: 0.6092\n",
            "Epoch 3, Sample 14898: Loss: 1.0524\n",
            "Epoch 3, Sample 14899: Loss: 1.4187\n",
            "Epoch 3, Sample 14900: Loss: 0.3949\n",
            "Epoch 3, Sample 14901: Loss: 0.6867\n",
            "Epoch 3, Sample 14902: Loss: 0.1056\n",
            "Epoch 3, Sample 14903: Loss: 0.0026\n",
            "Epoch 3, Sample 14904: Loss: 0.3758\n",
            "Epoch 3, Sample 14905: Loss: 1.0524\n",
            "Epoch 3, Sample 14906: Loss: 0.2959\n",
            "Epoch 3, Sample 14907: Loss: 1.7192\n",
            "Epoch 3, Sample 14908: Loss: 0.4644\n",
            "Epoch 3, Sample 14909: Loss: 1.0155\n",
            "Epoch 3, Sample 14910: Loss: 0.0018\n",
            "Epoch 3, Sample 14911: Loss: 0.2044\n",
            "Epoch 3, Sample 14912: Loss: 0.0026\n",
            "Epoch 3, Sample 14913: Loss: 0.0205\n",
            "Epoch 3, Sample 14914: Loss: 0.0661\n",
            "Epoch 3, Sample 14915: Loss: 0.5003\n",
            "Epoch 3, Sample 14916: Loss: 0.0363\n",
            "Epoch 3, Sample 14917: Loss: 0.6990\n",
            "Epoch 3, Sample 14918: Loss: 0.3441\n",
            "Epoch 3, Sample 14919: Loss: 3.0845\n",
            "Epoch 3, Sample 14920: Loss: 0.2032\n",
            "Epoch 3, Sample 14921: Loss: 0.0150\n",
            "Epoch 3, Sample 14922: Loss: 0.1170\n",
            "Epoch 3, Sample 14923: Loss: 0.0062\n",
            "Epoch 3, Sample 14924: Loss: 0.0121\n",
            "Epoch 3, Sample 14925: Loss: 0.0626\n",
            "Epoch 3, Sample 14926: Loss: 0.0001\n",
            "Epoch 3, Sample 14927: Loss: 0.6304\n",
            "Epoch 3, Sample 14928: Loss: 0.0025\n",
            "Epoch 3, Sample 14929: Loss: 1.6131\n",
            "Epoch 3, Sample 14930: Loss: 0.0018\n",
            "Epoch 3, Sample 14931: Loss: 0.0802\n",
            "Epoch 3, Sample 14932: Loss: 0.3399\n",
            "Epoch 3, Sample 14933: Loss: 0.0108\n",
            "Epoch 3, Sample 14934: Loss: 1.8755\n",
            "Epoch 3, Sample 14935: Loss: 0.0325\n",
            "Epoch 3, Sample 14936: Loss: 0.3441\n",
            "Epoch 3, Sample 14937: Loss: 0.2182\n",
            "Epoch 3, Sample 14938: Loss: 0.0013\n",
            "Epoch 3, Sample 14939: Loss: 0.3399\n",
            "Epoch 3, Sample 14940: Loss: 0.6304\n",
            "Epoch 3, Sample 14941: Loss: 0.7625\n",
            "Epoch 3, Sample 14942: Loss: 0.1170\n",
            "Epoch 3, Sample 14943: Loss: 1.0530\n",
            "Epoch 3, Sample 14944: Loss: 0.4298\n",
            "Epoch 3, Sample 14945: Loss: 0.3399\n",
            "Epoch 3, Sample 14946: Loss: 0.4607\n",
            "Epoch 3, Sample 14947: Loss: 0.0630\n",
            "Epoch 3, Sample 14948: Loss: 0.2639\n",
            "Epoch 3, Sample 14949: Loss: 0.0062\n",
            "Epoch 3, Sample 14950: Loss: 0.5858\n",
            "Epoch 3, Sample 14951: Loss: 0.0084\n",
            "Epoch 3, Sample 14952: Loss: 0.0258\n",
            "Epoch 3, Sample 14953: Loss: 0.1397\n",
            "Epoch 3, Sample 14954: Loss: 0.0018\n",
            "Epoch 3, Sample 14955: Loss: 0.1559\n",
            "Epoch 3, Sample 14956: Loss: 0.2032\n",
            "Epoch 3, Sample 14957: Loss: 0.6227\n",
            "Epoch 3, Sample 14958: Loss: 0.3399\n",
            "Epoch 3, Sample 14959: Loss: 0.0336\n",
            "Epoch 3, Sample 14960: Loss: 1.1454\n",
            "Epoch 3, Sample 14961: Loss: 0.2219\n",
            "Epoch 3, Sample 14962: Loss: 0.0817\n",
            "Epoch 3, Sample 14963: Loss: 0.2044\n",
            "Epoch 3, Sample 14964: Loss: 0.0030\n",
            "Epoch 3, Sample 14965: Loss: 0.7036\n",
            "Epoch 3, Sample 14966: Loss: 0.0712\n",
            "Epoch 3, Sample 14967: Loss: 0.1252\n",
            "Epoch 3, Sample 14968: Loss: 0.0026\n",
            "Epoch 3, Sample 14969: Loss: 2.0108\n",
            "Epoch 3, Sample 14970: Loss: 0.0191\n",
            "Epoch 3, Sample 14971: Loss: 0.5003\n",
            "Epoch 3, Sample 14972: Loss: 0.0466\n",
            "Epoch 3, Sample 14973: Loss: 0.1246\n",
            "Epoch 3, Sample 14974: Loss: 1.0524\n",
            "Epoch 3, Sample 14975: Loss: 0.1463\n",
            "Epoch 3, Sample 14976: Loss: 0.0466\n",
            "Epoch 3, Sample 14977: Loss: 1.0524\n",
            "Epoch 3, Sample 14978: Loss: 0.2931\n",
            "Epoch 3, Sample 14979: Loss: 0.0026\n",
            "Epoch 3, Sample 14980: Loss: 0.0026\n",
            "Epoch 3, Sample 14981: Loss: 0.4799\n",
            "Epoch 3, Sample 14982: Loss: 0.8484\n",
            "Epoch 3, Sample 14983: Loss: 0.4930\n",
            "Epoch 3, Sample 14984: Loss: 1.0155\n",
            "Epoch 3, Sample 14985: Loss: 0.0026\n",
            "Epoch 3, Sample 14986: Loss: 0.0026\n",
            "Epoch 3, Sample 14987: Loss: 0.1416\n",
            "Epoch 3, Sample 14988: Loss: 1.0688\n",
            "Epoch 3, Sample 14989: Loss: 0.6737\n",
            "Epoch 3, Sample 14990: Loss: 0.0330\n",
            "Epoch 3, Sample 14991: Loss: 0.1225\n",
            "Epoch 3, Sample 14992: Loss: 1.0524\n",
            "Epoch 3, Sample 14993: Loss: 0.9785\n",
            "Epoch 3, Sample 14994: Loss: 0.4611\n",
            "Epoch 3, Sample 14995: Loss: 0.6990\n",
            "Epoch 3, Sample 14996: Loss: 0.4641\n",
            "Epoch 3, Sample 14997: Loss: 0.6990\n",
            "Epoch 3, Sample 14998: Loss: 0.6867\n",
            "Epoch 3, Sample 14999: Loss: 0.1250\n",
            "Epoch 3, Sample 15000: Loss: 0.3949\n",
            "Epoch 3, Sample 15001: Loss: 0.0018\n",
            "Epoch 3, Sample 15002: Loss: 0.2832\n",
            "Epoch 3, Sample 15003: Loss: 0.1364\n",
            "Epoch 3, Sample 15004: Loss: 0.2182\n",
            "Epoch 3, Sample 15005: Loss: 0.0744\n",
            "Epoch 3, Sample 15006: Loss: 0.1964\n",
            "Epoch 3, Sample 15007: Loss: 0.2032\n",
            "Epoch 3, Sample 15008: Loss: 0.2044\n",
            "Epoch 3, Sample 15009: Loss: 0.2219\n",
            "Epoch 3, Sample 15010: Loss: 0.3949\n",
            "Epoch 3, Sample 15011: Loss: 0.4930\n",
            "Epoch 3, Sample 15012: Loss: 0.2044\n",
            "Epoch 3, Sample 15013: Loss: 0.0006\n",
            "Epoch 3, Sample 15014: Loss: 1.0524\n",
            "Epoch 3, Sample 15015: Loss: 0.3399\n",
            "Epoch 3, Sample 15016: Loss: 0.0018\n",
            "Epoch 3, Sample 15017: Loss: 1.0524\n",
            "Epoch 3, Sample 15018: Loss: 0.7702\n",
            "Epoch 3, Sample 15019: Loss: 0.0991\n",
            "Epoch 3, Sample 15020: Loss: 1.8736\n",
            "Epoch 3, Sample 15021: Loss: 0.3402\n",
            "Epoch 3, Sample 15022: Loss: 0.7702\n",
            "Epoch 3, Sample 15023: Loss: 0.2089\n",
            "Epoch 3, Sample 15024: Loss: 0.1622\n",
            "Epoch 3, Sample 15025: Loss: 1.0155\n",
            "Epoch 3, Sample 15026: Loss: 0.0303\n",
            "Epoch 3, Sample 15027: Loss: 0.0048\n",
            "Epoch 3, Sample 15028: Loss: 0.0092\n",
            "Epoch 3, Sample 15029: Loss: 0.1039\n",
            "Epoch 3, Sample 15030: Loss: 1.0155\n",
            "Epoch 3, Sample 15031: Loss: 4.4660\n",
            "Epoch 3, Sample 15032: Loss: 0.1901\n",
            "Epoch 3, Sample 15033: Loss: 0.3332\n",
            "Epoch 3, Sample 15034: Loss: 0.0026\n",
            "Epoch 3, Sample 15035: Loss: 0.6990\n",
            "Epoch 3, Sample 15036: Loss: 0.1225\n",
            "Epoch 3, Sample 15037: Loss: 0.0007\n",
            "Epoch 3, Sample 15038: Loss: 0.0352\n",
            "Epoch 3, Sample 15039: Loss: 0.2034\n",
            "Epoch 3, Sample 15040: Loss: 0.5858\n",
            "Epoch 3, Sample 15041: Loss: 0.8951\n",
            "Epoch 3, Sample 15042: Loss: 1.0524\n",
            "Epoch 3, Sample 15043: Loss: 0.1957\n",
            "Epoch 3, Sample 15044: Loss: 0.0034\n",
            "Epoch 3, Sample 15045: Loss: 9.1245\n",
            "Epoch 3, Sample 15046: Loss: 1.0524\n",
            "Epoch 3, Sample 15047: Loss: 0.0026\n",
            "Epoch 3, Sample 15048: Loss: 1.5113\n",
            "Epoch 3, Sample 15049: Loss: 0.2558\n",
            "Epoch 3, Sample 15050: Loss: 0.7036\n",
            "Epoch 3, Sample 15051: Loss: 1.0524\n",
            "Epoch 3, Sample 15052: Loss: 0.1040\n",
            "Epoch 3, Sample 15053: Loss: 0.9246\n",
            "Epoch 3, Sample 15054: Loss: 0.2034\n",
            "Epoch 3, Sample 15055: Loss: 0.3399\n",
            "Epoch 3, Sample 15056: Loss: 0.3056\n",
            "Epoch 3, Sample 15057: Loss: 0.3984\n",
            "Epoch 3, Sample 15058: Loss: 8.3608\n",
            "Epoch 3, Sample 15059: Loss: 0.2044\n",
            "Epoch 3, Sample 15060: Loss: 1.0359\n",
            "Epoch 3, Sample 15061: Loss: 1.3403\n",
            "Epoch 3, Sample 15062: Loss: 0.3399\n",
            "Epoch 3, Sample 15063: Loss: 0.5636\n",
            "Epoch 3, Sample 15064: Loss: 0.1364\n",
            "Epoch 3, Sample 15065: Loss: 0.0281\n",
            "Epoch 3, Sample 15066: Loss: 0.3441\n",
            "Epoch 3, Sample 15067: Loss: 0.2032\n",
            "Epoch 3, Sample 15068: Loss: 0.2036\n",
            "Epoch 3, Sample 15069: Loss: 0.1250\n",
            "Epoch 3, Sample 15070: Loss: 1.0530\n",
            "Epoch 3, Sample 15071: Loss: 0.0026\n",
            "Epoch 3, Sample 15072: Loss: 0.2245\n",
            "Epoch 3, Sample 15073: Loss: 0.6628\n",
            "Epoch 3, Sample 15074: Loss: 0.4032\n",
            "Epoch 3, Sample 15075: Loss: 2.1306\n",
            "Epoch 3, Sample 15076: Loss: 0.4799\n",
            "Epoch 3, Sample 15077: Loss: 0.7036\n",
            "Epoch 3, Sample 15078: Loss: 0.0321\n",
            "Epoch 3, Sample 15079: Loss: 0.1240\n",
            "Epoch 3, Sample 15080: Loss: 0.2832\n",
            "Epoch 3, Sample 15081: Loss: 0.1170\n",
            "Epoch 3, Sample 15082: Loss: 0.6008\n",
            "Epoch 3, Sample 15083: Loss: 0.0000\n",
            "Epoch 3, Sample 15084: Loss: 0.0025\n",
            "Epoch 3, Sample 15085: Loss: 0.1055\n",
            "Epoch 3, Sample 15086: Loss: 0.3332\n",
            "Epoch 3, Sample 15087: Loss: 0.1252\n",
            "Epoch 3, Sample 15088: Loss: 0.3441\n",
            "Epoch 3, Sample 15089: Loss: 0.2032\n",
            "Epoch 3, Sample 15090: Loss: 0.0001\n",
            "Epoch 3, Sample 15091: Loss: 0.0637\n",
            "Epoch 3, Sample 15092: Loss: 0.3270\n",
            "Epoch 3, Sample 15093: Loss: 0.6990\n",
            "Epoch 3, Sample 15094: Loss: 0.0026\n",
            "Epoch 3, Sample 15095: Loss: 0.5000\n",
            "Epoch 3, Sample 15096: Loss: 0.0025\n",
            "Epoch 3, Sample 15097: Loss: 0.0026\n",
            "Epoch 3, Sample 15098: Loss: 1.0391\n",
            "Epoch 3, Sample 15099: Loss: 0.0306\n",
            "Epoch 3, Sample 15100: Loss: 0.0026\n",
            "Epoch 3, Sample 15101: Loss: 0.0026\n",
            "Epoch 3, Sample 15102: Loss: 0.7702\n",
            "Epoch 3, Sample 15103: Loss: 0.3949\n",
            "Epoch 3, Sample 15104: Loss: 1.0524\n",
            "Epoch 3, Sample 15105: Loss: 0.5003\n",
            "Epoch 3, Sample 15106: Loss: 0.2044\n",
            "Epoch 3, Sample 15107: Loss: 1.0155\n",
            "Epoch 3, Sample 15108: Loss: 0.0728\n",
            "Epoch 3, Sample 15109: Loss: 0.1248\n",
            "Epoch 3, Sample 15110: Loss: 1.0524\n",
            "Epoch 3, Sample 15111: Loss: 0.1397\n",
            "Epoch 3, Sample 15112: Loss: 0.0005\n",
            "Epoch 3, Sample 15113: Loss: 1.2686\n",
            "Epoch 3, Sample 15114: Loss: 0.5916\n",
            "Epoch 3, Sample 15115: Loss: 3.5504\n",
            "Epoch 3, Sample 15116: Loss: 0.5636\n",
            "Epoch 3, Sample 15117: Loss: 0.3441\n",
            "Epoch 3, Sample 15118: Loss: 1.0688\n",
            "Epoch 3, Sample 15119: Loss: 0.1170\n",
            "Epoch 3, Sample 15120: Loss: 1.0524\n",
            "Epoch 3, Sample 15121: Loss: 1.0524\n",
            "Epoch 3, Sample 15122: Loss: 0.0018\n",
            "Epoch 3, Sample 15123: Loss: 0.1627\n",
            "Epoch 3, Sample 15124: Loss: 0.0080\n",
            "Epoch 3, Sample 15125: Loss: 0.0630\n",
            "Epoch 3, Sample 15126: Loss: 0.0466\n",
            "Epoch 3, Sample 15127: Loss: 0.0025\n",
            "Epoch 3, Sample 15128: Loss: 0.2044\n",
            "Epoch 3, Sample 15129: Loss: 0.2034\n",
            "Epoch 3, Sample 15130: Loss: 0.4799\n",
            "Epoch 3, Sample 15131: Loss: 0.2759\n",
            "Epoch 3, Sample 15132: Loss: 0.1225\n",
            "Epoch 3, Sample 15133: Loss: 0.3791\n",
            "Epoch 3, Sample 15134: Loss: 0.0001\n",
            "Epoch 3, Sample 15135: Loss: 0.2086\n",
            "Epoch 3, Sample 15136: Loss: 0.2962\n",
            "Epoch 3, Sample 15137: Loss: 0.3872\n",
            "Epoch 3, Sample 15138: Loss: 0.7583\n",
            "Epoch 3, Sample 15139: Loss: 1.0524\n",
            "Epoch 3, Sample 15140: Loss: 0.3568\n",
            "Epoch 3, Sample 15141: Loss: 0.2044\n",
            "Epoch 3, Sample 15142: Loss: 1.0524\n",
            "Epoch 3, Sample 15143: Loss: 0.0023\n",
            "Epoch 3, Sample 15144: Loss: 0.0001\n",
            "Epoch 3, Sample 15145: Loss: 0.0422\n",
            "Epoch 3, Sample 15146: Loss: 1.0524\n",
            "Epoch 3, Sample 15147: Loss: 0.0026\n",
            "Epoch 3, Sample 15148: Loss: 0.6092\n",
            "Epoch 3, Sample 15149: Loss: 2.2309\n",
            "Epoch 3, Sample 15150: Loss: 0.0105\n",
            "Epoch 3, Sample 15151: Loss: 0.7036\n",
            "Epoch 3, Sample 15152: Loss: 0.5078\n",
            "Epoch 3, Sample 15153: Loss: 0.0625\n",
            "Epoch 3, Sample 15154: Loss: 0.1114\n",
            "Epoch 3, Sample 15155: Loss: 0.7036\n",
            "Epoch 3, Sample 15156: Loss: 0.0062\n",
            "Epoch 3, Sample 15157: Loss: 0.1252\n",
            "Epoch 3, Sample 15158: Loss: 0.0150\n",
            "Epoch 3, Sample 15159: Loss: 0.0476\n",
            "Epoch 3, Sample 15160: Loss: 2.3597\n",
            "Epoch 3, Sample 15161: Loss: 0.0258\n",
            "Epoch 3, Sample 15162: Loss: 0.4930\n",
            "Epoch 3, Sample 15163: Loss: 1.0524\n",
            "Epoch 3, Sample 15164: Loss: 1.9213\n",
            "Epoch 3, Sample 15165: Loss: 0.4588\n",
            "Epoch 3, Sample 15166: Loss: 0.1246\n",
            "Epoch 3, Sample 15167: Loss: 0.2759\n",
            "Epoch 3, Sample 15168: Loss: 0.9804\n",
            "Epoch 3, Sample 15169: Loss: 0.1924\n",
            "Epoch 3, Sample 15170: Loss: 0.5858\n",
            "Epoch 3, Sample 15171: Loss: 0.0000\n",
            "Epoch 3, Sample 15172: Loss: 1.1279\n",
            "Epoch 3, Sample 15173: Loss: 1.1793\n",
            "Epoch 3, Sample 15174: Loss: 0.0001\n",
            "Epoch 3, Sample 15175: Loss: 0.1523\n",
            "Epoch 3, Sample 15176: Loss: 0.3367\n",
            "Epoch 3, Sample 15177: Loss: 1.0524\n",
            "Epoch 3, Sample 15178: Loss: 0.3399\n",
            "Epoch 3, Sample 15179: Loss: 0.4032\n",
            "Epoch 3, Sample 15180: Loss: 0.1238\n",
            "Epoch 3, Sample 15181: Loss: 0.2034\n",
            "Epoch 3, Sample 15182: Loss: 0.1170\n",
            "Epoch 3, Sample 15183: Loss: 0.0018\n",
            "Epoch 3, Sample 15184: Loss: 0.6990\n",
            "Epoch 3, Sample 15185: Loss: 0.0212\n",
            "Epoch 3, Sample 15186: Loss: 0.4799\n",
            "Epoch 3, Sample 15187: Loss: 0.2494\n",
            "Epoch 3, Sample 15188: Loss: 0.1248\n",
            "Epoch 3, Sample 15189: Loss: 0.4505\n",
            "Epoch 3, Sample 15190: Loss: 1.0530\n",
            "Epoch 3, Sample 15191: Loss: 0.4294\n",
            "Epoch 3, Sample 15192: Loss: 0.2032\n",
            "Epoch 3, Sample 15193: Loss: 0.2032\n",
            "Epoch 3, Sample 15194: Loss: 0.2219\n",
            "Epoch 3, Sample 15195: Loss: 14.9105\n",
            "Epoch 3, Sample 15196: Loss: 0.4996\n",
            "Epoch 3, Sample 15197: Loss: 0.6304\n",
            "Epoch 3, Sample 15198: Loss: 0.0915\n",
            "Epoch 3, Sample 15199: Loss: 0.1170\n",
            "Epoch 3, Sample 15200: Loss: 1.0530\n",
            "Epoch 3, Sample 15201: Loss: 0.0049\n",
            "Epoch 3, Sample 15202: Loss: 0.1248\n",
            "Epoch 3, Sample 15203: Loss: 0.2132\n",
            "Epoch 3, Sample 15204: Loss: 0.2034\n",
            "Epoch 3, Sample 15205: Loss: 1.5019\n",
            "Epoch 3, Sample 15206: Loss: 0.0915\n",
            "Epoch 3, Sample 15207: Loss: 0.2219\n",
            "Epoch 3, Sample 15208: Loss: 0.0042\n",
            "Epoch 3, Sample 15209: Loss: 0.9990\n",
            "Epoch 3, Sample 15210: Loss: 0.0084\n",
            "Epoch 3, Sample 15211: Loss: 0.3949\n",
            "Epoch 3, Sample 15212: Loss: 0.2710\n",
            "Epoch 3, Sample 15213: Loss: 0.2112\n",
            "Epoch 3, Sample 15214: Loss: 0.3399\n",
            "Epoch 3, Sample 15215: Loss: 1.0524\n",
            "Epoch 3, Sample 15216: Loss: 0.3477\n",
            "Epoch 3, Sample 15217: Loss: 0.0415\n",
            "Epoch 3, Sample 15218: Loss: 0.0213\n",
            "Epoch 3, Sample 15219: Loss: 1.0625\n",
            "Epoch 3, Sample 15220: Loss: 0.2183\n",
            "Epoch 3, Sample 15221: Loss: 0.2759\n",
            "Epoch 3, Sample 15222: Loss: 0.3399\n",
            "Epoch 3, Sample 15223: Loss: 0.7262\n",
            "Epoch 3, Sample 15224: Loss: 0.2034\n",
            "Epoch 3, Sample 15225: Loss: 0.0630\n",
            "Epoch 3, Sample 15226: Loss: 0.0212\n",
            "Epoch 3, Sample 15227: Loss: 0.0124\n",
            "Epoch 3, Sample 15228: Loss: 1.0524\n",
            "Epoch 3, Sample 15229: Loss: 0.7036\n",
            "Epoch 3, Sample 15230: Loss: 0.2034\n",
            "Epoch 3, Sample 15231: Loss: 0.1559\n",
            "Epoch 3, Sample 15232: Loss: 0.0802\n",
            "Epoch 3, Sample 15233: Loss: 0.0938\n",
            "Epoch 3, Sample 15234: Loss: 0.1817\n",
            "Epoch 3, Sample 15235: Loss: 1.0524\n",
            "Epoch 3, Sample 15236: Loss: 0.2452\n",
            "Epoch 3, Sample 15237: Loss: 0.1300\n",
            "Epoch 3, Sample 15238: Loss: 1.0524\n",
            "Epoch 3, Sample 15239: Loss: 0.3949\n",
            "Epoch 3, Sample 15240: Loss: 0.0751\n",
            "Epoch 3, Sample 15241: Loss: 0.4607\n",
            "Epoch 3, Sample 15242: Loss: 0.3441\n",
            "Epoch 3, Sample 15243: Loss: 1.0524\n",
            "Epoch 3, Sample 15244: Loss: 0.1472\n",
            "Epoch 3, Sample 15245: Loss: 0.1170\n",
            "Epoch 3, Sample 15246: Loss: 0.7036\n",
            "Epoch 3, Sample 15247: Loss: 0.2938\n",
            "Epoch 3, Sample 15248: Loss: 0.2032\n",
            "Epoch 3, Sample 15249: Loss: 0.8951\n",
            "Epoch 3, Sample 15250: Loss: 1.0524\n",
            "Epoch 3, Sample 15251: Loss: 0.2034\n",
            "Epoch 3, Sample 15252: Loss: 0.0829\n",
            "Epoch 3, Sample 15253: Loss: 0.0026\n",
            "Epoch 3, Sample 15254: Loss: 0.6139\n",
            "Epoch 3, Sample 15255: Loss: 1.9820\n",
            "Epoch 3, Sample 15256: Loss: 1.0155\n",
            "Epoch 3, Sample 15257: Loss: 0.0067\n",
            "Epoch 3, Sample 15258: Loss: 0.1039\n",
            "Epoch 3, Sample 15259: Loss: 0.2759\n",
            "Epoch 3, Sample 15260: Loss: 0.5858\n",
            "Epoch 3, Sample 15261: Loss: 0.3441\n",
            "Epoch 3, Sample 15262: Loss: 1.0524\n",
            "Epoch 3, Sample 15263: Loss: 1.0530\n",
            "Epoch 3, Sample 15264: Loss: 0.4611\n",
            "Epoch 3, Sample 15265: Loss: 0.2759\n",
            "Epoch 3, Sample 15266: Loss: 0.0337\n",
            "Epoch 3, Sample 15267: Loss: 0.5636\n",
            "Epoch 3, Sample 15268: Loss: 0.2032\n",
            "Epoch 3, Sample 15269: Loss: 0.0682\n",
            "Epoch 3, Sample 15270: Loss: 0.0009\n",
            "Epoch 3, Sample 15271: Loss: 0.0026\n",
            "Epoch 3, Sample 15272: Loss: 1.0524\n",
            "Epoch 3, Sample 15273: Loss: 0.0000\n",
            "Epoch 3, Sample 15274: Loss: 0.2032\n",
            "Epoch 3, Sample 15275: Loss: 0.6914\n",
            "Epoch 3, Sample 15276: Loss: 0.1170\n",
            "Epoch 3, Sample 15277: Loss: 0.1336\n",
            "Epoch 3, Sample 15278: Loss: 0.1968\n",
            "Epoch 3, Sample 15279: Loss: 0.1264\n",
            "Epoch 3, Sample 15280: Loss: 0.9785\n",
            "Epoch 3, Sample 15281: Loss: 1.1569\n",
            "Epoch 3, Sample 15282: Loss: 0.0945\n",
            "Epoch 3, Sample 15283: Loss: 0.3418\n",
            "Epoch 3, Sample 15284: Loss: 0.1476\n",
            "Epoch 3, Sample 15285: Loss: 0.9464\n",
            "Epoch 3, Sample 15286: Loss: 0.0270\n",
            "Epoch 3, Sample 15287: Loss: 0.0754\n",
            "Epoch 3, Sample 15288: Loss: 0.3441\n",
            "Epoch 3, Sample 15289: Loss: 0.2044\n",
            "Epoch 3, Sample 15290: Loss: 0.1318\n",
            "Epoch 3, Sample 15291: Loss: 0.2034\n",
            "Epoch 3, Sample 15292: Loss: 0.2034\n",
            "Epoch 3, Sample 15293: Loss: 0.4799\n",
            "Epoch 3, Sample 15294: Loss: 0.1036\n",
            "Epoch 3, Sample 15295: Loss: 0.0025\n",
            "Epoch 3, Sample 15296: Loss: 0.2036\n",
            "Epoch 3, Sample 15297: Loss: 0.1397\n",
            "Epoch 3, Sample 15298: Loss: 0.1170\n",
            "Epoch 3, Sample 15299: Loss: 0.9227\n",
            "Epoch 3, Sample 15300: Loss: 0.0060\n",
            "Epoch 3, Sample 15301: Loss: 0.6353\n",
            "Epoch 3, Sample 15302: Loss: 0.0170\n",
            "Epoch 3, Sample 15303: Loss: 0.0135\n",
            "Epoch 3, Sample 15304: Loss: 0.1271\n",
            "Epoch 3, Sample 15305: Loss: 0.1040\n",
            "Epoch 3, Sample 15306: Loss: 0.3399\n",
            "Epoch 3, Sample 15307: Loss: 0.0626\n",
            "Epoch 3, Sample 15308: Loss: 0.1465\n",
            "Epoch 3, Sample 15309: Loss: 1.2978\n",
            "Epoch 3, Sample 15310: Loss: 10.3220\n",
            "Epoch 3, Sample 15311: Loss: 0.0466\n",
            "Epoch 3, Sample 15312: Loss: 1.0524\n",
            "Epoch 3, Sample 15313: Loss: 0.2639\n",
            "Epoch 3, Sample 15314: Loss: 0.3288\n",
            "Epoch 3, Sample 15315: Loss: 0.3477\n",
            "Epoch 3, Sample 15316: Loss: 0.6990\n",
            "Epoch 3, Sample 15317: Loss: 0.2044\n",
            "Epoch 3, Sample 15318: Loss: 0.0543\n",
            "Epoch 3, Sample 15319: Loss: 0.0310\n",
            "Epoch 3, Sample 15320: Loss: 1.0524\n",
            "Epoch 3, Sample 15321: Loss: 0.5799\n",
            "Epoch 3, Sample 15322: Loss: 0.4996\n",
            "Epoch 3, Sample 15323: Loss: 1.0155\n",
            "Epoch 3, Sample 15324: Loss: 0.0802\n",
            "Epoch 3, Sample 15325: Loss: 1.0524\n",
            "Epoch 3, Sample 15326: Loss: 0.0082\n",
            "Epoch 3, Sample 15327: Loss: 0.2032\n",
            "Epoch 3, Sample 15328: Loss: 0.3399\n",
            "Epoch 3, Sample 15329: Loss: 1.0524\n",
            "Epoch 3, Sample 15330: Loss: 1.0524\n",
            "Epoch 3, Sample 15331: Loss: 0.2034\n",
            "Epoch 3, Sample 15332: Loss: 0.6471\n",
            "Epoch 3, Sample 15333: Loss: 0.1546\n",
            "Epoch 3, Sample 15334: Loss: 0.1005\n",
            "Epoch 3, Sample 15335: Loss: 0.0018\n",
            "Epoch 3, Sample 15336: Loss: 0.0001\n",
            "Epoch 3, Sample 15337: Loss: 7.4078\n",
            "Epoch 3, Sample 15338: Loss: 0.0630\n",
            "Epoch 3, Sample 15339: Loss: 0.1039\n",
            "Epoch 3, Sample 15340: Loss: 0.0460\n",
            "Epoch 3, Sample 15341: Loss: 0.0270\n",
            "Epoch 3, Sample 15342: Loss: 0.7203\n",
            "Epoch 3, Sample 15343: Loss: 0.0640\n",
            "Epoch 3, Sample 15344: Loss: 0.7036\n",
            "Epoch 3, Sample 15345: Loss: 1.0524\n",
            "Epoch 3, Sample 15346: Loss: 0.2084\n",
            "Epoch 3, Sample 15347: Loss: 0.0426\n",
            "Epoch 3, Sample 15348: Loss: 0.0147\n",
            "Epoch 3, Sample 15349: Loss: 0.0209\n",
            "Epoch 3, Sample 15350: Loss: 0.2219\n",
            "Epoch 3, Sample 15351: Loss: 0.2036\n",
            "Epoch 3, Sample 15352: Loss: 0.4533\n",
            "Epoch 3, Sample 15353: Loss: 0.1559\n",
            "Epoch 3, Sample 15354: Loss: 1.0524\n",
            "Epoch 3, Sample 15355: Loss: 0.3949\n",
            "Epoch 3, Sample 15356: Loss: 0.1170\n",
            "Epoch 3, Sample 15357: Loss: 0.0064\n",
            "Epoch 3, Sample 15358: Loss: 0.0286\n",
            "Epoch 3, Sample 15359: Loss: 0.3399\n",
            "Epoch 3, Sample 15360: Loss: 1.3205\n",
            "Epoch 3, Sample 15361: Loss: 0.0001\n",
            "Epoch 3, Sample 15362: Loss: 0.3399\n",
            "Epoch 3, Sample 15363: Loss: 4.2335\n",
            "Epoch 3, Sample 15364: Loss: 1.5542\n",
            "Epoch 3, Sample 15365: Loss: 0.6990\n",
            "Epoch 3, Sample 15366: Loss: 0.4340\n",
            "Epoch 3, Sample 15367: Loss: 0.2759\n",
            "Epoch 3, Sample 15368: Loss: 0.3598\n",
            "Epoch 3, Sample 15369: Loss: 0.0915\n",
            "Epoch 3, Sample 15370: Loss: 0.7036\n",
            "Epoch 3, Sample 15371: Loss: 0.1204\n",
            "Epoch 3, Sample 15372: Loss: 0.1408\n",
            "Epoch 3, Sample 15373: Loss: 1.0530\n",
            "Epoch 3, Sample 15374: Loss: 0.2044\n",
            "Epoch 3, Sample 15375: Loss: 0.2974\n",
            "Epoch 3, Sample 15376: Loss: 0.0532\n",
            "Epoch 3, Sample 15377: Loss: 7.9443\n",
            "Epoch 3, Sample 15378: Loss: 0.6990\n",
            "Epoch 3, Sample 15379: Loss: 0.2044\n",
            "Epoch 3, Sample 15380: Loss: 0.1989\n",
            "Epoch 3, Sample 15381: Loss: 1.0524\n",
            "Epoch 3, Sample 15382: Loss: 0.5058\n",
            "Epoch 3, Sample 15383: Loss: 0.0005\n",
            "Epoch 3, Sample 15384: Loss: 0.3378\n",
            "Epoch 3, Sample 15385: Loss: 0.5000\n",
            "Epoch 3, Sample 15386: Loss: 0.9367\n",
            "Epoch 3, Sample 15387: Loss: 0.0040\n",
            "Epoch 3, Sample 15388: Loss: 1.6052\n",
            "Epoch 3, Sample 15389: Loss: 0.0063\n",
            "Epoch 3, Sample 15390: Loss: 1.0524\n",
            "Epoch 3, Sample 15391: Loss: 0.3549\n",
            "Epoch 3, Sample 15392: Loss: 0.4799\n",
            "Epoch 3, Sample 15393: Loss: 0.0359\n",
            "Epoch 3, Sample 15394: Loss: 0.0630\n",
            "Epoch 3, Sample 15395: Loss: 0.0063\n",
            "Epoch 3, Sample 15396: Loss: 0.1897\n",
            "Epoch 3, Sample 15397: Loss: 0.6092\n",
            "Epoch 3, Sample 15398: Loss: 1.5954\n",
            "Epoch 3, Sample 15399: Loss: 0.4996\n",
            "Epoch 3, Sample 15400: Loss: 0.5636\n",
            "Epoch 3, Sample 15401: Loss: 0.9492\n",
            "Epoch 3, Sample 15402: Loss: 1.0530\n",
            "Epoch 3, Sample 15403: Loss: 0.0001\n",
            "Epoch 3, Sample 15404: Loss: 0.0026\n",
            "Epoch 3, Sample 15405: Loss: 0.3582\n",
            "Epoch 3, Sample 15406: Loss: 0.5000\n",
            "Epoch 3, Sample 15407: Loss: 0.0838\n",
            "Epoch 3, Sample 15408: Loss: 0.0460\n",
            "Epoch 3, Sample 15409: Loss: 0.0001\n",
            "Epoch 3, Sample 15410: Loss: 0.0004\n",
            "Epoch 3, Sample 15411: Loss: 0.5396\n",
            "Epoch 3, Sample 15412: Loss: 0.7036\n",
            "Epoch 3, Sample 15413: Loss: 0.7453\n",
            "Epoch 3, Sample 15414: Loss: 0.2032\n",
            "Epoch 3, Sample 15415: Loss: 1.0524\n",
            "Epoch 3, Sample 15416: Loss: 0.7486\n",
            "Epoch 3, Sample 15417: Loss: 0.1437\n",
            "Epoch 3, Sample 15418: Loss: 0.5799\n",
            "Epoch 3, Sample 15419: Loss: 0.0026\n",
            "Epoch 3, Sample 15420: Loss: 0.5078\n",
            "Epoch 3, Sample 15421: Loss: 0.2795\n",
            "Epoch 3, Sample 15422: Loss: 1.0524\n",
            "Epoch 3, Sample 15423: Loss: 0.3062\n",
            "Epoch 3, Sample 15424: Loss: 0.1282\n",
            "Epoch 3, Sample 15425: Loss: 0.2032\n",
            "Epoch 3, Sample 15426: Loss: 0.0018\n",
            "Epoch 3, Sample 15427: Loss: 0.3449\n",
            "Epoch 3, Sample 15428: Loss: 0.7978\n",
            "Epoch 3, Sample 15429: Loss: 0.2329\n",
            "Epoch 3, Sample 15430: Loss: 0.6915\n",
            "Epoch 3, Sample 15431: Loss: 0.3637\n",
            "Epoch 3, Sample 15432: Loss: 0.4032\n",
            "Epoch 3, Sample 15433: Loss: 0.0915\n",
            "Epoch 3, Sample 15434: Loss: 0.2639\n",
            "Epoch 3, Sample 15435: Loss: 0.0706\n",
            "Epoch 3, Sample 15436: Loss: 0.0286\n",
            "Epoch 3, Sample 15437: Loss: 0.0003\n",
            "Epoch 3, Sample 15438: Loss: 0.8951\n",
            "Epoch 3, Sample 15439: Loss: 0.1588\n",
            "Epoch 3, Sample 15440: Loss: 0.1326\n",
            "Epoch 3, Sample 15441: Loss: 1.0524\n",
            "Epoch 3, Sample 15442: Loss: 0.5858\n",
            "Epoch 3, Sample 15443: Loss: 0.0089\n",
            "Epoch 3, Sample 15444: Loss: 0.2639\n",
            "Epoch 3, Sample 15445: Loss: 0.2075\n",
            "Epoch 3, Sample 15446: Loss: 1.0530\n",
            "Epoch 3, Sample 15447: Loss: 3.4179\n",
            "Epoch 3, Sample 15448: Loss: 0.2044\n",
            "Epoch 3, Sample 15449: Loss: 0.1170\n",
            "Epoch 3, Sample 15450: Loss: 0.0026\n",
            "Epoch 3, Sample 15451: Loss: 0.3399\n",
            "Epoch 3, Sample 15452: Loss: 0.3332\n",
            "Epoch 3, Sample 15453: Loss: 0.0625\n",
            "Epoch 3, Sample 15454: Loss: 0.7036\n",
            "Epoch 3, Sample 15455: Loss: 0.4659\n",
            "Epoch 3, Sample 15456: Loss: 0.0432\n",
            "Epoch 3, Sample 15457: Loss: 0.0150\n",
            "Epoch 3, Sample 15458: Loss: 0.0010\n",
            "Epoch 3, Sample 15459: Loss: 0.7036\n",
            "Epoch 3, Sample 15460: Loss: 0.5962\n",
            "Epoch 3, Sample 15461: Loss: 0.0630\n",
            "Epoch 3, Sample 15462: Loss: 0.0062\n",
            "Epoch 3, Sample 15463: Loss: 0.4278\n",
            "Epoch 3, Sample 15464: Loss: 0.3450\n",
            "Epoch 3, Sample 15465: Loss: 1.2553\n",
            "Epoch 3, Sample 15466: Loss: 0.0630\n",
            "Epoch 3, Sample 15467: Loss: 0.2044\n",
            "Epoch 3, Sample 15468: Loss: 0.5058\n",
            "Epoch 3, Sample 15469: Loss: 0.0469\n",
            "Epoch 3, Sample 15470: Loss: 0.2034\n",
            "Epoch 3, Sample 15471: Loss: 0.1417\n",
            "Epoch 3, Sample 15472: Loss: 0.4930\n",
            "Epoch 3, Sample 15473: Loss: 0.1559\n",
            "Epoch 3, Sample 15474: Loss: 0.2874\n",
            "Epoch 3, Sample 15475: Loss: 0.8951\n",
            "Epoch 3, Sample 15476: Loss: 0.0535\n",
            "Epoch 3, Sample 15477: Loss: 0.3584\n",
            "Epoch 3, Sample 15478: Loss: 1.0155\n",
            "Epoch 3, Sample 15479: Loss: 0.0220\n",
            "Epoch 3, Sample 15480: Loss: 0.5003\n",
            "Epoch 3, Sample 15481: Loss: 1.0155\n",
            "Epoch 3, Sample 15482: Loss: 0.7036\n",
            "Epoch 3, Sample 15483: Loss: 0.0313\n",
            "Epoch 3, Sample 15484: Loss: 0.6867\n",
            "Epoch 3, Sample 15485: Loss: 0.1399\n",
            "Epoch 3, Sample 15486: Loss: 0.3332\n",
            "Epoch 3, Sample 15487: Loss: 0.0640\n",
            "Epoch 3, Sample 15488: Loss: 0.3664\n",
            "Epoch 3, Sample 15489: Loss: 0.3418\n",
            "Epoch 3, Sample 15490: Loss: 0.0076\n",
            "Epoch 3, Sample 15491: Loss: 1.0524\n",
            "Epoch 3, Sample 15492: Loss: 1.0227\n",
            "Epoch 3, Sample 15493: Loss: 0.5000\n",
            "Epoch 3, Sample 15494: Loss: 0.5871\n",
            "Epoch 3, Sample 15495: Loss: 0.1225\n",
            "Epoch 3, Sample 15496: Loss: 0.0022\n",
            "Epoch 3, Sample 15497: Loss: 0.2355\n",
            "Epoch 3, Sample 15498: Loss: 0.1884\n",
            "Epoch 3, Sample 15499: Loss: 0.0018\n",
            "Epoch 3, Sample 15500: Loss: 1.0524\n",
            "Epoch 3, Sample 15501: Loss: 0.0001\n",
            "Epoch 3, Sample 15502: Loss: 0.7453\n",
            "Epoch 3, Sample 15503: Loss: 0.4990\n",
            "Epoch 3, Sample 15504: Loss: 0.2759\n",
            "Epoch 3, Sample 15505: Loss: 0.1629\n",
            "Epoch 3, Sample 15506: Loss: 5.2749\n",
            "Epoch 3, Sample 15507: Loss: 0.0270\n",
            "Epoch 3, Sample 15508: Loss: 0.0250\n",
            "Epoch 3, Sample 15509: Loss: 0.9367\n",
            "Epoch 3, Sample 15510: Loss: 1.0524\n",
            "Epoch 3, Sample 15511: Loss: 0.0018\n",
            "Epoch 3, Sample 15512: Loss: 0.2832\n",
            "Epoch 3, Sample 15513: Loss: 0.7036\n",
            "Epoch 3, Sample 15514: Loss: 3.9937\n",
            "Epoch 3, Sample 15515: Loss: 0.0364\n",
            "Epoch 3, Sample 15516: Loss: 0.0018\n",
            "Epoch 3, Sample 15517: Loss: 0.3441\n",
            "Epoch 3, Sample 15518: Loss: 0.2832\n",
            "Epoch 3, Sample 15519: Loss: 0.2175\n",
            "Epoch 3, Sample 15520: Loss: 0.2032\n",
            "Epoch 3, Sample 15521: Loss: 0.0240\n",
            "Epoch 3, Sample 15522: Loss: 0.3582\n",
            "Epoch 3, Sample 15523: Loss: 0.7036\n",
            "Epoch 3, Sample 15524: Loss: 0.3441\n",
            "Epoch 3, Sample 15525: Loss: 0.0212\n",
            "Epoch 3, Sample 15526: Loss: 1.0530\n",
            "Epoch 3, Sample 15527: Loss: 0.0212\n",
            "Epoch 3, Sample 15528: Loss: 0.0001\n",
            "Epoch 3, Sample 15529: Loss: 0.9237\n",
            "Epoch 3, Sample 15530: Loss: 0.6252\n",
            "Epoch 3, Sample 15531: Loss: 0.2704\n",
            "Epoch 3, Sample 15532: Loss: 0.0143\n",
            "Epoch 3, Sample 15533: Loss: 0.1588\n",
            "Epoch 3, Sample 15534: Loss: 0.3949\n",
            "Epoch 3, Sample 15535: Loss: 1.3504\n",
            "Epoch 3, Sample 15536: Loss: 0.1397\n",
            "Epoch 3, Sample 15537: Loss: 0.6596\n",
            "Epoch 3, Sample 15538: Loss: 1.0524\n",
            "Epoch 3, Sample 15539: Loss: 0.1546\n",
            "Epoch 3, Sample 15540: Loss: 0.0501\n",
            "Epoch 3, Sample 15541: Loss: 0.2851\n",
            "Epoch 3, Sample 15542: Loss: 0.3402\n",
            "Epoch 3, Sample 15543: Loss: 0.2759\n",
            "Epoch 3, Sample 15544: Loss: 0.2044\n",
            "Epoch 3, Sample 15545: Loss: 0.9367\n",
            "Epoch 3, Sample 15546: Loss: 0.2639\n",
            "Epoch 3, Sample 15547: Loss: 1.0524\n",
            "Epoch 3, Sample 15548: Loss: 0.1250\n",
            "Epoch 3, Sample 15549: Loss: 1.1558\n",
            "Epoch 3, Sample 15550: Loss: 0.0270\n",
            "Epoch 3, Sample 15551: Loss: 0.2962\n",
            "Epoch 3, Sample 15552: Loss: 0.3614\n",
            "Epoch 3, Sample 15553: Loss: 0.0490\n",
            "Epoch 3, Sample 15554: Loss: 0.8951\n",
            "Epoch 3, Sample 15555: Loss: 0.2759\n",
            "Epoch 3, Sample 15556: Loss: 2.1516\n",
            "Epoch 3, Sample 15557: Loss: 1.0266\n",
            "Epoch 3, Sample 15558: Loss: 0.0026\n",
            "Epoch 3, Sample 15559: Loss: 0.1593\n",
            "Epoch 3, Sample 15560: Loss: 1.0524\n",
            "Epoch 3, Sample 15561: Loss: 0.0145\n",
            "Epoch 3, Sample 15562: Loss: 0.3441\n",
            "Epoch 3, Sample 15563: Loss: 0.0026\n",
            "Epoch 3, Sample 15564: Loss: 0.1250\n",
            "Epoch 3, Sample 15565: Loss: 1.0524\n",
            "Epoch 3, Sample 15566: Loss: 0.1559\n",
            "Epoch 3, Sample 15567: Loss: 1.6811\n",
            "Epoch 3, Sample 15568: Loss: 0.2032\n",
            "Epoch 3, Sample 15569: Loss: 0.0915\n",
            "Epoch 3, Sample 15570: Loss: 0.2759\n",
            "Epoch 3, Sample 15571: Loss: 1.0524\n",
            "Epoch 3, Sample 15572: Loss: 0.3758\n",
            "Epoch 3, Sample 15573: Loss: 0.6139\n",
            "Epoch 3, Sample 15574: Loss: 1.0524\n",
            "Epoch 3, Sample 15575: Loss: 0.0018\n",
            "Epoch 3, Sample 15576: Loss: 1.1789\n",
            "Epoch 3, Sample 15577: Loss: 0.1143\n",
            "Epoch 3, Sample 15578: Loss: 0.0039\n",
            "Epoch 3, Sample 15579: Loss: 1.0524\n",
            "Epoch 3, Sample 15580: Loss: 0.2044\n",
            "Epoch 3, Sample 15581: Loss: 0.0062\n",
            "Epoch 3, Sample 15582: Loss: 0.2759\n",
            "Epoch 3, Sample 15583: Loss: 0.0630\n",
            "Epoch 3, Sample 15584: Loss: 0.1170\n",
            "Epoch 3, Sample 15585: Loss: 0.0001\n",
            "Epoch 3, Sample 15586: Loss: 0.2036\n",
            "Epoch 3, Sample 15587: Loss: 0.0018\n",
            "Epoch 3, Sample 15588: Loss: 1.0530\n",
            "Epoch 3, Sample 15589: Loss: 1.0524\n",
            "Epoch 3, Sample 15590: Loss: 1.7297\n",
            "Epoch 3, Sample 15591: Loss: 0.0378\n",
            "Epoch 3, Sample 15592: Loss: 0.0505\n",
            "Epoch 3, Sample 15593: Loss: 0.7637\n",
            "Epoch 3, Sample 15594: Loss: 0.4611\n",
            "Epoch 3, Sample 15595: Loss: 0.0630\n",
            "Epoch 3, Sample 15596: Loss: 1.0524\n",
            "Epoch 3, Sample 15597: Loss: 0.4392\n",
            "Epoch 3, Sample 15598: Loss: 0.6840\n",
            "Epoch 3, Sample 15599: Loss: 0.1248\n",
            "Epoch 3, Sample 15600: Loss: 0.2879\n",
            "Epoch 3, Sample 15601: Loss: 0.2832\n",
            "Epoch 3, Sample 15602: Loss: 0.1482\n",
            "Epoch 3, Sample 15603: Loss: 0.0277\n",
            "Epoch 3, Sample 15604: Loss: 0.9651\n",
            "Epoch 3, Sample 15605: Loss: 0.3247\n",
            "Epoch 3, Sample 15606: Loss: 1.0524\n",
            "Epoch 3, Sample 15607: Loss: 0.1924\n",
            "Epoch 3, Sample 15608: Loss: 1.0524\n",
            "Epoch 3, Sample 15609: Loss: 0.0026\n",
            "Epoch 3, Sample 15610: Loss: 0.4466\n",
            "Epoch 3, Sample 15611: Loss: 1.0524\n",
            "Epoch 3, Sample 15612: Loss: 0.7036\n",
            "Epoch 3, Sample 15613: Loss: 0.2044\n",
            "Epoch 3, Sample 15614: Loss: 0.4996\n",
            "Epoch 3, Sample 15615: Loss: 0.2034\n",
            "Epoch 3, Sample 15616: Loss: 0.4102\n",
            "Epoch 3, Sample 15617: Loss: 0.3661\n",
            "Epoch 3, Sample 15618: Loss: 0.6092\n",
            "Epoch 3, Sample 15619: Loss: 0.2044\n",
            "Epoch 3, Sample 15620: Loss: 0.2032\n",
            "Epoch 3, Sample 15621: Loss: 0.0838\n",
            "Epoch 3, Sample 15622: Loss: 0.1627\n",
            "Epoch 3, Sample 15623: Loss: 0.2639\n",
            "Epoch 3, Sample 15624: Loss: 0.5871\n",
            "Epoch 3, Sample 15625: Loss: 0.9267\n",
            "Epoch 3, Sample 15626: Loss: 0.3399\n",
            "Epoch 3, Sample 15627: Loss: 1.0524\n",
            "Epoch 3, Sample 15628: Loss: 0.0525\n",
            "Epoch 3, Sample 15629: Loss: 0.0044\n",
            "Epoch 3, Sample 15630: Loss: 0.1170\n",
            "Epoch 3, Sample 15631: Loss: 0.1989\n",
            "Epoch 3, Sample 15632: Loss: 0.1559\n",
            "Epoch 3, Sample 15633: Loss: 0.4611\n",
            "Epoch 3, Sample 15634: Loss: 0.4663\n",
            "Epoch 3, Sample 15635: Loss: 0.2032\n",
            "Epoch 3, Sample 15636: Loss: 0.2759\n",
            "Epoch 3, Sample 15637: Loss: 0.1337\n",
            "Epoch 3, Sample 15638: Loss: 0.5989\n",
            "Epoch 3, Sample 15639: Loss: 0.4930\n",
            "Epoch 3, Sample 15640: Loss: 0.2034\n",
            "Epoch 3, Sample 15641: Loss: 1.0524\n",
            "Epoch 3, Sample 15642: Loss: 0.1559\n",
            "Epoch 3, Sample 15643: Loss: 0.5019\n",
            "Epoch 3, Sample 15644: Loss: 1.0155\n",
            "Epoch 3, Sample 15645: Loss: 0.0145\n",
            "Epoch 3, Sample 15646: Loss: 0.3399\n",
            "Epoch 3, Sample 15647: Loss: 0.0938\n",
            "Epoch 3, Sample 15648: Loss: 0.0053\n",
            "Epoch 3, Sample 15649: Loss: 0.1170\n",
            "Epoch 3, Sample 15650: Loss: 0.7036\n",
            "Epoch 3, Sample 15651: Loss: 0.0145\n",
            "Epoch 3, Sample 15652: Loss: 0.7036\n",
            "Epoch 3, Sample 15653: Loss: 0.1170\n",
            "Epoch 3, Sample 15654: Loss: 0.5858\n",
            "Epoch 3, Sample 15655: Loss: 0.5662\n",
            "Epoch 3, Sample 15656: Loss: 0.7036\n",
            "Epoch 3, Sample 15657: Loss: 0.1336\n",
            "Epoch 3, Sample 15658: Loss: 0.0915\n",
            "Epoch 3, Sample 15659: Loss: 0.5000\n",
            "Epoch 3, Sample 15660: Loss: 0.2044\n",
            "Epoch 3, Sample 15661: Loss: 0.1173\n",
            "Epoch 3, Sample 15662: Loss: 0.0253\n",
            "Epoch 3, Sample 15663: Loss: 0.4082\n",
            "Epoch 3, Sample 15664: Loss: 0.4611\n",
            "Epoch 3, Sample 15665: Loss: 0.4740\n",
            "Epoch 3, Sample 15666: Loss: 0.7203\n",
            "Epoch 3, Sample 15667: Loss: 1.0155\n",
            "Epoch 3, Sample 15668: Loss: 1.0266\n",
            "Epoch 3, Sample 15669: Loss: 0.7193\n",
            "Epoch 3, Sample 15670: Loss: 0.0026\n",
            "Epoch 3, Sample 15671: Loss: 0.0972\n",
            "Epoch 3, Sample 15672: Loss: 0.1250\n",
            "Epoch 3, Sample 15673: Loss: 0.2989\n",
            "Epoch 3, Sample 15674: Loss: 0.0025\n",
            "Epoch 3, Sample 15675: Loss: 0.3347\n",
            "Epoch 3, Sample 15676: Loss: 0.4930\n",
            "Epoch 3, Sample 15677: Loss: 1.0524\n",
            "Epoch 3, Sample 15678: Loss: 0.3402\n",
            "Epoch 3, Sample 15679: Loss: 0.2112\n",
            "Epoch 3, Sample 15680: Loss: 1.0524\n",
            "Epoch 3, Sample 15681: Loss: 0.0025\n",
            "Epoch 3, Sample 15682: Loss: 0.3568\n",
            "Epoch 3, Sample 15683: Loss: 0.6333\n",
            "Epoch 3, Sample 15684: Loss: 0.1817\n",
            "Epoch 3, Sample 15685: Loss: 0.1036\n",
            "Epoch 3, Sample 15686: Loss: 1.0146\n",
            "Epoch 3, Sample 15687: Loss: 0.5898\n",
            "Epoch 3, Sample 15688: Loss: 0.1689\n",
            "Epoch 3, Sample 15689: Loss: 0.0079\n",
            "Epoch 3, Sample 15690: Loss: 0.2044\n",
            "Epoch 3, Sample 15691: Loss: 0.1625\n",
            "Epoch 3, Sample 15692: Loss: 0.2044\n",
            "Epoch 3, Sample 15693: Loss: 4.0456\n",
            "Epoch 3, Sample 15694: Loss: 1.0524\n",
            "Epoch 3, Sample 15695: Loss: 0.4550\n",
            "Epoch 3, Sample 15696: Loss: 0.7036\n",
            "Epoch 3, Sample 15697: Loss: 0.7453\n",
            "Epoch 3, Sample 15698: Loss: 0.3399\n",
            "Epoch 3, Sample 15699: Loss: 0.0026\n",
            "Epoch 3, Sample 15700: Loss: 0.0630\n",
            "Epoch 3, Sample 15701: Loss: 0.0026\n",
            "Epoch 3, Sample 15702: Loss: 0.0825\n",
            "Epoch 3, Sample 15703: Loss: 0.3247\n",
            "Epoch 3, Sample 15704: Loss: 0.0625\n",
            "Epoch 3, Sample 15705: Loss: 0.6990\n",
            "Epoch 3, Sample 15706: Loss: 0.3402\n",
            "Epoch 3, Sample 15707: Loss: 0.0079\n",
            "Epoch 3, Sample 15708: Loss: 0.0012\n",
            "Epoch 3, Sample 15709: Loss: 0.0003\n",
            "Epoch 3, Sample 15710: Loss: 0.3441\n",
            "Epoch 3, Sample 15711: Loss: 0.2759\n",
            "Epoch 3, Sample 15712: Loss: 0.7015\n",
            "Epoch 3, Sample 15713: Loss: 0.3320\n",
            "Epoch 3, Sample 15714: Loss: 0.6990\n",
            "Epoch 3, Sample 15715: Loss: 0.3399\n",
            "Epoch 3, Sample 15716: Loss: 0.0000\n",
            "Epoch 3, Sample 15717: Loss: 2.7331\n",
            "Epoch 3, Sample 15718: Loss: 0.1250\n",
            "Epoch 3, Sample 15719: Loss: 1.5582\n",
            "Epoch 3, Sample 15720: Loss: 0.1941\n",
            "Epoch 3, Sample 15721: Loss: 0.2404\n",
            "Epoch 3, Sample 15722: Loss: 0.0306\n",
            "Epoch 3, Sample 15723: Loss: 0.3949\n",
            "Epoch 3, Sample 15724: Loss: 2.9718\n",
            "Epoch 3, Sample 15725: Loss: 0.0221\n",
            "Epoch 3, Sample 15726: Loss: 0.2755\n",
            "Epoch 3, Sample 15727: Loss: 2.5405\n",
            "Epoch 3, Sample 15728: Loss: 1.0155\n",
            "Epoch 3, Sample 15729: Loss: 0.3949\n",
            "Epoch 3, Sample 15730: Loss: 0.6139\n",
            "Epoch 3, Sample 15731: Loss: 0.1559\n",
            "Epoch 3, Sample 15732: Loss: 2.2434\n",
            "Epoch 3, Sample 15733: Loss: 0.3332\n",
            "Epoch 3, Sample 15734: Loss: 0.1170\n",
            "Epoch 3, Sample 15735: Loss: 0.0505\n",
            "Epoch 3, Sample 15736: Loss: 0.2622\n",
            "Epoch 3, Sample 15737: Loss: 0.8951\n",
            "Epoch 3, Sample 15738: Loss: 0.4996\n",
            "Epoch 3, Sample 15739: Loss: 0.2219\n",
            "Epoch 3, Sample 15740: Loss: 0.2032\n",
            "Epoch 3, Sample 15741: Loss: 0.2044\n",
            "Epoch 3, Sample 15742: Loss: 0.4996\n",
            "Epoch 3, Sample 15743: Loss: 0.2219\n",
            "Epoch 3, Sample 15744: Loss: 0.3399\n",
            "Epoch 3, Sample 15745: Loss: 0.0460\n",
            "Epoch 3, Sample 15746: Loss: 0.1559\n",
            "Epoch 3, Sample 15747: Loss: 0.0630\n",
            "Epoch 3, Sample 15748: Loss: 0.1250\n",
            "Epoch 3, Sample 15749: Loss: 0.7486\n",
            "Epoch 3, Sample 15750: Loss: 0.0149\n",
            "Epoch 3, Sample 15751: Loss: 0.2044\n",
            "Epoch 3, Sample 15752: Loss: 0.1559\n",
            "Epoch 3, Sample 15753: Loss: 0.0018\n",
            "Epoch 3, Sample 15754: Loss: 0.0590\n",
            "Epoch 3, Sample 15755: Loss: 0.5000\n",
            "Epoch 3, Sample 15756: Loss: 0.0026\n",
            "Epoch 3, Sample 15757: Loss: 0.0761\n",
            "Epoch 3, Sample 15758: Loss: 0.1246\n",
            "Epoch 3, Sample 15759: Loss: 0.9367\n",
            "Epoch 3, Sample 15760: Loss: 0.1170\n",
            "Epoch 3, Sample 15761: Loss: 0.0601\n",
            "Epoch 3, Sample 15762: Loss: 0.4799\n",
            "Epoch 3, Sample 15763: Loss: 0.7453\n",
            "Epoch 3, Sample 15764: Loss: 0.6990\n",
            "Epoch 3, Sample 15765: Loss: 0.5003\n",
            "Epoch 3, Sample 15766: Loss: 1.0155\n",
            "Epoch 3, Sample 15767: Loss: 1.0524\n",
            "Epoch 3, Sample 15768: Loss: 0.3441\n",
            "Epoch 3, Sample 15769: Loss: 0.1013\n",
            "Epoch 3, Sample 15770: Loss: 0.0042\n",
            "Epoch 3, Sample 15771: Loss: 0.3539\n",
            "Epoch 3, Sample 15772: Loss: 0.6990\n",
            "Epoch 3, Sample 15773: Loss: 0.0042\n",
            "Epoch 3, Sample 15774: Loss: 0.7036\n",
            "Epoch 3, Sample 15775: Loss: 0.5871\n",
            "Epoch 3, Sample 15776: Loss: 0.3949\n",
            "Epoch 3, Sample 15777: Loss: 0.3441\n",
            "Epoch 3, Sample 15778: Loss: 0.0144\n",
            "Epoch 3, Sample 15779: Loss: 1.1569\n",
            "Epoch 3, Sample 15780: Loss: 0.1399\n",
            "Epoch 3, Sample 15781: Loss: 0.7036\n",
            "Epoch 3, Sample 15782: Loss: 0.1968\n",
            "Epoch 3, Sample 15783: Loss: 0.1397\n",
            "Epoch 3, Sample 15784: Loss: 0.8152\n",
            "Epoch 3, Sample 15785: Loss: 0.5003\n",
            "Epoch 3, Sample 15786: Loss: 0.3581\n",
            "Epoch 3, Sample 15787: Loss: 0.2034\n",
            "Epoch 3, Sample 15788: Loss: 1.0530\n",
            "Epoch 3, Sample 15789: Loss: 0.3441\n",
            "Epoch 3, Sample 15790: Loss: 0.1654\n",
            "Epoch 3, Sample 15791: Loss: 0.3399\n",
            "Epoch 3, Sample 15792: Loss: 0.4611\n",
            "Epoch 3, Sample 15793: Loss: 1.0524\n",
            "Epoch 3, Sample 15794: Loss: 1.0524\n",
            "Epoch 3, Sample 15795: Loss: 1.0524\n",
            "Epoch 3, Sample 15796: Loss: 0.0008\n",
            "Epoch 3, Sample 15797: Loss: 0.7486\n",
            "Epoch 3, Sample 15798: Loss: 0.1250\n",
            "Epoch 3, Sample 15799: Loss: 0.6216\n",
            "Epoch 3, Sample 15800: Loss: 1.0524\n",
            "Epoch 3, Sample 15801: Loss: 0.2034\n",
            "Epoch 3, Sample 15802: Loss: 0.3441\n",
            "Epoch 3, Sample 15803: Loss: 0.0838\n",
            "Epoch 3, Sample 15804: Loss: 0.4930\n",
            "Epoch 3, Sample 15805: Loss: 0.1075\n",
            "Epoch 3, Sample 15806: Loss: 1.1599\n",
            "Epoch 3, Sample 15807: Loss: 1.8246\n",
            "Epoch 3, Sample 15808: Loss: 1.0524\n",
            "Epoch 3, Sample 15809: Loss: 0.2010\n",
            "Epoch 3, Sample 15810: Loss: 0.0554\n",
            "Epoch 3, Sample 15811: Loss: 0.7036\n",
            "Epoch 3, Sample 15812: Loss: 0.1625\n",
            "Epoch 3, Sample 15813: Loss: 0.0145\n",
            "Epoch 3, Sample 15814: Loss: 0.2034\n",
            "Epoch 3, Sample 15815: Loss: 0.3441\n",
            "Epoch 3, Sample 15816: Loss: 0.0005\n",
            "Epoch 3, Sample 15817: Loss: 0.0018\n",
            "Epoch 3, Sample 15818: Loss: 0.0212\n",
            "Epoch 3, Sample 15819: Loss: 0.2203\n",
            "Epoch 3, Sample 15820: Loss: 1.7724\n",
            "Epoch 3, Sample 15821: Loss: 0.0892\n",
            "Epoch 3, Sample 15822: Loss: 0.4032\n",
            "Epoch 3, Sample 15823: Loss: 0.2989\n",
            "Epoch 3, Sample 15824: Loss: 0.2340\n",
            "Epoch 3, Sample 15825: Loss: 0.0026\n",
            "Epoch 3, Sample 15826: Loss: 0.0026\n",
            "Epoch 3, Sample 15827: Loss: 0.1403\n",
            "Epoch 3, Sample 15828: Loss: 3.9669\n",
            "Epoch 3, Sample 15829: Loss: 0.0183\n",
            "Epoch 3, Sample 15830: Loss: 0.9367\n",
            "Epoch 3, Sample 15831: Loss: 1.0524\n",
            "Epoch 3, Sample 15832: Loss: 0.2044\n",
            "Epoch 3, Sample 15833: Loss: 0.1170\n",
            "Epoch 3, Sample 15834: Loss: 0.0460\n",
            "Epoch 3, Sample 15835: Loss: 0.2935\n",
            "Epoch 3, Sample 15836: Loss: 0.0907\n",
            "Epoch 3, Sample 15837: Loss: 0.2044\n",
            "Epoch 3, Sample 15838: Loss: 0.2704\n",
            "Epoch 3, Sample 15839: Loss: 0.6139\n",
            "Epoch 3, Sample 15840: Loss: 2.6860\n",
            "Epoch 3, Sample 15841: Loss: 5.4675\n",
            "Epoch 3, Sample 15842: Loss: 0.1250\n",
            "Epoch 3, Sample 15843: Loss: 0.1170\n",
            "Epoch 3, Sample 15844: Loss: 0.0608\n",
            "Epoch 3, Sample 15845: Loss: 0.7036\n",
            "Epoch 3, Sample 15846: Loss: 0.4799\n",
            "Epoch 3, Sample 15847: Loss: 0.1722\n",
            "Epoch 3, Sample 15848: Loss: 0.2759\n",
            "Epoch 3, Sample 15849: Loss: 0.3949\n",
            "Epoch 3, Sample 15850: Loss: 0.3759\n",
            "Epoch 3, Sample 15851: Loss: 0.5020\n",
            "Epoch 3, Sample 15852: Loss: 1.0555\n",
            "Epoch 3, Sample 15853: Loss: 0.0018\n",
            "Epoch 3, Sample 15854: Loss: 0.8951\n",
            "Epoch 3, Sample 15855: Loss: 0.4382\n",
            "Epoch 3, Sample 15856: Loss: 0.3758\n",
            "Epoch 3, Sample 15857: Loss: 0.0018\n",
            "Epoch 3, Sample 15858: Loss: 0.0026\n",
            "Epoch 3, Sample 15859: Loss: 0.4902\n",
            "Epoch 3, Sample 15860: Loss: 0.2034\n",
            "Epoch 3, Sample 15861: Loss: 0.1250\n",
            "Epoch 3, Sample 15862: Loss: 0.3399\n",
            "Epoch 3, Sample 15863: Loss: 0.4415\n",
            "Epoch 3, Sample 15864: Loss: 0.2032\n",
            "Epoch 3, Sample 15865: Loss: 0.9367\n",
            "Epoch 3, Sample 15866: Loss: 0.2036\n",
            "Epoch 3, Sample 15867: Loss: 0.6611\n",
            "Epoch 3, Sample 15868: Loss: 2.1901\n",
            "Epoch 3, Sample 15869: Loss: 0.2032\n",
            "Epoch 3, Sample 15870: Loss: 0.8951\n",
            "Epoch 3, Sample 15871: Loss: 0.1250\n",
            "Epoch 3, Sample 15872: Loss: 0.1470\n",
            "Epoch 3, Sample 15873: Loss: 0.3441\n",
            "Epoch 3, Sample 15874: Loss: 0.1399\n",
            "Epoch 3, Sample 15875: Loss: 0.1807\n",
            "Epoch 3, Sample 15876: Loss: 0.1485\n",
            "Epoch 3, Sample 15877: Loss: 0.2759\n",
            "Epoch 3, Sample 15878: Loss: 0.0026\n",
            "Epoch 3, Sample 15879: Loss: 0.1559\n",
            "Epoch 3, Sample 15880: Loss: 0.1233\n",
            "Epoch 3, Sample 15881: Loss: 0.2034\n",
            "Epoch 3, Sample 15882: Loss: 0.1170\n",
            "Epoch 3, Sample 15883: Loss: 0.0109\n",
            "Epoch 3, Sample 15884: Loss: 0.8951\n",
            "Epoch 3, Sample 15885: Loss: 0.2759\n",
            "Epoch 3, Sample 15886: Loss: 0.1170\n",
            "Epoch 3, Sample 15887: Loss: 0.1170\n",
            "Epoch 3, Sample 15888: Loss: 0.2832\n",
            "Epoch 3, Sample 15889: Loss: 0.2551\n",
            "Epoch 3, Sample 15890: Loss: 0.0292\n",
            "Epoch 3, Sample 15891: Loss: 0.2340\n",
            "Epoch 3, Sample 15892: Loss: 0.0312\n",
            "Epoch 3, Sample 15893: Loss: 0.2044\n",
            "Epoch 3, Sample 15894: Loss: 0.2778\n",
            "Epoch 3, Sample 15895: Loss: 1.0155\n",
            "Epoch 3, Sample 15896: Loss: 0.4799\n",
            "Epoch 3, Sample 15897: Loss: 0.0026\n",
            "Epoch 3, Sample 15898: Loss: 0.0001\n",
            "Epoch 3, Sample 15899: Loss: 1.3580\n",
            "Epoch 3, Sample 15900: Loss: 0.3399\n",
            "Epoch 3, Sample 15901: Loss: 0.6304\n",
            "Epoch 3, Sample 15902: Loss: 1.0760\n",
            "Epoch 3, Sample 15903: Loss: 0.0587\n",
            "Epoch 3, Sample 15904: Loss: 0.5858\n",
            "Epoch 3, Sample 15905: Loss: 0.2034\n",
            "Epoch 3, Sample 15906: Loss: 0.1133\n",
            "Epoch 3, Sample 15907: Loss: 0.6990\n",
            "Epoch 3, Sample 15908: Loss: 0.5858\n",
            "Epoch 3, Sample 15909: Loss: 0.8951\n",
            "Epoch 3, Sample 15910: Loss: 0.2121\n",
            "Epoch 3, Sample 15911: Loss: 0.0625\n",
            "Epoch 3, Sample 15912: Loss: 0.7158\n",
            "Epoch 3, Sample 15913: Loss: 0.0001\n",
            "Epoch 3, Sample 15914: Loss: 10.6930\n",
            "Epoch 3, Sample 15915: Loss: 0.0630\n",
            "Epoch 3, Sample 15916: Loss: 0.0108\n",
            "Epoch 3, Sample 15917: Loss: 0.2032\n",
            "Epoch 3, Sample 15918: Loss: 0.1313\n",
            "Epoch 3, Sample 15919: Loss: 0.1254\n",
            "Epoch 3, Sample 15920: Loss: 0.5196\n",
            "Epoch 3, Sample 15921: Loss: 0.3126\n",
            "Epoch 3, Sample 15922: Loss: 0.7036\n",
            "Epoch 3, Sample 15923: Loss: 0.7036\n",
            "Epoch 3, Sample 15924: Loss: 0.4799\n",
            "Epoch 3, Sample 15925: Loss: 0.0026\n",
            "Epoch 3, Sample 15926: Loss: 0.0014\n",
            "Epoch 3, Sample 15927: Loss: 1.0530\n",
            "Epoch 3, Sample 15928: Loss: 0.0838\n",
            "Epoch 3, Sample 15929: Loss: 0.0000\n",
            "Epoch 3, Sample 15930: Loss: 0.3758\n",
            "Epoch 3, Sample 15931: Loss: 0.0306\n",
            "Epoch 3, Sample 15932: Loss: 0.3450\n",
            "Epoch 3, Sample 15933: Loss: 0.5135\n",
            "Epoch 3, Sample 15934: Loss: 0.0001\n",
            "Epoch 3, Sample 15935: Loss: 0.1995\n",
            "Epoch 3, Sample 15936: Loss: 0.3238\n",
            "Epoch 3, Sample 15937: Loss: 0.5089\n",
            "Epoch 3, Sample 15938: Loss: 0.2388\n",
            "Epoch 3, Sample 15939: Loss: 0.0626\n",
            "Epoch 3, Sample 15940: Loss: 0.6990\n",
            "Epoch 3, Sample 15941: Loss: 1.3937\n",
            "Epoch 3, Sample 15942: Loss: 0.1588\n",
            "Epoch 3, Sample 15943: Loss: 0.2935\n",
            "Epoch 3, Sample 15944: Loss: 0.3399\n",
            "Epoch 3, Sample 15945: Loss: 0.0015\n",
            "Epoch 3, Sample 15946: Loss: 0.1252\n",
            "Epoch 3, Sample 15947: Loss: 0.3961\n",
            "Epoch 3, Sample 15948: Loss: 0.0062\n",
            "Epoch 3, Sample 15949: Loss: 0.0303\n",
            "Epoch 3, Sample 15950: Loss: 0.0376\n",
            "Epoch 3, Sample 15951: Loss: 1.0524\n",
            "Epoch 3, Sample 15952: Loss: 0.2759\n",
            "Epoch 3, Sample 15953: Loss: 0.1627\n",
            "Epoch 3, Sample 15954: Loss: 0.4148\n",
            "Epoch 3, Sample 15955: Loss: 0.3399\n",
            "Epoch 3, Sample 15956: Loss: 0.6867\n",
            "Epoch 3, Sample 15957: Loss: 0.4945\n",
            "Epoch 3, Sample 15958: Loss: 0.0057\n",
            "Epoch 3, Sample 15959: Loss: 0.0262\n",
            "Epoch 3, Sample 15960: Loss: 0.2340\n",
            "Epoch 3, Sample 15961: Loss: 0.6475\n",
            "Epoch 3, Sample 15962: Loss: 0.5855\n",
            "Epoch 3, Sample 15963: Loss: 1.0530\n",
            "Epoch 3, Sample 15964: Loss: 0.4333\n",
            "Epoch 3, Sample 15965: Loss: 0.3979\n",
            "Epoch 3, Sample 15966: Loss: 0.6139\n",
            "Epoch 3, Sample 15967: Loss: 0.2962\n",
            "Epoch 3, Sample 15968: Loss: 0.0490\n",
            "Epoch 3, Sample 15969: Loss: 0.0630\n",
            "Epoch 3, Sample 15970: Loss: 0.1999\n",
            "Epoch 3, Sample 15971: Loss: 0.4422\n",
            "Epoch 3, Sample 15972: Loss: 0.0026\n",
            "Epoch 3, Sample 15973: Loss: 1.1945\n",
            "Epoch 3, Sample 15974: Loss: 0.3399\n",
            "Epoch 3, Sample 15975: Loss: 0.2337\n",
            "Epoch 3, Sample 15976: Loss: 1.0524\n",
            "Epoch 3, Sample 15977: Loss: 0.6867\n",
            "Epoch 3, Sample 15978: Loss: 0.2044\n",
            "Epoch 3, Sample 15979: Loss: 0.0630\n",
            "Epoch 3, Sample 15980: Loss: 0.8951\n",
            "Epoch 3, Sample 15981: Loss: 0.3441\n",
            "Epoch 3, Sample 15982: Loss: 0.3399\n",
            "Epoch 3, Sample 15983: Loss: 1.0524\n",
            "Epoch 3, Sample 15984: Loss: 0.0018\n",
            "Epoch 3, Sample 15985: Loss: 0.8951\n",
            "Epoch 3, Sample 15986: Loss: 0.0002\n",
            "Epoch 3, Sample 15987: Loss: 0.0026\n",
            "Epoch 3, Sample 15988: Loss: 0.0026\n",
            "Epoch 3, Sample 15989: Loss: 1.0155\n",
            "Epoch 3, Sample 15990: Loss: 0.4641\n",
            "Epoch 3, Sample 15991: Loss: 0.0097\n",
            "Epoch 3, Sample 15992: Loss: 0.1219\n",
            "Epoch 3, Sample 15993: Loss: 0.2182\n",
            "Epoch 3, Sample 15994: Loss: 0.1246\n",
            "Epoch 3, Sample 15995: Loss: 0.6139\n",
            "Epoch 3, Sample 15996: Loss: 3.5760\n",
            "Epoch 3, Sample 15997: Loss: 0.0006\n",
            "Epoch 3, Sample 15998: Loss: 0.5972\n",
            "Epoch 3, Sample 15999: Loss: 0.0047\n",
            "Epoch 3, Sample 16000: Loss: 0.6867\n",
            "\n",
            "Epoch 3 Average Loss: 0.5442\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could see that the sixth iteration had the lowest average loss, so we decided to use that one for our test validation"
      ],
      "metadata": {
        "id": "mcDoK4-1yo0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X_test to PyTorch tensor\n",
        "tensor_test_X = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# Convert y_test to PyTorch tensor\n",
        "tensor_test_Y = torch.tensor(y_test, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "Nt8SgO6zgDlV"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets save our trained model\n",
        "# save the trained model\n",
        "torch.save(model_net6, 'model_net6.pkl')"
      ],
      "metadata": {
        "id": "WAbCqa2Ugepc"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   Lets load the model for inference\n",
        "\n",
        "model_net6_trained = torch.load('model_net6.pkl')\n",
        "model_net6_trained.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow7Hpp2rgfhu",
        "outputId": "748a0bdc-51ac-43e1-80fe-69ca9efa22ba"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=20, out_features=70, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Dropout(p=0.33, inplace=False)\n",
              "  (3): Linear(in_features=70, out_features=1, bias=True)\n",
              "  (4): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the parameters of all layers\n",
        "for name, param in model_net6_trained.named_parameters():\n",
        "    print(f\"Layer: {name}\")\n",
        "    print(f\"Size: {param.size()}\")\n",
        "    print(f\"Values: \\n{param.data}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5evz9ewdgkV7",
        "outputId": "559c58ca-e501-418c-e3de-07529eb077d1"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: 0.weight\n",
            "Size: torch.Size([70, 20])\n",
            "Values: \n",
            "tensor([[-0.3908,  0.1770,  0.1061,  ...,  0.1203, -0.1229,  0.1744],\n",
            "        [ 0.0890, -0.5378,  0.0921,  ..., -0.0056, -0.0719,  0.0807],\n",
            "        [ 0.0198,  0.3877, -0.0649,  ..., -0.0637,  0.0533,  0.2519],\n",
            "        ...,\n",
            "        [ 0.0132,  0.7884, -0.0078,  ...,  0.0720,  0.0394,  0.0225],\n",
            "        [ 0.0857,  0.5062,  0.1818,  ...,  0.0779, -0.0653,  0.0943],\n",
            "        [ 0.0963,  0.2689, -0.0769,  ...,  0.1805, -0.1895, -0.0557]])\n",
            "\n",
            "Layer: 0.bias\n",
            "Size: torch.Size([70])\n",
            "Values: \n",
            "tensor([-1.4038e-01, -4.3543e-01, -1.3614e-01, -2.3436e-01,  3.2598e-02,\n",
            "        -3.8732e-01, -4.0747e-01,  2.0155e-02, -4.8901e-01, -5.1958e-01,\n",
            "        -2.3408e-01, -2.1652e-01, -4.7086e-01, -6.7362e-01,  1.5375e-01,\n",
            "         1.7421e-01, -9.2186e-02,  2.5974e-01, -1.3835e-01,  3.3796e-01,\n",
            "        -2.0318e-01, -2.0343e-01, -5.7636e-01,  4.3888e-01,  1.5453e-01,\n",
            "         1.0880e-01,  1.9838e-01,  1.3791e-01,  1.8012e-02,  1.2548e-01,\n",
            "         5.1607e-01, -2.0668e-01, -2.0530e-01, -2.3644e-01,  1.6586e-02,\n",
            "        -1.9917e-01, -2.2955e-01, -4.5474e-01,  4.0579e-04, -2.8462e-01,\n",
            "         1.3094e-01, -2.4288e-02,  2.8275e-01, -4.7127e-01,  2.1889e-01,\n",
            "        -3.1914e-01, -1.5160e-01,  1.5201e-01, -4.7145e-01, -1.2978e-01,\n",
            "        -5.0692e-01,  3.0716e-01, -1.2158e-01,  1.2643e-01, -2.8414e-01,\n",
            "         2.6829e-01, -2.0453e-01, -1.6873e-01, -2.6383e-01, -3.6748e-01,\n",
            "         5.1841e-02,  3.0017e-03, -1.4146e-01,  1.1900e-01,  2.1774e-01,\n",
            "        -2.0079e-01, -2.7595e-01,  3.1767e-01,  2.1799e-01,  2.9271e-02])\n",
            "\n",
            "Layer: 3.weight\n",
            "Size: torch.Size([1, 70])\n",
            "Values: \n",
            "tensor([[-0.2864,  0.1246, -0.1681,  0.0779, -0.2004,  0.1395,  0.1470, -0.2748,\n",
            "          0.0477,  0.1158,  0.0309,  0.0934,  0.1270,  0.1246, -0.2324, -0.0804,\n",
            "         -0.1817, -0.3764, -0.2504, -0.3832,  0.0234, -0.3625,  0.1253, -0.4177,\n",
            "         -0.2460, -0.0593, -0.2967, -0.2214, -0.1871, -0.2794, -0.5524, -0.1698,\n",
            "          0.0531, -0.0750, -0.1554, -0.2832,  0.1826,  0.1150, -0.1923,  0.0138,\n",
            "         -0.2497, -0.2209, -0.3207,  0.1941, -0.1817,  0.0577, -0.2121, -0.3253,\n",
            "          0.0634, -0.0962,  0.0624, -0.2315, -0.0872, -0.2106, -0.1269, -0.4398,\n",
            "          0.0766, -0.0955,  0.0714,  0.2040, -0.2159, -0.2710, -0.1825, -0.2374,\n",
            "         -0.3442,  0.1067,  0.1219, -0.2984, -0.2532, -0.1157]])\n",
            "\n",
            "Layer: 3.bias\n",
            "Size: torch.Size([1])\n",
            "Values: \n",
            "tensor([1.0062])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "with torch.no_grad():\n",
        "    model_net6.eval()  # Set the model to evaluation mode\n",
        "    predictions = model_net6(tensor_test_X)\n",
        "\n",
        "# Print the predictions\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiQmmIvCeJSI",
        "outputId": "96ce0c1b-ce03-4ec7-c405-6af080228501"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.8196],\n",
            "        [1.2584],\n",
            "        [0.0000],\n",
            "        ...,\n",
            "        [1.4436],\n",
            "        [0.0000],\n",
            "        [0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loss = 0.0\n",
        "\n",
        "# Loop over each sample in the test dataset\n",
        "for i in range(tensor_test_X.size(0)):\n",
        "\n",
        "    # 1. Forward Pass\n",
        "    output = model_net6.forward(tensor_test_X[i].reshape(-1))\n",
        "\n",
        "    # 2. Calculate Loss\n",
        "    loss = loss_mse(output, tensor_test_Y[i].reshape(-1))\n",
        "\n",
        "    # Aggregate test loss\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    # Display the loss for the current sample\n",
        "    print(f\"Sample {i+1}: Test Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Calculate and display average test loss\n",
        "test_loss /= tensor_test_X.size(0)\n",
        "print(f\"\\nAverage Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8IhQ_EBlOuJ",
        "outputId": "a11e6372-f1a2-4c55-aeac-b92f7e1be179"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: Test Loss: 0.5792\n",
            "Sample 2: Test Loss: 0.3916\n",
            "Sample 3: Test Loss: 0.0630\n",
            "Sample 4: Test Loss: 0.0026\n",
            "Sample 5: Test Loss: 0.2879\n",
            "Sample 6: Test Loss: 0.0300\n",
            "Sample 7: Test Loss: 0.0205\n",
            "Sample 8: Test Loss: 0.7433\n",
            "Sample 9: Test Loss: 0.3441\n",
            "Sample 10: Test Loss: 0.8951\n",
            "Sample 11: Test Loss: 0.0000\n",
            "Sample 12: Test Loss: 0.2339\n",
            "Sample 13: Test Loss: 0.7036\n",
            "Sample 14: Test Loss: 0.3399\n",
            "Sample 15: Test Loss: 0.2032\n",
            "Sample 16: Test Loss: 0.0234\n",
            "Sample 17: Test Loss: 0.2032\n",
            "Sample 18: Test Loss: 0.2036\n",
            "Sample 19: Test Loss: 0.1559\n",
            "Sample 20: Test Loss: 0.0000\n",
            "Sample 21: Test Loss: 0.0838\n",
            "Sample 22: Test Loss: 1.9666\n",
            "Sample 23: Test Loss: 0.0590\n",
            "Sample 24: Test Loss: 0.3441\n",
            "Sample 25: Test Loss: 0.0018\n",
            "Sample 26: Test Loss: 0.1355\n",
            "Sample 27: Test Loss: 0.3399\n",
            "Sample 28: Test Loss: 0.0610\n",
            "Sample 29: Test Loss: 0.7036\n",
            "Sample 30: Test Loss: 0.5196\n",
            "Sample 31: Test Loss: 0.0364\n",
            "Sample 32: Test Loss: 0.2759\n",
            "Sample 33: Test Loss: 0.7036\n",
            "Sample 34: Test Loss: 0.5550\n",
            "Sample 35: Test Loss: 4.2277\n",
            "Sample 36: Test Loss: 0.0456\n",
            "Sample 37: Test Loss: 0.6440\n",
            "Sample 38: Test Loss: 0.5078\n",
            "Sample 39: Test Loss: 0.2044\n",
            "Sample 40: Test Loss: 0.2044\n",
            "Sample 41: Test Loss: 0.2044\n",
            "Sample 42: Test Loss: 0.1250\n",
            "Sample 43: Test Loss: 0.0915\n",
            "Sample 44: Test Loss: 0.0247\n",
            "Sample 45: Test Loss: 0.2639\n",
            "Sample 46: Test Loss: 0.7036\n",
            "Sample 47: Test Loss: 0.7036\n",
            "Sample 48: Test Loss: 0.3949\n",
            "Sample 49: Test Loss: 0.7036\n",
            "Sample 50: Test Loss: 0.9367\n",
            "Sample 51: Test Loss: 0.3399\n",
            "Sample 52: Test Loss: 0.2036\n",
            "Sample 53: Test Loss: 0.5003\n",
            "Sample 54: Test Loss: 0.3399\n",
            "Sample 55: Test Loss: 0.2716\n",
            "Sample 56: Test Loss: 0.5858\n",
            "Sample 57: Test Loss: 0.4996\n",
            "Sample 58: Test Loss: 0.0407\n",
            "Sample 59: Test Loss: 0.7036\n",
            "Sample 60: Test Loss: 0.2941\n",
            "Sample 61: Test Loss: 0.1588\n",
            "Sample 62: Test Loss: 0.2252\n",
            "Sample 63: Test Loss: 0.0460\n",
            "Sample 64: Test Loss: 0.0632\n",
            "Sample 65: Test Loss: 0.6990\n",
            "Sample 66: Test Loss: 0.3399\n",
            "Sample 67: Test Loss: 0.4663\n",
            "Sample 68: Test Loss: 0.0270\n",
            "Sample 69: Test Loss: 0.3669\n",
            "Sample 70: Test Loss: 0.3037\n",
            "Sample 71: Test Loss: 0.0018\n",
            "Sample 72: Test Loss: 0.8360\n",
            "Sample 73: Test Loss: 1.0524\n",
            "Sample 74: Test Loss: 0.1250\n",
            "Sample 75: Test Loss: 0.2034\n",
            "Sample 76: Test Loss: 0.2759\n",
            "Sample 77: Test Loss: 0.2112\n",
            "Sample 78: Test Loss: 0.0116\n",
            "Sample 79: Test Loss: 0.5196\n",
            "Sample 80: Test Loss: 1.0524\n",
            "Sample 81: Test Loss: 0.0617\n",
            "Sample 82: Test Loss: 1.0155\n",
            "Sample 83: Test Loss: 13.7029\n",
            "Sample 84: Test Loss: 1.2926\n",
            "Sample 85: Test Loss: 0.2032\n",
            "Sample 86: Test Loss: 0.3399\n",
            "Sample 87: Test Loss: 0.3450\n",
            "Sample 88: Test Loss: 0.0625\n",
            "Sample 89: Test Loss: 1.0524\n",
            "Sample 90: Test Loss: 0.6499\n",
            "Sample 91: Test Loss: 0.0915\n",
            "Sample 92: Test Loss: 0.0306\n",
            "Sample 93: Test Loss: 0.7036\n",
            "Sample 94: Test Loss: 0.6852\n",
            "Sample 95: Test Loss: 1.0037\n",
            "Sample 96: Test Loss: 0.2725\n",
            "Sample 97: Test Loss: 0.2759\n",
            "Sample 98: Test Loss: 1.5542\n",
            "Sample 99: Test Loss: 0.5858\n",
            "Sample 100: Test Loss: 0.0026\n",
            "Sample 101: Test Loss: 0.0205\n",
            "Sample 102: Test Loss: 0.3949\n",
            "Sample 103: Test Loss: 1.0155\n",
            "Sample 104: Test Loss: 0.0829\n",
            "Sample 105: Test Loss: 0.2699\n",
            "Sample 106: Test Loss: 1.6802\n",
            "Sample 107: Test Loss: 0.0823\n",
            "Sample 108: Test Loss: 0.1170\n",
            "Sample 109: Test Loss: 0.4042\n",
            "Sample 110: Test Loss: 2.3027\n",
            "Sample 111: Test Loss: 0.2034\n",
            "Sample 112: Test Loss: 0.7453\n",
            "Sample 113: Test Loss: 0.0168\n",
            "Sample 114: Test Loss: 0.2034\n",
            "Sample 115: Test Loss: 0.1246\n",
            "Sample 116: Test Loss: 0.2068\n",
            "Sample 117: Test Loss: 1.0530\n",
            "Sample 118: Test Loss: 0.1104\n",
            "Sample 119: Test Loss: 0.1399\n",
            "Sample 120: Test Loss: 1.2296\n",
            "Sample 121: Test Loss: 1.0155\n",
            "Sample 122: Test Loss: 0.2970\n",
            "Sample 123: Test Loss: 0.2750\n",
            "Sample 124: Test Loss: 0.0315\n",
            "Sample 125: Test Loss: 0.0063\n",
            "Sample 126: Test Loss: 0.0026\n",
            "Sample 127: Test Loss: 0.4126\n",
            "Sample 128: Test Loss: 1.0155\n",
            "Sample 129: Test Loss: 0.0262\n",
            "Sample 130: Test Loss: 0.9785\n",
            "Sample 131: Test Loss: 0.0025\n",
            "Sample 132: Test Loss: 0.2840\n",
            "Sample 133: Test Loss: 0.1397\n",
            "Sample 134: Test Loss: 0.0334\n",
            "Sample 135: Test Loss: 0.0018\n",
            "Sample 136: Test Loss: 0.3457\n",
            "Sample 137: Test Loss: 0.0006\n",
            "Sample 138: Test Loss: 0.2044\n",
            "Sample 139: Test Loss: 0.2034\n",
            "Sample 140: Test Loss: 0.2034\n",
            "Sample 141: Test Loss: 0.3332\n",
            "Sample 142: Test Loss: 0.2044\n",
            "Sample 143: Test Loss: 1.0524\n",
            "Sample 144: Test Loss: 0.0000\n",
            "Sample 145: Test Loss: 0.4550\n",
            "Sample 146: Test Loss: 0.2044\n",
            "Sample 147: Test Loss: 0.5003\n",
            "Sample 148: Test Loss: 0.0001\n",
            "Sample 149: Test Loss: 0.3949\n",
            "Sample 150: Test Loss: 0.1327\n",
            "Sample 151: Test Loss: 0.7453\n",
            "Sample 152: Test Loss: 0.0026\n",
            "Sample 153: Test Loss: 0.0180\n",
            "Sample 154: Test Loss: 0.4930\n",
            "Sample 155: Test Loss: 0.2759\n",
            "Sample 156: Test Loss: 1.0530\n",
            "Sample 157: Test Loss: 0.0026\n",
            "Sample 158: Test Loss: 2.2791\n",
            "Sample 159: Test Loss: 0.4761\n",
            "Sample 160: Test Loss: 1.0524\n",
            "Sample 161: Test Loss: 2.3988\n",
            "Sample 162: Test Loss: 0.0040\n",
            "Sample 163: Test Loss: 0.4930\n",
            "Sample 164: Test Loss: 0.0287\n",
            "Sample 165: Test Loss: 0.3949\n",
            "Sample 166: Test Loss: 0.8951\n",
            "Sample 167: Test Loss: 0.2034\n",
            "Sample 168: Test Loss: 5.7427\n",
            "Sample 169: Test Loss: 0.0025\n",
            "Sample 170: Test Loss: 1.0530\n",
            "Sample 171: Test Loss: 0.4018\n",
            "Sample 172: Test Loss: 0.2032\n",
            "Sample 173: Test Loss: 0.7153\n",
            "Sample 174: Test Loss: 0.3651\n",
            "Sample 175: Test Loss: 0.3949\n",
            "Sample 176: Test Loss: 0.0008\n",
            "Sample 177: Test Loss: 0.2044\n",
            "Sample 178: Test Loss: 0.7036\n",
            "Sample 179: Test Loss: 0.7036\n",
            "Sample 180: Test Loss: 0.0018\n",
            "Sample 181: Test Loss: 0.2032\n",
            "Sample 182: Test Loss: 0.0018\n",
            "Sample 183: Test Loss: 0.3441\n",
            "Sample 184: Test Loss: 0.5858\n",
            "Sample 185: Test Loss: 0.7036\n",
            "Sample 186: Test Loss: 0.0220\n",
            "Sample 187: Test Loss: 0.8632\n",
            "Sample 188: Test Loss: 1.0530\n",
            "Sample 189: Test Loss: 0.5378\n",
            "Sample 190: Test Loss: 0.0392\n",
            "Sample 191: Test Loss: 1.0155\n",
            "Sample 192: Test Loss: 0.0258\n",
            "Sample 193: Test Loss: 0.0022\n",
            "Sample 194: Test Loss: 0.4841\n",
            "Sample 195: Test Loss: 0.0026\n",
            "Sample 196: Test Loss: 0.0142\n",
            "Sample 197: Test Loss: 0.0026\n",
            "Sample 198: Test Loss: 1.0530\n",
            "Sample 199: Test Loss: 0.5058\n",
            "Sample 200: Test Loss: 1.7588\n",
            "Sample 201: Test Loss: 0.2034\n",
            "Sample 202: Test Loss: 1.0524\n",
            "Sample 203: Test Loss: 1.0755\n",
            "Sample 204: Test Loss: 0.4074\n",
            "Sample 205: Test Loss: 2.2715\n",
            "Sample 206: Test Loss: 1.0524\n",
            "Sample 207: Test Loss: 0.0290\n",
            "Sample 208: Test Loss: 1.0524\n",
            "Sample 209: Test Loss: 0.2759\n",
            "Sample 210: Test Loss: 0.5196\n",
            "Sample 211: Test Loss: 3.2578\n",
            "Sample 212: Test Loss: 0.2044\n",
            "Sample 213: Test Loss: 2.5454\n",
            "Sample 214: Test Loss: 0.3949\n",
            "Sample 215: Test Loss: 1.8989\n",
            "Sample 216: Test Loss: 0.2044\n",
            "Sample 217: Test Loss: 0.0915\n",
            "Sample 218: Test Loss: 1.0155\n",
            "Sample 219: Test Loss: 0.2456\n",
            "Sample 220: Test Loss: 0.2044\n",
            "Sample 221: Test Loss: 0.0375\n",
            "Sample 222: Test Loss: 0.7036\n",
            "Sample 223: Test Loss: 0.2044\n",
            "Sample 224: Test Loss: 0.1724\n",
            "Sample 225: Test Loss: 0.5364\n",
            "Sample 226: Test Loss: 5.4577\n",
            "Sample 227: Test Loss: 1.0155\n",
            "Sample 228: Test Loss: 0.0212\n",
            "Sample 229: Test Loss: 0.1131\n",
            "Sample 230: Test Loss: 3.3543\n",
            "Sample 231: Test Loss: 0.5871\n",
            "Sample 232: Test Loss: 0.5972\n",
            "Sample 233: Test Loss: 0.6779\n",
            "Sample 234: Test Loss: 0.9960\n",
            "Sample 235: Test Loss: 0.3949\n",
            "Sample 236: Test Loss: 0.0883\n",
            "Sample 237: Test Loss: 0.1057\n",
            "Sample 238: Test Loss: 0.0084\n",
            "Sample 239: Test Loss: 0.9367\n",
            "Sample 240: Test Loss: 0.3441\n",
            "Sample 241: Test Loss: 0.2832\n",
            "Sample 242: Test Loss: 1.0524\n",
            "Sample 243: Test Loss: 0.2230\n",
            "Sample 244: Test Loss: 0.0026\n",
            "Sample 245: Test Loss: 0.6610\n",
            "Sample 246: Test Loss: 0.5000\n",
            "Sample 247: Test Loss: 0.0363\n",
            "Sample 248: Test Loss: 1.0155\n",
            "Sample 249: Test Loss: 0.0573\n",
            "Sample 250: Test Loss: 0.2034\n",
            "Sample 251: Test Loss: 0.0005\n",
            "Sample 252: Test Loss: 0.1250\n",
            "Sample 253: Test Loss: 0.0899\n",
            "Sample 254: Test Loss: 0.7453\n",
            "Sample 255: Test Loss: 0.2014\n",
            "Sample 256: Test Loss: 0.1250\n",
            "Sample 257: Test Loss: 1.0524\n",
            "Sample 258: Test Loss: 0.7036\n",
            "Sample 259: Test Loss: 0.2036\n",
            "Sample 260: Test Loss: 0.0414\n",
            "Sample 261: Test Loss: 31.8372\n",
            "Sample 262: Test Loss: 0.2044\n",
            "Sample 263: Test Loss: 0.5871\n",
            "Sample 264: Test Loss: 1.7162\n",
            "Sample 265: Test Loss: 0.0306\n",
            "Sample 266: Test Loss: 1.4064\n",
            "Sample 267: Test Loss: 0.3949\n",
            "Sample 268: Test Loss: 0.6259\n",
            "Sample 269: Test Loss: 0.0630\n",
            "Sample 270: Test Loss: 0.1250\n",
            "Sample 271: Test Loss: 0.0626\n",
            "Sample 272: Test Loss: 0.0005\n",
            "Sample 273: Test Loss: 1.0524\n",
            "Sample 274: Test Loss: 5.0976\n",
            "Sample 275: Test Loss: 0.2034\n",
            "Sample 276: Test Loss: 0.0001\n",
            "Sample 277: Test Loss: 0.3399\n",
            "Sample 278: Test Loss: 0.7036\n",
            "Sample 279: Test Loss: 0.2044\n",
            "Sample 280: Test Loss: 0.7036\n",
            "Sample 281: Test Loss: 0.0258\n",
            "Sample 282: Test Loss: 0.6304\n",
            "Sample 283: Test Loss: 0.0014\n",
            "Sample 284: Test Loss: 0.1336\n",
            "Sample 285: Test Loss: 0.2034\n",
            "Sample 286: Test Loss: 0.7398\n",
            "Sample 287: Test Loss: 0.0069\n",
            "Sample 288: Test Loss: 0.0514\n",
            "Sample 289: Test Loss: 0.4139\n",
            "Sample 290: Test Loss: 1.0524\n",
            "Sample 291: Test Loss: 0.2044\n",
            "Sample 292: Test Loss: 0.5636\n",
            "Sample 293: Test Loss: 0.0212\n",
            "Sample 294: Test Loss: 0.0915\n",
            "Sample 295: Test Loss: 0.4799\n",
            "Sample 296: Test Loss: 1.3820\n",
            "Sample 297: Test Loss: 0.0513\n",
            "Sample 298: Test Loss: 0.0838\n",
            "Sample 299: Test Loss: 0.5972\n",
            "Sample 300: Test Loss: 1.0530\n",
            "Sample 301: Test Loss: 0.3399\n",
            "Sample 302: Test Loss: 0.5972\n",
            "Sample 303: Test Loss: 0.7036\n",
            "Sample 304: Test Loss: 0.8951\n",
            "Sample 305: Test Loss: 0.2034\n",
            "Sample 306: Test Loss: 0.4432\n",
            "Sample 307: Test Loss: 0.7036\n",
            "Sample 308: Test Loss: 0.0006\n",
            "Sample 309: Test Loss: 0.2213\n",
            "Sample 310: Test Loss: 0.3441\n",
            "Sample 311: Test Loss: 0.0407\n",
            "Sample 312: Test Loss: 0.2970\n",
            "Sample 313: Test Loss: 0.0123\n",
            "Sample 314: Test Loss: 0.0018\n",
            "Sample 315: Test Loss: 0.8951\n",
            "Sample 316: Test Loss: 0.2182\n",
            "Sample 317: Test Loss: 0.3402\n",
            "Sample 318: Test Loss: 0.2044\n",
            "Sample 319: Test Loss: 0.2044\n",
            "Sample 320: Test Loss: 0.2759\n",
            "Sample 321: Test Loss: 0.3949\n",
            "Sample 322: Test Loss: 0.0630\n",
            "Sample 323: Test Loss: 0.8951\n",
            "Sample 324: Test Loss: 0.6981\n",
            "Sample 325: Test Loss: 0.5858\n",
            "Sample 326: Test Loss: 0.3399\n",
            "Sample 327: Test Loss: 1.7855\n",
            "Sample 328: Test Loss: 0.2032\n",
            "Sample 329: Test Loss: 0.0838\n",
            "Sample 330: Test Loss: 0.0026\n",
            "Sample 331: Test Loss: 0.0018\n",
            "Sample 332: Test Loss: 0.6990\n",
            "Sample 333: Test Loss: 0.1122\n",
            "Sample 334: Test Loss: 0.0026\n",
            "Sample 335: Test Loss: 0.5858\n",
            "Sample 336: Test Loss: 0.1364\n",
            "Sample 337: Test Loss: 0.2941\n",
            "Sample 338: Test Loss: 0.0632\n",
            "Sample 339: Test Loss: 0.1523\n",
            "Sample 340: Test Loss: 0.0102\n",
            "Sample 341: Test Loss: 0.8951\n",
            "Sample 342: Test Loss: 0.2864\n",
            "Sample 343: Test Loss: 0.5799\n",
            "Sample 344: Test Loss: 0.4032\n",
            "Sample 345: Test Loss: 0.5858\n",
            "Sample 346: Test Loss: 0.3450\n",
            "Sample 347: Test Loss: 0.0398\n",
            "Sample 348: Test Loss: 0.2044\n",
            "Sample 349: Test Loss: 0.6930\n",
            "Sample 350: Test Loss: 0.2459\n",
            "Sample 351: Test Loss: 0.0026\n",
            "Sample 352: Test Loss: 0.1341\n",
            "Sample 353: Test Loss: 0.0026\n",
            "Sample 354: Test Loss: 0.6304\n",
            "Sample 355: Test Loss: 0.2832\n",
            "Sample 356: Test Loss: 0.2034\n",
            "Sample 357: Test Loss: 0.2036\n",
            "Sample 358: Test Loss: 1.0155\n",
            "Sample 359: Test Loss: 1.0155\n",
            "Sample 360: Test Loss: 0.0000\n",
            "Sample 361: Test Loss: 0.3441\n",
            "Sample 362: Test Loss: 0.4382\n",
            "Sample 363: Test Loss: 0.0630\n",
            "Sample 364: Test Loss: 0.3399\n",
            "Sample 365: Test Loss: 0.0026\n",
            "Sample 366: Test Loss: 0.3399\n",
            "Sample 367: Test Loss: 0.5893\n",
            "Sample 368: Test Loss: 0.2034\n",
            "Sample 369: Test Loss: 0.2032\n",
            "Sample 370: Test Loss: 0.7036\n",
            "Sample 371: Test Loss: 0.2032\n",
            "Sample 372: Test Loss: 0.0018\n",
            "Sample 373: Test Loss: 0.1546\n",
            "Sample 374: Test Loss: 3.4424\n",
            "Sample 375: Test Loss: 0.2044\n",
            "Sample 376: Test Loss: 0.2044\n",
            "Sample 377: Test Loss: 1.1386\n",
            "Sample 378: Test Loss: 0.2044\n",
            "Sample 379: Test Loss: 0.5972\n",
            "Sample 380: Test Loss: 0.0001\n",
            "Sample 381: Test Loss: 0.3441\n",
            "Sample 382: Test Loss: 0.3399\n",
            "Sample 383: Test Loss: 0.0116\n",
            "Sample 384: Test Loss: 0.4809\n",
            "Sample 385: Test Loss: 0.6990\n",
            "Sample 386: Test Loss: 0.4761\n",
            "Sample 387: Test Loss: 0.2032\n",
            "Sample 388: Test Loss: 1.0524\n",
            "Sample 389: Test Loss: 0.1170\n",
            "Sample 390: Test Loss: 0.0630\n",
            "Sample 391: Test Loss: 0.7747\n",
            "Sample 392: Test Loss: 1.0524\n",
            "Sample 393: Test Loss: 0.5056\n",
            "Sample 394: Test Loss: 1.3772\n",
            "Sample 395: Test Loss: 0.2219\n",
            "Sample 396: Test Loss: 0.7036\n",
            "Sample 397: Test Loss: 0.1633\n",
            "Sample 398: Test Loss: 0.2032\n",
            "Sample 399: Test Loss: 1.0524\n",
            "Sample 400: Test Loss: 1.0524\n",
            "Sample 401: Test Loss: 0.6990\n",
            "Sample 402: Test Loss: 0.0001\n",
            "Sample 403: Test Loss: 0.3441\n",
            "Sample 404: Test Loss: 0.0072\n",
            "Sample 405: Test Loss: 1.0530\n",
            "Sample 406: Test Loss: 0.0964\n",
            "Sample 407: Test Loss: 0.2084\n",
            "Sample 408: Test Loss: 0.8217\n",
            "Sample 409: Test Loss: 1.0524\n",
            "Sample 410: Test Loss: 0.3734\n",
            "Sample 411: Test Loss: 1.0530\n",
            "Sample 412: Test Loss: 0.2034\n",
            "Sample 413: Test Loss: 1.0530\n",
            "Sample 414: Test Loss: 0.2865\n",
            "Sample 415: Test Loss: 1.1046\n",
            "Sample 416: Test Loss: 0.4588\n",
            "Sample 417: Test Loss: 0.6990\n",
            "Sample 418: Test Loss: 1.0155\n",
            "Sample 419: Test Loss: 0.7486\n",
            "Sample 420: Test Loss: 0.1170\n",
            "Sample 421: Test Loss: 1.4559\n",
            "Sample 422: Test Loss: 0.7036\n",
            "Sample 423: Test Loss: 0.2032\n",
            "Sample 424: Test Loss: 1.0524\n",
            "Sample 425: Test Loss: 0.2436\n",
            "Sample 426: Test Loss: 1.0524\n",
            "Sample 427: Test Loss: 0.8401\n",
            "Sample 428: Test Loss: 0.0000\n",
            "Sample 429: Test Loss: 0.2759\n",
            "Sample 430: Test Loss: 0.0347\n",
            "Sample 431: Test Loss: 0.0018\n",
            "Sample 432: Test Loss: 0.7735\n",
            "Sample 433: Test Loss: 8.6480\n",
            "Sample 434: Test Loss: 0.1890\n",
            "Sample 435: Test Loss: 0.2034\n",
            "Sample 436: Test Loss: 0.3399\n",
            "Sample 437: Test Loss: 0.0505\n",
            "Sample 438: Test Loss: 0.1516\n",
            "Sample 439: Test Loss: 0.0001\n",
            "Sample 440: Test Loss: 0.6990\n",
            "Sample 441: Test Loss: 0.1170\n",
            "Sample 442: Test Loss: 0.9239\n",
            "Sample 443: Test Loss: 0.1491\n",
            "Sample 444: Test Loss: 1.0524\n",
            "Sample 445: Test Loss: 8.0137\n",
            "Sample 446: Test Loss: 0.2032\n",
            "Sample 447: Test Loss: 0.0838\n",
            "Sample 448: Test Loss: 0.0001\n",
            "Sample 449: Test Loss: 1.0524\n",
            "Sample 450: Test Loss: 0.2032\n",
            "Sample 451: Test Loss: 0.3450\n",
            "Sample 452: Test Loss: 0.6304\n",
            "Sample 453: Test Loss: 0.5320\n",
            "Sample 454: Test Loss: 0.3408\n",
            "Sample 455: Test Loss: 0.3967\n",
            "Sample 456: Test Loss: 1.0691\n",
            "Sample 457: Test Loss: 0.0038\n",
            "Sample 458: Test Loss: 0.0234\n",
            "Sample 459: Test Loss: 0.4139\n",
            "Sample 460: Test Loss: 0.2016\n",
            "Sample 461: Test Loss: 0.6970\n",
            "Sample 462: Test Loss: 1.6086\n",
            "Sample 463: Test Loss: 0.5028\n",
            "Sample 464: Test Loss: 0.3399\n",
            "Sample 465: Test Loss: 0.2989\n",
            "Sample 466: Test Loss: 0.3441\n",
            "Sample 467: Test Loss: 1.0530\n",
            "Sample 468: Test Loss: 0.3441\n",
            "Sample 469: Test Loss: 0.1588\n",
            "Sample 470: Test Loss: 0.2032\n",
            "Sample 471: Test Loss: 0.0026\n",
            "Sample 472: Test Loss: 0.8951\n",
            "Sample 473: Test Loss: 0.0152\n",
            "Sample 474: Test Loss: 0.2286\n",
            "Sample 475: Test Loss: 0.3568\n",
            "Sample 476: Test Loss: 1.0524\n",
            "Sample 477: Test Loss: 0.4283\n",
            "Sample 478: Test Loss: 0.7036\n",
            "Sample 479: Test Loss: 0.2044\n",
            "Sample 480: Test Loss: 0.0595\n",
            "Sample 481: Test Loss: 0.0391\n",
            "Sample 482: Test Loss: 0.7892\n",
            "Sample 483: Test Loss: 0.0560\n",
            "Sample 484: Test Loss: 1.0530\n",
            "Sample 485: Test Loss: 0.0026\n",
            "Sample 486: Test Loss: 0.2340\n",
            "Sample 487: Test Loss: 0.0150\n",
            "Sample 488: Test Loss: 0.0018\n",
            "Sample 489: Test Loss: 0.1225\n",
            "Sample 490: Test Loss: 0.2962\n",
            "Sample 491: Test Loss: 0.2219\n",
            "Sample 492: Test Loss: 0.0953\n",
            "Sample 493: Test Loss: 1.1919\n",
            "Sample 494: Test Loss: 0.0000\n",
            "Sample 495: Test Loss: 0.0018\n",
            "Sample 496: Test Loss: 0.0382\n",
            "Sample 497: Test Loss: 0.1559\n",
            "Sample 498: Test Loss: 10.2273\n",
            "Sample 499: Test Loss: 0.3399\n",
            "Sample 500: Test Loss: 0.1535\n",
            "Sample 501: Test Loss: 0.0026\n",
            "Sample 502: Test Loss: 1.6184\n",
            "Sample 503: Test Loss: 0.5858\n",
            "Sample 504: Test Loss: 0.3949\n",
            "Sample 505: Test Loss: 0.0838\n",
            "Sample 506: Test Loss: 0.2032\n",
            "Sample 507: Test Loss: 0.1562\n",
            "Sample 508: Test Loss: 0.7453\n",
            "Sample 509: Test Loss: 1.0524\n",
            "Sample 510: Test Loss: 0.0630\n",
            "Sample 511: Test Loss: 0.4160\n",
            "Sample 512: Test Loss: 0.5000\n",
            "Sample 513: Test Loss: 0.0032\n",
            "Sample 514: Test Loss: 0.0018\n",
            "Sample 515: Test Loss: 0.0103\n",
            "Sample 516: Test Loss: 0.1559\n",
            "Sample 517: Test Loss: 0.0212\n",
            "Sample 518: Test Loss: 0.0505\n",
            "Sample 519: Test Loss: 0.8951\n",
            "Sample 520: Test Loss: 0.0838\n",
            "Sample 521: Test Loss: 0.3031\n",
            "Sample 522: Test Loss: 0.2639\n",
            "Sample 523: Test Loss: 0.0523\n",
            "Sample 524: Test Loss: 0.0731\n",
            "Sample 525: Test Loss: 0.2044\n",
            "Sample 526: Test Loss: 0.2846\n",
            "Sample 527: Test Loss: 0.2032\n",
            "Sample 528: Test Loss: 0.2292\n",
            "Sample 529: Test Loss: 0.0270\n",
            "Sample 530: Test Loss: 0.3249\n",
            "Sample 531: Test Loss: 0.0682\n",
            "Sample 532: Test Loss: 0.0026\n",
            "Sample 533: Test Loss: 0.4270\n",
            "Sample 534: Test Loss: 1.0530\n",
            "Sample 535: Test Loss: 1.0530\n",
            "Sample 536: Test Loss: 7.6534\n",
            "Sample 537: Test Loss: 0.2044\n",
            "Sample 538: Test Loss: 0.0108\n",
            "Sample 539: Test Loss: 3.2010\n",
            "Sample 540: Test Loss: 0.0915\n",
            "Sample 541: Test Loss: 0.0188\n",
            "Sample 542: Test Loss: 0.3568\n",
            "Sample 543: Test Loss: 0.0258\n",
            "Sample 544: Test Loss: 1.0524\n",
            "Sample 545: Test Loss: 0.7453\n",
            "Sample 546: Test Loss: 0.3758\n",
            "Sample 547: Test Loss: 1.0530\n",
            "Sample 548: Test Loss: 0.1924\n",
            "Sample 549: Test Loss: 0.1366\n",
            "Sample 550: Test Loss: 0.2759\n",
            "Sample 551: Test Loss: 0.0116\n",
            "Sample 552: Test Loss: 1.0524\n",
            "Sample 553: Test Loss: 0.0005\n",
            "Sample 554: Test Loss: 0.2044\n",
            "Sample 555: Test Loss: 0.0070\n",
            "Sample 556: Test Loss: 0.7036\n",
            "Sample 557: Test Loss: 0.4306\n",
            "Sample 558: Test Loss: 0.0025\n",
            "Sample 559: Test Loss: 0.3399\n",
            "Sample 560: Test Loss: 1.0524\n",
            "Sample 561: Test Loss: 0.0915\n",
            "Sample 562: Test Loss: 0.3399\n",
            "Sample 563: Test Loss: 0.2832\n",
            "Sample 564: Test Loss: 12.2125\n",
            "Sample 565: Test Loss: 0.1625\n",
            "Sample 566: Test Loss: 0.0026\n",
            "Sample 567: Test Loss: 0.1559\n",
            "Sample 568: Test Loss: 0.1559\n",
            "Sample 569: Test Loss: 0.0205\n",
            "Sample 570: Test Loss: 0.0018\n",
            "Sample 571: Test Loss: 1.0524\n",
            "Sample 572: Test Loss: 1.4897\n",
            "Sample 573: Test Loss: 0.3681\n",
            "Sample 574: Test Loss: 0.0013\n",
            "Sample 575: Test Loss: 0.2513\n",
            "Sample 576: Test Loss: 0.3949\n",
            "Sample 577: Test Loss: 0.9367\n",
            "Sample 578: Test Loss: 0.2044\n",
            "Sample 579: Test Loss: 0.2044\n",
            "Sample 580: Test Loss: 0.2036\n",
            "Sample 581: Test Loss: 0.0062\n",
            "Sample 582: Test Loss: 0.0258\n",
            "Sample 583: Test Loss: 0.2776\n",
            "Sample 584: Test Loss: 1.0530\n",
            "Sample 585: Test Loss: 0.7036\n",
            "Sample 586: Test Loss: 0.0108\n",
            "Sample 587: Test Loss: 0.1067\n",
            "Sample 588: Test Loss: 0.0026\n",
            "Sample 589: Test Loss: 1.0524\n",
            "Sample 590: Test Loss: 0.0379\n",
            "Sample 591: Test Loss: 0.0026\n",
            "Sample 592: Test Loss: 0.0023\n",
            "Sample 593: Test Loss: 0.7036\n",
            "Sample 594: Test Loss: 1.0359\n",
            "Sample 595: Test Loss: 0.3949\n",
            "Sample 596: Test Loss: 0.0493\n",
            "Sample 597: Test Loss: 0.2044\n",
            "Sample 598: Test Loss: 0.0150\n",
            "Sample 599: Test Loss: 0.4032\n",
            "Sample 600: Test Loss: 0.0626\n",
            "Sample 601: Test Loss: 0.2032\n",
            "Sample 602: Test Loss: 0.6867\n",
            "Sample 603: Test Loss: 1.0524\n",
            "Sample 604: Test Loss: 0.0084\n",
            "Sample 605: Test Loss: 0.1807\n",
            "Sample 606: Test Loss: 0.3402\n",
            "Sample 607: Test Loss: 0.3399\n",
            "Sample 608: Test Loss: 0.5972\n",
            "Sample 609: Test Loss: 0.2340\n",
            "Sample 610: Test Loss: 1.0524\n",
            "Sample 611: Test Loss: 1.5666\n",
            "Sample 612: Test Loss: 0.1118\n",
            "Sample 613: Test Loss: 0.0008\n",
            "Sample 614: Test Loss: 0.1482\n",
            "Sample 615: Test Loss: 0.1250\n",
            "Sample 616: Test Loss: 1.0524\n",
            "Sample 617: Test Loss: 0.4607\n",
            "Sample 618: Test Loss: 0.0938\n",
            "Sample 619: Test Loss: 0.8951\n",
            "Sample 620: Test Loss: 3.5639\n",
            "Sample 621: Test Loss: 0.3166\n",
            "Sample 622: Test Loss: 0.2032\n",
            "Sample 623: Test Loss: 1.0524\n",
            "Sample 624: Test Loss: 0.5858\n",
            "Sample 625: Test Loss: 0.1252\n",
            "Sample 626: Test Loss: 0.2044\n",
            "Sample 627: Test Loss: 1.0524\n",
            "Sample 628: Test Loss: 0.0630\n",
            "Sample 629: Test Loss: 0.7036\n",
            "Sample 630: Test Loss: 0.1337\n",
            "Sample 631: Test Loss: 0.0025\n",
            "Sample 632: Test Loss: 1.0524\n",
            "Sample 633: Test Loss: 1.6363\n",
            "Sample 634: Test Loss: 0.0026\n",
            "Sample 635: Test Loss: 0.0502\n",
            "Sample 636: Test Loss: 0.1508\n",
            "Sample 637: Test Loss: 0.0018\n",
            "Sample 638: Test Loss: 1.0524\n",
            "Sample 639: Test Loss: 0.3949\n",
            "Sample 640: Test Loss: 0.0147\n",
            "Sample 641: Test Loss: 0.0234\n",
            "Sample 642: Test Loss: 0.0060\n",
            "Sample 643: Test Loss: 0.0750\n",
            "Sample 644: Test Loss: 0.5799\n",
            "Sample 645: Test Loss: 0.3441\n",
            "Sample 646: Test Loss: 0.0145\n",
            "Sample 647: Test Loss: 0.6981\n",
            "Sample 648: Test Loss: 0.3332\n",
            "Sample 649: Test Loss: 0.6572\n",
            "Sample 650: Test Loss: 0.7036\n",
            "Sample 651: Test Loss: 0.2975\n",
            "Sample 652: Test Loss: 0.7036\n",
            "Sample 653: Test Loss: 0.0359\n",
            "Sample 654: Test Loss: 0.4799\n",
            "Sample 655: Test Loss: 0.0065\n",
            "Sample 656: Test Loss: 0.7036\n",
            "Sample 657: Test Loss: 1.0530\n",
            "Sample 658: Test Loss: 0.8951\n",
            "Sample 659: Test Loss: 0.2628\n",
            "Sample 660: Test Loss: 0.1156\n",
            "Sample 661: Test Loss: 0.0915\n",
            "Sample 662: Test Loss: 0.1039\n",
            "Sample 663: Test Loss: 1.0524\n",
            "Sample 664: Test Loss: 0.7036\n",
            "Sample 665: Test Loss: 0.0001\n",
            "Sample 666: Test Loss: 0.7036\n",
            "Sample 667: Test Loss: 0.6304\n",
            "Sample 668: Test Loss: 0.5024\n",
            "Sample 669: Test Loss: 0.0026\n",
            "Sample 670: Test Loss: 0.1039\n",
            "Sample 671: Test Loss: 0.2112\n",
            "Sample 672: Test Loss: 7.9524\n",
            "Sample 673: Test Loss: 0.2034\n",
            "Sample 674: Test Loss: 0.6641\n",
            "Sample 675: Test Loss: 0.2034\n",
            "Sample 676: Test Loss: 0.0475\n",
            "Sample 677: Test Loss: 1.0524\n",
            "Sample 678: Test Loss: 1.0524\n",
            "Sample 679: Test Loss: 1.0227\n",
            "Sample 680: Test Loss: 35.9752\n",
            "Sample 681: Test Loss: 1.1595\n",
            "Sample 682: Test Loss: 0.0936\n",
            "Sample 683: Test Loss: 0.2044\n",
            "Sample 684: Test Loss: 0.5231\n",
            "Sample 685: Test Loss: 0.1559\n",
            "Sample 686: Test Loss: 0.2044\n",
            "Sample 687: Test Loss: 0.1056\n",
            "Sample 688: Test Loss: 0.2034\n",
            "Sample 689: Test Loss: 1.1260\n",
            "Sample 690: Test Loss: 0.0221\n",
            "Sample 691: Test Loss: 0.3441\n",
            "Sample 692: Test Loss: 1.0155\n",
            "Sample 693: Test Loss: 0.0630\n",
            "Sample 694: Test Loss: 0.2962\n",
            "Sample 695: Test Loss: 0.6304\n",
            "Sample 696: Test Loss: 1.0524\n",
            "Sample 697: Test Loss: 1.0524\n",
            "Sample 698: Test Loss: 0.0406\n",
            "Sample 699: Test Loss: 0.1170\n",
            "Sample 700: Test Loss: 0.0026\n",
            "Sample 701: Test Loss: 0.2034\n",
            "Sample 702: Test Loss: 0.7036\n",
            "Sample 703: Test Loss: 0.1298\n",
            "Sample 704: Test Loss: 0.0026\n",
            "Sample 705: Test Loss: 0.7010\n",
            "Sample 706: Test Loss: 0.2363\n",
            "Sample 707: Test Loss: 0.0505\n",
            "Sample 708: Test Loss: 0.0002\n",
            "Sample 709: Test Loss: 1.0266\n",
            "Sample 710: Test Loss: 0.5196\n",
            "Sample 711: Test Loss: 0.0630\n",
            "Sample 712: Test Loss: 0.0026\n",
            "Sample 713: Test Loss: 0.0082\n",
            "Sample 714: Test Loss: 0.2034\n",
            "Sample 715: Test Loss: 0.0020\n",
            "Sample 716: Test Loss: 0.0272\n",
            "Sample 717: Test Loss: 1.4043\n",
            "Sample 718: Test Loss: 0.3949\n",
            "Sample 719: Test Loss: 0.8155\n",
            "Sample 720: Test Loss: 0.0031\n",
            "Sample 721: Test Loss: 1.0524\n",
            "Sample 722: Test Loss: 0.1170\n",
            "Sample 723: Test Loss: 0.3399\n",
            "Sample 724: Test Loss: 0.6990\n",
            "Sample 725: Test Loss: 0.3399\n",
            "Sample 726: Test Loss: 0.3465\n",
            "Sample 727: Test Loss: 0.7760\n",
            "Sample 728: Test Loss: 0.7036\n",
            "Sample 729: Test Loss: 0.0026\n",
            "Sample 730: Test Loss: 0.2032\n",
            "Sample 731: Test Loss: 0.1147\n",
            "Sample 732: Test Loss: 0.3568\n",
            "Sample 733: Test Loss: 0.2759\n",
            "Sample 734: Test Loss: 0.0466\n",
            "Sample 735: Test Loss: 0.0460\n",
            "Sample 736: Test Loss: 0.2639\n",
            "Sample 737: Test Loss: 0.1170\n",
            "Sample 738: Test Loss: 0.7036\n",
            "Sample 739: Test Loss: 0.5886\n",
            "Sample 740: Test Loss: 0.2483\n",
            "Sample 741: Test Loss: 0.0316\n",
            "Sample 742: Test Loss: 1.4183\n",
            "Sample 743: Test Loss: 0.3949\n",
            "Sample 744: Test Loss: 0.3480\n",
            "Sample 745: Test Loss: 0.5972\n",
            "Sample 746: Test Loss: 0.7036\n",
            "Sample 747: Test Loss: 0.2034\n",
            "Sample 748: Test Loss: 0.2935\n",
            "Sample 749: Test Loss: 0.2759\n",
            "Sample 750: Test Loss: 0.7036\n",
            "Sample 751: Test Loss: 0.1166\n",
            "Sample 752: Test Loss: 0.3074\n",
            "Sample 753: Test Loss: 0.1170\n",
            "Sample 754: Test Loss: 0.1271\n",
            "Sample 755: Test Loss: 0.0220\n",
            "Sample 756: Test Loss: 0.8217\n",
            "Sample 757: Test Loss: 0.3506\n",
            "Sample 758: Test Loss: 0.3198\n",
            "Sample 759: Test Loss: 0.0031\n",
            "Sample 760: Test Loss: 0.4641\n",
            "Sample 761: Test Loss: 0.1783\n",
            "Sample 762: Test Loss: 0.0034\n",
            "Sample 763: Test Loss: 0.1817\n",
            "Sample 764: Test Loss: 0.1170\n",
            "Sample 765: Test Loss: 0.0144\n",
            "Sample 766: Test Loss: 2.0077\n",
            "Sample 767: Test Loss: 0.2044\n",
            "Sample 768: Test Loss: 0.0012\n",
            "Sample 769: Test Loss: 0.3166\n",
            "Sample 770: Test Loss: 0.2044\n",
            "Sample 771: Test Loss: 0.0292\n",
            "Sample 772: Test Loss: 0.5858\n",
            "Sample 773: Test Loss: 0.0142\n",
            "Sample 774: Test Loss: 1.0524\n",
            "Sample 775: Test Loss: 0.0005\n",
            "Sample 776: Test Loss: 0.2639\n",
            "Sample 777: Test Loss: 0.7036\n",
            "Sample 778: Test Loss: 0.3367\n",
            "Sample 779: Test Loss: 2.4541\n",
            "Sample 780: Test Loss: 0.1352\n",
            "Sample 781: Test Loss: 0.2034\n",
            "Sample 782: Test Loss: 0.0044\n",
            "Sample 783: Test Loss: 0.1559\n",
            "Sample 784: Test Loss: 0.2044\n",
            "Sample 785: Test Loss: 1.0524\n",
            "Sample 786: Test Loss: 0.6805\n",
            "Sample 787: Test Loss: 1.0530\n",
            "Sample 788: Test Loss: 0.2832\n",
            "Sample 789: Test Loss: 0.7036\n",
            "Sample 790: Test Loss: 1.0524\n",
            "Sample 791: Test Loss: 0.0037\n",
            "Sample 792: Test Loss: 0.0270\n",
            "Sample 793: Test Loss: 0.0035\n",
            "Sample 794: Test Loss: 0.1546\n",
            "Sample 795: Test Loss: 0.2219\n",
            "Sample 796: Test Loss: 0.7036\n",
            "Sample 797: Test Loss: 0.0915\n",
            "Sample 798: Test Loss: 0.6990\n",
            "Sample 799: Test Loss: 0.0145\n",
            "Sample 800: Test Loss: 0.2044\n",
            "Sample 801: Test Loss: 0.2639\n",
            "Sample 802: Test Loss: 1.0524\n",
            "Sample 803: Test Loss: 0.0017\n",
            "Sample 804: Test Loss: 0.2032\n",
            "Sample 805: Test Loss: 0.2036\n",
            "Sample 806: Test Loss: 0.0972\n",
            "Sample 807: Test Loss: 1.8302\n",
            "Sample 808: Test Loss: 0.0013\n",
            "Sample 809: Test Loss: 0.0408\n",
            "Sample 810: Test Loss: 1.0524\n",
            "Sample 811: Test Loss: 1.0524\n",
            "Sample 812: Test Loss: 0.2310\n",
            "Sample 813: Test Loss: 0.0026\n",
            "Sample 814: Test Loss: 0.3949\n",
            "Sample 815: Test Loss: 0.9141\n",
            "Sample 816: Test Loss: 0.1482\n",
            "Sample 817: Test Loss: 2.5777\n",
            "Sample 818: Test Loss: 0.3399\n",
            "Sample 819: Test Loss: 0.4514\n",
            "Sample 820: Test Loss: 0.4032\n",
            "Sample 821: Test Loss: 0.2044\n",
            "Sample 822: Test Loss: 0.0026\n",
            "Sample 823: Test Loss: 2.1450\n",
            "Sample 824: Test Loss: 0.2759\n",
            "Sample 825: Test Loss: 0.5273\n",
            "Sample 826: Test Loss: 3.4139\n",
            "Sample 827: Test Loss: 2.2861\n",
            "Sample 828: Test Loss: 1.0524\n",
            "Sample 829: Test Loss: 0.0630\n",
            "Sample 830: Test Loss: 0.5972\n",
            "Sample 831: Test Loss: 0.0630\n",
            "Sample 832: Test Loss: 0.2219\n",
            "Sample 833: Test Loss: 0.8519\n",
            "Sample 834: Test Loss: 0.8709\n",
            "Sample 835: Test Loss: 0.3418\n",
            "Sample 836: Test Loss: 0.7486\n",
            "Sample 837: Test Loss: 0.2501\n",
            "Sample 838: Test Loss: 0.0075\n",
            "Sample 839: Test Loss: 0.1663\n",
            "Sample 840: Test Loss: 0.7730\n",
            "Sample 841: Test Loss: 0.0840\n",
            "Sample 842: Test Loss: 0.2832\n",
            "Sample 843: Test Loss: 0.2044\n",
            "Sample 844: Test Loss: 0.1414\n",
            "Sample 845: Test Loss: 2.0108\n",
            "Sample 846: Test Loss: 0.7036\n",
            "Sample 847: Test Loss: 0.6506\n",
            "Sample 848: Test Loss: 0.0188\n",
            "Sample 849: Test Loss: 0.1654\n",
            "Sample 850: Test Loss: 1.0155\n",
            "Sample 851: Test Loss: 0.7036\n",
            "Sample 852: Test Loss: 0.0038\n",
            "Sample 853: Test Loss: 0.2032\n",
            "Sample 854: Test Loss: 0.3399\n",
            "Sample 855: Test Loss: 1.0524\n",
            "Sample 856: Test Loss: 0.2044\n",
            "Sample 857: Test Loss: 1.0530\n",
            "Sample 858: Test Loss: 0.5858\n",
            "Sample 859: Test Loss: 1.9668\n",
            "Sample 860: Test Loss: 0.2044\n",
            "Sample 861: Test Loss: 0.0013\n",
            "Sample 862: Test Loss: 1.0524\n",
            "Sample 863: Test Loss: 0.8951\n",
            "Sample 864: Test Loss: 0.0992\n",
            "Sample 865: Test Loss: 0.2759\n",
            "Sample 866: Test Loss: 0.1252\n",
            "Sample 867: Test Loss: 1.0524\n",
            "Sample 868: Test Loss: 0.0205\n",
            "Sample 869: Test Loss: 1.0524\n",
            "Sample 870: Test Loss: 0.1170\n",
            "Sample 871: Test Loss: 0.4466\n",
            "Sample 872: Test Loss: 0.5645\n",
            "Sample 873: Test Loss: 1.0155\n",
            "Sample 874: Test Loss: 0.1523\n",
            "Sample 875: Test Loss: 0.4032\n",
            "Sample 876: Test Loss: 0.3949\n",
            "Sample 877: Test Loss: 0.5858\n",
            "Sample 878: Test Loss: 0.5871\n",
            "Sample 879: Test Loss: 0.0181\n",
            "Sample 880: Test Loss: 0.2044\n",
            "Sample 881: Test Loss: 0.4152\n",
            "Sample 882: Test Loss: 0.7036\n",
            "Sample 883: Test Loss: 0.2219\n",
            "Sample 884: Test Loss: 0.0088\n",
            "Sample 885: Test Loss: 0.0026\n",
            "Sample 886: Test Loss: 0.2325\n",
            "Sample 887: Test Loss: 0.7203\n",
            "Sample 888: Test Loss: 0.1627\n",
            "Sample 889: Test Loss: 0.2879\n",
            "Sample 890: Test Loss: 0.7453\n",
            "Sample 891: Test Loss: 1.0524\n",
            "Sample 892: Test Loss: 0.1588\n",
            "Sample 893: Test Loss: 1.0530\n",
            "Sample 894: Test Loss: 0.3007\n",
            "Sample 895: Test Loss: 1.0155\n",
            "Sample 896: Test Loss: 0.3399\n",
            "Sample 897: Test Loss: 2.0247\n",
            "Sample 898: Test Loss: 0.1155\n",
            "Sample 899: Test Loss: 0.0039\n",
            "Sample 900: Test Loss: 0.2759\n",
            "Sample 901: Test Loss: 0.1142\n",
            "Sample 902: Test Loss: 0.0630\n",
            "Sample 903: Test Loss: 0.0168\n",
            "Sample 904: Test Loss: 1.0530\n",
            "Sample 905: Test Loss: 1.3355\n",
            "Sample 906: Test Loss: 0.7036\n",
            "Sample 907: Test Loss: 0.7036\n",
            "Sample 908: Test Loss: 2.6458\n",
            "Sample 909: Test Loss: 0.1559\n",
            "Sample 910: Test Loss: 1.8713\n",
            "Sample 911: Test Loss: 0.0655\n",
            "Sample 912: Test Loss: 0.0001\n",
            "Sample 913: Test Loss: 1.0524\n",
            "Sample 914: Test Loss: 0.2036\n",
            "Sample 915: Test Loss: 1.0524\n",
            "Sample 916: Test Loss: 0.1170\n",
            "Sample 917: Test Loss: 0.1250\n",
            "Sample 918: Test Loss: 0.0071\n",
            "Sample 919: Test Loss: 0.8951\n",
            "Sample 920: Test Loss: 3.0553\n",
            "Sample 921: Test Loss: 1.0530\n",
            "Sample 922: Test Loss: 1.0524\n",
            "Sample 923: Test Loss: 0.7036\n",
            "Sample 924: Test Loss: 0.6585\n",
            "Sample 925: Test Loss: 0.0682\n",
            "Sample 926: Test Loss: 0.2032\n",
            "Sample 927: Test Loss: 0.0630\n",
            "Sample 928: Test Loss: 0.4382\n",
            "Sample 929: Test Loss: 0.5871\n",
            "Sample 930: Test Loss: 0.1649\n",
            "Sample 931: Test Loss: 2.0225\n",
            "Sample 932: Test Loss: 0.0063\n",
            "Sample 933: Test Loss: 1.0524\n",
            "Sample 934: Test Loss: 0.0316\n",
            "Sample 935: Test Loss: 0.0018\n",
            "Sample 936: Test Loss: 31.4789\n",
            "Sample 937: Test Loss: 0.0015\n",
            "Sample 938: Test Loss: 0.1559\n",
            "Sample 939: Test Loss: 0.6234\n",
            "Sample 940: Test Loss: 0.0018\n",
            "Sample 941: Test Loss: 0.3247\n",
            "Sample 942: Test Loss: 0.5972\n",
            "Sample 943: Test Loss: 0.8951\n",
            "Sample 944: Test Loss: 0.2032\n",
            "Sample 945: Test Loss: 0.0026\n",
            "Sample 946: Test Loss: 0.0630\n",
            "Sample 947: Test Loss: 1.0155\n",
            "Sample 948: Test Loss: 0.1170\n",
            "Sample 949: Test Loss: 0.4190\n",
            "Sample 950: Test Loss: 0.4799\n",
            "Sample 951: Test Loss: 0.2044\n",
            "Sample 952: Test Loss: 0.0168\n",
            "Sample 953: Test Loss: 0.4126\n",
            "Sample 954: Test Loss: 0.0055\n",
            "Sample 955: Test Loss: 0.1397\n",
            "Sample 956: Test Loss: 0.1091\n",
            "Sample 957: Test Loss: 1.1998\n",
            "Sample 958: Test Loss: 0.2044\n",
            "Sample 959: Test Loss: 0.5062\n",
            "Sample 960: Test Loss: 0.4761\n",
            "Sample 961: Test Loss: 0.1246\n",
            "Sample 962: Test Loss: 0.2832\n",
            "Sample 963: Test Loss: 0.1170\n",
            "Sample 964: Test Loss: 0.1372\n",
            "Sample 965: Test Loss: 0.3332\n",
            "Sample 966: Test Loss: 0.1396\n",
            "Sample 967: Test Loss: 0.1250\n",
            "Sample 968: Test Loss: 2.7331\n",
            "Sample 969: Test Loss: 0.0145\n",
            "Sample 970: Test Loss: 0.3693\n",
            "Sample 971: Test Loss: 0.5858\n",
            "Sample 972: Test Loss: 0.0027\n",
            "Sample 973: Test Loss: 0.1170\n",
            "Sample 974: Test Loss: 0.4032\n",
            "Sample 975: Test Loss: 1.0524\n",
            "Sample 976: Test Loss: 0.0915\n",
            "Sample 977: Test Loss: 1.0155\n",
            "Sample 978: Test Loss: 0.4611\n",
            "Sample 979: Test Loss: 0.7927\n",
            "Sample 980: Test Loss: 0.0018\n",
            "Sample 981: Test Loss: 0.1588\n",
            "Sample 982: Test Loss: 0.2036\n",
            "Sample 983: Test Loss: 0.1091\n",
            "Sample 984: Test Loss: 0.2816\n",
            "Sample 985: Test Loss: 0.0303\n",
            "Sample 986: Test Loss: 0.7036\n",
            "Sample 987: Test Loss: 0.2750\n",
            "Sample 988: Test Loss: 1.0524\n",
            "Sample 989: Test Loss: 0.3288\n",
            "Sample 990: Test Loss: 0.0205\n",
            "Sample 991: Test Loss: 0.2034\n",
            "Sample 992: Test Loss: 0.1170\n",
            "Sample 993: Test Loss: 0.0018\n",
            "Sample 994: Test Loss: 0.1559\n",
            "Sample 995: Test Loss: 1.0551\n",
            "Sample 996: Test Loss: 3.9214\n",
            "Sample 997: Test Loss: 0.3399\n",
            "Sample 998: Test Loss: 1.0917\n",
            "Sample 999: Test Loss: 0.2205\n",
            "Sample 1000: Test Loss: 1.3432\n",
            "Sample 1001: Test Loss: 0.1248\n",
            "Sample 1002: Test Loss: 0.8951\n",
            "Sample 1003: Test Loss: 0.2639\n",
            "Sample 1004: Test Loss: 0.2759\n",
            "Sample 1005: Test Loss: 0.0729\n",
            "Sample 1006: Test Loss: 0.5858\n",
            "Sample 1007: Test Loss: 0.1559\n",
            "Sample 1008: Test Loss: 1.4317\n",
            "Sample 1009: Test Loss: 1.0155\n",
            "Sample 1010: Test Loss: 0.3399\n",
            "Sample 1011: Test Loss: 0.2759\n",
            "Sample 1012: Test Loss: 0.3332\n",
            "Sample 1013: Test Loss: 1.4027\n",
            "Sample 1014: Test Loss: 0.0062\n",
            "Sample 1015: Test Loss: 0.0026\n",
            "Sample 1016: Test Loss: 0.3399\n",
            "Sample 1017: Test Loss: 0.3441\n",
            "Sample 1018: Test Loss: 0.4622\n",
            "Sample 1019: Test Loss: 0.0775\n",
            "Sample 1020: Test Loss: 0.2036\n",
            "Sample 1021: Test Loss: 0.6427\n",
            "Sample 1022: Test Loss: 0.5871\n",
            "Sample 1023: Test Loss: 0.3949\n",
            "Sample 1024: Test Loss: 0.0883\n",
            "Sample 1025: Test Loss: 0.1588\n",
            "Sample 1026: Test Loss: 0.0590\n",
            "Sample 1027: Test Loss: 0.5000\n",
            "Sample 1028: Test Loss: 0.3441\n",
            "Sample 1029: Test Loss: 0.3441\n",
            "Sample 1030: Test Loss: 0.0640\n",
            "Sample 1031: Test Loss: 0.0915\n",
            "Sample 1032: Test Loss: 0.1559\n",
            "Sample 1033: Test Loss: 0.8951\n",
            "Sample 1034: Test Loss: 0.2989\n",
            "Sample 1035: Test Loss: 0.3399\n",
            "Sample 1036: Test Loss: 0.0938\n",
            "Sample 1037: Test Loss: 0.8951\n",
            "Sample 1038: Test Loss: 0.0303\n",
            "Sample 1039: Test Loss: 0.0026\n",
            "Sample 1040: Test Loss: 0.0756\n",
            "Sample 1041: Test Loss: 0.2759\n",
            "Sample 1042: Test Loss: 0.2182\n",
            "Sample 1043: Test Loss: 0.0660\n",
            "Sample 1044: Test Loss: 0.2032\n",
            "Sample 1045: Test Loss: 0.3399\n",
            "Sample 1046: Test Loss: 0.6378\n",
            "Sample 1047: Test Loss: 0.3402\n",
            "Sample 1048: Test Loss: 0.0002\n",
            "Sample 1049: Test Loss: 0.0466\n",
            "Sample 1050: Test Loss: 0.0026\n",
            "Sample 1051: Test Loss: 0.6156\n",
            "Sample 1052: Test Loss: 0.7036\n",
            "Sample 1053: Test Loss: 0.7036\n",
            "Sample 1054: Test Loss: 0.3441\n",
            "Sample 1055: Test Loss: 0.0018\n",
            "Sample 1056: Test Loss: 0.4165\n",
            "Sample 1057: Test Loss: 0.0040\n",
            "Sample 1058: Test Loss: 0.5858\n",
            "Sample 1059: Test Loss: 0.0026\n",
            "Sample 1060: Test Loss: 0.7453\n",
            "Sample 1061: Test Loss: 0.1170\n",
            "Sample 1062: Test Loss: 0.2092\n",
            "Sample 1063: Test Loss: 1.0524\n",
            "Sample 1064: Test Loss: 0.1248\n",
            "Sample 1065: Test Loss: 0.5858\n",
            "Sample 1066: Test Loss: 0.2135\n",
            "Sample 1067: Test Loss: 0.7453\n",
            "Sample 1068: Test Loss: 0.4930\n",
            "Sample 1069: Test Loss: 0.0630\n",
            "Sample 1070: Test Loss: 0.0630\n",
            "Sample 1071: Test Loss: 0.5351\n",
            "Sample 1072: Test Loss: 0.2750\n",
            "Sample 1073: Test Loss: 0.6313\n",
            "Sample 1074: Test Loss: 0.0374\n",
            "Sample 1075: Test Loss: 0.4799\n",
            "Sample 1076: Test Loss: 1.0524\n",
            "Sample 1077: Test Loss: 0.4611\n",
            "Sample 1078: Test Loss: 1.0530\n",
            "Sample 1079: Test Loss: 0.0915\n",
            "Sample 1080: Test Loss: 0.0026\n",
            "Sample 1081: Test Loss: 0.3399\n",
            "Sample 1082: Test Loss: 0.5003\n",
            "Sample 1083: Test Loss: 1.0759\n",
            "Sample 1084: Test Loss: 0.0292\n",
            "Sample 1085: Test Loss: 0.2032\n",
            "Sample 1086: Test Loss: 0.4265\n",
            "Sample 1087: Test Loss: 0.0638\n",
            "Sample 1088: Test Loss: 1.0530\n",
            "Sample 1089: Test Loss: 0.0026\n",
            "Sample 1090: Test Loss: 0.0306\n",
            "Sample 1091: Test Loss: 1.1855\n",
            "Sample 1092: Test Loss: 0.4607\n",
            "Sample 1093: Test Loss: 0.7453\n",
            "Sample 1094: Test Loss: 0.1219\n",
            "Sample 1095: Test Loss: 0.2770\n",
            "Sample 1096: Test Loss: 0.0005\n",
            "Sample 1097: Test Loss: 0.3399\n",
            "Sample 1098: Test Loss: 0.0014\n",
            "Sample 1099: Test Loss: 0.9447\n",
            "Sample 1100: Test Loss: 0.0005\n",
            "Sample 1101: Test Loss: 0.0001\n",
            "Sample 1102: Test Loss: 1.1789\n",
            "Sample 1103: Test Loss: 0.0834\n",
            "Sample 1104: Test Loss: 0.2044\n",
            "Sample 1105: Test Loss: 1.0155\n",
            "Sample 1106: Test Loss: 0.2886\n",
            "Sample 1107: Test Loss: 0.0630\n",
            "Sample 1108: Test Loss: 0.0503\n",
            "Sample 1109: Test Loss: 1.3207\n",
            "Sample 1110: Test Loss: 0.1252\n",
            "Sample 1111: Test Loss: 0.0915\n",
            "Sample 1112: Test Loss: 0.0026\n",
            "Sample 1113: Test Loss: 0.1553\n",
            "Sample 1114: Test Loss: 0.2363\n",
            "Sample 1115: Test Loss: 0.0274\n",
            "Sample 1116: Test Loss: 0.3399\n",
            "Sample 1117: Test Loss: 0.2048\n",
            "Sample 1118: Test Loss: 0.8854\n",
            "Sample 1119: Test Loss: 0.6558\n",
            "Sample 1120: Test Loss: 0.9651\n",
            "Sample 1121: Test Loss: 0.0026\n",
            "Sample 1122: Test Loss: 1.1789\n",
            "Sample 1123: Test Loss: 0.0018\n",
            "Sample 1124: Test Loss: 1.0524\n",
            "Sample 1125: Test Loss: 1.2129\n",
            "Sample 1126: Test Loss: 0.1608\n",
            "Sample 1127: Test Loss: 0.2297\n",
            "Sample 1128: Test Loss: 0.2032\n",
            "Sample 1129: Test Loss: 0.6990\n",
            "Sample 1130: Test Loss: 0.0011\n",
            "Sample 1131: Test Loss: 0.4032\n",
            "Sample 1132: Test Loss: 0.0144\n",
            "Sample 1133: Test Loss: 0.3399\n",
            "Sample 1134: Test Loss: 0.3833\n",
            "Sample 1135: Test Loss: 0.5858\n",
            "Sample 1136: Test Loss: 0.2032\n",
            "Sample 1137: Test Loss: 3.5208\n",
            "Sample 1138: Test Loss: 0.2044\n",
            "Sample 1139: Test Loss: 0.2133\n",
            "Sample 1140: Test Loss: 0.8951\n",
            "Sample 1141: Test Loss: 0.0018\n",
            "Sample 1142: Test Loss: 0.0000\n",
            "Sample 1143: Test Loss: 0.2340\n",
            "Sample 1144: Test Loss: 0.4761\n",
            "Sample 1145: Test Loss: 0.2699\n",
            "Sample 1146: Test Loss: 0.2639\n",
            "Sample 1147: Test Loss: 0.6304\n",
            "Sample 1148: Test Loss: 0.1523\n",
            "Sample 1149: Test Loss: 0.0187\n",
            "Sample 1150: Test Loss: 0.3441\n",
            "Sample 1151: Test Loss: 0.0041\n",
            "Sample 1152: Test Loss: 0.1523\n",
            "Sample 1153: Test Loss: 0.8677\n",
            "Sample 1154: Test Loss: 0.0915\n",
            "Sample 1155: Test Loss: 0.1559\n",
            "Sample 1156: Test Loss: 0.0915\n",
            "Sample 1157: Test Loss: 0.5972\n",
            "Sample 1158: Test Loss: 1.5826\n",
            "Sample 1159: Test Loss: 0.7036\n",
            "Sample 1160: Test Loss: 0.2044\n",
            "Sample 1161: Test Loss: 0.0808\n",
            "Sample 1162: Test Loss: 0.1250\n",
            "Sample 1163: Test Loss: 0.2044\n",
            "Sample 1164: Test Loss: 0.3288\n",
            "Sample 1165: Test Loss: 0.1559\n",
            "Sample 1166: Test Loss: 0.0466\n",
            "Sample 1167: Test Loss: 0.0424\n",
            "Sample 1168: Test Loss: 0.0063\n",
            "Sample 1169: Test Loss: 0.0062\n",
            "Sample 1170: Test Loss: 1.0524\n",
            "Sample 1171: Test Loss: 0.4306\n",
            "Sample 1172: Test Loss: 0.4400\n",
            "Sample 1173: Test Loss: 0.2750\n",
            "Sample 1174: Test Loss: 0.4032\n",
            "Sample 1175: Test Loss: 1.8653\n",
            "Sample 1176: Test Loss: 0.5858\n",
            "Sample 1177: Test Loss: 0.2044\n",
            "Sample 1178: Test Loss: 0.0071\n",
            "Sample 1179: Test Loss: 0.0088\n",
            "Sample 1180: Test Loss: 0.7036\n",
            "Sample 1181: Test Loss: 0.2962\n",
            "Sample 1182: Test Loss: 0.0007\n",
            "Sample 1183: Test Loss: 0.8951\n",
            "Sample 1184: Test Loss: 0.4032\n",
            "Sample 1185: Test Loss: 1.0428\n",
            "Sample 1186: Test Loss: 0.0030\n",
            "Sample 1187: Test Loss: 0.0039\n",
            "Sample 1188: Test Loss: 0.0108\n",
            "Sample 1189: Test Loss: 0.3390\n",
            "Sample 1190: Test Loss: 0.4382\n",
            "Sample 1191: Test Loss: 0.8951\n",
            "Sample 1192: Test Loss: 0.1559\n",
            "Sample 1193: Test Loss: 1.0524\n",
            "Sample 1194: Test Loss: 0.7036\n",
            "Sample 1195: Test Loss: 0.0513\n",
            "Sample 1196: Test Loss: 0.2904\n",
            "Sample 1197: Test Loss: 0.0133\n",
            "Sample 1198: Test Loss: 0.0303\n",
            "Sample 1199: Test Loss: 0.5000\n",
            "Sample 1200: Test Loss: 0.0066\n",
            "Sample 1201: Test Loss: 0.2639\n",
            "Sample 1202: Test Loss: 0.2206\n",
            "Sample 1203: Test Loss: 0.2034\n",
            "Sample 1204: Test Loss: 0.2036\n",
            "Sample 1205: Test Loss: 0.1003\n",
            "Sample 1206: Test Loss: 0.3441\n",
            "Sample 1207: Test Loss: 0.0587\n",
            "Sample 1208: Test Loss: 0.0717\n",
            "Sample 1209: Test Loss: 0.2832\n",
            "Sample 1210: Test Loss: 0.0001\n",
            "Sample 1211: Test Loss: 0.2340\n",
            "Sample 1212: Test Loss: 0.0039\n",
            "Sample 1213: Test Loss: 0.1087\n",
            "Sample 1214: Test Loss: 0.8951\n",
            "Sample 1215: Test Loss: 0.2032\n",
            "Sample 1216: Test Loss: 0.1250\n",
            "Sample 1217: Test Loss: 0.3399\n",
            "Sample 1218: Test Loss: 0.3399\n",
            "Sample 1219: Test Loss: 0.0001\n",
            "Sample 1220: Test Loss: 0.2032\n",
            "Sample 1221: Test Loss: 0.0505\n",
            "Sample 1222: Test Loss: 0.7453\n",
            "Sample 1223: Test Loss: 0.2219\n",
            "Sample 1224: Test Loss: 0.4681\n",
            "Sample 1225: Test Loss: 0.0714\n",
            "Sample 1226: Test Loss: 0.3997\n",
            "Sample 1227: Test Loss: 0.4041\n",
            "Sample 1228: Test Loss: 0.0059\n",
            "Sample 1229: Test Loss: 0.3332\n",
            "Sample 1230: Test Loss: 0.9367\n",
            "Sample 1231: Test Loss: 0.0306\n",
            "Sample 1232: Test Loss: 0.5003\n",
            "Sample 1233: Test Loss: 0.4382\n",
            "Sample 1234: Test Loss: 0.1170\n",
            "Sample 1235: Test Loss: 0.4438\n",
            "Sample 1236: Test Loss: 0.1170\n",
            "Sample 1237: Test Loss: 0.4423\n",
            "Sample 1238: Test Loss: 0.6304\n",
            "Sample 1239: Test Loss: 2.8905\n",
            "Sample 1240: Test Loss: 0.2759\n",
            "Sample 1241: Test Loss: 0.3399\n",
            "Sample 1242: Test Loss: 0.4382\n",
            "Sample 1243: Test Loss: 0.1170\n",
            "Sample 1244: Test Loss: 0.8951\n",
            "Sample 1245: Test Loss: 1.0530\n",
            "Sample 1246: Test Loss: 0.2687\n",
            "Sample 1247: Test Loss: 0.2036\n",
            "Sample 1248: Test Loss: 0.2750\n",
            "Sample 1249: Test Loss: 0.7036\n",
            "Sample 1250: Test Loss: 0.3402\n",
            "Sample 1251: Test Loss: 0.8951\n",
            "Sample 1252: Test Loss: 1.6597\n",
            "Sample 1253: Test Loss: 0.2759\n",
            "Sample 1254: Test Loss: 0.0611\n",
            "Sample 1255: Test Loss: 0.0625\n",
            "Sample 1256: Test Loss: 0.0476\n",
            "Sample 1257: Test Loss: 0.0224\n",
            "Sample 1258: Test Loss: 0.0990\n",
            "Sample 1259: Test Loss: 1.0524\n",
            "Sample 1260: Test Loss: 0.1523\n",
            "Sample 1261: Test Loss: 1.1340\n",
            "Sample 1262: Test Loss: 0.7036\n",
            "Sample 1263: Test Loss: 0.0018\n",
            "Sample 1264: Test Loss: 0.7468\n",
            "Sample 1265: Test Loss: 0.1250\n",
            "Sample 1266: Test Loss: 0.5858\n",
            "Sample 1267: Test Loss: 0.6510\n",
            "Sample 1268: Test Loss: 0.0018\n",
            "Sample 1269: Test Loss: 0.3568\n",
            "Sample 1270: Test Loss: 0.2604\n",
            "Sample 1271: Test Loss: 0.6304\n",
            "Sample 1272: Test Loss: 0.2036\n",
            "Sample 1273: Test Loss: 0.1559\n",
            "Sample 1274: Test Loss: 0.5375\n",
            "Sample 1275: Test Loss: 0.2759\n",
            "Sample 1276: Test Loss: 0.7036\n",
            "Sample 1277: Test Loss: 0.2851\n",
            "Sample 1278: Test Loss: 0.1999\n",
            "Sample 1279: Test Loss: 4.8819\n",
            "Sample 1280: Test Loss: 0.2032\n",
            "Sample 1281: Test Loss: 0.0287\n",
            "Sample 1282: Test Loss: 0.1463\n",
            "Sample 1283: Test Loss: 0.4032\n",
            "Sample 1284: Test Loss: 0.2044\n",
            "Sample 1285: Test Loss: 0.2759\n",
            "Sample 1286: Test Loss: 0.1170\n",
            "Sample 1287: Test Loss: 0.0864\n",
            "Sample 1288: Test Loss: 0.3399\n",
            "Sample 1289: Test Loss: 0.2044\n",
            "Sample 1290: Test Loss: 0.0140\n",
            "Sample 1291: Test Loss: 0.0026\n",
            "Sample 1292: Test Loss: 0.1202\n",
            "Sample 1293: Test Loss: 0.2219\n",
            "Sample 1294: Test Loss: 0.0838\n",
            "Sample 1295: Test Loss: 1.7895\n",
            "Sample 1296: Test Loss: 0.1884\n",
            "Sample 1297: Test Loss: 1.0524\n",
            "Sample 1298: Test Loss: 1.0155\n",
            "Sample 1299: Test Loss: 0.3206\n",
            "Sample 1300: Test Loss: 0.3399\n",
            "Sample 1301: Test Loss: 0.1250\n",
            "Sample 1302: Test Loss: 0.5078\n",
            "Sample 1303: Test Loss: 0.9202\n",
            "Sample 1304: Test Loss: 1.0524\n",
            "Sample 1305: Test Loss: 0.0083\n",
            "Sample 1306: Test Loss: 0.0022\n",
            "Sample 1307: Test Loss: 0.1040\n",
            "Sample 1308: Test Loss: 0.2034\n",
            "Sample 1309: Test Loss: 0.6990\n",
            "Sample 1310: Test Loss: 0.2032\n",
            "Sample 1311: Test Loss: 0.0025\n",
            "Sample 1312: Test Loss: 0.0630\n",
            "Sample 1313: Test Loss: 4.1354\n",
            "Sample 1314: Test Loss: 0.9962\n",
            "Sample 1315: Test Loss: 0.0313\n",
            "Sample 1316: Test Loss: 1.0524\n",
            "Sample 1317: Test Loss: 0.0744\n",
            "Sample 1318: Test Loss: 0.1337\n",
            "Sample 1319: Test Loss: 0.0744\n",
            "Sample 1320: Test Loss: 2.8104\n",
            "Sample 1321: Test Loss: 0.0234\n",
            "Sample 1322: Test Loss: 0.0532\n",
            "Sample 1323: Test Loss: 0.7036\n",
            "Sample 1324: Test Loss: 0.1170\n",
            "Sample 1325: Test Loss: 0.2034\n",
            "Sample 1326: Test Loss: 0.2079\n",
            "Sample 1327: Test Loss: 0.7036\n",
            "Sample 1328: Test Loss: 1.0530\n",
            "Sample 1329: Test Loss: 0.3584\n",
            "Sample 1330: Test Loss: 0.0621\n",
            "Sample 1331: Test Loss: 0.2044\n",
            "Sample 1332: Test Loss: 0.3949\n",
            "Sample 1333: Test Loss: 0.1170\n",
            "Sample 1334: Test Loss: 0.7036\n",
            "Sample 1335: Test Loss: 0.4229\n",
            "Sample 1336: Test Loss: 0.0084\n",
            "Sample 1337: Test Loss: 0.1465\n",
            "Sample 1338: Test Loss: 1.0316\n",
            "Sample 1339: Test Loss: 0.2044\n",
            "Sample 1340: Test Loss: 1.0530\n",
            "Sample 1341: Test Loss: 1.0511\n",
            "Sample 1342: Test Loss: 0.0004\n",
            "Sample 1343: Test Loss: 1.1265\n",
            "Sample 1344: Test Loss: 0.5314\n",
            "Sample 1345: Test Loss: 1.5542\n",
            "Sample 1346: Test Loss: 0.0913\n",
            "Sample 1347: Test Loss: 0.2759\n",
            "Sample 1348: Test Loss: 0.6981\n",
            "Sample 1349: Test Loss: 0.2962\n",
            "Sample 1350: Test Loss: 1.5542\n",
            "Sample 1351: Test Loss: 0.0906\n",
            "Sample 1352: Test Loss: 1.0524\n",
            "Sample 1353: Test Loss: 0.1212\n",
            "Sample 1354: Test Loss: 0.4641\n",
            "Sample 1355: Test Loss: 0.7036\n",
            "Sample 1356: Test Loss: 0.1170\n",
            "Sample 1357: Test Loss: 0.2032\n",
            "Sample 1358: Test Loss: 0.1559\n",
            "Sample 1359: Test Loss: 0.6993\n",
            "Sample 1360: Test Loss: 1.0530\n",
            "Sample 1361: Test Loss: 0.0630\n",
            "Sample 1362: Test Loss: 0.2704\n",
            "Sample 1363: Test Loss: 0.0084\n",
            "Sample 1364: Test Loss: 0.0554\n",
            "Sample 1365: Test Loss: 0.0030\n",
            "Sample 1366: Test Loss: 0.7453\n",
            "Sample 1367: Test Loss: 0.1039\n",
            "Sample 1368: Test Loss: 1.0524\n",
            "Sample 1369: Test Loss: 0.0116\n",
            "Sample 1370: Test Loss: 0.3211\n",
            "Sample 1371: Test Loss: 0.0313\n",
            "Sample 1372: Test Loss: 1.0524\n",
            "Sample 1373: Test Loss: 0.4644\n",
            "Sample 1374: Test Loss: 0.2483\n",
            "Sample 1375: Test Loss: 0.9367\n",
            "Sample 1376: Test Loss: 0.0205\n",
            "Sample 1377: Test Loss: 0.2219\n",
            "Sample 1378: Test Loss: 2.6476\n",
            "Sample 1379: Test Loss: 0.0194\n",
            "Sample 1380: Test Loss: 1.5542\n",
            "Sample 1381: Test Loss: 0.2639\n",
            "Sample 1382: Test Loss: 0.0002\n",
            "Sample 1383: Test Loss: 0.4930\n",
            "Sample 1384: Test Loss: 0.3957\n",
            "Sample 1385: Test Loss: 0.2759\n",
            "Sample 1386: Test Loss: 1.0155\n",
            "Sample 1387: Test Loss: 0.0630\n",
            "Sample 1388: Test Loss: 0.3441\n",
            "Sample 1389: Test Loss: 0.1559\n",
            "Sample 1390: Test Loss: 1.0524\n",
            "Sample 1391: Test Loss: 0.1170\n",
            "Sample 1392: Test Loss: 0.5411\n",
            "Sample 1393: Test Loss: 1.0266\n",
            "Sample 1394: Test Loss: 0.2204\n",
            "Sample 1395: Test Loss: 0.0060\n",
            "Sample 1396: Test Loss: 0.9367\n",
            "Sample 1397: Test Loss: 1.0530\n",
            "Sample 1398: Test Loss: 0.0026\n",
            "Sample 1399: Test Loss: 1.0155\n",
            "Sample 1400: Test Loss: 0.3399\n",
            "Sample 1401: Test Loss: 0.2832\n",
            "Sample 1402: Test Loss: 0.0000\n",
            "Sample 1403: Test Loss: 0.5858\n",
            "Sample 1404: Test Loss: 0.6990\n",
            "Sample 1405: Test Loss: 0.0018\n",
            "Sample 1406: Test Loss: 0.1535\n",
            "Sample 1407: Test Loss: 0.2764\n",
            "Sample 1408: Test Loss: 0.1337\n",
            "Sample 1409: Test Loss: 0.7453\n",
            "Sample 1410: Test Loss: 0.4841\n",
            "Sample 1411: Test Loss: 0.0007\n",
            "Sample 1412: Test Loss: 0.2219\n",
            "Sample 1413: Test Loss: 0.8188\n",
            "Sample 1414: Test Loss: 0.2962\n",
            "Sample 1415: Test Loss: 0.7453\n",
            "Sample 1416: Test Loss: 0.0915\n",
            "Sample 1417: Test Loss: 0.0630\n",
            "Sample 1418: Test Loss: 4.5316\n",
            "Sample 1419: Test Loss: 0.1559\n",
            "Sample 1420: Test Loss: 0.2044\n",
            "Sample 1421: Test Loss: 0.1395\n",
            "Sample 1422: Test Loss: 0.4930\n",
            "Sample 1423: Test Loss: 0.0965\n",
            "Sample 1424: Test Loss: 0.5871\n",
            "Sample 1425: Test Loss: 0.1535\n",
            "Sample 1426: Test Loss: 0.1601\n",
            "Sample 1427: Test Loss: 0.3441\n",
            "Sample 1428: Test Loss: 0.0513\n",
            "Sample 1429: Test Loss: 0.3399\n",
            "Sample 1430: Test Loss: 0.2173\n",
            "Sample 1431: Test Loss: 0.0466\n",
            "Sample 1432: Test Loss: 1.0155\n",
            "Sample 1433: Test Loss: 0.2032\n",
            "Sample 1434: Test Loss: 0.2044\n",
            "Sample 1435: Test Loss: 1.3427\n",
            "Sample 1436: Test Loss: 0.0498\n",
            "Sample 1437: Test Loss: 0.2716\n",
            "Sample 1438: Test Loss: 0.0048\n",
            "Sample 1439: Test Loss: 1.0524\n",
            "Sample 1440: Test Loss: 1.0524\n",
            "Sample 1441: Test Loss: 0.5003\n",
            "Sample 1442: Test Loss: 0.3399\n",
            "Sample 1443: Test Loss: 0.1039\n",
            "Sample 1444: Test Loss: 0.0915\n",
            "Sample 1445: Test Loss: 0.1056\n",
            "Sample 1446: Test Loss: 0.1170\n",
            "Sample 1447: Test Loss: 0.0269\n",
            "Sample 1448: Test Loss: 0.0004\n",
            "Sample 1449: Test Loss: 0.2044\n",
            "Sample 1450: Test Loss: 0.2044\n",
            "Sample 1451: Test Loss: 0.0060\n",
            "Sample 1452: Test Loss: 0.0031\n",
            "Sample 1453: Test Loss: 0.1248\n",
            "Sample 1454: Test Loss: 0.7518\n",
            "Sample 1455: Test Loss: 1.0524\n",
            "Sample 1456: Test Loss: 1.0070\n",
            "Sample 1457: Test Loss: 0.7453\n",
            "Sample 1458: Test Loss: 0.0609\n",
            "Sample 1459: Test Loss: 0.0042\n",
            "Sample 1460: Test Loss: 0.3441\n",
            "Sample 1461: Test Loss: 0.0625\n",
            "Sample 1462: Test Loss: 0.5858\n",
            "Sample 1463: Test Loss: 0.2941\n",
            "Sample 1464: Test Loss: 0.0640\n",
            "Sample 1465: Test Loss: 0.0303\n",
            "Sample 1466: Test Loss: 1.0524\n",
            "Sample 1467: Test Loss: 0.1170\n",
            "Sample 1468: Test Loss: 0.3568\n",
            "Sample 1469: Test Loss: 0.8951\n",
            "Sample 1470: Test Loss: 0.1654\n",
            "Sample 1471: Test Loss: 1.0524\n",
            "Sample 1472: Test Loss: 0.0018\n",
            "Sample 1473: Test Loss: 0.5972\n",
            "Sample 1474: Test Loss: 0.5196\n",
            "Sample 1475: Test Loss: 0.6139\n",
            "Sample 1476: Test Loss: 0.1096\n",
            "Sample 1477: Test Loss: 0.7036\n",
            "Sample 1478: Test Loss: 0.2036\n",
            "Sample 1479: Test Loss: 0.1170\n",
            "Sample 1480: Test Loss: 0.1353\n",
            "Sample 1481: Test Loss: 0.0168\n",
            "Sample 1482: Test Loss: 1.1333\n",
            "Sample 1483: Test Loss: 1.0155\n",
            "Sample 1484: Test Loss: 0.0165\n",
            "Sample 1485: Test Loss: 0.1170\n",
            "Sample 1486: Test Loss: 0.3912\n",
            "Sample 1487: Test Loss: 0.2044\n",
            "Sample 1488: Test Loss: 0.3399\n",
            "Sample 1489: Test Loss: 0.7628\n",
            "Sample 1490: Test Loss: 0.3478\n",
            "Sample 1491: Test Loss: 7.4863\n",
            "Sample 1492: Test Loss: 1.0524\n",
            "Sample 1493: Test Loss: 0.1250\n",
            "Sample 1494: Test Loss: 0.0009\n",
            "Sample 1495: Test Loss: 0.1250\n",
            "Sample 1496: Test Loss: 0.7917\n",
            "Sample 1497: Test Loss: 0.0000\n",
            "Sample 1498: Test Loss: 0.3859\n",
            "Sample 1499: Test Loss: 0.3450\n",
            "Sample 1500: Test Loss: 0.0689\n",
            "Sample 1501: Test Loss: 1.0155\n",
            "Sample 1502: Test Loss: 0.2044\n",
            "Sample 1503: Test Loss: 0.7036\n",
            "Sample 1504: Test Loss: 0.0323\n",
            "Sample 1505: Test Loss: 0.7036\n",
            "Sample 1506: Test Loss: 0.0030\n",
            "Sample 1507: Test Loss: 0.1250\n",
            "Sample 1508: Test Loss: 0.0026\n",
            "Sample 1509: Test Loss: 1.0134\n",
            "Sample 1510: Test Loss: 0.2704\n",
            "Sample 1511: Test Loss: 0.3441\n",
            "Sample 1512: Test Loss: 0.3568\n",
            "Sample 1513: Test Loss: 0.1350\n",
            "Sample 1514: Test Loss: 0.0434\n",
            "Sample 1515: Test Loss: 1.0524\n",
            "Sample 1516: Test Loss: 0.4611\n",
            "Sample 1517: Test Loss: 0.3332\n",
            "Sample 1518: Test Loss: 0.0333\n",
            "Sample 1519: Test Loss: 0.2434\n",
            "Sample 1520: Test Loss: 0.0234\n",
            "Sample 1521: Test Loss: 0.3067\n",
            "Sample 1522: Test Loss: 0.0640\n",
            "Sample 1523: Test Loss: 0.0504\n",
            "Sample 1524: Test Loss: 0.0026\n",
            "Sample 1525: Test Loss: 1.1729\n",
            "Sample 1526: Test Loss: 0.2146\n",
            "Sample 1527: Test Loss: 0.0383\n",
            "Sample 1528: Test Loss: 0.6302\n",
            "Sample 1529: Test Loss: 0.2759\n",
            "Sample 1530: Test Loss: 0.0026\n",
            "Sample 1531: Test Loss: 0.0026\n",
            "Sample 1532: Test Loss: 0.0144\n",
            "Sample 1533: Test Loss: 0.5858\n",
            "Sample 1534: Test Loss: 0.1170\n",
            "Sample 1535: Test Loss: 0.7036\n",
            "Sample 1536: Test Loss: 0.0102\n",
            "Sample 1537: Test Loss: 0.3399\n",
            "Sample 1538: Test Loss: 0.5062\n",
            "Sample 1539: Test Loss: 2.4541\n",
            "Sample 1540: Test Loss: 0.0291\n",
            "Sample 1541: Test Loss: 0.0014\n",
            "Sample 1542: Test Loss: 1.0530\n",
            "Sample 1543: Test Loss: 1.0530\n",
            "Sample 1544: Test Loss: 0.3390\n",
            "Sample 1545: Test Loss: 0.2204\n",
            "Sample 1546: Test Loss: 1.0524\n",
            "Sample 1547: Test Loss: 0.2339\n",
            "Sample 1548: Test Loss: 0.0744\n",
            "Sample 1549: Test Loss: 0.2989\n",
            "Sample 1550: Test Loss: 0.2476\n",
            "Sample 1551: Test Loss: 1.0524\n",
            "Sample 1552: Test Loss: 0.0590\n",
            "Sample 1553: Test Loss: 1.0645\n",
            "Sample 1554: Test Loss: 0.5375\n",
            "Sample 1555: Test Loss: 0.6092\n",
            "Sample 1556: Test Loss: 0.4382\n",
            "Sample 1557: Test Loss: 0.0026\n",
            "Sample 1558: Test Loss: 0.3441\n",
            "Sample 1559: Test Loss: 0.0907\n",
            "Sample 1560: Test Loss: 2.9190\n",
            "Sample 1561: Test Loss: 0.1218\n",
            "Sample 1562: Test Loss: 0.2044\n",
            "Sample 1563: Test Loss: 0.2638\n",
            "Sample 1564: Test Loss: 0.1559\n",
            "Sample 1565: Test Loss: 0.3402\n",
            "Sample 1566: Test Loss: 0.0026\n",
            "Sample 1567: Test Loss: 0.0630\n",
            "Sample 1568: Test Loss: 0.2034\n",
            "Sample 1569: Test Loss: 0.0630\n",
            "Sample 1570: Test Loss: 0.2682\n",
            "Sample 1571: Test Loss: 0.0349\n",
            "Sample 1572: Test Loss: 0.0018\n",
            "Sample 1573: Test Loss: 1.0524\n",
            "Sample 1574: Test Loss: 0.0838\n",
            "Sample 1575: Test Loss: 0.5858\n",
            "Sample 1576: Test Loss: 0.0590\n",
            "Sample 1577: Test Loss: 0.1508\n",
            "Sample 1578: Test Loss: 0.2044\n",
            "Sample 1579: Test Loss: 0.9628\n",
            "Sample 1580: Test Loss: 0.3441\n",
            "Sample 1581: Test Loss: 0.2032\n",
            "Sample 1582: Test Loss: 0.3949\n",
            "Sample 1583: Test Loss: 1.3310\n",
            "Sample 1584: Test Loss: 0.0826\n",
            "Sample 1585: Test Loss: 0.1675\n",
            "Sample 1586: Test Loss: 0.2048\n",
            "Sample 1587: Test Loss: 1.0155\n",
            "Sample 1588: Test Loss: 0.7036\n",
            "Sample 1589: Test Loss: 1.0227\n",
            "Sample 1590: Test Loss: 0.2363\n",
            "Sample 1591: Test Loss: 0.0000\n",
            "Sample 1592: Test Loss: 1.0524\n",
            "Sample 1593: Test Loss: 1.0530\n",
            "Sample 1594: Test Loss: 0.3062\n",
            "Sample 1595: Test Loss: 0.7036\n",
            "Sample 1596: Test Loss: 1.0524\n",
            "Sample 1597: Test Loss: 3.9818\n",
            "Sample 1598: Test Loss: 0.0212\n",
            "Sample 1599: Test Loss: 0.0303\n",
            "Sample 1600: Test Loss: 0.1246\n",
            "Sample 1601: Test Loss: 1.0530\n",
            "Sample 1602: Test Loss: 1.6418\n",
            "Sample 1603: Test Loss: 0.2044\n",
            "Sample 1604: Test Loss: 0.5858\n",
            "Sample 1605: Test Loss: 0.2935\n",
            "Sample 1606: Test Loss: 0.8484\n",
            "Sample 1607: Test Loss: 0.4996\n",
            "Sample 1608: Test Loss: 0.2044\n",
            "Sample 1609: Test Loss: 0.5003\n",
            "Sample 1610: Test Loss: 0.2036\n",
            "Sample 1611: Test Loss: 0.2034\n",
            "Sample 1612: Test Loss: 0.6016\n",
            "Sample 1613: Test Loss: 0.0062\n",
            "Sample 1614: Test Loss: 0.6599\n",
            "Sample 1615: Test Loss: 0.0915\n",
            "Sample 1616: Test Loss: 0.2044\n",
            "Sample 1617: Test Loss: 1.0155\n",
            "Sample 1618: Test Loss: 0.0034\n",
            "Sample 1619: Test Loss: 0.0220\n",
            "Sample 1620: Test Loss: 0.6304\n",
            "Sample 1621: Test Loss: 0.1105\n",
            "Sample 1622: Test Loss: 0.7453\n",
            "Sample 1623: Test Loss: 0.0188\n",
            "Sample 1624: Test Loss: 1.0530\n",
            "Sample 1625: Test Loss: 1.0524\n",
            "Sample 1626: Test Loss: 0.1399\n",
            "Sample 1627: Test Loss: 0.0026\n",
            "Sample 1628: Test Loss: 0.2084\n",
            "Sample 1629: Test Loss: 0.2938\n",
            "Sample 1630: Test Loss: 0.0630\n",
            "Sample 1631: Test Loss: 0.2036\n",
            "Sample 1632: Test Loss: 0.0460\n",
            "Sample 1633: Test Loss: 0.1588\n",
            "Sample 1634: Test Loss: 0.8951\n",
            "Sample 1635: Test Loss: 0.7036\n",
            "Sample 1636: Test Loss: 0.3399\n",
            "Sample 1637: Test Loss: 0.0864\n",
            "Sample 1638: Test Loss: 1.0530\n",
            "Sample 1639: Test Loss: 0.3157\n",
            "Sample 1640: Test Loss: 0.1860\n",
            "Sample 1641: Test Loss: 0.0174\n",
            "Sample 1642: Test Loss: 0.2034\n",
            "Sample 1643: Test Loss: 1.8065\n",
            "Sample 1644: Test Loss: 4.6293\n",
            "Sample 1645: Test Loss: 0.6115\n",
            "Sample 1646: Test Loss: 0.0112\n",
            "Sample 1647: Test Loss: 1.0524\n",
            "Sample 1648: Test Loss: 0.1250\n",
            "Sample 1649: Test Loss: 0.7891\n",
            "Sample 1650: Test Loss: 0.6990\n",
            "Sample 1651: Test Loss: 0.0835\n",
            "Sample 1652: Test Loss: 0.4996\n",
            "Sample 1653: Test Loss: 0.2699\n",
            "Sample 1654: Test Loss: 0.7036\n",
            "Sample 1655: Test Loss: 0.0026\n",
            "Sample 1656: Test Loss: 0.4607\n",
            "Sample 1657: Test Loss: 0.7203\n",
            "Sample 1658: Test Loss: 0.1887\n",
            "Sample 1659: Test Loss: 12.8755\n",
            "Sample 1660: Test Loss: 0.4996\n",
            "Sample 1661: Test Loss: 0.1250\n",
            "Sample 1662: Test Loss: 0.1523\n",
            "Sample 1663: Test Loss: 1.0524\n",
            "Sample 1664: Test Loss: 0.2759\n",
            "Sample 1665: Test Loss: 0.3399\n",
            "Sample 1666: Test Loss: 1.0530\n",
            "Sample 1667: Test Loss: 1.2646\n",
            "Sample 1668: Test Loss: 0.0034\n",
            "Sample 1669: Test Loss: 0.0018\n",
            "Sample 1670: Test Loss: 2.7865\n",
            "Sample 1671: Test Loss: 1.9242\n",
            "Sample 1672: Test Loss: 0.3949\n",
            "Sample 1673: Test Loss: 1.0524\n",
            "Sample 1674: Test Loss: 0.5184\n",
            "Sample 1675: Test Loss: 0.0026\n",
            "Sample 1676: Test Loss: 0.0038\n",
            "Sample 1677: Test Loss: 0.0026\n",
            "Sample 1678: Test Loss: 0.0009\n",
            "Sample 1679: Test Loss: 0.2032\n",
            "Sample 1680: Test Loss: 0.0286\n",
            "Sample 1681: Test Loss: 0.2759\n",
            "Sample 1682: Test Loss: 0.3871\n",
            "Sample 1683: Test Loss: 1.0524\n",
            "Sample 1684: Test Loss: 0.0043\n",
            "Sample 1685: Test Loss: 0.2034\n",
            "Sample 1686: Test Loss: 1.0524\n",
            "Sample 1687: Test Loss: 0.2219\n",
            "Sample 1688: Test Loss: 0.1549\n",
            "Sample 1689: Test Loss: 0.0944\n",
            "Sample 1690: Test Loss: 1.0530\n",
            "Sample 1691: Test Loss: 0.2144\n",
            "Sample 1692: Test Loss: 0.0640\n",
            "Sample 1693: Test Loss: 0.2112\n",
            "Sample 1694: Test Loss: 25.3738\n",
            "Sample 1695: Test Loss: 0.2750\n",
            "Sample 1696: Test Loss: 0.0145\n",
            "Sample 1697: Test Loss: 0.7453\n",
            "Sample 1698: Test Loss: 0.1890\n",
            "Sample 1699: Test Loss: 0.1199\n",
            "Sample 1700: Test Loss: 0.0744\n",
            "Sample 1701: Test Loss: 0.0747\n",
            "Sample 1702: Test Loss: 3.6753\n",
            "Sample 1703: Test Loss: 0.2639\n",
            "Sample 1704: Test Loss: 0.9392\n",
            "Sample 1705: Test Loss: 0.0915\n",
            "Sample 1706: Test Loss: 0.2201\n",
            "Sample 1707: Test Loss: 0.0060\n",
            "Sample 1708: Test Loss: 0.1588\n",
            "Sample 1709: Test Loss: 0.4607\n",
            "Sample 1710: Test Loss: 1.0524\n",
            "Sample 1711: Test Loss: 0.6990\n",
            "Sample 1712: Test Loss: 0.7901\n",
            "Sample 1713: Test Loss: 5.1741\n",
            "Sample 1714: Test Loss: 0.0630\n",
            "Sample 1715: Test Loss: 0.3399\n",
            "Sample 1716: Test Loss: 0.6990\n",
            "Sample 1717: Test Loss: 1.0530\n",
            "Sample 1718: Test Loss: 0.0015\n",
            "Sample 1719: Test Loss: 0.4255\n",
            "Sample 1720: Test Loss: 0.2044\n",
            "Sample 1721: Test Loss: 0.0391\n",
            "Sample 1722: Test Loss: 0.2832\n",
            "Sample 1723: Test Loss: 1.7467\n",
            "Sample 1724: Test Loss: 0.1559\n",
            "Sample 1725: Test Loss: 0.2036\n",
            "Sample 1726: Test Loss: 0.2044\n",
            "Sample 1727: Test Loss: 0.0413\n",
            "Sample 1728: Test Loss: 1.0693\n",
            "Sample 1729: Test Loss: 0.4799\n",
            "Sample 1730: Test Loss: 0.0150\n",
            "Sample 1731: Test Loss: 0.2044\n",
            "Sample 1732: Test Loss: 1.2144\n",
            "Sample 1733: Test Loss: 0.2044\n",
            "Sample 1734: Test Loss: 0.4772\n",
            "Sample 1735: Test Loss: 0.2036\n",
            "Sample 1736: Test Loss: 0.7036\n",
            "Sample 1737: Test Loss: 0.6867\n",
            "Sample 1738: Test Loss: 0.0915\n",
            "Sample 1739: Test Loss: 0.5799\n",
            "Sample 1740: Test Loss: 0.2034\n",
            "Sample 1741: Test Loss: 0.0018\n",
            "Sample 1742: Test Loss: 0.2339\n",
            "Sample 1743: Test Loss: 0.1482\n",
            "Sample 1744: Test Loss: 0.3949\n",
            "Sample 1745: Test Loss: 0.5505\n",
            "Sample 1746: Test Loss: 0.3441\n",
            "Sample 1747: Test Loss: 0.2355\n",
            "Sample 1748: Test Loss: 0.2034\n",
            "Sample 1749: Test Loss: 0.0203\n",
            "Sample 1750: Test Loss: 1.1381\n",
            "Sample 1751: Test Loss: 0.1372\n",
            "Sample 1752: Test Loss: 0.3510\n",
            "Sample 1753: Test Loss: 3.0676\n",
            "Sample 1754: Test Loss: 1.0530\n",
            "Sample 1755: Test Loss: 1.0155\n",
            "Sample 1756: Test Loss: 0.0089\n",
            "Sample 1757: Test Loss: 0.0116\n",
            "Sample 1758: Test Loss: 0.2034\n",
            "Sample 1759: Test Loss: 0.0630\n",
            "Sample 1760: Test Loss: 0.2034\n",
            "Sample 1761: Test Loss: 0.2044\n",
            "Sample 1762: Test Loss: 0.7036\n",
            "Sample 1763: Test Loss: 0.0042\n",
            "Sample 1764: Test Loss: 0.9367\n",
            "Sample 1765: Test Loss: 0.5972\n",
            "Sample 1766: Test Loss: 0.5155\n",
            "Sample 1767: Test Loss: 0.5000\n",
            "Sample 1768: Test Loss: 1.0524\n",
            "Sample 1769: Test Loss: 0.0303\n",
            "Sample 1770: Test Loss: 0.0212\n",
            "Sample 1771: Test Loss: 0.4996\n",
            "Sample 1772: Test Loss: 0.0666\n",
            "Sample 1773: Test Loss: 0.0898\n",
            "Sample 1774: Test Loss: 0.0483\n",
            "Sample 1775: Test Loss: 0.2879\n",
            "Sample 1776: Test Loss: 0.7203\n",
            "Sample 1777: Test Loss: 0.4032\n",
            "Sample 1778: Test Loss: 1.2976\n",
            "Sample 1779: Test Loss: 0.0402\n",
            "Sample 1780: Test Loss: 0.5000\n",
            "Sample 1781: Test Loss: 0.7036\n",
            "Sample 1782: Test Loss: 0.0201\n",
            "Sample 1783: Test Loss: 1.0530\n",
            "Sample 1784: Test Loss: 1.0524\n",
            "Sample 1785: Test Loss: 1.0524\n",
            "Sample 1786: Test Loss: 0.3925\n",
            "Sample 1787: Test Loss: 0.2459\n",
            "Sample 1788: Test Loss: 0.0565\n",
            "Sample 1789: Test Loss: 0.6981\n",
            "Sample 1790: Test Loss: 3.9288\n",
            "Sample 1791: Test Loss: 0.0838\n",
            "Sample 1792: Test Loss: 0.0063\n",
            "Sample 1793: Test Loss: 0.1989\n",
            "Sample 1794: Test Loss: 1.0524\n",
            "Sample 1795: Test Loss: 0.0068\n",
            "Sample 1796: Test Loss: 0.2044\n",
            "Sample 1797: Test Loss: 0.1559\n",
            "Sample 1798: Test Loss: 0.7036\n",
            "Sample 1799: Test Loss: 0.1941\n",
            "Sample 1800: Test Loss: 0.1094\n",
            "Sample 1801: Test Loss: 1.0524\n",
            "Sample 1802: Test Loss: 1.0524\n",
            "Sample 1803: Test Loss: 1.9762\n",
            "Sample 1804: Test Loss: 0.2044\n",
            "Sample 1805: Test Loss: 0.2044\n",
            "Sample 1806: Test Loss: 0.1619\n",
            "Sample 1807: Test Loss: 1.0530\n",
            "Sample 1808: Test Loss: 0.2032\n",
            "Sample 1809: Test Loss: 0.7036\n",
            "Sample 1810: Test Loss: 0.7036\n",
            "Sample 1811: Test Loss: 0.7453\n",
            "Sample 1812: Test Loss: 1.7711\n",
            "Sample 1813: Test Loss: 0.0062\n",
            "Sample 1814: Test Loss: 0.0286\n",
            "Sample 1815: Test Loss: 0.1559\n",
            "Sample 1816: Test Loss: 1.0524\n",
            "Sample 1817: Test Loss: 0.0027\n",
            "Sample 1818: Test Loss: 0.8951\n",
            "Sample 1819: Test Loss: 0.3399\n",
            "Sample 1820: Test Loss: 0.9742\n",
            "Sample 1821: Test Loss: 2.6500\n",
            "Sample 1822: Test Loss: 0.2044\n",
            "Sample 1823: Test Loss: 0.2112\n",
            "Sample 1824: Test Loss: 0.3441\n",
            "Sample 1825: Test Loss: 1.0524\n",
            "Sample 1826: Test Loss: 0.0630\n",
            "Sample 1827: Test Loss: 0.5978\n",
            "Sample 1828: Test Loss: 0.5858\n",
            "Sample 1829: Test Loss: 0.0915\n",
            "Sample 1830: Test Loss: 0.3399\n",
            "Sample 1831: Test Loss: 0.0026\n",
            "Sample 1832: Test Loss: 0.2975\n",
            "Sample 1833: Test Loss: 0.0898\n",
            "Sample 1834: Test Loss: 0.8951\n",
            "Sample 1835: Test Loss: 0.7036\n",
            "Sample 1836: Test Loss: 0.3441\n",
            "Sample 1837: Test Loss: 0.4930\n",
            "Sample 1838: Test Loss: 0.0604\n",
            "Sample 1839: Test Loss: 0.1170\n",
            "Sample 1840: Test Loss: 0.0013\n",
            "Sample 1841: Test Loss: 0.1170\n",
            "Sample 1842: Test Loss: 0.6981\n",
            "Sample 1843: Test Loss: 0.0630\n",
            "Sample 1844: Test Loss: 0.7805\n",
            "Sample 1845: Test Loss: 0.0751\n",
            "Sample 1846: Test Loss: 0.8217\n",
            "Sample 1847: Test Loss: 0.0001\n",
            "Sample 1848: Test Loss: 0.1526\n",
            "Sample 1849: Test Loss: 0.2044\n",
            "Sample 1850: Test Loss: 0.2678\n",
            "Sample 1851: Test Loss: 0.5196\n",
            "Sample 1852: Test Loss: 1.6859\n",
            "Sample 1853: Test Loss: 0.3949\n",
            "Sample 1854: Test Loss: 0.4425\n",
            "Sample 1855: Test Loss: 0.4962\n",
            "Sample 1856: Test Loss: 0.2036\n",
            "Sample 1857: Test Loss: 0.5310\n",
            "Sample 1858: Test Loss: 0.6311\n",
            "Sample 1859: Test Loss: 0.2879\n",
            "Sample 1860: Test Loss: 0.3441\n",
            "Sample 1861: Test Loss: 0.2034\n",
            "Sample 1862: Test Loss: 0.0626\n",
            "Sample 1863: Test Loss: 0.2034\n",
            "Sample 1864: Test Loss: 0.1170\n",
            "Sample 1865: Test Loss: 1.0524\n",
            "Sample 1866: Test Loss: 0.0505\n",
            "Sample 1867: Test Loss: 0.2044\n",
            "Sample 1868: Test Loss: 1.0524\n",
            "Sample 1869: Test Loss: 0.1999\n",
            "Sample 1870: Test Loss: 0.1129\n",
            "Sample 1871: Test Loss: 0.2219\n",
            "Sample 1872: Test Loss: 0.0013\n",
            "Sample 1873: Test Loss: 0.8951\n",
            "Sample 1874: Test Loss: 0.3441\n",
            "Sample 1875: Test Loss: 0.1807\n",
            "Sample 1876: Test Loss: 0.2558\n",
            "Sample 1877: Test Loss: 0.2032\n",
            "Sample 1878: Test Loss: 0.7036\n",
            "Sample 1879: Test Loss: 0.1463\n",
            "Sample 1880: Test Loss: 0.7036\n",
            "Sample 1881: Test Loss: 3.8970\n",
            "Sample 1882: Test Loss: 0.2879\n",
            "Sample 1883: Test Loss: 0.3441\n",
            "Sample 1884: Test Loss: 0.5000\n",
            "Sample 1885: Test Loss: 0.3441\n",
            "Sample 1886: Test Loss: 1.0524\n",
            "Sample 1887: Test Loss: 0.2034\n",
            "Sample 1888: Test Loss: 0.0608\n",
            "Sample 1889: Test Loss: 1.0524\n",
            "Sample 1890: Test Loss: 0.0026\n",
            "Sample 1891: Test Loss: 0.6092\n",
            "Sample 1892: Test Loss: 0.2032\n",
            "Sample 1893: Test Loss: 0.5858\n",
            "Sample 1894: Test Loss: 0.5858\n",
            "Sample 1895: Test Loss: 0.2032\n",
            "Sample 1896: Test Loss: 0.7453\n",
            "Sample 1897: Test Loss: 0.0630\n",
            "Sample 1898: Test Loss: 0.1588\n",
            "Sample 1899: Test Loss: 0.2639\n",
            "Sample 1900: Test Loss: 3.4739\n",
            "Sample 1901: Test Loss: 0.1465\n",
            "Sample 1902: Test Loss: 0.4799\n",
            "Sample 1903: Test Loss: 0.2044\n",
            "Sample 1904: Test Loss: 0.0558\n",
            "Sample 1905: Test Loss: 0.2032\n",
            "Sample 1906: Test Loss: 0.4026\n",
            "Sample 1907: Test Loss: 0.0001\n",
            "Sample 1908: Test Loss: 0.2639\n",
            "Sample 1909: Test Loss: 1.0524\n",
            "Sample 1910: Test Loss: 0.1250\n",
            "Sample 1911: Test Loss: 0.0063\n",
            "Sample 1912: Test Loss: 0.4032\n",
            "Sample 1913: Test Loss: 3.6540\n",
            "Sample 1914: Test Loss: 0.0000\n",
            "Sample 1915: Test Loss: 0.5078\n",
            "Sample 1916: Test Loss: 0.2034\n",
            "Sample 1917: Test Loss: 0.0915\n",
            "Sample 1918: Test Loss: 0.1397\n",
            "Sample 1919: Test Loss: 0.3367\n",
            "Sample 1920: Test Loss: 0.8951\n",
            "Sample 1921: Test Loss: 0.0379\n",
            "Sample 1922: Test Loss: 0.1606\n",
            "Sample 1923: Test Loss: 1.0524\n",
            "Sample 1924: Test Loss: 0.1523\n",
            "Sample 1925: Test Loss: 0.5003\n",
            "Sample 1926: Test Loss: 0.0084\n",
            "Sample 1927: Test Loss: 0.4611\n",
            "Sample 1928: Test Loss: 0.0415\n",
            "Sample 1929: Test Loss: 1.0155\n",
            "Sample 1930: Test Loss: 0.2941\n",
            "Sample 1931: Test Loss: 0.2219\n",
            "Sample 1932: Test Loss: 1.1606\n",
            "Sample 1933: Test Loss: 0.0626\n",
            "Sample 1934: Test Loss: 0.3872\n",
            "Sample 1935: Test Loss: 1.0524\n",
            "Sample 1936: Test Loss: 0.3218\n",
            "Sample 1937: Test Loss: 1.0524\n",
            "Sample 1938: Test Loss: 0.3949\n",
            "Sample 1939: Test Loss: 0.5196\n",
            "Sample 1940: Test Loss: 0.5799\n",
            "Sample 1941: Test Loss: 0.0026\n",
            "Sample 1942: Test Loss: 1.0356\n",
            "Sample 1943: Test Loss: 0.0026\n",
            "Sample 1944: Test Loss: 0.9601\n",
            "Sample 1945: Test Loss: 0.4099\n",
            "Sample 1946: Test Loss: 0.4951\n",
            "Sample 1947: Test Loss: 0.4841\n",
            "Sample 1948: Test Loss: 0.7453\n",
            "Sample 1949: Test Loss: 0.3793\n",
            "Sample 1950: Test Loss: 0.0000\n",
            "Sample 1951: Test Loss: 1.0155\n",
            "Sample 1952: Test Loss: 0.3506\n",
            "Sample 1953: Test Loss: 1.6277\n",
            "Sample 1954: Test Loss: 0.2339\n",
            "Sample 1955: Test Loss: 0.2851\n",
            "Sample 1956: Test Loss: 0.0018\n",
            "Sample 1957: Test Loss: 0.0026\n",
            "Sample 1958: Test Loss: 0.2989\n",
            "Sample 1959: Test Loss: 0.0126\n",
            "Sample 1960: Test Loss: 0.8484\n",
            "Sample 1961: Test Loss: 0.0106\n",
            "Sample 1962: Test Loss: 2.0108\n",
            "Sample 1963: Test Loss: 0.7486\n",
            "Sample 1964: Test Loss: 0.1397\n",
            "Sample 1965: Test Loss: 0.1252\n",
            "Sample 1966: Test Loss: 0.2044\n",
            "Sample 1967: Test Loss: 1.0524\n",
            "Sample 1968: Test Loss: 0.6981\n",
            "Sample 1969: Test Loss: 0.6981\n",
            "Sample 1970: Test Loss: 0.7036\n",
            "Sample 1971: Test Loss: 0.0630\n",
            "Sample 1972: Test Loss: 0.0026\n",
            "Sample 1973: Test Loss: 0.3441\n",
            "Sample 1974: Test Loss: 1.0524\n",
            "Sample 1975: Test Loss: 0.1545\n",
            "Sample 1976: Test Loss: 0.1227\n",
            "Sample 1977: Test Loss: 0.2036\n",
            "Sample 1978: Test Loss: 0.1325\n",
            "Sample 1979: Test Loss: 0.5963\n",
            "Sample 1980: Test Loss: 1.0524\n",
            "Sample 1981: Test Loss: 0.0212\n",
            "Sample 1982: Test Loss: 0.3441\n",
            "Sample 1983: Test Loss: 0.7486\n",
            "Sample 1984: Test Loss: 2.8151\n",
            "Sample 1985: Test Loss: 0.4849\n",
            "Sample 1986: Test Loss: 0.7036\n",
            "Sample 1987: Test Loss: 0.4469\n",
            "Sample 1988: Test Loss: 0.0630\n",
            "Sample 1989: Test Loss: 0.0121\n",
            "Sample 1990: Test Loss: 1.0530\n",
            "Sample 1991: Test Loss: 1.0530\n",
            "Sample 1992: Test Loss: 0.0460\n",
            "Sample 1993: Test Loss: 1.0530\n",
            "Sample 1994: Test Loss: 0.4799\n",
            "Sample 1995: Test Loss: 0.2270\n",
            "Sample 1996: Test Loss: 0.0938\n",
            "Sample 1997: Test Loss: 0.2474\n",
            "Sample 1998: Test Loss: 0.2175\n",
            "Sample 1999: Test Loss: 0.0001\n",
            "Sample 2000: Test Loss: 0.6304\n",
            "Sample 2001: Test Loss: 0.3441\n",
            "Sample 2002: Test Loss: 0.1762\n",
            "Sample 2003: Test Loss: 0.1372\n",
            "Sample 2004: Test Loss: 0.0363\n",
            "Sample 2005: Test Loss: 0.1572\n",
            "Sample 2006: Test Loss: 0.0258\n",
            "Sample 2007: Test Loss: 0.0661\n",
            "Sample 2008: Test Loss: 0.2044\n",
            "Sample 2009: Test Loss: 0.0630\n",
            "Sample 2010: Test Loss: 1.0530\n",
            "Sample 2011: Test Loss: 0.6183\n",
            "Sample 2012: Test Loss: 0.3367\n",
            "Sample 2013: Test Loss: 0.7036\n",
            "Sample 2014: Test Loss: 0.1807\n",
            "Sample 2015: Test Loss: 0.0032\n",
            "Sample 2016: Test Loss: 0.5858\n",
            "Sample 2017: Test Loss: 8.3699\n",
            "Sample 2018: Test Loss: 0.2832\n",
            "Sample 2019: Test Loss: 0.2639\n",
            "Sample 2020: Test Loss: 0.0181\n",
            "Sample 2021: Test Loss: 0.3598\n",
            "Sample 2022: Test Loss: 0.4108\n",
            "Sample 2023: Test Loss: 1.0524\n",
            "Sample 2024: Test Loss: 0.2340\n",
            "Sample 2025: Test Loss: 0.1044\n",
            "Sample 2026: Test Loss: 0.3007\n",
            "Sample 2027: Test Loss: 0.1989\n",
            "Sample 2028: Test Loss: 0.0366\n",
            "Sample 2029: Test Loss: 0.2264\n",
            "Sample 2030: Test Loss: 0.1250\n",
            "Sample 2031: Test Loss: 0.3332\n",
            "Sample 2032: Test Loss: 0.0021\n",
            "Sample 2033: Test Loss: 0.0516\n",
            "Sample 2034: Test Loss: 0.0258\n",
            "Sample 2035: Test Loss: 0.1250\n",
            "Sample 2036: Test Loss: 0.1252\n",
            "Sample 2037: Test Loss: 0.0101\n",
            "Sample 2038: Test Loss: 0.2034\n",
            "Sample 2039: Test Loss: 0.0915\n",
            "Sample 2040: Test Loss: 0.4611\n",
            "Sample 2041: Test Loss: 0.7181\n",
            "Sample 2042: Test Loss: 0.2941\n",
            "Sample 2043: Test Loss: 7.1333\n",
            "Sample 2044: Test Loss: 0.3441\n",
            "Sample 2045: Test Loss: 1.0227\n",
            "Sample 2046: Test Loss: 0.0026\n",
            "Sample 2047: Test Loss: 1.0155\n",
            "Sample 2048: Test Loss: 1.0524\n",
            "Sample 2049: Test Loss: 0.6990\n",
            "Sample 2050: Test Loss: 0.0630\n",
            "Sample 2051: Test Loss: 0.7036\n",
            "Sample 2052: Test Loss: 0.0018\n",
            "Sample 2053: Test Loss: 0.5972\n",
            "Sample 2054: Test Loss: 0.0604\n",
            "Sample 2055: Test Loss: 0.7412\n",
            "Sample 2056: Test Loss: 0.2483\n",
            "Sample 2057: Test Loss: 0.5972\n",
            "Sample 2058: Test Loss: 0.2032\n",
            "Sample 2059: Test Loss: 1.0524\n",
            "Sample 2060: Test Loss: 0.8951\n",
            "Sample 2061: Test Loss: 1.0524\n",
            "Sample 2062: Test Loss: 0.6990\n",
            "Sample 2063: Test Loss: 0.0364\n",
            "Sample 2064: Test Loss: 0.0838\n",
            "Sample 2065: Test Loss: 0.0611\n",
            "Sample 2066: Test Loss: 0.5000\n",
            "Sample 2067: Test Loss: 0.0026\n",
            "Sample 2068: Test Loss: 0.2044\n",
            "Sample 2069: Test Loss: 1.1511\n",
            "Sample 2070: Test Loss: 0.0043\n",
            "Sample 2071: Test Loss: 0.6304\n",
            "Sample 2072: Test Loss: 0.0011\n",
            "Sample 2073: Test Loss: 1.2511\n",
            "Sample 2074: Test Loss: 0.0168\n",
            "Sample 2075: Test Loss: 0.0460\n",
            "Sample 2076: Test Loss: 0.0632\n",
            "Sample 2077: Test Loss: 0.0640\n",
            "Sample 2078: Test Loss: 0.3399\n",
            "Sample 2079: Test Loss: 1.0524\n",
            "Sample 2080: Test Loss: 0.5733\n",
            "Sample 2081: Test Loss: 0.3441\n",
            "Sample 2082: Test Loss: 0.0026\n",
            "Sample 2083: Test Loss: 0.0287\n",
            "Sample 2084: Test Loss: 0.7036\n",
            "Sample 2085: Test Loss: 0.3441\n",
            "Sample 2086: Test Loss: 0.0018\n",
            "Sample 2087: Test Loss: 0.3598\n",
            "Sample 2088: Test Loss: 0.1170\n",
            "Sample 2089: Test Loss: 0.8951\n",
            "Sample 2090: Test Loss: 1.0524\n",
            "Sample 2091: Test Loss: 0.0026\n",
            "Sample 2092: Test Loss: 0.1174\n",
            "Sample 2093: Test Loss: 0.3933\n",
            "Sample 2094: Test Loss: 0.5000\n",
            "Sample 2095: Test Loss: 0.1250\n",
            "Sample 2096: Test Loss: 0.0596\n",
            "Sample 2097: Test Loss: 0.0476\n",
            "Sample 2098: Test Loss: 0.7036\n",
            "Sample 2099: Test Loss: 0.0909\n",
            "Sample 2100: Test Loss: 0.0466\n",
            "Sample 2101: Test Loss: 0.2032\n",
            "Sample 2102: Test Loss: 1.0224\n",
            "Sample 2103: Test Loss: 0.5858\n",
            "Sample 2104: Test Loss: 0.6741\n",
            "Sample 2105: Test Loss: 0.1927\n",
            "Sample 2106: Test Loss: 0.2032\n",
            "Sample 2107: Test Loss: 0.5858\n",
            "Sample 2108: Test Loss: 0.0005\n",
            "Sample 2109: Test Loss: 0.4397\n",
            "Sample 2110: Test Loss: 0.3568\n",
            "Sample 2111: Test Loss: 1.6573\n",
            "Sample 2112: Test Loss: 1.0524\n",
            "Sample 2113: Test Loss: 0.1250\n",
            "Sample 2114: Test Loss: 0.9367\n",
            "Sample 2115: Test Loss: 0.1465\n",
            "Sample 2116: Test Loss: 0.0013\n",
            "Sample 2117: Test Loss: 0.2034\n",
            "Sample 2118: Test Loss: 0.1113\n",
            "Sample 2119: Test Loss: 0.2153\n",
            "Sample 2120: Test Loss: 0.2032\n",
            "Sample 2121: Test Loss: 0.2034\n",
            "Sample 2122: Test Loss: 0.0000\n",
            "Sample 2123: Test Loss: 0.2759\n",
            "Sample 2124: Test Loss: 0.0768\n",
            "Sample 2125: Test Loss: 0.0560\n",
            "Sample 2126: Test Loss: 0.2034\n",
            "Sample 2127: Test Loss: 0.2832\n",
            "Sample 2128: Test Loss: 0.0102\n",
            "Sample 2129: Test Loss: 1.0266\n",
            "Sample 2130: Test Loss: 0.1523\n",
            "Sample 2131: Test Loss: 0.2611\n",
            "Sample 2132: Test Loss: 0.0576\n",
            "Sample 2133: Test Loss: 0.0898\n",
            "Sample 2134: Test Loss: 0.6990\n",
            "Sample 2135: Test Loss: 1.0155\n",
            "Sample 2136: Test Loss: 1.0524\n",
            "Sample 2137: Test Loss: 0.0626\n",
            "Sample 2138: Test Loss: 2.6565\n",
            "Sample 2139: Test Loss: 0.2639\n",
            "Sample 2140: Test Loss: 0.2032\n",
            "Sample 2141: Test Loss: 0.3441\n",
            "Sample 2142: Test Loss: 0.1559\n",
            "Sample 2143: Test Loss: 0.0026\n",
            "Sample 2144: Test Loss: 0.0020\n",
            "Sample 2145: Test Loss: 0.0001\n",
            "Sample 2146: Test Loss: 0.0286\n",
            "Sample 2147: Test Loss: 0.7453\n",
            "Sample 2148: Test Loss: 0.7453\n",
            "Sample 2149: Test Loss: 1.0524\n",
            "Sample 2150: Test Loss: 1.0524\n",
            "Sample 2151: Test Loss: 0.7036\n",
            "Sample 2152: Test Loss: 2.6555\n",
            "Sample 2153: Test Loss: 0.0007\n",
            "Sample 2154: Test Loss: 1.0155\n",
            "Sample 2155: Test Loss: 1.0524\n",
            "Sample 2156: Test Loss: 0.1482\n",
            "Sample 2157: Test Loss: 0.0505\n",
            "Sample 2158: Test Loss: 0.0063\n",
            "Sample 2159: Test Loss: 0.2044\n",
            "Sample 2160: Test Loss: 0.0075\n",
            "Sample 2161: Test Loss: 1.0524\n",
            "Sample 2162: Test Loss: 0.1625\n",
            "Sample 2163: Test Loss: 1.0524\n",
            "Sample 2164: Test Loss: 0.7576\n",
            "Sample 2165: Test Loss: 0.2036\n",
            "Sample 2166: Test Loss: 0.0594\n",
            "Sample 2167: Test Loss: 0.0303\n",
            "Sample 2168: Test Loss: 0.0001\n",
            "Sample 2169: Test Loss: 0.0391\n",
            "Sample 2170: Test Loss: 0.1170\n",
            "Sample 2171: Test Loss: 2.0097\n",
            "Sample 2172: Test Loss: 0.0042\n",
            "Sample 2173: Test Loss: 0.8951\n",
            "Sample 2174: Test Loss: 4.5364\n",
            "Sample 2175: Test Loss: 2.6500\n",
            "Sample 2176: Test Loss: 0.2361\n",
            "Sample 2177: Test Loss: 0.0116\n",
            "Sample 2178: Test Loss: 0.0027\n",
            "Sample 2179: Test Loss: 0.3402\n",
            "Sample 2180: Test Loss: 1.0524\n",
            "Sample 2181: Test Loss: 0.4650\n",
            "Sample 2182: Test Loss: 0.0145\n",
            "Sample 2183: Test Loss: 0.8951\n",
            "Sample 2184: Test Loss: 0.1559\n",
            "Sample 2185: Test Loss: 0.0258\n",
            "Sample 2186: Test Loss: 0.0026\n",
            "Sample 2187: Test Loss: 0.5003\n",
            "Sample 2188: Test Loss: 0.0284\n",
            "Sample 2189: Test Loss: 0.3399\n",
            "Sample 2190: Test Loss: 0.1508\n",
            "Sample 2191: Test Loss: 1.0524\n",
            "Sample 2192: Test Loss: 1.0266\n",
            "Sample 2193: Test Loss: 0.2276\n",
            "Sample 2194: Test Loss: 1.0524\n",
            "Sample 2195: Test Loss: 0.2044\n",
            "Sample 2196: Test Loss: 0.1989\n",
            "Sample 2197: Test Loss: 0.2639\n",
            "Sample 2198: Test Loss: 0.0001\n",
            "Sample 2199: Test Loss: 0.0066\n",
            "Sample 2200: Test Loss: 0.6990\n",
            "Sample 2201: Test Loss: 0.3519\n",
            "Sample 2202: Test Loss: 0.3441\n",
            "Sample 2203: Test Loss: 0.2879\n",
            "Sample 2204: Test Loss: 0.0915\n",
            "Sample 2205: Test Loss: 0.1441\n",
            "Sample 2206: Test Loss: 0.0144\n",
            "Sample 2207: Test Loss: 0.4841\n",
            "Sample 2208: Test Loss: 0.1330\n",
            "Sample 2209: Test Loss: 0.5196\n",
            "Sample 2210: Test Loss: 0.0125\n",
            "Sample 2211: Test Loss: 0.1118\n",
            "Sample 2212: Test Loss: 0.2034\n",
            "Sample 2213: Test Loss: 1.0524\n",
            "Sample 2214: Test Loss: 1.0524\n",
            "Sample 2215: Test Loss: 0.9367\n",
            "Sample 2216: Test Loss: 0.1039\n",
            "Sample 2217: Test Loss: 0.5161\n",
            "Sample 2218: Test Loss: 1.5887\n",
            "Sample 2219: Test Loss: 0.0000\n",
            "Sample 2220: Test Loss: 0.0063\n",
            "Sample 2221: Test Loss: 0.2034\n",
            "Sample 2222: Test Loss: 1.4226\n",
            "Sample 2223: Test Loss: 0.7036\n",
            "Sample 2224: Test Loss: 0.0005\n",
            "Sample 2225: Test Loss: 1.0155\n",
            "Sample 2226: Test Loss: 0.8121\n",
            "Sample 2227: Test Loss: 1.0524\n",
            "Sample 2228: Test Loss: 0.0390\n",
            "Sample 2229: Test Loss: 0.0018\n",
            "Sample 2230: Test Loss: 0.3399\n",
            "Sample 2231: Test Loss: 0.7036\n",
            "Sample 2232: Test Loss: 0.7036\n",
            "Sample 2233: Test Loss: 0.5972\n",
            "Sample 2234: Test Loss: 0.0005\n",
            "Sample 2235: Test Loss: 0.1817\n",
            "Sample 2236: Test Loss: 1.0155\n",
            "Sample 2237: Test Loss: 0.3399\n",
            "Sample 2238: Test Loss: 0.2204\n",
            "Sample 2239: Test Loss: 0.0004\n",
            "Sample 2240: Test Loss: 0.2032\n",
            "Sample 2241: Test Loss: 0.5000\n",
            "Sample 2242: Test Loss: 1.0155\n",
            "Sample 2243: Test Loss: 0.2699\n",
            "Sample 2244: Test Loss: 0.3332\n",
            "Sample 2245: Test Loss: 0.4930\n",
            "Sample 2246: Test Loss: 0.1950\n",
            "Sample 2247: Test Loss: 0.0247\n",
            "Sample 2248: Test Loss: 1.0524\n",
            "Sample 2249: Test Loss: 0.5972\n",
            "Sample 2250: Test Loss: 0.3584\n",
            "Sample 2251: Test Loss: 0.2935\n",
            "Sample 2252: Test Loss: 0.2079\n",
            "Sample 2253: Test Loss: 0.2832\n",
            "Sample 2254: Test Loss: 0.7036\n",
            "Sample 2255: Test Loss: 0.0989\n",
            "Sample 2256: Test Loss: 0.6242\n",
            "Sample 2257: Test Loss: 0.1362\n",
            "Sample 2258: Test Loss: 0.3441\n",
            "Sample 2259: Test Loss: 0.2198\n",
            "Sample 2260: Test Loss: 0.1250\n",
            "Sample 2261: Test Loss: 8.7942\n",
            "Sample 2262: Test Loss: 0.1250\n",
            "Sample 2263: Test Loss: 0.2759\n",
            "Sample 2264: Test Loss: 0.0553\n",
            "Sample 2265: Test Loss: 0.9367\n",
            "Sample 2266: Test Loss: 0.4841\n",
            "Sample 2267: Test Loss: 0.0626\n",
            "Sample 2268: Test Loss: 0.0466\n",
            "Sample 2269: Test Loss: 0.5743\n",
            "Sample 2270: Test Loss: 0.4799\n",
            "Sample 2271: Test Loss: 0.5972\n",
            "Sample 2272: Test Loss: 0.2032\n",
            "Sample 2273: Test Loss: 0.2044\n",
            "Sample 2274: Test Loss: 0.8748\n",
            "Sample 2275: Test Loss: 0.3568\n",
            "Sample 2276: Test Loss: 0.0590\n",
            "Sample 2277: Test Loss: 0.3353\n",
            "Sample 2278: Test Loss: 0.0108\n",
            "Sample 2279: Test Loss: 0.4607\n",
            "Sample 2280: Test Loss: 0.2759\n",
            "Sample 2281: Test Loss: 0.0630\n",
            "Sample 2282: Test Loss: 0.5972\n",
            "Sample 2283: Test Loss: 0.3949\n",
            "Sample 2284: Test Loss: 0.9651\n",
            "Sample 2285: Test Loss: 0.1989\n",
            "Sample 2286: Test Loss: 0.0502\n",
            "Sample 2287: Test Loss: 1.0524\n",
            "Sample 2288: Test Loss: 0.0234\n",
            "Sample 2289: Test Loss: 0.0001\n",
            "Sample 2290: Test Loss: 0.0005\n",
            "Sample 2291: Test Loss: 0.2112\n",
            "Sample 2292: Test Loss: 0.8484\n",
            "Sample 2293: Test Loss: 0.0454\n",
            "Sample 2294: Test Loss: 0.1559\n",
            "Sample 2295: Test Loss: 0.2044\n",
            "Sample 2296: Test Loss: 0.0018\n",
            "Sample 2297: Test Loss: 0.8828\n",
            "Sample 2298: Test Loss: 0.0630\n",
            "Sample 2299: Test Loss: 1.0524\n",
            "Sample 2300: Test Loss: 0.4611\n",
            "Sample 2301: Test Loss: 0.1599\n",
            "Sample 2302: Test Loss: 0.2759\n",
            "Sample 2303: Test Loss: 1.0063\n",
            "Sample 2304: Test Loss: 2.2806\n",
            "Sample 2305: Test Loss: 1.7778\n",
            "Sample 2306: Test Loss: 0.8951\n",
            "Sample 2307: Test Loss: 0.1298\n",
            "Sample 2308: Test Loss: 0.2044\n",
            "Sample 2309: Test Loss: 0.6092\n",
            "Sample 2310: Test Loss: 0.0060\n",
            "Sample 2311: Test Loss: 0.7259\n",
            "Sample 2312: Test Loss: 0.2032\n",
            "Sample 2313: Test Loss: 1.0524\n",
            "Sample 2314: Test Loss: 1.0524\n",
            "Sample 2315: Test Loss: 0.0630\n",
            "Sample 2316: Test Loss: 0.8951\n",
            "Sample 2317: Test Loss: 0.0915\n",
            "Sample 2318: Test Loss: 0.5003\n",
            "Sample 2319: Test Loss: 0.3399\n",
            "Sample 2320: Test Loss: 0.3441\n",
            "Sample 2321: Test Loss: 0.0018\n",
            "Sample 2322: Test Loss: 0.3949\n",
            "Sample 2323: Test Loss: 1.0524\n",
            "Sample 2324: Test Loss: 0.2759\n",
            "Sample 2325: Test Loss: 0.2832\n",
            "Sample 2326: Test Loss: 0.1264\n",
            "Sample 2327: Test Loss: 0.4799\n",
            "Sample 2328: Test Loss: 0.1551\n",
            "Sample 2329: Test Loss: 0.0062\n",
            "Sample 2330: Test Loss: 0.2935\n",
            "Sample 2331: Test Loss: 0.0183\n",
            "Sample 2332: Test Loss: 0.1399\n",
            "Sample 2333: Test Loss: 0.0007\n",
            "Sample 2334: Test Loss: 1.0524\n",
            "Sample 2335: Test Loss: 0.7036\n",
            "Sample 2336: Test Loss: 0.3949\n",
            "Sample 2337: Test Loss: 0.1250\n",
            "Sample 2338: Test Loss: 0.7036\n",
            "Sample 2339: Test Loss: 0.7036\n",
            "Sample 2340: Test Loss: 0.0026\n",
            "Sample 2341: Test Loss: 0.0001\n",
            "Sample 2342: Test Loss: 0.5310\n",
            "Sample 2343: Test Loss: 0.5972\n",
            "Sample 2344: Test Loss: 0.1559\n",
            "Sample 2345: Test Loss: 0.0685\n",
            "Sample 2346: Test Loss: 0.7036\n",
            "Sample 2347: Test Loss: 1.0524\n",
            "Sample 2348: Test Loss: 0.5000\n",
            "Sample 2349: Test Loss: 0.2032\n",
            "Sample 2350: Test Loss: 0.2759\n",
            "Sample 2351: Test Loss: 1.0524\n",
            "Sample 2352: Test Loss: 0.8484\n",
            "Sample 2353: Test Loss: 0.3441\n",
            "Sample 2354: Test Loss: 0.0258\n",
            "Sample 2355: Test Loss: 0.2304\n",
            "Sample 2356: Test Loss: 0.2738\n",
            "Sample 2357: Test Loss: 0.6571\n",
            "Sample 2358: Test Loss: 0.1250\n",
            "Sample 2359: Test Loss: 0.2699\n",
            "Sample 2360: Test Loss: 0.5972\n",
            "Sample 2361: Test Loss: 1.0155\n",
            "Sample 2362: Test Loss: 0.1250\n",
            "Sample 2363: Test Loss: 0.3399\n",
            "Sample 2364: Test Loss: 0.0077\n",
            "Sample 2365: Test Loss: 0.3399\n",
            "Sample 2366: Test Loss: 1.0524\n",
            "Sample 2367: Test Loss: 0.6483\n",
            "Sample 2368: Test Loss: 0.2534\n",
            "Sample 2369: Test Loss: 0.2639\n",
            "Sample 2370: Test Loss: 1.0524\n",
            "Sample 2371: Test Loss: 0.3949\n",
            "Sample 2372: Test Loss: 0.6990\n",
            "Sample 2373: Test Loss: 0.1274\n",
            "Sample 2374: Test Loss: 0.2984\n",
            "Sample 2375: Test Loss: 0.3352\n",
            "Sample 2376: Test Loss: 1.0530\n",
            "Sample 2377: Test Loss: 0.0026\n",
            "Sample 2378: Test Loss: 0.2032\n",
            "Sample 2379: Test Loss: 0.2032\n",
            "Sample 2380: Test Loss: 0.0133\n",
            "Sample 2381: Test Loss: 0.2044\n",
            "Sample 2382: Test Loss: 1.0197\n",
            "Sample 2383: Test Loss: 0.0630\n",
            "Sample 2384: Test Loss: 1.0524\n",
            "Sample 2385: Test Loss: 0.0001\n",
            "Sample 2386: Test Loss: 1.0524\n",
            "Sample 2387: Test Loss: 1.0155\n",
            "Sample 2388: Test Loss: 0.2323\n",
            "Sample 2389: Test Loss: 0.7036\n",
            "Sample 2390: Test Loss: 0.0026\n",
            "Sample 2391: Test Loss: 0.0505\n",
            "Sample 2392: Test Loss: 0.0435\n",
            "Sample 2393: Test Loss: 1.0524\n",
            "Sample 2394: Test Loss: 0.0594\n",
            "Sample 2395: Test Loss: 0.5972\n",
            "Sample 2396: Test Loss: 0.2219\n",
            "Sample 2397: Test Loss: 0.0000\n",
            "Sample 2398: Test Loss: 0.0499\n",
            "Sample 2399: Test Loss: 0.0455\n",
            "Sample 2400: Test Loss: 0.3367\n",
            "Sample 2401: Test Loss: 0.8951\n",
            "Sample 2402: Test Loss: 0.3441\n",
            "Sample 2403: Test Loss: 0.0552\n",
            "Sample 2404: Test Loss: 0.8225\n",
            "Sample 2405: Test Loss: 1.0524\n",
            "Sample 2406: Test Loss: 0.0026\n",
            "Sample 2407: Test Loss: 0.0005\n",
            "Sample 2408: Test Loss: 0.4611\n",
            "Sample 2409: Test Loss: 0.4841\n",
            "Sample 2410: Test Loss: 1.0530\n",
            "Sample 2411: Test Loss: 0.0418\n",
            "Sample 2412: Test Loss: 0.9367\n",
            "Sample 2413: Test Loss: 0.2778\n",
            "Sample 2414: Test Loss: 0.2048\n",
            "Sample 2415: Test Loss: 0.8358\n",
            "Sample 2416: Test Loss: 0.8363\n",
            "Sample 2417: Test Loss: 0.0478\n",
            "Sample 2418: Test Loss: 0.1040\n",
            "Sample 2419: Test Loss: 0.1170\n",
            "Sample 2420: Test Loss: 0.1192\n",
            "Sample 2421: Test Loss: 0.4701\n",
            "Sample 2422: Test Loss: 0.2112\n",
            "Sample 2423: Test Loss: 0.9367\n",
            "Sample 2424: Test Loss: 0.5392\n",
            "Sample 2425: Test Loss: 0.0023\n",
            "Sample 2426: Test Loss: 0.3764\n",
            "Sample 2427: Test Loss: 0.3575\n",
            "Sample 2428: Test Loss: 0.3006\n",
            "Sample 2429: Test Loss: 0.9859\n",
            "Sample 2430: Test Loss: 1.0524\n",
            "Sample 2431: Test Loss: 0.0068\n",
            "Sample 2432: Test Loss: 0.3399\n",
            "Sample 2433: Test Loss: 0.0026\n",
            "Sample 2434: Test Loss: 0.2363\n",
            "Sample 2435: Test Loss: 0.8951\n",
            "Sample 2436: Test Loss: 0.1559\n",
            "Sample 2437: Test Loss: 0.2219\n",
            "Sample 2438: Test Loss: 0.4799\n",
            "Sample 2439: Test Loss: 0.2962\n",
            "Sample 2440: Test Loss: 2.4699\n",
            "Sample 2441: Test Loss: 1.0155\n",
            "Sample 2442: Test Loss: 1.4537\n",
            "Sample 2443: Test Loss: 0.0630\n",
            "Sample 2444: Test Loss: 0.0298\n",
            "Sample 2445: Test Loss: 0.1114\n",
            "Sample 2446: Test Loss: 0.2750\n",
            "Sample 2447: Test Loss: 0.0212\n",
            "Sample 2448: Test Loss: 0.2339\n",
            "Sample 2449: Test Loss: 0.4032\n",
            "Sample 2450: Test Loss: 0.3248\n",
            "Sample 2451: Test Loss: 0.7036\n",
            "Sample 2452: Test Loss: 0.0026\n",
            "Sample 2453: Test Loss: 0.0205\n",
            "Sample 2454: Test Loss: 0.0513\n",
            "Sample 2455: Test Loss: 1.0524\n",
            "Sample 2456: Test Loss: 0.0802\n",
            "Sample 2457: Test Loss: 0.2340\n",
            "Sample 2458: Test Loss: 1.4375\n",
            "Sample 2459: Test Loss: 1.0524\n",
            "Sample 2460: Test Loss: 0.6092\n",
            "Sample 2461: Test Loss: 0.2034\n",
            "Sample 2462: Test Loss: 0.6155\n",
            "Sample 2463: Test Loss: 0.0025\n",
            "Sample 2464: Test Loss: 1.0524\n",
            "Sample 2465: Test Loss: 0.2639\n",
            "Sample 2466: Test Loss: 0.0880\n",
            "Sample 2467: Test Loss: 0.2699\n",
            "Sample 2468: Test Loss: 0.3441\n",
            "Sample 2469: Test Loss: 0.2044\n",
            "Sample 2470: Test Loss: 0.2034\n",
            "Sample 2471: Test Loss: 1.0524\n",
            "Sample 2472: Test Loss: 0.1372\n",
            "Sample 2473: Test Loss: 0.6990\n",
            "Sample 2474: Test Loss: 0.4761\n",
            "Sample 2475: Test Loss: 0.2326\n",
            "Sample 2476: Test Loss: 0.2044\n",
            "Sample 2477: Test Loss: 0.2144\n",
            "Sample 2478: Test Loss: 0.4841\n",
            "Sample 2479: Test Loss: 0.7036\n",
            "Sample 2480: Test Loss: 0.1170\n",
            "Sample 2481: Test Loss: 0.0236\n",
            "Sample 2482: Test Loss: 0.0150\n",
            "Sample 2483: Test Loss: 0.0630\n",
            "Sample 2484: Test Loss: 0.4466\n",
            "Sample 2485: Test Loss: 0.0789\n",
            "Sample 2486: Test Loss: 0.3059\n",
            "Sample 2487: Test Loss: 0.0182\n",
            "Sample 2488: Test Loss: 0.0108\n",
            "Sample 2489: Test Loss: 0.1924\n",
            "Sample 2490: Test Loss: 0.0053\n",
            "Sample 2491: Test Loss: 1.0524\n",
            "Sample 2492: Test Loss: 0.4523\n",
            "Sample 2493: Test Loss: 0.8951\n",
            "Sample 2494: Test Loss: 0.0978\n",
            "Sample 2495: Test Loss: 0.2219\n",
            "Sample 2496: Test Loss: 0.3949\n",
            "Sample 2497: Test Loss: 1.0524\n",
            "Sample 2498: Test Loss: 1.0530\n",
            "Sample 2499: Test Loss: 0.0950\n",
            "Sample 2500: Test Loss: 0.0212\n",
            "Sample 2501: Test Loss: 0.1250\n",
            "Sample 2502: Test Loss: 0.1020\n",
            "Sample 2503: Test Loss: 0.2044\n",
            "Sample 2504: Test Loss: 0.0002\n",
            "Sample 2505: Test Loss: 0.0005\n",
            "Sample 2506: Test Loss: 0.2759\n",
            "Sample 2507: Test Loss: 0.0378\n",
            "Sample 2508: Test Loss: 0.0026\n",
            "Sample 2509: Test Loss: 0.2759\n",
            "Sample 2510: Test Loss: 1.0156\n",
            "Sample 2511: Test Loss: 0.1250\n",
            "Sample 2512: Test Loss: 0.3758\n",
            "Sample 2513: Test Loss: 0.0205\n",
            "Sample 2514: Test Loss: 0.0505\n",
            "Sample 2515: Test Loss: 0.2044\n",
            "Sample 2516: Test Loss: 0.7453\n",
            "Sample 2517: Test Loss: 0.0034\n",
            "Sample 2518: Test Loss: 0.7036\n",
            "Sample 2519: Test Loss: 0.9367\n",
            "Sample 2520: Test Loss: 0.0026\n",
            "Sample 2521: Test Loss: 0.2832\n",
            "Sample 2522: Test Loss: 0.6304\n",
            "Sample 2523: Test Loss: 0.0026\n",
            "Sample 2524: Test Loss: 0.0205\n",
            "Sample 2525: Test Loss: 0.1838\n",
            "Sample 2526: Test Loss: 0.3399\n",
            "Sample 2527: Test Loss: 0.5501\n",
            "Sample 2528: Test Loss: 0.6846\n",
            "Sample 2529: Test Loss: 0.0212\n",
            "Sample 2530: Test Loss: 26.0081\n",
            "Sample 2531: Test Loss: 0.2044\n",
            "Sample 2532: Test Loss: 0.3399\n",
            "Sample 2533: Test Loss: 0.4611\n",
            "Sample 2534: Test Loss: 0.7036\n",
            "Sample 2535: Test Loss: 0.0630\n",
            "Sample 2536: Test Loss: 0.0402\n",
            "Sample 2537: Test Loss: 0.0637\n",
            "Sample 2538: Test Loss: 1.0359\n",
            "Sample 2539: Test Loss: 0.3399\n",
            "Sample 2540: Test Loss: 0.2036\n",
            "Sample 2541: Test Loss: 0.2747\n",
            "Sample 2542: Test Loss: 0.8951\n",
            "Sample 2543: Test Loss: 0.0018\n",
            "Sample 2544: Test Loss: 0.2761\n",
            "Sample 2545: Test Loss: 0.2175\n",
            "Sample 2546: Test Loss: 0.0108\n",
            "Sample 2547: Test Loss: 1.0524\n",
            "Sample 2548: Test Loss: 1.0524\n",
            "Sample 2549: Test Loss: 0.1039\n",
            "Sample 2550: Test Loss: 0.4607\n",
            "Sample 2551: Test Loss: 0.1989\n",
            "Sample 2552: Test Loss: 0.5089\n",
            "Sample 2553: Test Loss: 0.6990\n",
            "Sample 2554: Test Loss: 0.0207\n",
            "Sample 2555: Test Loss: 0.0915\n",
            "Sample 2556: Test Loss: 0.2699\n",
            "Sample 2557: Test Loss: 0.0000\n",
            "Sample 2558: Test Loss: 0.3286\n",
            "Sample 2559: Test Loss: 0.0640\n",
            "Sample 2560: Test Loss: 0.8951\n",
            "Sample 2561: Test Loss: 0.1364\n",
            "Sample 2562: Test Loss: 0.0625\n",
            "Sample 2563: Test Loss: 0.0026\n",
            "Sample 2564: Test Loss: 0.1556\n",
            "Sample 2565: Test Loss: 0.6551\n",
            "Sample 2566: Test Loss: 0.5858\n",
            "Sample 2567: Test Loss: 0.5003\n",
            "Sample 2568: Test Loss: 1.0524\n",
            "Sample 2569: Test Loss: 0.1602\n",
            "Sample 2570: Test Loss: 0.4611\n",
            "Sample 2571: Test Loss: 0.0022\n",
            "Sample 2572: Test Loss: 1.0524\n",
            "Sample 2573: Test Loss: 0.0640\n",
            "Sample 2574: Test Loss: 0.0000\n",
            "Sample 2575: Test Loss: 0.0429\n",
            "Sample 2576: Test Loss: 10.1006\n",
            "Sample 2577: Test Loss: 0.3399\n",
            "Sample 2578: Test Loss: 0.0026\n",
            "Sample 2579: Test Loss: 0.0693\n",
            "Sample 2580: Test Loss: 1.0530\n",
            "Sample 2581: Test Loss: 0.8951\n",
            "Sample 2582: Test Loss: 0.2750\n",
            "Sample 2583: Test Loss: 0.1170\n",
            "Sample 2584: Test Loss: 1.0524\n",
            "Sample 2585: Test Loss: 0.6990\n",
            "Sample 2586: Test Loss: 0.2759\n",
            "Sample 2587: Test Loss: 1.2979\n",
            "Sample 2588: Test Loss: 1.2728\n",
            "Sample 2589: Test Loss: 0.0098\n",
            "Sample 2590: Test Loss: 0.4930\n",
            "Sample 2591: Test Loss: 0.0099\n",
            "Sample 2592: Test Loss: 1.0530\n",
            "Sample 2593: Test Loss: 0.1588\n",
            "Sample 2594: Test Loss: 0.2044\n",
            "Sample 2595: Test Loss: 0.1372\n",
            "Sample 2596: Test Loss: 0.3441\n",
            "Sample 2597: Test Loss: 0.0119\n",
            "Sample 2598: Test Loss: 0.0026\n",
            "Sample 2599: Test Loss: 0.5972\n",
            "Sample 2600: Test Loss: 0.4032\n",
            "Sample 2601: Test Loss: 0.8951\n",
            "Sample 2602: Test Loss: 0.3402\n",
            "Sample 2603: Test Loss: 0.7036\n",
            "Sample 2604: Test Loss: 0.0026\n",
            "Sample 2605: Test Loss: 0.4607\n",
            "Sample 2606: Test Loss: 0.1250\n",
            "Sample 2607: Test Loss: 0.0026\n",
            "Sample 2608: Test Loss: 0.2034\n",
            "Sample 2609: Test Loss: 0.0001\n",
            "Sample 2610: Test Loss: 0.0067\n",
            "Sample 2611: Test Loss: 0.3598\n",
            "Sample 2612: Test Loss: 0.6990\n",
            "Sample 2613: Test Loss: 0.0063\n",
            "Sample 2614: Test Loss: 0.4930\n",
            "Sample 2615: Test Loss: 1.0524\n",
            "Sample 2616: Test Loss: 0.8951\n",
            "Sample 2617: Test Loss: 0.0151\n",
            "Sample 2618: Test Loss: 0.2759\n",
            "Sample 2619: Test Loss: 0.0212\n",
            "Sample 2620: Test Loss: 0.2036\n",
            "Sample 2621: Test Loss: 0.6990\n",
            "Sample 2622: Test Loss: 0.2032\n",
            "Sample 2623: Test Loss: 0.5858\n",
            "Sample 2624: Test Loss: 0.6448\n",
            "Sample 2625: Test Loss: 0.0630\n",
            "Sample 2626: Test Loss: 0.0018\n",
            "Sample 2627: Test Loss: 0.6990\n",
            "Sample 2628: Test Loss: 2.8796\n",
            "Sample 2629: Test Loss: 0.4799\n",
            "Sample 2630: Test Loss: 0.0315\n",
            "Sample 2631: Test Loss: 0.3584\n",
            "Sample 2632: Test Loss: 0.1003\n",
            "Sample 2633: Test Loss: 0.4996\n",
            "Sample 2634: Test Loss: 0.7036\n",
            "Sample 2635: Test Loss: 0.0630\n",
            "Sample 2636: Test Loss: 0.2034\n",
            "Sample 2637: Test Loss: 0.0025\n",
            "Sample 2638: Test Loss: 0.3288\n",
            "Sample 2639: Test Loss: 1.0524\n",
            "Sample 2640: Test Loss: 0.5858\n",
            "Sample 2641: Test Loss: 0.3399\n",
            "Sample 2642: Test Loss: 0.0630\n",
            "Sample 2643: Test Loss: 0.8944\n",
            "Sample 2644: Test Loss: 0.0558\n",
            "Sample 2645: Test Loss: 0.2044\n",
            "Sample 2646: Test Loss: 0.1581\n",
            "Sample 2647: Test Loss: 0.0554\n",
            "Sample 2648: Test Loss: 0.0039\n",
            "Sample 2649: Test Loss: 0.2759\n",
            "Sample 2650: Test Loss: 0.1170\n",
            "Sample 2651: Test Loss: 0.0630\n",
            "Sample 2652: Test Loss: 0.2044\n",
            "Sample 2653: Test Loss: 0.2832\n",
            "Sample 2654: Test Loss: 1.0227\n",
            "Sample 2655: Test Loss: 0.0962\n",
            "Sample 2656: Test Loss: 0.9651\n",
            "Sample 2657: Test Loss: 0.1248\n",
            "Sample 2658: Test Loss: 0.0630\n",
            "Sample 2659: Test Loss: 0.0015\n",
            "Sample 2660: Test Loss: 0.0056\n",
            "Sample 2661: Test Loss: 0.3539\n",
            "Sample 2662: Test Loss: 0.0630\n",
            "Sample 2663: Test Loss: 0.2511\n",
            "Sample 2664: Test Loss: 0.1997\n",
            "Sample 2665: Test Loss: 0.0705\n",
            "Sample 2666: Test Loss: 0.0632\n",
            "Sample 2667: Test Loss: 0.0305\n",
            "Sample 2668: Test Loss: 0.0968\n",
            "Sample 2669: Test Loss: 1.0530\n",
            "Sample 2670: Test Loss: 0.2044\n",
            "Sample 2671: Test Loss: 1.3863\n",
            "Sample 2672: Test Loss: 0.0905\n",
            "Sample 2673: Test Loss: 0.5858\n",
            "Sample 2674: Test Loss: 0.0019\n",
            "Sample 2675: Test Loss: 0.0108\n",
            "Sample 2676: Test Loss: 0.1061\n",
            "Sample 2677: Test Loss: 0.2032\n",
            "Sample 2678: Test Loss: 0.0314\n",
            "Sample 2679: Test Loss: 0.8951\n",
            "Sample 2680: Test Loss: 0.5858\n",
            "Sample 2681: Test Loss: 0.5000\n",
            "Sample 2682: Test Loss: 0.5000\n",
            "Sample 2683: Test Loss: 0.4706\n",
            "Sample 2684: Test Loss: 0.0144\n",
            "Sample 2685: Test Loss: 0.2032\n",
            "Sample 2686: Test Loss: 0.5858\n",
            "Sample 2687: Test Loss: 0.0125\n",
            "Sample 2688: Test Loss: 5.7237\n",
            "Sample 2689: Test Loss: 0.0027\n",
            "Sample 2690: Test Loss: 0.2044\n",
            "Sample 2691: Test Loss: 0.5000\n",
            "Sample 2692: Test Loss: 0.5003\n",
            "Sample 2693: Test Loss: 1.0524\n",
            "Sample 2694: Test Loss: 0.2034\n",
            "Sample 2695: Test Loss: 0.2290\n",
            "Sample 2696: Test Loss: 0.0175\n",
            "Sample 2697: Test Loss: 0.1946\n",
            "Sample 2698: Test Loss: 1.0530\n",
            "Sample 2699: Test Loss: 0.6063\n",
            "Sample 2700: Test Loss: 0.2044\n",
            "Sample 2701: Test Loss: 0.0303\n",
            "Sample 2702: Test Loss: 6.0867\n",
            "Sample 2703: Test Loss: 0.0483\n",
            "Sample 2704: Test Loss: 0.3399\n",
            "Sample 2705: Test Loss: 2.9620\n",
            "Sample 2706: Test Loss: 0.6304\n",
            "Sample 2707: Test Loss: 0.2962\n",
            "Sample 2708: Test Loss: 0.1989\n",
            "Sample 2709: Test Loss: 0.0027\n",
            "Sample 2710: Test Loss: 1.0530\n",
            "Sample 2711: Test Loss: 0.4792\n",
            "Sample 2712: Test Loss: 0.5356\n",
            "Sample 2713: Test Loss: 0.4382\n",
            "Sample 2714: Test Loss: 1.2654\n",
            "Sample 2715: Test Loss: 0.0408\n",
            "Sample 2716: Test Loss: 0.0915\n",
            "Sample 2717: Test Loss: 0.1023\n",
            "Sample 2718: Test Loss: 0.2044\n",
            "Sample 2719: Test Loss: 0.4032\n",
            "Sample 2720: Test Loss: 0.3332\n",
            "Sample 2721: Test Loss: 0.0286\n",
            "Sample 2722: Test Loss: 0.1129\n",
            "Sample 2723: Test Loss: 0.3399\n",
            "Sample 2724: Test Loss: 0.3949\n",
            "Sample 2725: Test Loss: 0.1588\n",
            "Sample 2726: Test Loss: 0.3399\n",
            "Sample 2727: Test Loss: 1.0530\n",
            "Sample 2728: Test Loss: 0.3288\n",
            "Sample 2729: Test Loss: 0.0073\n",
            "Sample 2730: Test Loss: 0.4400\n",
            "Sample 2731: Test Loss: 0.2034\n",
            "Sample 2732: Test Loss: 10.5015\n",
            "Sample 2733: Test Loss: 0.5799\n",
            "Sample 2734: Test Loss: 0.2759\n",
            "Sample 2735: Test Loss: 0.2639\n",
            "Sample 2736: Test Loss: 0.0026\n",
            "Sample 2737: Test Loss: 0.2832\n",
            "Sample 2738: Test Loss: 0.0838\n",
            "Sample 2739: Test Loss: 0.2032\n",
            "Sample 2740: Test Loss: 0.0231\n",
            "Sample 2741: Test Loss: 0.2034\n",
            "Sample 2742: Test Loss: 0.2034\n",
            "Sample 2743: Test Loss: 0.2044\n",
            "Sample 2744: Test Loss: 0.2044\n",
            "Sample 2745: Test Loss: 0.2032\n",
            "Sample 2746: Test Loss: 0.6960\n",
            "Sample 2747: Test Loss: 0.5487\n",
            "Sample 2748: Test Loss: 3.6129\n",
            "Sample 2749: Test Loss: 0.6981\n",
            "Sample 2750: Test Loss: 1.9823\n",
            "Sample 2751: Test Loss: 0.7036\n",
            "Sample 2752: Test Loss: 0.2832\n",
            "Sample 2753: Test Loss: 0.2340\n",
            "Sample 2754: Test Loss: 0.2851\n",
            "Sample 2755: Test Loss: 0.0084\n",
            "Sample 2756: Test Loss: 0.0947\n",
            "Sample 2757: Test Loss: 0.4368\n",
            "Sample 2758: Test Loss: 0.0234\n",
            "Sample 2759: Test Loss: 1.0956\n",
            "Sample 2760: Test Loss: 0.0018\n",
            "Sample 2761: Test Loss: 0.4930\n",
            "Sample 2762: Test Loss: 0.0938\n",
            "Sample 2763: Test Loss: 0.0382\n",
            "Sample 2764: Test Loss: 0.7453\n",
            "Sample 2765: Test Loss: 1.0155\n",
            "Sample 2766: Test Loss: 0.3949\n",
            "Sample 2767: Test Loss: 0.2044\n",
            "Sample 2768: Test Loss: 0.2032\n",
            "Sample 2769: Test Loss: 0.6981\n",
            "Sample 2770: Test Loss: 0.8951\n",
            "Sample 2771: Test Loss: 0.1250\n",
            "Sample 2772: Test Loss: 0.6304\n",
            "Sample 2773: Test Loss: 0.1239\n",
            "Sample 2774: Test Loss: 0.3288\n",
            "Sample 2775: Test Loss: 0.5858\n",
            "Sample 2776: Test Loss: 0.3402\n",
            "Sample 2777: Test Loss: 0.5871\n",
            "Sample 2778: Test Loss: 0.2639\n",
            "Sample 2779: Test Loss: 1.4115\n",
            "Sample 2780: Test Loss: 1.0155\n",
            "Sample 2781: Test Loss: 0.2044\n",
            "Sample 2782: Test Loss: 0.0038\n",
            "Sample 2783: Test Loss: 0.1941\n",
            "Sample 2784: Test Loss: 1.4564\n",
            "Sample 2785: Test Loss: 0.2034\n",
            "Sample 2786: Test Loss: 0.2112\n",
            "Sample 2787: Test Loss: 0.3441\n",
            "Sample 2788: Test Loss: 0.7036\n",
            "Sample 2789: Test Loss: 5.6287\n",
            "Sample 2790: Test Loss: 0.6867\n",
            "Sample 2791: Test Loss: 0.7036\n",
            "Sample 2792: Test Loss: 0.3815\n",
            "Sample 2793: Test Loss: 1.0155\n",
            "Sample 2794: Test Loss: 0.3399\n",
            "Sample 2795: Test Loss: 0.1411\n",
            "Sample 2796: Test Loss: 0.4230\n",
            "Sample 2797: Test Loss: 0.4641\n",
            "Sample 2798: Test Loss: 0.2034\n",
            "Sample 2799: Test Loss: 0.0026\n",
            "Sample 2800: Test Loss: 2.6314\n",
            "Sample 2801: Test Loss: 0.3402\n",
            "Sample 2802: Test Loss: 0.2832\n",
            "Sample 2803: Test Loss: 0.0026\n",
            "Sample 2804: Test Loss: 3.3599\n",
            "Sample 2805: Test Loss: 0.1240\n",
            "Sample 2806: Test Loss: 0.0001\n",
            "Sample 2807: Test Loss: 0.7036\n",
            "Sample 2808: Test Loss: 0.8634\n",
            "Sample 2809: Test Loss: 0.6092\n",
            "Sample 2810: Test Loss: 0.0005\n",
            "Sample 2811: Test Loss: 1.0045\n",
            "Sample 2812: Test Loss: 0.3441\n",
            "Sample 2813: Test Loss: 0.4101\n",
            "Sample 2814: Test Loss: 2.5762\n",
            "Sample 2815: Test Loss: 0.1687\n",
            "Sample 2816: Test Loss: 0.0758\n",
            "Sample 2817: Test Loss: 0.0630\n",
            "Sample 2818: Test Loss: 0.0460\n",
            "Sample 2819: Test Loss: 0.9331\n",
            "Sample 2820: Test Loss: 0.7036\n",
            "Sample 2821: Test Loss: 0.1724\n",
            "Sample 2822: Test Loss: 1.2959\n",
            "Sample 2823: Test Loss: 0.1523\n",
            "Sample 2824: Test Loss: 0.5399\n",
            "Sample 2825: Test Loss: 0.0412\n",
            "Sample 2826: Test Loss: 0.1337\n",
            "Sample 2827: Test Loss: 0.0018\n",
            "Sample 2828: Test Loss: 0.5003\n",
            "Sample 2829: Test Loss: 0.3441\n",
            "Sample 2830: Test Loss: 0.7453\n",
            "Sample 2831: Test Loss: 0.2776\n",
            "Sample 2832: Test Loss: 1.0155\n",
            "Sample 2833: Test Loss: 0.0303\n",
            "Sample 2834: Test Loss: 0.1629\n",
            "Sample 2835: Test Loss: 0.1027\n",
            "Sample 2836: Test Loss: 0.3945\n",
            "Sample 2837: Test Loss: 0.0258\n",
            "Sample 2838: Test Loss: 0.2034\n",
            "Sample 2839: Test Loss: 0.1736\n",
            "Sample 2840: Test Loss: 0.1170\n",
            "Sample 2841: Test Loss: 0.2832\n",
            "Sample 2842: Test Loss: 0.4930\n",
            "Sample 2843: Test Loss: 0.5799\n",
            "Sample 2844: Test Loss: 0.7036\n",
            "Sample 2845: Test Loss: 0.2032\n",
            "Sample 2846: Test Loss: 0.0018\n",
            "Sample 2847: Test Loss: 0.0838\n",
            "Sample 2848: Test Loss: 0.2044\n",
            "Sample 2849: Test Loss: 0.3949\n",
            "Sample 2850: Test Loss: 0.0005\n",
            "Sample 2851: Test Loss: 0.0134\n",
            "Sample 2852: Test Loss: 0.0026\n",
            "Sample 2853: Test Loss: 0.2962\n",
            "Sample 2854: Test Loss: 0.2306\n",
            "Sample 2855: Test Loss: 0.1707\n",
            "Sample 2856: Test Loss: 0.5000\n",
            "Sample 2857: Test Loss: 1.0530\n",
            "Sample 2858: Test Loss: 0.2639\n",
            "Sample 2859: Test Loss: 0.2935\n",
            "Sample 2860: Test Loss: 0.3441\n",
            "Sample 2861: Test Loss: 0.7036\n",
            "Sample 2862: Test Loss: 0.2639\n",
            "Sample 2863: Test Loss: 0.5799\n",
            "Sample 2864: Test Loss: 0.1170\n",
            "Sample 2865: Test Loss: 0.1732\n",
            "Sample 2866: Test Loss: 0.7036\n",
            "Sample 2867: Test Loss: 0.0460\n",
            "Sample 2868: Test Loss: 0.0236\n",
            "Sample 2869: Test Loss: 0.4382\n",
            "Sample 2870: Test Loss: 0.6990\n",
            "Sample 2871: Test Loss: 1.0530\n",
            "Sample 2872: Test Loss: 0.2034\n",
            "Sample 2873: Test Loss: 0.8622\n",
            "Sample 2874: Test Loss: 0.0270\n",
            "Sample 2875: Test Loss: 0.1559\n",
            "Sample 2876: Test Loss: 0.6990\n",
            "Sample 2877: Test Loss: 1.0530\n",
            "Sample 2878: Test Loss: 0.3949\n",
            "Sample 2879: Test Loss: 0.1559\n",
            "Sample 2880: Test Loss: 0.2447\n",
            "Sample 2881: Test Loss: 0.3089\n",
            "Sample 2882: Test Loss: 0.0716\n",
            "Sample 2883: Test Loss: 0.0000\n",
            "Sample 2884: Test Loss: 1.0530\n",
            "Sample 2885: Test Loss: 0.4607\n",
            "Sample 2886: Test Loss: 0.0286\n",
            "Sample 2887: Test Loss: 0.2639\n",
            "Sample 2888: Test Loss: 0.6304\n",
            "Sample 2889: Test Loss: 0.0915\n",
            "Sample 2890: Test Loss: 0.2044\n",
            "Sample 2891: Test Loss: 1.0155\n",
            "Sample 2892: Test Loss: 0.4930\n",
            "Sample 2893: Test Loss: 1.0155\n",
            "Sample 2894: Test Loss: 0.2811\n",
            "Sample 2895: Test Loss: 0.0297\n",
            "Sample 2896: Test Loss: 0.1039\n",
            "Sample 2897: Test Loss: 1.0155\n",
            "Sample 2898: Test Loss: 1.0524\n",
            "Sample 2899: Test Loss: 1.0524\n",
            "Sample 2900: Test Loss: 0.0151\n",
            "Sample 2901: Test Loss: 0.1588\n",
            "Sample 2902: Test Loss: 0.5268\n",
            "Sample 2903: Test Loss: 0.0026\n",
            "Sample 2904: Test Loss: 0.2034\n",
            "Sample 2905: Test Loss: 0.5000\n",
            "Sample 2906: Test Loss: 0.0007\n",
            "Sample 2907: Test Loss: 0.2639\n",
            "Sample 2908: Test Loss: 0.4864\n",
            "Sample 2909: Test Loss: 0.3402\n",
            "Sample 2910: Test Loss: 0.3949\n",
            "Sample 2911: Test Loss: 0.3402\n",
            "Sample 2912: Test Loss: 0.1170\n",
            "Sample 2913: Test Loss: 0.0026\n",
            "Sample 2914: Test Loss: 0.1508\n",
            "Sample 2915: Test Loss: 1.0155\n",
            "Sample 2916: Test Loss: 0.1417\n",
            "Sample 2917: Test Loss: 0.2044\n",
            "Sample 2918: Test Loss: 0.2044\n",
            "Sample 2919: Test Loss: 0.0082\n",
            "Sample 2920: Test Loss: 0.5000\n",
            "Sample 2921: Test Loss: 0.2084\n",
            "Sample 2922: Test Loss: 0.2639\n",
            "Sample 2923: Test Loss: 0.0303\n",
            "Sample 2924: Test Loss: 0.4611\n",
            "Sample 2925: Test Loss: 0.7036\n",
            "Sample 2926: Test Loss: 0.0034\n",
            "Sample 2927: Test Loss: 0.7036\n",
            "Sample 2928: Test Loss: 0.0018\n",
            "Sample 2929: Test Loss: 0.0630\n",
            "Sample 2930: Test Loss: 0.4326\n",
            "Sample 2931: Test Loss: 0.5871\n",
            "Sample 2932: Test Loss: 0.5058\n",
            "Sample 2933: Test Loss: 0.0781\n",
            "Sample 2934: Test Loss: 0.1055\n",
            "Sample 2935: Test Loss: 0.2044\n",
            "Sample 2936: Test Loss: 0.3399\n",
            "Sample 2937: Test Loss: 0.4611\n",
            "Sample 2938: Test Loss: 0.0026\n",
            "Sample 2939: Test Loss: 0.2935\n",
            "Sample 2940: Test Loss: 0.2759\n",
            "Sample 2941: Test Loss: 0.0785\n",
            "Sample 2942: Test Loss: 5.1063\n",
            "Sample 2943: Test Loss: 0.5438\n",
            "Sample 2944: Test Loss: 0.2639\n",
            "Sample 2945: Test Loss: 0.5196\n",
            "Sample 2946: Test Loss: 0.1924\n",
            "Sample 2947: Test Loss: 1.0155\n",
            "Sample 2948: Test Loss: 0.0148\n",
            "Sample 2949: Test Loss: 0.7300\n",
            "Sample 2950: Test Loss: 0.6806\n",
            "Sample 2951: Test Loss: 0.6990\n",
            "Sample 2952: Test Loss: 0.1841\n",
            "Sample 2953: Test Loss: 0.3441\n",
            "Sample 2954: Test Loss: 0.7036\n",
            "Sample 2955: Test Loss: 0.5858\n",
            "Sample 2956: Test Loss: 0.3568\n",
            "Sample 2957: Test Loss: 0.6867\n",
            "Sample 2958: Test Loss: 1.0155\n",
            "Sample 2959: Test Loss: 0.0313\n",
            "Sample 2960: Test Loss: 0.2219\n",
            "Sample 2961: Test Loss: 0.0030\n",
            "Sample 2962: Test Loss: 1.0530\n",
            "Sample 2963: Test Loss: 0.2832\n",
            "Sample 2964: Test Loss: 0.2032\n",
            "Sample 2965: Test Loss: 0.1063\n",
            "Sample 2966: Test Loss: 0.3949\n",
            "Sample 2967: Test Loss: 0.3949\n",
            "Sample 2968: Test Loss: 0.7036\n",
            "Sample 2969: Test Loss: 0.3450\n",
            "Sample 2970: Test Loss: 2.5762\n",
            "Sample 2971: Test Loss: 0.0630\n",
            "Sample 2972: Test Loss: 0.2333\n",
            "Sample 2973: Test Loss: 0.3399\n",
            "Sample 2974: Test Loss: 0.4981\n",
            "Sample 2975: Test Loss: 1.0530\n",
            "Sample 2976: Test Loss: 0.2044\n",
            "Sample 2977: Test Loss: 2.0981\n",
            "Sample 2978: Test Loss: 0.2832\n",
            "Sample 2979: Test Loss: 0.0025\n",
            "Sample 2980: Test Loss: 0.9367\n",
            "Sample 2981: Test Loss: 0.0062\n",
            "Sample 2982: Test Loss: 0.6558\n",
            "Sample 2983: Test Loss: 0.2219\n",
            "Sample 2984: Test Loss: 0.0288\n",
            "Sample 2985: Test Loss: 0.1423\n",
            "Sample 2986: Test Loss: 1.4392\n",
            "Sample 2987: Test Loss: 0.1397\n",
            "Sample 2988: Test Loss: 0.1455\n",
            "Sample 2989: Test Loss: 0.5858\n",
            "Sample 2990: Test Loss: 0.2759\n",
            "Sample 2991: Test Loss: 0.0194\n",
            "Sample 2992: Test Loss: 0.2032\n",
            "Sample 2993: Test Loss: 0.9367\n",
            "Sample 2994: Test Loss: 0.4841\n",
            "Sample 2995: Test Loss: 0.1199\n",
            "Sample 2996: Test Loss: 0.0258\n",
            "Sample 2997: Test Loss: 0.0028\n",
            "Sample 2998: Test Loss: 1.0524\n",
            "Sample 2999: Test Loss: 0.0916\n",
            "Sample 3000: Test Loss: 0.7036\n",
            "Sample 3001: Test Loss: 0.3399\n",
            "Sample 3002: Test Loss: 0.2832\n",
            "Sample 3003: Test Loss: 0.0611\n",
            "Sample 3004: Test Loss: 1.0155\n",
            "Sample 3005: Test Loss: 0.0212\n",
            "Sample 3006: Test Loss: 0.8951\n",
            "Sample 3007: Test Loss: 0.4841\n",
            "Sample 3008: Test Loss: 0.7453\n",
            "Sample 3009: Test Loss: 0.5858\n",
            "Sample 3010: Test Loss: 0.2759\n",
            "Sample 3011: Test Loss: 0.5858\n",
            "Sample 3012: Test Loss: 0.2112\n",
            "Sample 3013: Test Loss: 0.7036\n",
            "Sample 3014: Test Loss: 0.2146\n",
            "Sample 3015: Test Loss: 0.2639\n",
            "Sample 3016: Test Loss: 0.0107\n",
            "Sample 3017: Test Loss: 0.3399\n",
            "Sample 3018: Test Loss: 0.1076\n",
            "Sample 3019: Test Loss: 0.5799\n",
            "Sample 3020: Test Loss: 0.4930\n",
            "Sample 3021: Test Loss: 0.2094\n",
            "Sample 3022: Test Loss: 0.7892\n",
            "Sample 3023: Test Loss: 1.5542\n",
            "Sample 3024: Test Loss: 1.0155\n",
            "Sample 3025: Test Loss: 0.3539\n",
            "Sample 3026: Test Loss: 0.6664\n",
            "Sample 3027: Test Loss: 0.1170\n",
            "Sample 3028: Test Loss: 0.0026\n",
            "Sample 3029: Test Loss: 0.0026\n",
            "Sample 3030: Test Loss: 0.1167\n",
            "Sample 3031: Test Loss: 0.2340\n",
            "Sample 3032: Test Loss: 0.1054\n",
            "Sample 3033: Test Loss: 0.1472\n",
            "Sample 3034: Test Loss: 0.4497\n",
            "Sample 3035: Test Loss: 0.3399\n",
            "Sample 3036: Test Loss: 0.1508\n",
            "Sample 3037: Test Loss: 0.2554\n",
            "Sample 3038: Test Loss: 0.0019\n",
            "Sample 3039: Test Loss: 0.7036\n",
            "Sample 3040: Test Loss: 0.2429\n",
            "Sample 3041: Test Loss: 0.2044\n",
            "Sample 3042: Test Loss: 0.0286\n",
            "Sample 3043: Test Loss: 0.1455\n",
            "Sample 3044: Test Loss: 0.1028\n",
            "Sample 3045: Test Loss: 1.7445\n",
            "Sample 3046: Test Loss: 0.2032\n",
            "Sample 3047: Test Loss: 0.0466\n",
            "Sample 3048: Test Loss: 0.0391\n",
            "Sample 3049: Test Loss: 0.3402\n",
            "Sample 3050: Test Loss: 0.1250\n",
            "Sample 3051: Test Loss: 0.0026\n",
            "Sample 3052: Test Loss: 0.7453\n",
            "Sample 3053: Test Loss: 1.0524\n",
            "Sample 3054: Test Loss: 0.2044\n",
            "Sample 3055: Test Loss: 0.0208\n",
            "Sample 3056: Test Loss: 0.5972\n",
            "Sample 3057: Test Loss: 0.1225\n",
            "Sample 3058: Test Loss: 1.0524\n",
            "Sample 3059: Test Loss: 0.0212\n",
            "Sample 3060: Test Loss: 0.0315\n",
            "Sample 3061: Test Loss: 0.2032\n",
            "Sample 3062: Test Loss: 0.0011\n",
            "Sample 3063: Test Loss: 0.2759\n",
            "Sample 3064: Test Loss: 0.2227\n",
            "Sample 3065: Test Loss: 0.5858\n",
            "Sample 3066: Test Loss: 3.8158\n",
            "Sample 3067: Test Loss: 0.2032\n",
            "Sample 3068: Test Loss: 0.0630\n",
            "Sample 3069: Test Loss: 0.4611\n",
            "Sample 3070: Test Loss: 0.0018\n",
            "Sample 3071: Test Loss: 0.0902\n",
            "Sample 3072: Test Loss: 0.3393\n",
            "Sample 3073: Test Loss: 0.3399\n",
            "Sample 3074: Test Loss: 1.8692\n",
            "Sample 3075: Test Loss: 0.2639\n",
            "Sample 3076: Test Loss: 0.2044\n",
            "Sample 3077: Test Loss: 0.7036\n",
            "Sample 3078: Test Loss: 0.0630\n",
            "Sample 3079: Test Loss: 0.0000\n",
            "Sample 3080: Test Loss: 1.0530\n",
            "Sample 3081: Test Loss: 1.0266\n",
            "Sample 3082: Test Loss: 0.0086\n",
            "Sample 3083: Test Loss: 1.7990\n",
            "Sample 3084: Test Loss: 0.3399\n",
            "Sample 3085: Test Loss: 0.7473\n",
            "Sample 3086: Test Loss: 0.3399\n",
            "Sample 3087: Test Loss: 3.8636\n",
            "Sample 3088: Test Loss: 0.5000\n",
            "Sample 3089: Test Loss: 0.1051\n",
            "Sample 3090: Test Loss: 0.3399\n",
            "Sample 3091: Test Loss: 0.6990\n",
            "Sample 3092: Test Loss: 0.1402\n",
            "Sample 3093: Test Loss: 0.5858\n",
            "Sample 3094: Test Loss: 1.0155\n",
            "Sample 3095: Test Loss: 0.0604\n",
            "Sample 3096: Test Loss: 0.3399\n",
            "Sample 3097: Test Loss: 0.7218\n",
            "Sample 3098: Test Loss: 0.9367\n",
            "Sample 3099: Test Loss: 2.0233\n",
            "Sample 3100: Test Loss: 0.0026\n",
            "Sample 3101: Test Loss: 0.0253\n",
            "Sample 3102: Test Loss: 0.6990\n",
            "Sample 3103: Test Loss: 1.0524\n",
            "Sample 3104: Test Loss: 1.0070\n",
            "Sample 3105: Test Loss: 0.2034\n",
            "Sample 3106: Test Loss: 0.2044\n",
            "Sample 3107: Test Loss: 1.0524\n",
            "Sample 3108: Test Loss: 0.0001\n",
            "Sample 3109: Test Loss: 0.2044\n",
            "Sample 3110: Test Loss: 1.0155\n",
            "Sample 3111: Test Loss: 0.0039\n",
            "Sample 3112: Test Loss: 2.0792\n",
            "Sample 3113: Test Loss: 0.1399\n",
            "Sample 3114: Test Loss: 11.6334\n",
            "Sample 3115: Test Loss: 0.7036\n",
            "Sample 3116: Test Loss: 0.2032\n",
            "Sample 3117: Test Loss: 0.1264\n",
            "Sample 3118: Test Loss: 0.0890\n",
            "Sample 3119: Test Loss: 0.3166\n",
            "Sample 3120: Test Loss: 0.0799\n",
            "Sample 3121: Test Loss: 1.0266\n",
            "Sample 3122: Test Loss: 0.0026\n",
            "Sample 3123: Test Loss: 0.0630\n",
            "Sample 3124: Test Loss: 0.2036\n",
            "Sample 3125: Test Loss: 2.2422\n",
            "Sample 3126: Test Loss: 0.9367\n",
            "Sample 3127: Test Loss: 1.0530\n",
            "Sample 3128: Test Loss: 0.5000\n",
            "Sample 3129: Test Loss: 1.0414\n",
            "Sample 3130: Test Loss: 1.4740\n",
            "Sample 3131: Test Loss: 0.0042\n",
            "Sample 3132: Test Loss: 0.0630\n",
            "Sample 3133: Test Loss: 0.0034\n",
            "Sample 3134: Test Loss: 2.8680\n",
            "Sample 3135: Test Loss: 0.4611\n",
            "Sample 3136: Test Loss: 0.0630\n",
            "Sample 3137: Test Loss: 0.0558\n",
            "Sample 3138: Test Loss: 1.0155\n",
            "Sample 3139: Test Loss: 0.2639\n",
            "Sample 3140: Test Loss: 0.5858\n",
            "Sample 3141: Test Loss: 0.7453\n",
            "Sample 3142: Test Loss: 0.2879\n",
            "Sample 3143: Test Loss: 0.3399\n",
            "Sample 3144: Test Loss: 0.0026\n",
            "Sample 3145: Test Loss: 0.2759\n",
            "Sample 3146: Test Loss: 0.3126\n",
            "Sample 3147: Test Loss: 0.3399\n",
            "Sample 3148: Test Loss: 0.4032\n",
            "Sample 3149: Test Loss: 0.2639\n",
            "Sample 3150: Test Loss: 0.0026\n",
            "Sample 3151: Test Loss: 1.0524\n",
            "Sample 3152: Test Loss: 1.0524\n",
            "Sample 3153: Test Loss: 1.1847\n",
            "Sample 3154: Test Loss: 0.0600\n",
            "Sample 3155: Test Loss: 0.0026\n",
            "Sample 3156: Test Loss: 0.3399\n",
            "Sample 3157: Test Loss: 1.0266\n",
            "Sample 3158: Test Loss: 2.4541\n",
            "Sample 3159: Test Loss: 0.1170\n",
            "Sample 3160: Test Loss: 0.4342\n",
            "Sample 3161: Test Loss: 0.1998\n",
            "Sample 3162: Test Loss: 0.5058\n",
            "Sample 3163: Test Loss: 0.0626\n",
            "Sample 3164: Test Loss: 1.8804\n",
            "Sample 3165: Test Loss: 0.4382\n",
            "Sample 3166: Test Loss: 0.0234\n",
            "Sample 3167: Test Loss: 0.1323\n",
            "Sample 3168: Test Loss: 0.3399\n",
            "Sample 3169: Test Loss: 0.0008\n",
            "Sample 3170: Test Loss: 0.2431\n",
            "Sample 3171: Test Loss: 0.5375\n",
            "Sample 3172: Test Loss: 0.0400\n",
            "Sample 3173: Test Loss: 0.0009\n",
            "Sample 3174: Test Loss: 0.1219\n",
            "Sample 3175: Test Loss: 0.0082\n",
            "Sample 3176: Test Loss: 0.1559\n",
            "Sample 3177: Test Loss: 1.0155\n",
            "Sample 3178: Test Loss: 0.3397\n",
            "Sample 3179: Test Loss: 0.0082\n",
            "Sample 3180: Test Loss: 0.2034\n",
            "Sample 3181: Test Loss: 1.0155\n",
            "Sample 3182: Test Loss: 0.8484\n",
            "Sample 3183: Test Loss: 0.0915\n",
            "Sample 3184: Test Loss: 0.2759\n",
            "Sample 3185: Test Loss: 0.7036\n",
            "Sample 3186: Test Loss: 0.2989\n",
            "Sample 3187: Test Loss: 1.0524\n",
            "Sample 3188: Test Loss: 1.0511\n",
            "Sample 3189: Test Loss: 0.2044\n",
            "Sample 3190: Test Loss: 0.0018\n",
            "Sample 3191: Test Loss: 0.3399\n",
            "Sample 3192: Test Loss: 0.0085\n",
            "Sample 3193: Test Loss: 0.2639\n",
            "Sample 3194: Test Loss: 0.2048\n",
            "Sample 3195: Test Loss: 0.8951\n",
            "Sample 3196: Test Loss: 0.3537\n",
            "Sample 3197: Test Loss: 1.0524\n",
            "Sample 3198: Test Loss: 0.5078\n",
            "Sample 3199: Test Loss: 1.0524\n",
            "Sample 3200: Test Loss: 16.3321\n",
            "Sample 3201: Test Loss: 0.2855\n",
            "Sample 3202: Test Loss: 0.7453\n",
            "Sample 3203: Test Loss: 1.0530\n",
            "Sample 3204: Test Loss: 0.9367\n",
            "Sample 3205: Test Loss: 0.0787\n",
            "Sample 3206: Test Loss: 0.2229\n",
            "Sample 3207: Test Loss: 0.2034\n",
            "Sample 3208: Test Loss: 0.1523\n",
            "Sample 3209: Test Loss: 0.2036\n",
            "Sample 3210: Test Loss: 1.0524\n",
            "Sample 3211: Test Loss: 0.9960\n",
            "Sample 3212: Test Loss: 0.0212\n",
            "Sample 3213: Test Loss: 0.2639\n",
            "Sample 3214: Test Loss: 0.9163\n",
            "Sample 3215: Test Loss: 0.0001\n",
            "Sample 3216: Test Loss: 0.5858\n",
            "Sample 3217: Test Loss: 0.2639\n",
            "Sample 3218: Test Loss: 1.0266\n",
            "Sample 3219: Test Loss: 0.0460\n",
            "Sample 3220: Test Loss: 1.0524\n",
            "Sample 3221: Test Loss: 0.4032\n",
            "Sample 3222: Test Loss: 0.2962\n",
            "Sample 3223: Test Loss: 0.0205\n",
            "Sample 3224: Test Loss: 0.0026\n",
            "Sample 3225: Test Loss: 0.5799\n",
            "Sample 3226: Test Loss: 0.7453\n",
            "Sample 3227: Test Loss: 0.1048\n",
            "Sample 3228: Test Loss: 0.0830\n",
            "Sample 3229: Test Loss: 0.1465\n",
            "Sample 3230: Test Loss: 0.8217\n",
            "Sample 3231: Test Loss: 0.0630\n",
            "Sample 3232: Test Loss: 1.0524\n",
            "Sample 3233: Test Loss: 1.2782\n",
            "Sample 3234: Test Loss: 0.3007\n",
            "Sample 3235: Test Loss: 0.1345\n",
            "Sample 3236: Test Loss: 0.5498\n",
            "Sample 3237: Test Loss: 0.0026\n",
            "Sample 3238: Test Loss: 0.0625\n",
            "Sample 3239: Test Loss: 0.4032\n",
            "Sample 3240: Test Loss: 1.1590\n",
            "Sample 3241: Test Loss: 0.2832\n",
            "Sample 3242: Test Loss: 0.3949\n",
            "Sample 3243: Test Loss: 0.2295\n",
            "Sample 3244: Test Loss: 0.1266\n",
            "Sample 3245: Test Loss: 2.0254\n",
            "Sample 3246: Test Loss: 1.0530\n",
            "Sample 3247: Test Loss: 1.0524\n",
            "Sample 3248: Test Loss: 0.0915\n",
            "Sample 3249: Test Loss: 0.2036\n",
            "Sample 3250: Test Loss: 0.2032\n",
            "Sample 3251: Test Loss: 0.1559\n",
            "Sample 3252: Test Loss: 0.7867\n",
            "Sample 3253: Test Loss: 0.0303\n",
            "Sample 3254: Test Loss: 0.0682\n",
            "Sample 3255: Test Loss: 1.0266\n",
            "Sample 3256: Test Loss: 0.2219\n",
            "Sample 3257: Test Loss: 0.5426\n",
            "Sample 3258: Test Loss: 0.0915\n",
            "Sample 3259: Test Loss: 0.0271\n",
            "Sample 3260: Test Loss: 0.5837\n",
            "Sample 3261: Test Loss: 0.0018\n",
            "Sample 3262: Test Loss: 0.2044\n",
            "Sample 3263: Test Loss: 0.6139\n",
            "Sample 3264: Test Loss: 0.3399\n",
            "Sample 3265: Test Loss: 0.1273\n",
            "Sample 3266: Test Loss: 0.0838\n",
            "Sample 3267: Test Loss: 0.0044\n",
            "Sample 3268: Test Loss: 0.2014\n",
            "Sample 3269: Test Loss: 0.0003\n",
            "Sample 3270: Test Loss: 0.2034\n",
            "Sample 3271: Test Loss: 0.7036\n",
            "Sample 3272: Test Loss: 0.5000\n",
            "Sample 3273: Test Loss: 0.2759\n",
            "Sample 3274: Test Loss: 0.5972\n",
            "Sample 3275: Test Loss: 1.0155\n",
            "Sample 3276: Test Loss: 1.1893\n",
            "Sample 3277: Test Loss: 0.4032\n",
            "Sample 3278: Test Loss: 0.0022\n",
            "Sample 3279: Test Loss: 0.6304\n",
            "Sample 3280: Test Loss: 0.3450\n",
            "Sample 3281: Test Loss: 0.2759\n",
            "Sample 3282: Test Loss: 0.7036\n",
            "Sample 3283: Test Loss: 1.0530\n",
            "Sample 3284: Test Loss: 0.0000\n",
            "Sample 3285: Test Loss: 1.0524\n",
            "Sample 3286: Test Loss: 0.4611\n",
            "Sample 3287: Test Loss: 0.2759\n",
            "Sample 3288: Test Loss: 0.0744\n",
            "Sample 3289: Test Loss: 0.1044\n",
            "Sample 3290: Test Loss: 0.5320\n",
            "Sample 3291: Test Loss: 0.0362\n",
            "Sample 3292: Test Loss: 0.2412\n",
            "Sample 3293: Test Loss: 0.5003\n",
            "Sample 3294: Test Loss: 0.1559\n",
            "Sample 3295: Test Loss: 0.2339\n",
            "Sample 3296: Test Loss: 0.2032\n",
            "Sample 3297: Test Loss: 0.0026\n",
            "Sample 3298: Test Loss: 0.0630\n",
            "Sample 3299: Test Loss: 0.2032\n",
            "Sample 3300: Test Loss: 0.1170\n",
            "Sample 3301: Test Loss: 0.0060\n",
            "Sample 3302: Test Loss: 0.2032\n",
            "Sample 3303: Test Loss: 0.1113\n",
            "Sample 3304: Test Loss: 0.8951\n",
            "Sample 3305: Test Loss: 0.5858\n",
            "Sample 3306: Test Loss: 0.2639\n",
            "Sample 3307: Test Loss: 0.5000\n",
            "Sample 3308: Test Loss: 0.7538\n",
            "Sample 3309: Test Loss: 0.6867\n",
            "Sample 3310: Test Loss: 0.1225\n",
            "Sample 3311: Test Loss: 0.2044\n",
            "Sample 3312: Test Loss: 5.8548\n",
            "Sample 3313: Test Loss: 0.4026\n",
            "Sample 3314: Test Loss: 0.2277\n",
            "Sample 3315: Test Loss: 0.1170\n",
            "Sample 3316: Test Loss: 0.8625\n",
            "Sample 3317: Test Loss: 0.7984\n",
            "Sample 3318: Test Loss: 0.0116\n",
            "Sample 3319: Test Loss: 0.0151\n",
            "Sample 3320: Test Loss: 0.3399\n",
            "Sample 3321: Test Loss: 0.0364\n",
            "Sample 3322: Test Loss: 0.6981\n",
            "Sample 3323: Test Loss: 8.7942\n",
            "Sample 3324: Test Loss: 0.0018\n",
            "Sample 3325: Test Loss: 0.1471\n",
            "Sample 3326: Test Loss: 0.0404\n",
            "Sample 3327: Test Loss: 0.2639\n",
            "Sample 3328: Test Loss: 1.0530\n",
            "Sample 3329: Test Loss: 0.2832\n",
            "Sample 3330: Test Loss: 0.6867\n",
            "Sample 3331: Test Loss: 0.2044\n",
            "Sample 3332: Test Loss: 0.6990\n",
            "Sample 3333: Test Loss: 0.2219\n",
            "Sample 3334: Test Loss: 0.3288\n",
            "Sample 3335: Test Loss: 0.2036\n",
            "Sample 3336: Test Loss: 0.0026\n",
            "Sample 3337: Test Loss: 0.0838\n",
            "Sample 3338: Test Loss: 0.2032\n",
            "Sample 3339: Test Loss: 0.7036\n",
            "Sample 3340: Test Loss: 2.8787\n",
            "Sample 3341: Test Loss: 1.0530\n",
            "Sample 3342: Test Loss: 0.0507\n",
            "Sample 3343: Test Loss: 0.2044\n",
            "Sample 3344: Test Loss: 0.0026\n",
            "Sample 3345: Test Loss: 0.2034\n",
            "Sample 3346: Test Loss: 0.4841\n",
            "Sample 3347: Test Loss: 0.0200\n",
            "Sample 3348: Test Loss: 0.4032\n",
            "Sample 3349: Test Loss: 0.1170\n",
            "Sample 3350: Test Loss: 1.0524\n",
            "Sample 3351: Test Loss: 0.0084\n",
            "Sample 3352: Test Loss: 0.0048\n",
            "Sample 3353: Test Loss: 0.0108\n",
            "Sample 3354: Test Loss: 1.0155\n",
            "Sample 3355: Test Loss: 2.0108\n",
            "Sample 3356: Test Loss: 1.4305\n",
            "Sample 3357: Test Loss: 0.0625\n",
            "Sample 3358: Test Loss: 0.3399\n",
            "Sample 3359: Test Loss: 0.0026\n",
            "Sample 3360: Test Loss: 0.0313\n",
            "Sample 3361: Test Loss: 0.3399\n",
            "Sample 3362: Test Loss: 0.1170\n",
            "Sample 3363: Test Loss: 1.0524\n",
            "Sample 3364: Test Loss: 1.0524\n",
            "Sample 3365: Test Loss: 1.2095\n",
            "Sample 3366: Test Loss: 1.6951\n",
            "Sample 3367: Test Loss: 0.0590\n",
            "Sample 3368: Test Loss: 0.4611\n",
            "Sample 3369: Test Loss: 0.6990\n",
            "Sample 3370: Test Loss: 0.1233\n",
            "Sample 3371: Test Loss: 0.6981\n",
            "Sample 3372: Test Loss: 0.2044\n",
            "Sample 3373: Test Loss: 0.2878\n",
            "Sample 3374: Test Loss: 0.3598\n",
            "Sample 3375: Test Loss: 0.3949\n",
            "Sample 3376: Test Loss: 0.2639\n",
            "Sample 3377: Test Loss: 0.5858\n",
            "Sample 3378: Test Loss: 1.0524\n",
            "Sample 3379: Test Loss: 0.2032\n",
            "Sample 3380: Test Loss: 0.0042\n",
            "Sample 3381: Test Loss: 0.0460\n",
            "Sample 3382: Test Loss: 0.8951\n",
            "Sample 3383: Test Loss: 1.0530\n",
            "Sample 3384: Test Loss: 0.0145\n",
            "Sample 3385: Test Loss: 0.8630\n",
            "Sample 3386: Test Loss: 1.2783\n",
            "Sample 3387: Test Loss: 0.0415\n",
            "Sample 3388: Test Loss: 0.0399\n",
            "Sample 3389: Test Loss: 0.3242\n",
            "Sample 3390: Test Loss: 0.3767\n",
            "Sample 3391: Test Loss: 0.2032\n",
            "Sample 3392: Test Loss: 0.0471\n",
            "Sample 3393: Test Loss: 0.0402\n",
            "Sample 3394: Test Loss: 0.1067\n",
            "Sample 3395: Test Loss: 0.0029\n",
            "Sample 3396: Test Loss: 0.2971\n",
            "Sample 3397: Test Loss: 0.0004\n",
            "Sample 3398: Test Loss: 1.0524\n",
            "Sample 3399: Test Loss: 0.6990\n",
            "Sample 3400: Test Loss: 0.0060\n",
            "Sample 3401: Test Loss: 0.8753\n",
            "Sample 3402: Test Loss: 0.2034\n",
            "Sample 3403: Test Loss: 0.3399\n",
            "Sample 3404: Test Loss: 1.3480\n",
            "Sample 3405: Test Loss: 0.3076\n",
            "Sample 3406: Test Loss: 0.0049\n",
            "Sample 3407: Test Loss: 0.0212\n",
            "Sample 3408: Test Loss: 0.0109\n",
            "Sample 3409: Test Loss: 0.8677\n",
            "Sample 3410: Test Loss: 0.3367\n",
            "Sample 3411: Test Loss: 0.3399\n",
            "Sample 3412: Test Loss: 0.2971\n",
            "Sample 3413: Test Loss: 7.2341\n",
            "Sample 3414: Test Loss: 1.0524\n",
            "Sample 3415: Test Loss: 1.0524\n",
            "Sample 3416: Test Loss: 0.2759\n",
            "Sample 3417: Test Loss: 1.0524\n",
            "Sample 3418: Test Loss: 0.7036\n",
            "Sample 3419: Test Loss: 0.4588\n",
            "Sample 3420: Test Loss: 0.6568\n",
            "Sample 3421: Test Loss: 0.4841\n",
            "Sample 3422: Test Loss: 0.8692\n",
            "Sample 3423: Test Loss: 0.1246\n",
            "Sample 3424: Test Loss: 0.1773\n",
            "Sample 3425: Test Loss: 0.2034\n",
            "Sample 3426: Test Loss: 1.0524\n",
            "Sample 3427: Test Loss: 0.0002\n",
            "Sample 3428: Test Loss: 0.0110\n",
            "Sample 3429: Test Loss: 0.7036\n",
            "Sample 3430: Test Loss: 0.3399\n",
            "Sample 3431: Test Loss: 0.1250\n",
            "Sample 3432: Test Loss: 1.0524\n",
            "Sample 3433: Test Loss: 1.0155\n",
            "Sample 3434: Test Loss: 0.6776\n",
            "Sample 3435: Test Loss: 0.3399\n",
            "Sample 3436: Test Loss: 0.0001\n",
            "Sample 3437: Test Loss: 2.8162\n",
            "Sample 3438: Test Loss: 0.7036\n",
            "Sample 3439: Test Loss: 0.0099\n",
            "Sample 3440: Test Loss: 0.2713\n",
            "Sample 3441: Test Loss: 0.0306\n",
            "Sample 3442: Test Loss: 1.0524\n",
            "Sample 3443: Test Loss: 1.2232\n",
            "Sample 3444: Test Loss: 0.0084\n",
            "Sample 3445: Test Loss: 0.8951\n",
            "Sample 3446: Test Loss: 0.0144\n",
            "Sample 3447: Test Loss: 0.0212\n",
            "Sample 3448: Test Loss: 0.0883\n",
            "Sample 3449: Test Loss: 0.2226\n",
            "Sample 3450: Test Loss: 0.2032\n",
            "Sample 3451: Test Loss: 0.2112\n",
            "Sample 3452: Test Loss: 0.1250\n",
            "Sample 3453: Test Loss: 0.7036\n",
            "Sample 3454: Test Loss: 0.2034\n",
            "Sample 3455: Test Loss: 0.2034\n",
            "Sample 3456: Test Loss: 0.0630\n",
            "Sample 3457: Test Loss: 0.0286\n",
            "Sample 3458: Test Loss: 0.1508\n",
            "Sample 3459: Test Loss: 0.0118\n",
            "Sample 3460: Test Loss: 0.6092\n",
            "Sample 3461: Test Loss: 0.7036\n",
            "Sample 3462: Test Loss: 0.0205\n",
            "Sample 3463: Test Loss: 0.2044\n",
            "Sample 3464: Test Loss: 0.2481\n",
            "Sample 3465: Test Loss: 1.0524\n",
            "Sample 3466: Test Loss: 0.0476\n",
            "Sample 3467: Test Loss: 0.2032\n",
            "Sample 3468: Test Loss: 0.4937\n",
            "Sample 3469: Test Loss: 0.1967\n",
            "Sample 3470: Test Loss: 0.5320\n",
            "Sample 3471: Test Loss: 0.2044\n",
            "Sample 3472: Test Loss: 0.3441\n",
            "Sample 3473: Test Loss: 0.5858\n",
            "Sample 3474: Test Loss: 0.2962\n",
            "Sample 3475: Test Loss: 0.5196\n",
            "Sample 3476: Test Loss: 0.1588\n",
            "Sample 3477: Test Loss: 0.5858\n",
            "Sample 3478: Test Loss: 14.7236\n",
            "Sample 3479: Test Loss: 1.0524\n",
            "Sample 3480: Test Loss: 0.1248\n",
            "Sample 3481: Test Loss: 0.5196\n",
            "Sample 3482: Test Loss: 0.0082\n",
            "Sample 3483: Test Loss: 0.3399\n",
            "Sample 3484: Test Loss: 0.2707\n",
            "Sample 3485: Test Loss: 0.1252\n",
            "Sample 3486: Test Loss: 0.0025\n",
            "Sample 3487: Test Loss: 0.6534\n",
            "Sample 3488: Test Loss: 1.7526\n",
            "Sample 3489: Test Loss: 0.2182\n",
            "Sample 3490: Test Loss: 0.0590\n",
            "Sample 3491: Test Loss: 0.0026\n",
            "Sample 3492: Test Loss: 0.1170\n",
            "Sample 3493: Test Loss: 0.7036\n",
            "Sample 3494: Test Loss: 0.2098\n",
            "Sample 3495: Test Loss: 0.2759\n",
            "Sample 3496: Test Loss: 1.0530\n",
            "Sample 3497: Test Loss: 0.0026\n",
            "Sample 3498: Test Loss: 0.0924\n",
            "Sample 3499: Test Loss: 0.2036\n",
            "Sample 3500: Test Loss: 0.9367\n",
            "Sample 3501: Test Loss: 0.2036\n",
            "Sample 3502: Test Loss: 1.0530\n",
            "Sample 3503: Test Loss: 1.0328\n",
            "Sample 3504: Test Loss: 0.8484\n",
            "Sample 3505: Test Loss: 2.5762\n",
            "Sample 3506: Test Loss: 0.1250\n",
            "Sample 3507: Test Loss: 3.4068\n",
            "Sample 3508: Test Loss: 0.8951\n",
            "Sample 3509: Test Loss: 0.0026\n",
            "Sample 3510: Test Loss: 0.5196\n",
            "Sample 3511: Test Loss: 0.2600\n",
            "Sample 3512: Test Loss: 0.3441\n",
            "Sample 3513: Test Loss: 1.0227\n",
            "Sample 3514: Test Loss: 0.7036\n",
            "Sample 3515: Test Loss: 4.3386\n",
            "Sample 3516: Test Loss: 0.0915\n",
            "Sample 3517: Test Loss: 0.2032\n",
            "Sample 3518: Test Loss: 1.0155\n",
            "Sample 3519: Test Loss: 0.3949\n",
            "Sample 3520: Test Loss: 0.9367\n",
            "Sample 3521: Test Loss: 1.3320\n",
            "Sample 3522: Test Loss: 1.2926\n",
            "Sample 3523: Test Loss: 0.0865\n",
            "Sample 3524: Test Loss: 0.8307\n",
            "Sample 3525: Test Loss: 0.0476\n",
            "Sample 3526: Test Loss: 0.4588\n",
            "Sample 3527: Test Loss: 0.6304\n",
            "Sample 3528: Test Loss: 0.2219\n",
            "Sample 3529: Test Loss: 0.5196\n",
            "Sample 3530: Test Loss: 0.0630\n",
            "Sample 3531: Test Loss: 0.2032\n",
            "Sample 3532: Test Loss: 0.0838\n",
            "Sample 3533: Test Loss: 0.4523\n",
            "Sample 3534: Test Loss: 0.1170\n",
            "Sample 3535: Test Loss: 0.2034\n",
            "Sample 3536: Test Loss: 0.1039\n",
            "Sample 3537: Test Loss: 0.0080\n",
            "Sample 3538: Test Loss: 0.1838\n",
            "Sample 3539: Test Loss: 0.2463\n",
            "Sample 3540: Test Loss: 0.3450\n",
            "Sample 3541: Test Loss: 0.2032\n",
            "Sample 3542: Test Loss: 0.1854\n",
            "Sample 3543: Test Loss: 0.0000\n",
            "Sample 3544: Test Loss: 1.2426\n",
            "Sample 3545: Test Loss: 0.2513\n",
            "Sample 3546: Test Loss: 0.5972\n",
            "Sample 3547: Test Loss: 0.5858\n",
            "Sample 3548: Test Loss: 0.1875\n",
            "Sample 3549: Test Loss: 0.3399\n",
            "Sample 3550: Test Loss: 0.4799\n",
            "Sample 3551: Test Loss: 0.2572\n",
            "Sample 3552: Test Loss: 0.2044\n",
            "Sample 3553: Test Loss: 0.3367\n",
            "Sample 3554: Test Loss: 0.2219\n",
            "Sample 3555: Test Loss: 0.8951\n",
            "Sample 3556: Test Loss: 0.1273\n",
            "Sample 3557: Test Loss: 0.0032\n",
            "Sample 3558: Test Loss: 0.4799\n",
            "Sample 3559: Test Loss: 0.7453\n",
            "Sample 3560: Test Loss: 1.0155\n",
            "Sample 3561: Test Loss: 0.0026\n",
            "Sample 3562: Test Loss: 0.0040\n",
            "Sample 3563: Test Loss: 0.0001\n",
            "Sample 3564: Test Loss: 0.3399\n",
            "Sample 3565: Test Loss: 0.3441\n",
            "Sample 3566: Test Loss: 0.0905\n",
            "Sample 3567: Test Loss: 0.2044\n",
            "Sample 3568: Test Loss: 0.2459\n",
            "Sample 3569: Test Loss: 0.2179\n",
            "Sample 3570: Test Loss: 0.1302\n",
            "Sample 3571: Test Loss: 1.0524\n",
            "Sample 3572: Test Loss: 0.4367\n",
            "Sample 3573: Test Loss: 5.4464\n",
            "Sample 3574: Test Loss: 0.2699\n",
            "Sample 3575: Test Loss: 1.1213\n",
            "Sample 3576: Test Loss: 0.5003\n",
            "Sample 3577: Test Loss: 1.0266\n",
            "Sample 3578: Test Loss: 0.2750\n",
            "Sample 3579: Test Loss: 0.7036\n",
            "Sample 3580: Test Loss: 0.0505\n",
            "Sample 3581: Test Loss: 1.0524\n",
            "Sample 3582: Test Loss: 0.3399\n",
            "Sample 3583: Test Loss: 0.0018\n",
            "Sample 3584: Test Loss: 0.2759\n",
            "Sample 3585: Test Loss: 0.3399\n",
            "Sample 3586: Test Loss: 0.2832\n",
            "Sample 3587: Test Loss: 0.4625\n",
            "Sample 3588: Test Loss: 0.0045\n",
            "Sample 3589: Test Loss: 2.9652\n",
            "Sample 3590: Test Loss: 0.7036\n",
            "Sample 3591: Test Loss: 0.2112\n",
            "Sample 3592: Test Loss: 0.0008\n",
            "Sample 3593: Test Loss: 1.0688\n",
            "Sample 3594: Test Loss: 0.0576\n",
            "Sample 3595: Test Loss: 0.4841\n",
            "Sample 3596: Test Loss: 0.5858\n",
            "Sample 3597: Test Loss: 1.2863\n",
            "Sample 3598: Test Loss: 0.3421\n",
            "Sample 3599: Test Loss: 0.3399\n",
            "Sample 3600: Test Loss: 0.2340\n",
            "Sample 3601: Test Loss: 0.0626\n",
            "Sample 3602: Test Loss: 0.0642\n",
            "Sample 3603: Test Loss: 0.0825\n",
            "Sample 3604: Test Loss: 1.5542\n",
            "Sample 3605: Test Loss: 0.5000\n",
            "Sample 3606: Test Loss: 0.1397\n",
            "Sample 3607: Test Loss: 0.0066\n",
            "Sample 3608: Test Loss: 0.7453\n",
            "Sample 3609: Test Loss: 0.0622\n",
            "Sample 3610: Test Loss: 0.0364\n",
            "Sample 3611: Test Loss: 1.0530\n",
            "Sample 3612: Test Loss: 0.0838\n",
            "Sample 3613: Test Loss: 0.1170\n",
            "Sample 3614: Test Loss: 0.2245\n",
            "Sample 3615: Test Loss: 1.2144\n",
            "Sample 3616: Test Loss: 0.3949\n",
            "Sample 3617: Test Loss: 0.0133\n",
            "Sample 3618: Test Loss: 0.3450\n",
            "Sample 3619: Test Loss: 0.1892\n",
            "Sample 3620: Test Loss: 2.3678\n",
            "Sample 3621: Test Loss: 1.0530\n",
            "Sample 3622: Test Loss: 0.0915\n",
            "Sample 3623: Test Loss: 0.1252\n",
            "Sample 3624: Test Loss: 0.0794\n",
            "Sample 3625: Test Loss: 0.7453\n",
            "Sample 3626: Test Loss: 0.7246\n",
            "Sample 3627: Test Loss: 1.0524\n",
            "Sample 3628: Test Loss: 0.0284\n",
            "Sample 3629: Test Loss: 1.0524\n",
            "Sample 3630: Test Loss: 0.2773\n",
            "Sample 3631: Test Loss: 0.0630\n",
            "Sample 3632: Test Loss: 0.0026\n",
            "Sample 3633: Test Loss: 0.3949\n",
            "Sample 3634: Test Loss: 0.3399\n",
            "Sample 3635: Test Loss: 0.2773\n",
            "Sample 3636: Test Loss: 0.3441\n",
            "Sample 3637: Test Loss: 0.6092\n",
            "Sample 3638: Test Loss: 0.0630\n",
            "Sample 3639: Test Loss: 0.2044\n",
            "Sample 3640: Test Loss: 0.3402\n",
            "Sample 3641: Test Loss: 0.2941\n",
            "Sample 3642: Test Loss: 1.0227\n",
            "Sample 3643: Test Loss: 0.0630\n",
            "Sample 3644: Test Loss: 0.7661\n",
            "Sample 3645: Test Loss: 0.0026\n",
            "Sample 3646: Test Loss: 1.0530\n",
            "Sample 3647: Test Loss: 0.0073\n",
            "Sample 3648: Test Loss: 0.1273\n",
            "Sample 3649: Test Loss: 1.0530\n",
            "Sample 3650: Test Loss: 1.3832\n",
            "Sample 3651: Test Loss: 0.7036\n",
            "Sample 3652: Test Loss: 0.0018\n",
            "Sample 3653: Test Loss: 2.0747\n",
            "Sample 3654: Test Loss: 0.6139\n",
            "Sample 3655: Test Loss: 0.0391\n",
            "Sample 3656: Test Loss: 0.0234\n",
            "Sample 3657: Test Loss: 0.3873\n",
            "Sample 3658: Test Loss: 0.3399\n",
            "Sample 3659: Test Loss: 0.9840\n",
            "Sample 3660: Test Loss: 0.2032\n",
            "Sample 3661: Test Loss: 0.3399\n",
            "Sample 3662: Test Loss: 0.0212\n",
            "Sample 3663: Test Loss: 0.2036\n",
            "Sample 3664: Test Loss: 0.3441\n",
            "Sample 3665: Test Loss: 0.0168\n",
            "Sample 3666: Test Loss: 0.7453\n",
            "Sample 3667: Test Loss: 0.2034\n",
            "Sample 3668: Test Loss: 0.3870\n",
            "Sample 3669: Test Loss: 0.0960\n",
            "Sample 3670: Test Loss: 0.1248\n",
            "Sample 3671: Test Loss: 0.0024\n",
            "Sample 3672: Test Loss: 0.2639\n",
            "Sample 3673: Test Loss: 0.0026\n",
            "Sample 3674: Test Loss: 0.7203\n",
            "Sample 3675: Test Loss: 0.5496\n",
            "Sample 3676: Test Loss: 0.1008\n",
            "Sample 3677: Test Loss: 1.0099\n",
            "Sample 3678: Test Loss: 0.7256\n",
            "Sample 3679: Test Loss: 1.8192\n",
            "Sample 3680: Test Loss: 0.5134\n",
            "Sample 3681: Test Loss: 0.0034\n",
            "Sample 3682: Test Loss: 0.4607\n",
            "Sample 3683: Test Loss: 0.0211\n",
            "Sample 3684: Test Loss: 0.2832\n",
            "Sample 3685: Test Loss: 0.0026\n",
            "Sample 3686: Test Loss: 0.3441\n",
            "Sample 3687: Test Loss: 0.0001\n",
            "Sample 3688: Test Loss: 4.4107\n",
            "Sample 3689: Test Loss: 0.1225\n",
            "Sample 3690: Test Loss: 0.0018\n",
            "Sample 3691: Test Loss: 0.9782\n",
            "Sample 3692: Test Loss: 0.4795\n",
            "Sample 3693: Test Loss: 1.1362\n",
            "Sample 3694: Test Loss: 0.1237\n",
            "Sample 3695: Test Loss: 0.5196\n",
            "Sample 3696: Test Loss: 0.3399\n",
            "Sample 3697: Test Loss: 2.4541\n",
            "Sample 3698: Test Loss: 0.5089\n",
            "Sample 3699: Test Loss: 0.0554\n",
            "Sample 3700: Test Loss: 0.0923\n",
            "Sample 3701: Test Loss: 1.0530\n",
            "Sample 3702: Test Loss: 1.0524\n",
            "Sample 3703: Test Loss: 0.2034\n",
            "Sample 3704: Test Loss: 0.6981\n",
            "Sample 3705: Test Loss: 0.3624\n",
            "Sample 3706: Test Loss: 0.1250\n",
            "Sample 3707: Test Loss: 0.2644\n",
            "Sample 3708: Test Loss: 0.3399\n",
            "Sample 3709: Test Loss: 0.0026\n",
            "Sample 3710: Test Loss: 0.0030\n",
            "Sample 3711: Test Loss: 0.2540\n",
            "Sample 3712: Test Loss: 0.1508\n",
            "Sample 3713: Test Loss: 0.0008\n",
            "Sample 3714: Test Loss: 6.4659\n",
            "Sample 3715: Test Loss: 1.0155\n",
            "Sample 3716: Test Loss: 0.2036\n",
            "Sample 3717: Test Loss: 0.0018\n",
            "Sample 3718: Test Loss: 0.0300\n",
            "Sample 3719: Test Loss: 0.5871\n",
            "Sample 3720: Test Loss: 1.5932\n",
            "Sample 3721: Test Loss: 1.0524\n",
            "Sample 3722: Test Loss: 0.5587\n",
            "Sample 3723: Test Loss: 0.2337\n",
            "Sample 3724: Test Loss: 0.2044\n",
            "Sample 3725: Test Loss: 0.7130\n",
            "Sample 3726: Test Loss: 0.1761\n",
            "Sample 3727: Test Loss: 2.4044\n",
            "Sample 3728: Test Loss: 1.0227\n",
            "Sample 3729: Test Loss: 0.4032\n",
            "Sample 3730: Test Loss: 0.0271\n",
            "Sample 3731: Test Loss: 0.5858\n",
            "Sample 3732: Test Loss: 1.0668\n",
            "Sample 3733: Test Loss: 0.0441\n",
            "Sample 3734: Test Loss: 1.7566\n",
            "Sample 3735: Test Loss: 0.3054\n",
            "Sample 3736: Test Loss: 0.0915\n",
            "Sample 3737: Test Loss: 0.0234\n",
            "Sample 3738: Test Loss: 0.2044\n",
            "Sample 3739: Test Loss: 24.3541\n",
            "Sample 3740: Test Loss: 0.0026\n",
            "Sample 3741: Test Loss: 0.0197\n",
            "Sample 3742: Test Loss: 0.2044\n",
            "Sample 3743: Test Loss: 0.5858\n",
            "Sample 3744: Test Loss: 0.2600\n",
            "Sample 3745: Test Loss: 0.0630\n",
            "Sample 3746: Test Loss: 0.0034\n",
            "Sample 3747: Test Loss: 1.0524\n",
            "Sample 3748: Test Loss: 0.8542\n",
            "Sample 3749: Test Loss: 0.0318\n",
            "Sample 3750: Test Loss: 0.6636\n",
            "Sample 3751: Test Loss: 0.7036\n",
            "Sample 3752: Test Loss: 0.2771\n",
            "Sample 3753: Test Loss: 0.6304\n",
            "Sample 3754: Test Loss: 0.2989\n",
            "Sample 3755: Test Loss: 0.3254\n",
            "Sample 3756: Test Loss: 0.0391\n",
            "Sample 3757: Test Loss: 0.3399\n",
            "Sample 3758: Test Loss: 1.0530\n",
            "Sample 3759: Test Loss: 0.0212\n",
            "Sample 3760: Test Loss: 0.0915\n",
            "Sample 3761: Test Loss: 0.8156\n",
            "Sample 3762: Test Loss: 0.5841\n",
            "Sample 3763: Test Loss: 1.9009\n",
            "Sample 3764: Test Loss: 1.0155\n",
            "Sample 3765: Test Loss: 0.0042\n",
            "Sample 3766: Test Loss: 1.0530\n",
            "Sample 3767: Test Loss: 1.0524\n",
            "Sample 3768: Test Loss: 0.1337\n",
            "Sample 3769: Test Loss: 0.2032\n",
            "Sample 3770: Test Loss: 0.2032\n",
            "Sample 3771: Test Loss: 0.1246\n",
            "Sample 3772: Test Loss: 0.0626\n",
            "Sample 3773: Test Loss: 0.2219\n",
            "Sample 3774: Test Loss: 1.0524\n",
            "Sample 3775: Test Loss: 0.0295\n",
            "Sample 3776: Test Loss: 0.2044\n",
            "Sample 3777: Test Loss: 0.0212\n",
            "Sample 3778: Test Loss: 0.0181\n",
            "Sample 3779: Test Loss: 0.0838\n",
            "Sample 3780: Test Loss: 0.3418\n",
            "Sample 3781: Test Loss: 0.1711\n",
            "Sample 3782: Test Loss: 0.0070\n",
            "Sample 3783: Test Loss: 0.6019\n",
            "Sample 3784: Test Loss: 0.3399\n",
            "Sample 3785: Test Loss: 0.1361\n",
            "Sample 3786: Test Loss: 0.0415\n",
            "Sample 3787: Test Loss: 1.0155\n",
            "Sample 3788: Test Loss: 0.2044\n",
            "Sample 3789: Test Loss: 0.0015\n",
            "Sample 3790: Test Loss: 0.0228\n",
            "Sample 3791: Test Loss: 0.3399\n",
            "Sample 3792: Test Loss: 0.7486\n",
            "Sample 3793: Test Loss: 0.1559\n",
            "Sample 3794: Test Loss: 0.3584\n",
            "Sample 3795: Test Loss: 0.2711\n",
            "Sample 3796: Test Loss: 0.3399\n",
            "Sample 3797: Test Loss: 0.0216\n",
            "Sample 3798: Test Loss: 0.4864\n",
            "Sample 3799: Test Loss: 0.2182\n",
            "Sample 3800: Test Loss: 0.0006\n",
            "Sample 3801: Test Loss: 0.0038\n",
            "Sample 3802: Test Loss: 0.0630\n",
            "Sample 3803: Test Loss: 0.1170\n",
            "Sample 3804: Test Loss: 0.0838\n",
            "Sample 3805: Test Loss: 0.2032\n",
            "Sample 3806: Test Loss: 0.2034\n",
            "Sample 3807: Test Loss: 1.0524\n",
            "Sample 3808: Test Loss: 0.0247\n",
            "Sample 3809: Test Loss: 0.5972\n",
            "Sample 3810: Test Loss: 1.9114\n",
            "Sample 3811: Test Loss: 0.0234\n",
            "Sample 3812: Test Loss: 0.0026\n",
            "Sample 3813: Test Loss: 0.0363\n",
            "Sample 3814: Test Loss: 0.1275\n",
            "Sample 3815: Test Loss: 1.0530\n",
            "Sample 3816: Test Loss: 0.3598\n",
            "Sample 3817: Test Loss: 0.2044\n",
            "Sample 3818: Test Loss: 0.7036\n",
            "Sample 3819: Test Loss: 0.1467\n",
            "Sample 3820: Test Loss: 0.5003\n",
            "Sample 3821: Test Loss: 0.3099\n",
            "Sample 3822: Test Loss: 1.0524\n",
            "Sample 3823: Test Loss: 0.9834\n",
            "Sample 3824: Test Loss: 0.7453\n",
            "Sample 3825: Test Loss: 0.4571\n",
            "Sample 3826: Test Loss: 0.0730\n",
            "Sample 3827: Test Loss: 0.1982\n",
            "Sample 3828: Test Loss: 0.2044\n",
            "Sample 3829: Test Loss: 0.7036\n",
            "Sample 3830: Test Loss: 0.0303\n",
            "Sample 3831: Test Loss: 0.1417\n",
            "Sample 3832: Test Loss: 0.8951\n",
            "Sample 3833: Test Loss: 1.2095\n",
            "Sample 3834: Test Loss: 0.1944\n",
            "Sample 3835: Test Loss: 0.0026\n",
            "Sample 3836: Test Loss: 0.0815\n",
            "Sample 3837: Test Loss: 0.2835\n",
            "Sample 3838: Test Loss: 0.5797\n",
            "Sample 3839: Test Loss: 0.0026\n",
            "Sample 3840: Test Loss: 0.4368\n",
            "Sample 3841: Test Loss: 0.5000\n",
            "Sample 3842: Test Loss: 1.0524\n",
            "Sample 3843: Test Loss: 0.0081\n",
            "Sample 3844: Test Loss: 0.0838\n",
            "Sample 3845: Test Loss: 0.3949\n",
            "Sample 3846: Test Loss: 0.0026\n",
            "Sample 3847: Test Loss: 14.9144\n",
            "Sample 3848: Test Loss: 0.2759\n",
            "Sample 3849: Test Loss: 0.2034\n",
            "Sample 3850: Test Loss: 0.2941\n",
            "Sample 3851: Test Loss: 0.7036\n",
            "Sample 3852: Test Loss: 1.3099\n",
            "Sample 3853: Test Loss: 0.0052\n",
            "Sample 3854: Test Loss: 0.1250\n",
            "Sample 3855: Test Loss: 0.0306\n",
            "Sample 3856: Test Loss: 0.4607\n",
            "Sample 3857: Test Loss: 0.4032\n",
            "Sample 3858: Test Loss: 0.2639\n",
            "Sample 3859: Test Loss: 1.6084\n",
            "Sample 3860: Test Loss: 0.5858\n",
            "Sample 3861: Test Loss: 0.5291\n",
            "Sample 3862: Test Loss: 0.2034\n",
            "Sample 3863: Test Loss: 0.0006\n",
            "Sample 3864: Test Loss: 0.7740\n",
            "Sample 3865: Test Loss: 0.3568\n",
            "Sample 3866: Test Loss: 0.0145\n",
            "Sample 3867: Test Loss: 0.2639\n",
            "Sample 3868: Test Loss: 3.6894\n",
            "Sample 3869: Test Loss: 1.0320\n",
            "Sample 3870: Test Loss: 0.1559\n",
            "Sample 3871: Test Loss: 0.0514\n",
            "Sample 3872: Test Loss: 0.3450\n",
            "Sample 3873: Test Loss: 0.1246\n",
            "Sample 3874: Test Loss: 0.2602\n",
            "Sample 3875: Test Loss: 0.0035\n",
            "Sample 3876: Test Loss: 8.2130\n",
            "Sample 3877: Test Loss: 0.0208\n",
            "Sample 3878: Test Loss: 0.2044\n",
            "Sample 3879: Test Loss: 2.7417\n",
            "Sample 3880: Test Loss: 1.0530\n",
            "Sample 3881: Test Loss: 1.0524\n",
            "Sample 3882: Test Loss: 0.1648\n",
            "Sample 3883: Test Loss: 0.0110\n",
            "Sample 3884: Test Loss: 6.8333\n",
            "Sample 3885: Test Loss: 1.0524\n",
            "Sample 3886: Test Loss: 0.0026\n",
            "Sample 3887: Test Loss: 0.1355\n",
            "Sample 3888: Test Loss: 0.1170\n",
            "Sample 3889: Test Loss: 0.1250\n",
            "Sample 3890: Test Loss: 0.0005\n",
            "Sample 3891: Test Loss: 1.0266\n",
            "Sample 3892: Test Loss: 0.0625\n",
            "Sample 3893: Test Loss: 0.2935\n",
            "Sample 3894: Test Loss: 0.0534\n",
            "Sample 3895: Test Loss: 1.0530\n",
            "Sample 3896: Test Loss: 0.1337\n",
            "Sample 3897: Test Loss: 0.4799\n",
            "Sample 3898: Test Loss: 0.2379\n",
            "Sample 3899: Test Loss: 0.2044\n",
            "Sample 3900: Test Loss: 0.0026\n",
            "Sample 3901: Test Loss: 0.0026\n",
            "Sample 3902: Test Loss: 0.4666\n",
            "Sample 3903: Test Loss: 0.7036\n",
            "Sample 3904: Test Loss: 1.0524\n",
            "Sample 3905: Test Loss: 0.3399\n",
            "Sample 3906: Test Loss: 0.0016\n",
            "Sample 3907: Test Loss: 0.6605\n",
            "Sample 3908: Test Loss: 0.5003\n",
            "Sample 3909: Test Loss: 1.0530\n",
            "Sample 3910: Test Loss: 1.0524\n",
            "Sample 3911: Test Loss: 0.7702\n",
            "Sample 3912: Test Loss: 0.0002\n",
            "Sample 3913: Test Loss: 0.0611\n",
            "Sample 3914: Test Loss: 0.7737\n",
            "Sample 3915: Test Loss: 1.0070\n",
            "Sample 3916: Test Loss: 0.0319\n",
            "Sample 3917: Test Loss: 0.8951\n",
            "Sample 3918: Test Loss: 0.3137\n",
            "Sample 3919: Test Loss: 0.0145\n",
            "Sample 3920: Test Loss: 0.1559\n",
            "Sample 3921: Test Loss: 0.8209\n",
            "Sample 3922: Test Loss: 0.1170\n",
            "Sample 3923: Test Loss: 0.7036\n",
            "Sample 3924: Test Loss: 0.4611\n",
            "Sample 3925: Test Loss: 1.0524\n",
            "Sample 3926: Test Loss: 0.0777\n",
            "Sample 3927: Test Loss: 0.0466\n",
            "Sample 3928: Test Loss: 0.1924\n",
            "Sample 3929: Test Loss: 0.2759\n",
            "Sample 3930: Test Loss: 0.1136\n",
            "Sample 3931: Test Loss: 1.0524\n",
            "Sample 3932: Test Loss: 0.2588\n",
            "Sample 3933: Test Loss: 0.7036\n",
            "Sample 3934: Test Loss: 0.5226\n",
            "Sample 3935: Test Loss: 0.7036\n",
            "Sample 3936: Test Loss: 0.1248\n",
            "Sample 3937: Test Loss: 0.2962\n",
            "Sample 3938: Test Loss: 0.2034\n",
            "Sample 3939: Test Loss: 0.1246\n",
            "Sample 3940: Test Loss: 0.5972\n",
            "Sample 3941: Test Loss: 0.1559\n",
            "Sample 3942: Test Loss: 0.1248\n",
            "Sample 3943: Test Loss: 0.0460\n",
            "Sample 3944: Test Loss: 0.0062\n",
            "Sample 3945: Test Loss: 0.7036\n",
            "Sample 3946: Test Loss: 1.0524\n",
            "Sample 3947: Test Loss: 0.4623\n",
            "Sample 3948: Test Loss: 0.2759\n",
            "Sample 3949: Test Loss: 0.2032\n",
            "Sample 3950: Test Loss: 0.3166\n",
            "Sample 3951: Test Loss: 0.3399\n",
            "Sample 3952: Test Loss: 1.0524\n",
            "Sample 3953: Test Loss: 0.0466\n",
            "Sample 3954: Test Loss: 0.9762\n",
            "Sample 3955: Test Loss: 0.3648\n",
            "Sample 3956: Test Loss: 0.4761\n",
            "Sample 3957: Test Loss: 0.1091\n",
            "Sample 3958: Test Loss: 0.3598\n",
            "Sample 3959: Test Loss: 0.1354\n",
            "Sample 3960: Test Loss: 0.0192\n",
            "Sample 3961: Test Loss: 1.0524\n",
            "Sample 3962: Test Loss: 0.4024\n",
            "Sample 3963: Test Loss: 1.0530\n",
            "Sample 3964: Test Loss: 0.2639\n",
            "Sample 3965: Test Loss: 2.5917\n",
            "Sample 3966: Test Loss: 0.0205\n",
            "Sample 3967: Test Loss: 0.3425\n",
            "Sample 3968: Test Loss: 1.4853\n",
            "Sample 3969: Test Loss: 0.3399\n",
            "Sample 3970: Test Loss: 1.0524\n",
            "Sample 3971: Test Loss: 0.0108\n",
            "Sample 3972: Test Loss: 0.2339\n",
            "Sample 3973: Test Loss: 0.2347\n",
            "Sample 3974: Test Loss: 0.6990\n",
            "Sample 3975: Test Loss: 0.0906\n",
            "Sample 3976: Test Loss: 0.7702\n",
            "Sample 3977: Test Loss: 0.0640\n",
            "Sample 3978: Test Loss: 0.1039\n",
            "Sample 3979: Test Loss: 0.0819\n",
            "Sample 3980: Test Loss: 0.4588\n",
            "Sample 3981: Test Loss: 0.3260\n",
            "Sample 3982: Test Loss: 0.4978\n",
            "Sample 3983: Test Loss: 0.5196\n",
            "Sample 3984: Test Loss: 1.6430\n",
            "Sample 3985: Test Loss: 0.9024\n",
            "Sample 3986: Test Loss: 0.5858\n",
            "Sample 3987: Test Loss: 0.1039\n",
            "Sample 3988: Test Loss: 0.0205\n",
            "Sample 3989: Test Loss: 0.2451\n",
            "Sample 3990: Test Loss: 0.0005\n",
            "Sample 3991: Test Loss: 0.1559\n",
            "Sample 3992: Test Loss: 0.0026\n",
            "Sample 3993: Test Loss: 0.0019\n",
            "Sample 3994: Test Loss: 0.2941\n",
            "Sample 3995: Test Loss: 0.5821\n",
            "Sample 3996: Test Loss: 0.5972\n",
            "Sample 3997: Test Loss: 0.1559\n",
            "Sample 3998: Test Loss: 1.1893\n",
            "Sample 3999: Test Loss: 0.0026\n",
            "Sample 4000: Test Loss: 0.3399\n",
            "\n",
            "Average Test Loss: 0.5574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aktiLip_uPP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bds-streamlit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a8a6e372d6946e8a16b5960b6b5bbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_871bd571f88d43d2a7b6b5e45e0a6c46",
              "IPY_MODEL_137bfb6bf42140bdb7c594c4520ad3dd",
              "IPY_MODEL_29523d1116e34f378f954933b068771d"
            ],
            "layout": "IPY_MODEL_4f23741247c946bbb23b6ce0a3da6a1a"
          }
        },
        "871bd571f88d43d2a7b6b5e45e0a6c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e320ff06c3de4833a92246d4eed758a7",
            "placeholder": "​",
            "style": "IPY_MODEL_f4e5e3df39b64046837bb22e0e7dbc2b",
            "value": "Epochs: 100%"
          }
        },
        "137bfb6bf42140bdb7c594c4520ad3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b4dc6b0f3b40d0a74ff23253991fa4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f5080e77ffd4806a655a9ceaa4b718a",
            "value": 3
          }
        },
        "29523d1116e34f378f954933b068771d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569fa31e08954f00811d2d47a8e62230",
            "placeholder": "​",
            "style": "IPY_MODEL_734a43fea25b43a1a9b1589932d5857a",
            "value": " 3/3 [01:43&lt;00:00, 34.49s/it]"
          }
        },
        "4f23741247c946bbb23b6ce0a3da6a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e320ff06c3de4833a92246d4eed758a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e5e3df39b64046837bb22e0e7dbc2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18b4dc6b0f3b40d0a74ff23253991fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5080e77ffd4806a655a9ceaa4b718a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "569fa31e08954f00811d2d47a8e62230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734a43fea25b43a1a9b1589932d5857a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b6a43a52eb248848d20929e868eee1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bed8a0513ae543869c7cafa7998381fd",
              "IPY_MODEL_1613e52ec3324d8f9967b37656e8e451",
              "IPY_MODEL_52d6ebbcb0e24767bf16c2ebffdd2938"
            ],
            "layout": "IPY_MODEL_0de17172e400486ba64ae454ed94b372"
          }
        },
        "bed8a0513ae543869c7cafa7998381fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11bee05cd71649068861db2111821960",
            "placeholder": "​",
            "style": "IPY_MODEL_5f4011a59eee428eb2e64bb550f10400",
            "value": "Epochs: 100%"
          }
        },
        "1613e52ec3324d8f9967b37656e8e451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69906c2f595543d383fb2b281470a4b9",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6b6cb388b0b4f7fbf46fb71a6435d35",
            "value": 3
          }
        },
        "52d6ebbcb0e24767bf16c2ebffdd2938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b96c0ac20e2447b5a00d2e4d2eaffbb4",
            "placeholder": "​",
            "style": "IPY_MODEL_7bb7532926424400b24511a151284b66",
            "value": " 3/3 [01:12&lt;00:00, 24.18s/it]"
          }
        },
        "0de17172e400486ba64ae454ed94b372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11bee05cd71649068861db2111821960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4011a59eee428eb2e64bb550f10400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69906c2f595543d383fb2b281470a4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b6cb388b0b4f7fbf46fb71a6435d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b96c0ac20e2447b5a00d2e4d2eaffbb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb7532926424400b24511a151284b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f58c171f2b74c7abe6ec6f5fc26bbaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec17beb0135d4c58a790bda28af0bdef",
              "IPY_MODEL_39127a2bc1294c9b8e5c2226a5d291f5",
              "IPY_MODEL_651f8a5f97824cbb92233c3cb46202a0"
            ],
            "layout": "IPY_MODEL_c99e36cffcfc4e228f7f54852f53d370"
          }
        },
        "ec17beb0135d4c58a790bda28af0bdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1981c0b578364c629073b9e80764918f",
            "placeholder": "​",
            "style": "IPY_MODEL_30e9d82498944be6b0461e1b9ff21fee",
            "value": "Epochs: 100%"
          }
        },
        "39127a2bc1294c9b8e5c2226a5d291f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948d0eff5d414561a0f4e17dcd24cbae",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8149a6229d504a8dbb45ff7139f4ed3f",
            "value": 3
          }
        },
        "651f8a5f97824cbb92233c3cb46202a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78cd6a929a6a4dffbce223eeb311d950",
            "placeholder": "​",
            "style": "IPY_MODEL_092c0d7ec74544d7a3f02931c2f5493a",
            "value": " 3/3 [01:12&lt;00:00, 24.24s/it]"
          }
        },
        "c99e36cffcfc4e228f7f54852f53d370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1981c0b578364c629073b9e80764918f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e9d82498944be6b0461e1b9ff21fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "948d0eff5d414561a0f4e17dcd24cbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8149a6229d504a8dbb45ff7139f4ed3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78cd6a929a6a4dffbce223eeb311d950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "092c0d7ec74544d7a3f02931c2f5493a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72112380f98e468696ef7235579c81b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aab43c42137f40cdacae65ae031e31fe",
              "IPY_MODEL_c5def1dc6da94005a217cc6e99721358",
              "IPY_MODEL_36035bd01fe54a02b4de199e19520985"
            ],
            "layout": "IPY_MODEL_b9e226d409b04c04ac274557d4fb410b"
          }
        },
        "aab43c42137f40cdacae65ae031e31fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf952b26701443a6a0b7f33cc9c70ae1",
            "placeholder": "​",
            "style": "IPY_MODEL_2fb30e705e494c8ba5fabdffaa05c6aa",
            "value": "Epochs: 100%"
          }
        },
        "c5def1dc6da94005a217cc6e99721358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49ee4521203a4eadb8907b6b97182198",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a39981ace4b4bb68f3eb5b06cfd48f1",
            "value": 3
          }
        },
        "36035bd01fe54a02b4de199e19520985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7354902be29549c3b3d404e8ec0b6039",
            "placeholder": "​",
            "style": "IPY_MODEL_c2351e96a8b345e8bd7c00ec9a6c78a0",
            "value": " 3/3 [01:12&lt;00:00, 24.22s/it]"
          }
        },
        "b9e226d409b04c04ac274557d4fb410b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf952b26701443a6a0b7f33cc9c70ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb30e705e494c8ba5fabdffaa05c6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49ee4521203a4eadb8907b6b97182198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a39981ace4b4bb68f3eb5b06cfd48f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7354902be29549c3b3d404e8ec0b6039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2351e96a8b345e8bd7c00ec9a6c78a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81924f3010e5497f8a9ec9c4f1c0e40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfe441742f53496bb7cfab8e4daee78b",
              "IPY_MODEL_79e1566b97bd4052a6f031a7ea8e9022",
              "IPY_MODEL_238cb37d23444dcab5985b5223f929e3"
            ],
            "layout": "IPY_MODEL_ff99a18a923946b0b1dfaed33c310dc2"
          }
        },
        "bfe441742f53496bb7cfab8e4daee78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b8bcbb15c14137b9998ffbb8f61a4f",
            "placeholder": "​",
            "style": "IPY_MODEL_cf8f8e94bac2460e94d1a5ef5cec3f6f",
            "value": "Epochs: 100%"
          }
        },
        "79e1566b97bd4052a6f031a7ea8e9022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f73f589463e4c9bba39ba2588e3b6df",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f1976a0751545baadfcde92d7f0f3f7",
            "value": 3
          }
        },
        "238cb37d23444dcab5985b5223f929e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7f849e237d475bbc95eb51a8b69f10",
            "placeholder": "​",
            "style": "IPY_MODEL_5a8aca56d02c42a6883b3c1e5762564f",
            "value": " 3/3 [01:13&lt;00:00, 24.42s/it]"
          }
        },
        "ff99a18a923946b0b1dfaed33c310dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b8bcbb15c14137b9998ffbb8f61a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8f8e94bac2460e94d1a5ef5cec3f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f73f589463e4c9bba39ba2588e3b6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f1976a0751545baadfcde92d7f0f3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f7f849e237d475bbc95eb51a8b69f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a8aca56d02c42a6883b3c1e5762564f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ed153701408472baa87ed1d1bafff8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de12b941d23841a7840d020bbe20e089",
              "IPY_MODEL_37ec6e1e99194356b9d310de9824a6d5",
              "IPY_MODEL_ff15079743b5498b9a88dece8fec0912"
            ],
            "layout": "IPY_MODEL_bf650b2ffd804aa88dd47285cb36f6ee"
          }
        },
        "de12b941d23841a7840d020bbe20e089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eb8a4f227d1464a9a23174d7792a88a",
            "placeholder": "​",
            "style": "IPY_MODEL_4b9effe01d64464bad6e771f6d8249f8",
            "value": "Epochs: 100%"
          }
        },
        "37ec6e1e99194356b9d310de9824a6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab9f784d802e43acaf31027b03dca824",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_006e3c145aa24c88aeed60b0a476ed2a",
            "value": 3
          }
        },
        "ff15079743b5498b9a88dece8fec0912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8cd96f7d2e49ad8cfbc63e01c6c6a2",
            "placeholder": "​",
            "style": "IPY_MODEL_b16867b1e68b4d6f9f5af725d5bcc76b",
            "value": " 3/3 [01:12&lt;00:00, 24.15s/it]"
          }
        },
        "bf650b2ffd804aa88dd47285cb36f6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb8a4f227d1464a9a23174d7792a88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9effe01d64464bad6e771f6d8249f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab9f784d802e43acaf31027b03dca824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "006e3c145aa24c88aeed60b0a476ed2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa8cd96f7d2e49ad8cfbc63e01c6c6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b16867b1e68b4d6f9f5af725d5bcc76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b9877aecdd748e5a5b9899bb1dbed2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63ed299e38df4d08a84e182d353730b8",
              "IPY_MODEL_d1443db93e0f4e5aaa5c6fd1a1a0fc42",
              "IPY_MODEL_4e27e026b1204d8f8e82ad5bfb6a7ace"
            ],
            "layout": "IPY_MODEL_01d4b4a66b814998942f15039a65fce0"
          }
        },
        "63ed299e38df4d08a84e182d353730b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c32080c66e474b84c995ace371731a",
            "placeholder": "​",
            "style": "IPY_MODEL_03dacb15e4144d3fbef377739fdbe160",
            "value": "Epochs: 100%"
          }
        },
        "d1443db93e0f4e5aaa5c6fd1a1a0fc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e14b4d98feaf480ab549677dfd99661b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fd6b49303d04afca4cf2617680b3262",
            "value": 3
          }
        },
        "4e27e026b1204d8f8e82ad5bfb6a7ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f4e7ae3143a4fb89ee9563a33c5cbd0",
            "placeholder": "​",
            "style": "IPY_MODEL_f38cceb21b684b9fa213093d68ecb6ee",
            "value": " 3/3 [01:12&lt;00:00, 24.17s/it]"
          }
        },
        "01d4b4a66b814998942f15039a65fce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c32080c66e474b84c995ace371731a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03dacb15e4144d3fbef377739fdbe160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e14b4d98feaf480ab549677dfd99661b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fd6b49303d04afca4cf2617680b3262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f4e7ae3143a4fb89ee9563a33c5cbd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38cceb21b684b9fa213093d68ecb6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}